{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lilaiguernelala/Programmation-GPU/blob/main/CorrigeTD1ProgGPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjov-qc1v32O",
        "outputId": "805e5c2f-3994-4323-a90f-0774e44a28d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNTbL4fywF2i",
        "outputId": "130f3af5-2a44-41b2-bad9-f90444629228"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-2krm4v3w\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-2krm4v3w\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 781ff5b76ba6c4c2d80dcbbec9983e147613cc71\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.1.0-py3-none-any.whl size=8011 sha256=e2b2acbb79d726227ace2ffdeb18b901e4debb9cf9419b13a35a389a655ee4ac\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-iosnbexc/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.1.0\n",
            "Source files will be saved in \"/tmp/tmp_a71w10v\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3"
      ],
      "metadata": {
        "id": "vdZBR7NSxMLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void linear_regression(float *inputs, float *targets, int size, float *weights, float *bias, float learning_rate, int epochs) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float cost;\n",
        "    for (int epoch = 0; epoch < epochs; ++epoch) {\n",
        "        float predicted = inputs[idx] * weights[0] + bias[0];\n",
        "        float loss = predicted - targets[idx];\n",
        "        float d_weights = inputs[idx] * loss / (2 * size);\n",
        "        float d_bias = loss / (2 * size);\n",
        "        weights[0] -= learning_rate * d_weights;\n",
        "        bias[0] -= learning_rate * d_bias;\n",
        "        cost = sqrtf(powf(loss, 2) / (2 * size));\n",
        "        if (idx == 0) {\n",
        "            printf(\"Iteration: %d | Cost/Loss: %f | Weight: %f | Bias: %f\\n\", epoch + 1, cost, weights[0], bias[0]);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    int m = 300; // Number of training data points\n",
        "    int n = 50; // Number of testing data points\n",
        "    float learning_rate = 0.0001;\n",
        "    int epochs = 200000;\n",
        "    float a = 0.5; // y = ax + b\n",
        "    float b = 2.0;\n",
        "    int size = m;\n",
        "    int dataSize = size * sizeof(float);\n",
        "    float *h_inputs, *h_targets, *h_weights, *h_bias;\n",
        "    float *d_inputs, *d_targets, *d_weights, *d_bias;\n",
        "\n",
        "    // Allocate host memory\n",
        "    h_inputs = (float*)malloc(dataSize);\n",
        "    h_targets = (float*)malloc(dataSize);\n",
        "    h_weights = (float*)malloc(sizeof(float));\n",
        "    h_bias = (float*)malloc(sizeof(float));\n",
        "\n",
        "    // Generate data\n",
        "    for (int i = 0; i < m; ++i) {\n",
        "        h_inputs[i] = i + 1;\n",
        "        h_targets[i] = (i + 1) * a + b;\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaMalloc((void**)&d_inputs, dataSize);\n",
        "    cudaMalloc((void**)&d_targets, dataSize);\n",
        "    cudaMalloc((void**)&d_weights, sizeof(float));\n",
        "    cudaMalloc((void**)&d_bias, sizeof(float));\n",
        "\n",
        "    // Copy data to device memory\n",
        "    cudaMemcpy(d_inputs, h_inputs, dataSize, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_targets, h_targets, dataSize, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Initialize weights and bias\n",
        "    h_weights[0] = 0;\n",
        "    h_bias[0] = 0;\n",
        "\n",
        "    // Copy initial weights and bias to device memory\n",
        "    cudaMemcpy(d_weights, h_weights, sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_bias, h_bias, sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch kernel\n",
        "    linear_regression<<<1, m>>>(d_inputs, d_targets, size, d_weights, d_bias, learning_rate, epochs);\n",
        "\n",
        "    // Copy back weights and bias\n",
        "    cudaMemcpy(h_weights, d_weights, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(h_bias, d_bias, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Final Weights: %f\\n\", h_weights[0]);\n",
        "    printf(\"Final Bias: %f\\n\", h_bias[0]);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_inputs);\n",
        "    cudaFree(d_targets);\n",
        "    cudaFree(d_weights);\n",
        "    cudaFree(d_bias);\n",
        "\n",
        "    // Free host memory\n",
        "    free(h_inputs);\n",
        "    free(h_targets);\n",
        "    free(h_weights);\n",
        "    free(h_bias);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "KssMuanhxSgC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be174c7f-efcd-41f6-c8c0-44c2a9cd6b75"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "Iteration: 45150 | Cost/Loss: 0.077659 | Weight: 0.528270 | Bias: 0.069489\n",
            "Iteration: 45151 | Cost/Loss: 0.077659 | Weight: 0.528270 | Bias: 0.069489\n",
            "Iteration: 45152 | Cost/Loss: 0.077659 | Weight: 0.528271 | Bias: 0.069490\n",
            "Iteration: 45153 | Cost/Loss: 0.077659 | Weight: 0.528271 | Bias: 0.069490\n",
            "Iteration: 45154 | Cost/Loss: 0.077659 | Weight: 0.528271 | Bias: 0.069490\n",
            "Iteration: 45155 | Cost/Loss: 0.077659 | Weight: 0.528272 | Bias: 0.069491\n",
            "Iteration: 45156 | Cost/Loss: 0.077659 | Weight: 0.528272 | Bias: 0.069491\n",
            "Iteration: 45157 | Cost/Loss: 0.077659 | Weight: 0.528272 | Bias: 0.069491\n",
            "Iteration: 45158 | Cost/Loss: 0.077658 | Weight: 0.528273 | Bias: 0.069492\n",
            "Iteration: 45159 | Cost/Loss: 0.077658 | Weight: 0.528273 | Bias: 0.069492\n",
            "Iteration: 45160 | Cost/Loss: 0.077658 | Weight: 0.528273 | Bias: 0.069492\n",
            "Iteration: 45161 | Cost/Loss: 0.077658 | Weight: 0.528273 | Bias: 0.069493\n",
            "Iteration: 45162 | Cost/Loss: 0.077658 | Weight: 0.528274 | Bias: 0.069493\n",
            "Iteration: 45163 | Cost/Loss: 0.077658 | Weight: 0.528274 | Bias: 0.069493\n",
            "Iteration: 45164 | Cost/Loss: 0.077658 | Weight: 0.528274 | Bias: 0.069493\n",
            "Iteration: 45165 | Cost/Loss: 0.077658 | Weight: 0.528275 | Bias: 0.069494\n",
            "Iteration: 45166 | Cost/Loss: 0.077658 | Weight: 0.528275 | Bias: 0.069494\n",
            "Iteration: 45167 | Cost/Loss: 0.077658 | Weight: 0.528275 | Bias: 0.069494\n",
            "Iteration: 45168 | Cost/Loss: 0.077658 | Weight: 0.528275 | Bias: 0.069495\n",
            "Iteration: 45169 | Cost/Loss: 0.077658 | Weight: 0.528276 | Bias: 0.069495\n",
            "Iteration: 45170 | Cost/Loss: 0.077658 | Weight: 0.528276 | Bias: 0.069495\n",
            "Iteration: 45171 | Cost/Loss: 0.077658 | Weight: 0.528276 | Bias: 0.069496\n",
            "Iteration: 45172 | Cost/Loss: 0.077658 | Weight: 0.528277 | Bias: 0.069496\n",
            "Iteration: 45173 | Cost/Loss: 0.077658 | Weight: 0.528277 | Bias: 0.069496\n",
            "Iteration: 45174 | Cost/Loss: 0.077658 | Weight: 0.528277 | Bias: 0.069497\n",
            "Iteration: 45175 | Cost/Loss: 0.077658 | Weight: 0.528278 | Bias: 0.069497\n",
            "Iteration: 45176 | Cost/Loss: 0.077658 | Weight: 0.528278 | Bias: 0.069497\n",
            "Iteration: 45177 | Cost/Loss: 0.077658 | Weight: 0.528278 | Bias: 0.069498\n",
            "Iteration: 45178 | Cost/Loss: 0.077658 | Weight: 0.528278 | Bias: 0.069498\n",
            "Iteration: 45179 | Cost/Loss: 0.077658 | Weight: 0.528279 | Bias: 0.069498\n",
            "Iteration: 45180 | Cost/Loss: 0.077658 | Weight: 0.528279 | Bias: 0.069499\n",
            "Iteration: 45181 | Cost/Loss: 0.077658 | Weight: 0.528279 | Bias: 0.069499\n",
            "Iteration: 45182 | Cost/Loss: 0.077658 | Weight: 0.528280 | Bias: 0.069499\n",
            "Iteration: 45183 | Cost/Loss: 0.077658 | Weight: 0.528280 | Bias: 0.069500\n",
            "Iteration: 45184 | Cost/Loss: 0.077658 | Weight: 0.528280 | Bias: 0.069500\n",
            "Iteration: 45185 | Cost/Loss: 0.077658 | Weight: 0.528281 | Bias: 0.069500\n",
            "Iteration: 45186 | Cost/Loss: 0.077658 | Weight: 0.528281 | Bias: 0.069501\n",
            "Iteration: 45187 | Cost/Loss: 0.077658 | Weight: 0.528281 | Bias: 0.069501\n",
            "Iteration: 45188 | Cost/Loss: 0.077658 | Weight: 0.528281 | Bias: 0.069501\n",
            "Iteration: 45189 | Cost/Loss: 0.077658 | Weight: 0.528282 | Bias: 0.069501\n",
            "Iteration: 45190 | Cost/Loss: 0.077658 | Weight: 0.528282 | Bias: 0.069502\n",
            "Iteration: 45191 | Cost/Loss: 0.077658 | Weight: 0.528282 | Bias: 0.069502\n",
            "Iteration: 45192 | Cost/Loss: 0.077658 | Weight: 0.528283 | Bias: 0.069502\n",
            "Iteration: 45193 | Cost/Loss: 0.077658 | Weight: 0.528283 | Bias: 0.069503\n",
            "Iteration: 45194 | Cost/Loss: 0.077658 | Weight: 0.528283 | Bias: 0.069503\n",
            "Iteration: 45195 | Cost/Loss: 0.077658 | Weight: 0.528284 | Bias: 0.069503\n",
            "Iteration: 45196 | Cost/Loss: 0.077658 | Weight: 0.528284 | Bias: 0.069504\n",
            "Iteration: 45197 | Cost/Loss: 0.077657 | Weight: 0.528284 | Bias: 0.069504\n",
            "Iteration: 45198 | Cost/Loss: 0.077657 | Weight: 0.528284 | Bias: 0.069504\n",
            "Iteration: 45199 | Cost/Loss: 0.077657 | Weight: 0.528285 | Bias: 0.069505\n",
            "Iteration: 45200 | Cost/Loss: 0.077657 | Weight: 0.528285 | Bias: 0.069505\n",
            "Iteration: 45201 | Cost/Loss: 0.077657 | Weight: 0.528285 | Bias: 0.069505\n",
            "Iteration: 45202 | Cost/Loss: 0.077657 | Weight: 0.528286 | Bias: 0.069506\n",
            "Iteration: 45203 | Cost/Loss: 0.077657 | Weight: 0.528286 | Bias: 0.069506\n",
            "Iteration: 45204 | Cost/Loss: 0.077657 | Weight: 0.528286 | Bias: 0.069506\n",
            "Iteration: 45205 | Cost/Loss: 0.077657 | Weight: 0.528287 | Bias: 0.069507\n",
            "Iteration: 45206 | Cost/Loss: 0.077657 | Weight: 0.528287 | Bias: 0.069507\n",
            "Iteration: 45207 | Cost/Loss: 0.077657 | Weight: 0.528287 | Bias: 0.069507\n",
            "Iteration: 45208 | Cost/Loss: 0.077657 | Weight: 0.528287 | Bias: 0.069508\n",
            "Iteration: 45209 | Cost/Loss: 0.077657 | Weight: 0.528288 | Bias: 0.069508\n",
            "Iteration: 45210 | Cost/Loss: 0.077657 | Weight: 0.528288 | Bias: 0.069508\n",
            "Iteration: 45211 | Cost/Loss: 0.077657 | Weight: 0.528288 | Bias: 0.069509\n",
            "Iteration: 45212 | Cost/Loss: 0.077657 | Weight: 0.528289 | Bias: 0.069509\n",
            "Iteration: 45213 | Cost/Loss: 0.077657 | Weight: 0.528289 | Bias: 0.069509\n",
            "Iteration: 45214 | Cost/Loss: 0.077657 | Weight: 0.528289 | Bias: 0.069509\n",
            "Iteration: 45215 | Cost/Loss: 0.077657 | Weight: 0.528289 | Bias: 0.069510\n",
            "Iteration: 45216 | Cost/Loss: 0.077657 | Weight: 0.528290 | Bias: 0.069510\n",
            "Iteration: 45217 | Cost/Loss: 0.077657 | Weight: 0.528290 | Bias: 0.069510\n",
            "Iteration: 45218 | Cost/Loss: 0.077657 | Weight: 0.528290 | Bias: 0.069511\n",
            "Iteration: 45219 | Cost/Loss: 0.077657 | Weight: 0.528291 | Bias: 0.069511\n",
            "Iteration: 45220 | Cost/Loss: 0.077657 | Weight: 0.528291 | Bias: 0.069511\n",
            "Iteration: 45221 | Cost/Loss: 0.077657 | Weight: 0.528291 | Bias: 0.069512\n",
            "Iteration: 45222 | Cost/Loss: 0.077657 | Weight: 0.528292 | Bias: 0.069512\n",
            "Iteration: 45223 | Cost/Loss: 0.077657 | Weight: 0.528292 | Bias: 0.069512\n",
            "Iteration: 45224 | Cost/Loss: 0.077657 | Weight: 0.528292 | Bias: 0.069513\n",
            "Iteration: 45225 | Cost/Loss: 0.077657 | Weight: 0.528292 | Bias: 0.069513\n",
            "Iteration: 45226 | Cost/Loss: 0.077657 | Weight: 0.528293 | Bias: 0.069513\n",
            "Iteration: 45227 | Cost/Loss: 0.077657 | Weight: 0.528293 | Bias: 0.069514\n",
            "Iteration: 45228 | Cost/Loss: 0.077657 | Weight: 0.528293 | Bias: 0.069514\n",
            "Iteration: 45229 | Cost/Loss: 0.077657 | Weight: 0.528294 | Bias: 0.069514\n",
            "Iteration: 45230 | Cost/Loss: 0.077657 | Weight: 0.528294 | Bias: 0.069515\n",
            "Iteration: 45231 | Cost/Loss: 0.077657 | Weight: 0.528294 | Bias: 0.069515\n",
            "Iteration: 45232 | Cost/Loss: 0.077657 | Weight: 0.528295 | Bias: 0.069515\n",
            "Iteration: 45233 | Cost/Loss: 0.077657 | Weight: 0.528295 | Bias: 0.069516\n",
            "Iteration: 45234 | Cost/Loss: 0.077657 | Weight: 0.528295 | Bias: 0.069516\n",
            "Iteration: 45235 | Cost/Loss: 0.077657 | Weight: 0.528295 | Bias: 0.069516\n",
            "Iteration: 45236 | Cost/Loss: 0.077657 | Weight: 0.528296 | Bias: 0.069517\n",
            "Iteration: 45237 | Cost/Loss: 0.077656 | Weight: 0.528296 | Bias: 0.069517\n",
            "Iteration: 45238 | Cost/Loss: 0.077656 | Weight: 0.528296 | Bias: 0.069517\n",
            "Iteration: 45239 | Cost/Loss: 0.077656 | Weight: 0.528297 | Bias: 0.069517\n",
            "Iteration: 45240 | Cost/Loss: 0.077656 | Weight: 0.528297 | Bias: 0.069518\n",
            "Iteration: 45241 | Cost/Loss: 0.077656 | Weight: 0.528297 | Bias: 0.069518\n",
            "Iteration: 45242 | Cost/Loss: 0.077656 | Weight: 0.528298 | Bias: 0.069518\n",
            "Iteration: 45243 | Cost/Loss: 0.077656 | Weight: 0.528298 | Bias: 0.069519\n",
            "Iteration: 45244 | Cost/Loss: 0.077656 | Weight: 0.528298 | Bias: 0.069519\n",
            "Iteration: 45245 | Cost/Loss: 0.077656 | Weight: 0.528298 | Bias: 0.069519\n",
            "Iteration: 45246 | Cost/Loss: 0.077656 | Weight: 0.528299 | Bias: 0.069520\n",
            "Iteration: 45247 | Cost/Loss: 0.077656 | Weight: 0.528299 | Bias: 0.069520\n",
            "Iteration: 45248 | Cost/Loss: 0.077656 | Weight: 0.528299 | Bias: 0.069520\n",
            "Iteration: 45249 | Cost/Loss: 0.077656 | Weight: 0.528300 | Bias: 0.069521\n",
            "Iteration: 45250 | Cost/Loss: 0.077656 | Weight: 0.528300 | Bias: 0.069521\n",
            "Iteration: 45251 | Cost/Loss: 0.077656 | Weight: 0.528300 | Bias: 0.069521\n",
            "Iteration: 45252 | Cost/Loss: 0.077656 | Weight: 0.528301 | Bias: 0.069522\n",
            "Iteration: 45253 | Cost/Loss: 0.077656 | Weight: 0.528301 | Bias: 0.069522\n",
            "Iteration: 45254 | Cost/Loss: 0.077656 | Weight: 0.528301 | Bias: 0.069522\n",
            "Iteration: 45255 | Cost/Loss: 0.077656 | Weight: 0.528301 | Bias: 0.069523\n",
            "Iteration: 45256 | Cost/Loss: 0.077656 | Weight: 0.528302 | Bias: 0.069523\n",
            "Iteration: 45257 | Cost/Loss: 0.077656 | Weight: 0.528302 | Bias: 0.069523\n",
            "Iteration: 45258 | Cost/Loss: 0.077656 | Weight: 0.528302 | Bias: 0.069524\n",
            "Iteration: 45259 | Cost/Loss: 0.077656 | Weight: 0.528303 | Bias: 0.069524\n",
            "Iteration: 45260 | Cost/Loss: 0.077656 | Weight: 0.528303 | Bias: 0.069524\n",
            "Iteration: 45261 | Cost/Loss: 0.077656 | Weight: 0.528303 | Bias: 0.069525\n",
            "Iteration: 45262 | Cost/Loss: 0.077656 | Weight: 0.528304 | Bias: 0.069525\n",
            "Iteration: 45263 | Cost/Loss: 0.077656 | Weight: 0.528304 | Bias: 0.069525\n",
            "Iteration: 45264 | Cost/Loss: 0.077656 | Weight: 0.528304 | Bias: 0.069526\n",
            "Iteration: 45265 | Cost/Loss: 0.077656 | Weight: 0.528304 | Bias: 0.069526\n",
            "Iteration: 45266 | Cost/Loss: 0.077656 | Weight: 0.528305 | Bias: 0.069526\n",
            "Iteration: 45267 | Cost/Loss: 0.077656 | Weight: 0.528305 | Bias: 0.069526\n",
            "Iteration: 45268 | Cost/Loss: 0.077656 | Weight: 0.528305 | Bias: 0.069527\n",
            "Iteration: 45269 | Cost/Loss: 0.077656 | Weight: 0.528306 | Bias: 0.069527\n",
            "Iteration: 45270 | Cost/Loss: 0.077656 | Weight: 0.528306 | Bias: 0.069527\n",
            "Iteration: 45271 | Cost/Loss: 0.077656 | Weight: 0.528306 | Bias: 0.069528\n",
            "Iteration: 45272 | Cost/Loss: 0.077656 | Weight: 0.528306 | Bias: 0.069528\n",
            "Iteration: 45273 | Cost/Loss: 0.077656 | Weight: 0.528307 | Bias: 0.069528\n",
            "Iteration: 45274 | Cost/Loss: 0.077656 | Weight: 0.528307 | Bias: 0.069529\n",
            "Iteration: 45275 | Cost/Loss: 0.077656 | Weight: 0.528307 | Bias: 0.069529\n",
            "Iteration: 45276 | Cost/Loss: 0.077656 | Weight: 0.528308 | Bias: 0.069529\n",
            "Iteration: 45277 | Cost/Loss: 0.077655 | Weight: 0.528308 | Bias: 0.069530\n",
            "Iteration: 45278 | Cost/Loss: 0.077655 | Weight: 0.528308 | Bias: 0.069530\n",
            "Iteration: 45279 | Cost/Loss: 0.077655 | Weight: 0.528309 | Bias: 0.069530\n",
            "Iteration: 45280 | Cost/Loss: 0.077655 | Weight: 0.528309 | Bias: 0.069531\n",
            "Iteration: 45281 | Cost/Loss: 0.077655 | Weight: 0.528309 | Bias: 0.069531\n",
            "Iteration: 45282 | Cost/Loss: 0.077655 | Weight: 0.528309 | Bias: 0.069531\n",
            "Iteration: 45283 | Cost/Loss: 0.077655 | Weight: 0.528310 | Bias: 0.069532\n",
            "Iteration: 45284 | Cost/Loss: 0.077655 | Weight: 0.528310 | Bias: 0.069532\n",
            "Iteration: 45285 | Cost/Loss: 0.077655 | Weight: 0.528310 | Bias: 0.069532\n",
            "Iteration: 45286 | Cost/Loss: 0.077655 | Weight: 0.528311 | Bias: 0.069533\n",
            "Iteration: 45287 | Cost/Loss: 0.077655 | Weight: 0.528311 | Bias: 0.069533\n",
            "Iteration: 45288 | Cost/Loss: 0.077655 | Weight: 0.528311 | Bias: 0.069533\n",
            "Iteration: 45289 | Cost/Loss: 0.077655 | Weight: 0.528312 | Bias: 0.069534\n",
            "Iteration: 45290 | Cost/Loss: 0.077655 | Weight: 0.528312 | Bias: 0.069534\n",
            "Iteration: 45291 | Cost/Loss: 0.077655 | Weight: 0.528312 | Bias: 0.069534\n",
            "Iteration: 45292 | Cost/Loss: 0.077655 | Weight: 0.528312 | Bias: 0.069534\n",
            "Iteration: 45293 | Cost/Loss: 0.077655 | Weight: 0.528313 | Bias: 0.069535\n",
            "Iteration: 45294 | Cost/Loss: 0.077655 | Weight: 0.528313 | Bias: 0.069535\n",
            "Iteration: 45295 | Cost/Loss: 0.077655 | Weight: 0.528313 | Bias: 0.069535\n",
            "Iteration: 45296 | Cost/Loss: 0.077655 | Weight: 0.528314 | Bias: 0.069536\n",
            "Iteration: 45297 | Cost/Loss: 0.077655 | Weight: 0.528314 | Bias: 0.069536\n",
            "Iteration: 45298 | Cost/Loss: 0.077655 | Weight: 0.528314 | Bias: 0.069536\n",
            "Iteration: 45299 | Cost/Loss: 0.077655 | Weight: 0.528315 | Bias: 0.069537\n",
            "Iteration: 45300 | Cost/Loss: 0.077655 | Weight: 0.528315 | Bias: 0.069537\n",
            "Iteration: 45301 | Cost/Loss: 0.077655 | Weight: 0.528315 | Bias: 0.069537\n",
            "Iteration: 45302 | Cost/Loss: 0.077655 | Weight: 0.528315 | Bias: 0.069538\n",
            "Iteration: 45303 | Cost/Loss: 0.077655 | Weight: 0.528316 | Bias: 0.069538\n",
            "Iteration: 45304 | Cost/Loss: 0.077655 | Weight: 0.528316 | Bias: 0.069538\n",
            "Iteration: 45305 | Cost/Loss: 0.077655 | Weight: 0.528316 | Bias: 0.069539\n",
            "Iteration: 45306 | Cost/Loss: 0.077655 | Weight: 0.528317 | Bias: 0.069539\n",
            "Iteration: 45307 | Cost/Loss: 0.077655 | Weight: 0.528317 | Bias: 0.069539\n",
            "Iteration: 45308 | Cost/Loss: 0.077655 | Weight: 0.528317 | Bias: 0.069540\n",
            "Iteration: 45309 | Cost/Loss: 0.077655 | Weight: 0.528318 | Bias: 0.069540\n",
            "Iteration: 45310 | Cost/Loss: 0.077655 | Weight: 0.528318 | Bias: 0.069540\n",
            "Iteration: 45311 | Cost/Loss: 0.077655 | Weight: 0.528318 | Bias: 0.069541\n",
            "Iteration: 45312 | Cost/Loss: 0.077655 | Weight: 0.528318 | Bias: 0.069541\n",
            "Iteration: 45313 | Cost/Loss: 0.077655 | Weight: 0.528319 | Bias: 0.069541\n",
            "Iteration: 45314 | Cost/Loss: 0.077655 | Weight: 0.528319 | Bias: 0.069542\n",
            "Iteration: 45315 | Cost/Loss: 0.077655 | Weight: 0.528319 | Bias: 0.069542\n",
            "Iteration: 45316 | Cost/Loss: 0.077654 | Weight: 0.528320 | Bias: 0.069542\n",
            "Iteration: 45317 | Cost/Loss: 0.077654 | Weight: 0.528320 | Bias: 0.069542\n",
            "Iteration: 45318 | Cost/Loss: 0.077654 | Weight: 0.528320 | Bias: 0.069543\n",
            "Iteration: 45319 | Cost/Loss: 0.077654 | Weight: 0.528320 | Bias: 0.069543\n",
            "Iteration: 45320 | Cost/Loss: 0.077654 | Weight: 0.528321 | Bias: 0.069543\n",
            "Iteration: 45321 | Cost/Loss: 0.077654 | Weight: 0.528321 | Bias: 0.069544\n",
            "Iteration: 45322 | Cost/Loss: 0.077654 | Weight: 0.528321 | Bias: 0.069544\n",
            "Iteration: 45323 | Cost/Loss: 0.077654 | Weight: 0.528322 | Bias: 0.069544\n",
            "Iteration: 45324 | Cost/Loss: 0.077654 | Weight: 0.528322 | Bias: 0.069545\n",
            "Iteration: 45325 | Cost/Loss: 0.077654 | Weight: 0.528322 | Bias: 0.069545\n",
            "Iteration: 45326 | Cost/Loss: 0.077654 | Weight: 0.528323 | Bias: 0.069545\n",
            "Iteration: 45327 | Cost/Loss: 0.077654 | Weight: 0.528323 | Bias: 0.069546\n",
            "Iteration: 45328 | Cost/Loss: 0.077654 | Weight: 0.528323 | Bias: 0.069546\n",
            "Iteration: 45329 | Cost/Loss: 0.077654 | Weight: 0.528323 | Bias: 0.069546\n",
            "Iteration: 45330 | Cost/Loss: 0.077654 | Weight: 0.528324 | Bias: 0.069547\n",
            "Iteration: 45331 | Cost/Loss: 0.077654 | Weight: 0.528324 | Bias: 0.069547\n",
            "Iteration: 45332 | Cost/Loss: 0.077654 | Weight: 0.528324 | Bias: 0.069547\n",
            "Iteration: 45333 | Cost/Loss: 0.077654 | Weight: 0.528325 | Bias: 0.069548\n",
            "Iteration: 45334 | Cost/Loss: 0.077654 | Weight: 0.528325 | Bias: 0.069548\n",
            "Iteration: 45335 | Cost/Loss: 0.077654 | Weight: 0.528325 | Bias: 0.069548\n",
            "Iteration: 45336 | Cost/Loss: 0.077654 | Weight: 0.528326 | Bias: 0.069549\n",
            "Iteration: 45337 | Cost/Loss: 0.077654 | Weight: 0.528326 | Bias: 0.069549\n",
            "Iteration: 45338 | Cost/Loss: 0.077654 | Weight: 0.528326 | Bias: 0.069549\n",
            "Iteration: 45339 | Cost/Loss: 0.077654 | Weight: 0.528326 | Bias: 0.069550\n",
            "Iteration: 45340 | Cost/Loss: 0.077654 | Weight: 0.528327 | Bias: 0.069550\n",
            "Iteration: 45341 | Cost/Loss: 0.077654 | Weight: 0.528327 | Bias: 0.069550\n",
            "Iteration: 45342 | Cost/Loss: 0.077654 | Weight: 0.528327 | Bias: 0.069550\n",
            "Iteration: 45343 | Cost/Loss: 0.077654 | Weight: 0.528328 | Bias: 0.069551\n",
            "Iteration: 45344 | Cost/Loss: 0.077654 | Weight: 0.528328 | Bias: 0.069551\n",
            "Iteration: 45345 | Cost/Loss: 0.077654 | Weight: 0.528328 | Bias: 0.069551\n",
            "Iteration: 45346 | Cost/Loss: 0.077654 | Weight: 0.528329 | Bias: 0.069552\n",
            "Iteration: 45347 | Cost/Loss: 0.077654 | Weight: 0.528329 | Bias: 0.069552\n",
            "Iteration: 45348 | Cost/Loss: 0.077654 | Weight: 0.528329 | Bias: 0.069552\n",
            "Iteration: 45349 | Cost/Loss: 0.077654 | Weight: 0.528329 | Bias: 0.069553\n",
            "Iteration: 45350 | Cost/Loss: 0.077654 | Weight: 0.528330 | Bias: 0.069553\n",
            "Iteration: 45351 | Cost/Loss: 0.077654 | Weight: 0.528330 | Bias: 0.069553\n",
            "Iteration: 45352 | Cost/Loss: 0.077654 | Weight: 0.528330 | Bias: 0.069554\n",
            "Iteration: 45353 | Cost/Loss: 0.077654 | Weight: 0.528331 | Bias: 0.069554\n",
            "Iteration: 45354 | Cost/Loss: 0.077654 | Weight: 0.528331 | Bias: 0.069554\n",
            "Iteration: 45355 | Cost/Loss: 0.077654 | Weight: 0.528331 | Bias: 0.069555\n",
            "Iteration: 45356 | Cost/Loss: 0.077653 | Weight: 0.528332 | Bias: 0.069555\n",
            "Iteration: 45357 | Cost/Loss: 0.077653 | Weight: 0.528332 | Bias: 0.069555\n",
            "Iteration: 45358 | Cost/Loss: 0.077653 | Weight: 0.528332 | Bias: 0.069556\n",
            "Iteration: 45359 | Cost/Loss: 0.077653 | Weight: 0.528332 | Bias: 0.069556\n",
            "Iteration: 45360 | Cost/Loss: 0.077653 | Weight: 0.528333 | Bias: 0.069556\n",
            "Iteration: 45361 | Cost/Loss: 0.077653 | Weight: 0.528333 | Bias: 0.069557\n",
            "Iteration: 45362 | Cost/Loss: 0.077653 | Weight: 0.528333 | Bias: 0.069557\n",
            "Iteration: 45363 | Cost/Loss: 0.077653 | Weight: 0.528334 | Bias: 0.069557\n",
            "Iteration: 45364 | Cost/Loss: 0.077653 | Weight: 0.528334 | Bias: 0.069558\n",
            "Iteration: 45365 | Cost/Loss: 0.077653 | Weight: 0.528334 | Bias: 0.069558\n",
            "Iteration: 45366 | Cost/Loss: 0.077653 | Weight: 0.528334 | Bias: 0.069558\n",
            "Iteration: 45367 | Cost/Loss: 0.077653 | Weight: 0.528335 | Bias: 0.069559\n",
            "Iteration: 45368 | Cost/Loss: 0.077653 | Weight: 0.528335 | Bias: 0.069559\n",
            "Iteration: 45369 | Cost/Loss: 0.077653 | Weight: 0.528335 | Bias: 0.069559\n",
            "Iteration: 45370 | Cost/Loss: 0.077653 | Weight: 0.528336 | Bias: 0.069559\n",
            "Iteration: 45371 | Cost/Loss: 0.077653 | Weight: 0.528336 | Bias: 0.069560\n",
            "Iteration: 45372 | Cost/Loss: 0.077653 | Weight: 0.528336 | Bias: 0.069560\n",
            "Iteration: 45373 | Cost/Loss: 0.077653 | Weight: 0.528337 | Bias: 0.069560\n",
            "Iteration: 45374 | Cost/Loss: 0.077653 | Weight: 0.528337 | Bias: 0.069561\n",
            "Iteration: 45375 | Cost/Loss: 0.077653 | Weight: 0.528337 | Bias: 0.069561\n",
            "Iteration: 45376 | Cost/Loss: 0.077653 | Weight: 0.528337 | Bias: 0.069561\n",
            "Iteration: 45377 | Cost/Loss: 0.077653 | Weight: 0.528338 | Bias: 0.069562\n",
            "Iteration: 45378 | Cost/Loss: 0.077653 | Weight: 0.528338 | Bias: 0.069562\n",
            "Iteration: 45379 | Cost/Loss: 0.077653 | Weight: 0.528338 | Bias: 0.069562\n",
            "Iteration: 45380 | Cost/Loss: 0.077653 | Weight: 0.528339 | Bias: 0.069563\n",
            "Iteration: 45381 | Cost/Loss: 0.077653 | Weight: 0.528339 | Bias: 0.069563\n",
            "Iteration: 45382 | Cost/Loss: 0.077653 | Weight: 0.528339 | Bias: 0.069563\n",
            "Iteration: 45383 | Cost/Loss: 0.077653 | Weight: 0.528340 | Bias: 0.069564\n",
            "Iteration: 45384 | Cost/Loss: 0.077653 | Weight: 0.528340 | Bias: 0.069564\n",
            "Iteration: 45385 | Cost/Loss: 0.077653 | Weight: 0.528340 | Bias: 0.069564\n",
            "Iteration: 45386 | Cost/Loss: 0.077653 | Weight: 0.528340 | Bias: 0.069565\n",
            "Iteration: 45387 | Cost/Loss: 0.077653 | Weight: 0.528341 | Bias: 0.069565\n",
            "Iteration: 45388 | Cost/Loss: 0.077653 | Weight: 0.528341 | Bias: 0.069565\n",
            "Iteration: 45389 | Cost/Loss: 0.077653 | Weight: 0.528341 | Bias: 0.069566\n",
            "Iteration: 45390 | Cost/Loss: 0.077653 | Weight: 0.528342 | Bias: 0.069566\n",
            "Iteration: 45391 | Cost/Loss: 0.077653 | Weight: 0.528342 | Bias: 0.069566\n",
            "Iteration: 45392 | Cost/Loss: 0.077653 | Weight: 0.528342 | Bias: 0.069567\n",
            "Iteration: 45393 | Cost/Loss: 0.077653 | Weight: 0.528343 | Bias: 0.069567\n",
            "Iteration: 45394 | Cost/Loss: 0.077653 | Weight: 0.528343 | Bias: 0.069567\n",
            "Iteration: 45395 | Cost/Loss: 0.077652 | Weight: 0.528343 | Bias: 0.069567\n",
            "Iteration: 45396 | Cost/Loss: 0.077652 | Weight: 0.528343 | Bias: 0.069568\n",
            "Iteration: 45397 | Cost/Loss: 0.077652 | Weight: 0.528344 | Bias: 0.069568\n",
            "Iteration: 45398 | Cost/Loss: 0.077652 | Weight: 0.528344 | Bias: 0.069568\n",
            "Iteration: 45399 | Cost/Loss: 0.077652 | Weight: 0.528344 | Bias: 0.069569\n",
            "Iteration: 45400 | Cost/Loss: 0.077652 | Weight: 0.528345 | Bias: 0.069569\n",
            "Iteration: 45401 | Cost/Loss: 0.077652 | Weight: 0.528345 | Bias: 0.069569\n",
            "Iteration: 45402 | Cost/Loss: 0.077652 | Weight: 0.528345 | Bias: 0.069570\n",
            "Iteration: 45403 | Cost/Loss: 0.077652 | Weight: 0.528346 | Bias: 0.069570\n",
            "Iteration: 45404 | Cost/Loss: 0.077652 | Weight: 0.528346 | Bias: 0.069570\n",
            "Iteration: 45405 | Cost/Loss: 0.077652 | Weight: 0.528346 | Bias: 0.069571\n",
            "Iteration: 45406 | Cost/Loss: 0.077652 | Weight: 0.528346 | Bias: 0.069571\n",
            "Iteration: 45407 | Cost/Loss: 0.077652 | Weight: 0.528347 | Bias: 0.069571\n",
            "Iteration: 45408 | Cost/Loss: 0.077652 | Weight: 0.528347 | Bias: 0.069572\n",
            "Iteration: 45409 | Cost/Loss: 0.077652 | Weight: 0.528347 | Bias: 0.069572\n",
            "Iteration: 45410 | Cost/Loss: 0.077652 | Weight: 0.528348 | Bias: 0.069572\n",
            "Iteration: 45411 | Cost/Loss: 0.077652 | Weight: 0.528348 | Bias: 0.069573\n",
            "Iteration: 45412 | Cost/Loss: 0.077652 | Weight: 0.528348 | Bias: 0.069573\n",
            "Iteration: 45413 | Cost/Loss: 0.077652 | Weight: 0.528349 | Bias: 0.069573\n",
            "Iteration: 45414 | Cost/Loss: 0.077652 | Weight: 0.528349 | Bias: 0.069574\n",
            "Iteration: 45415 | Cost/Loss: 0.077652 | Weight: 0.528349 | Bias: 0.069574\n",
            "Iteration: 45416 | Cost/Loss: 0.077652 | Weight: 0.528349 | Bias: 0.069574\n",
            "Iteration: 45417 | Cost/Loss: 0.077652 | Weight: 0.528350 | Bias: 0.069575\n",
            "Iteration: 45418 | Cost/Loss: 0.077652 | Weight: 0.528350 | Bias: 0.069575\n",
            "Iteration: 45419 | Cost/Loss: 0.077652 | Weight: 0.528350 | Bias: 0.069575\n",
            "Iteration: 45420 | Cost/Loss: 0.077652 | Weight: 0.528351 | Bias: 0.069575\n",
            "Iteration: 45421 | Cost/Loss: 0.077652 | Weight: 0.528351 | Bias: 0.069576\n",
            "Iteration: 45422 | Cost/Loss: 0.077652 | Weight: 0.528351 | Bias: 0.069576\n",
            "Iteration: 45423 | Cost/Loss: 0.077652 | Weight: 0.528351 | Bias: 0.069576\n",
            "Iteration: 45424 | Cost/Loss: 0.077652 | Weight: 0.528352 | Bias: 0.069577\n",
            "Iteration: 45425 | Cost/Loss: 0.077652 | Weight: 0.528352 | Bias: 0.069577\n",
            "Iteration: 45426 | Cost/Loss: 0.077652 | Weight: 0.528352 | Bias: 0.069577\n",
            "Iteration: 45427 | Cost/Loss: 0.077652 | Weight: 0.528353 | Bias: 0.069578\n",
            "Iteration: 45428 | Cost/Loss: 0.077652 | Weight: 0.528353 | Bias: 0.069578\n",
            "Iteration: 45429 | Cost/Loss: 0.077652 | Weight: 0.528353 | Bias: 0.069578\n",
            "Iteration: 45430 | Cost/Loss: 0.077652 | Weight: 0.528354 | Bias: 0.069579\n",
            "Iteration: 45431 | Cost/Loss: 0.077652 | Weight: 0.528354 | Bias: 0.069579\n",
            "Iteration: 45432 | Cost/Loss: 0.077652 | Weight: 0.528354 | Bias: 0.069579\n",
            "Iteration: 45433 | Cost/Loss: 0.077652 | Weight: 0.528354 | Bias: 0.069580\n",
            "Iteration: 45434 | Cost/Loss: 0.077652 | Weight: 0.528355 | Bias: 0.069580\n",
            "Iteration: 45435 | Cost/Loss: 0.077651 | Weight: 0.528355 | Bias: 0.069580\n",
            "Iteration: 45436 | Cost/Loss: 0.077651 | Weight: 0.528355 | Bias: 0.069581\n",
            "Iteration: 45437 | Cost/Loss: 0.077651 | Weight: 0.528356 | Bias: 0.069581\n",
            "Iteration: 45438 | Cost/Loss: 0.077651 | Weight: 0.528356 | Bias: 0.069581\n",
            "Iteration: 45439 | Cost/Loss: 0.077651 | Weight: 0.528356 | Bias: 0.069582\n",
            "Iteration: 45440 | Cost/Loss: 0.077651 | Weight: 0.528357 | Bias: 0.069582\n",
            "Iteration: 45441 | Cost/Loss: 0.077651 | Weight: 0.528357 | Bias: 0.069582\n",
            "Iteration: 45442 | Cost/Loss: 0.077651 | Weight: 0.528357 | Bias: 0.069583\n",
            "Iteration: 45443 | Cost/Loss: 0.077651 | Weight: 0.528357 | Bias: 0.069583\n",
            "Iteration: 45444 | Cost/Loss: 0.077651 | Weight: 0.528358 | Bias: 0.069583\n",
            "Iteration: 45445 | Cost/Loss: 0.077651 | Weight: 0.528358 | Bias: 0.069583\n",
            "Iteration: 45446 | Cost/Loss: 0.077651 | Weight: 0.528358 | Bias: 0.069584\n",
            "Iteration: 45447 | Cost/Loss: 0.077651 | Weight: 0.528359 | Bias: 0.069584\n",
            "Iteration: 45448 | Cost/Loss: 0.077651 | Weight: 0.528359 | Bias: 0.069584\n",
            "Iteration: 45449 | Cost/Loss: 0.077651 | Weight: 0.528359 | Bias: 0.069585\n",
            "Iteration: 45450 | Cost/Loss: 0.077651 | Weight: 0.528360 | Bias: 0.069585\n",
            "Iteration: 45451 | Cost/Loss: 0.077651 | Weight: 0.528360 | Bias: 0.069585\n",
            "Iteration: 45452 | Cost/Loss: 0.077651 | Weight: 0.528360 | Bias: 0.069586\n",
            "Iteration: 45453 | Cost/Loss: 0.077651 | Weight: 0.528360 | Bias: 0.069586\n",
            "Iteration: 45454 | Cost/Loss: 0.077651 | Weight: 0.528361 | Bias: 0.069586\n",
            "Iteration: 45455 | Cost/Loss: 0.077651 | Weight: 0.528361 | Bias: 0.069587\n",
            "Iteration: 45456 | Cost/Loss: 0.077651 | Weight: 0.528361 | Bias: 0.069587\n",
            "Iteration: 45457 | Cost/Loss: 0.077651 | Weight: 0.528362 | Bias: 0.069587\n",
            "Iteration: 45458 | Cost/Loss: 0.077651 | Weight: 0.528362 | Bias: 0.069588\n",
            "Iteration: 45459 | Cost/Loss: 0.077651 | Weight: 0.528362 | Bias: 0.069588\n",
            "Iteration: 45460 | Cost/Loss: 0.077651 | Weight: 0.528363 | Bias: 0.069588\n",
            "Iteration: 45461 | Cost/Loss: 0.077651 | Weight: 0.528363 | Bias: 0.069589\n",
            "Iteration: 45462 | Cost/Loss: 0.077651 | Weight: 0.528363 | Bias: 0.069589\n",
            "Iteration: 45463 | Cost/Loss: 0.077651 | Weight: 0.528363 | Bias: 0.069589\n",
            "Iteration: 45464 | Cost/Loss: 0.077651 | Weight: 0.528364 | Bias: 0.069590\n",
            "Iteration: 45465 | Cost/Loss: 0.077651 | Weight: 0.528364 | Bias: 0.069590\n",
            "Iteration: 45466 | Cost/Loss: 0.077651 | Weight: 0.528364 | Bias: 0.069590\n",
            "Iteration: 45467 | Cost/Loss: 0.077651 | Weight: 0.528365 | Bias: 0.069591\n",
            "Iteration: 45468 | Cost/Loss: 0.077651 | Weight: 0.528365 | Bias: 0.069591\n",
            "Iteration: 45469 | Cost/Loss: 0.077651 | Weight: 0.528365 | Bias: 0.069591\n",
            "Iteration: 45470 | Cost/Loss: 0.077651 | Weight: 0.528365 | Bias: 0.069591\n",
            "Iteration: 45471 | Cost/Loss: 0.077651 | Weight: 0.528366 | Bias: 0.069592\n",
            "Iteration: 45472 | Cost/Loss: 0.077651 | Weight: 0.528366 | Bias: 0.069592\n",
            "Iteration: 45473 | Cost/Loss: 0.077651 | Weight: 0.528366 | Bias: 0.069592\n",
            "Iteration: 45474 | Cost/Loss: 0.077651 | Weight: 0.528367 | Bias: 0.069593\n",
            "Iteration: 45475 | Cost/Loss: 0.077650 | Weight: 0.528367 | Bias: 0.069593\n",
            "Iteration: 45476 | Cost/Loss: 0.077650 | Weight: 0.528367 | Bias: 0.069593\n",
            "Iteration: 45477 | Cost/Loss: 0.077650 | Weight: 0.528368 | Bias: 0.069594\n",
            "Iteration: 45478 | Cost/Loss: 0.077650 | Weight: 0.528368 | Bias: 0.069594\n",
            "Iteration: 45479 | Cost/Loss: 0.077650 | Weight: 0.528368 | Bias: 0.069594\n",
            "Iteration: 45480 | Cost/Loss: 0.077650 | Weight: 0.528368 | Bias: 0.069595\n",
            "Iteration: 45481 | Cost/Loss: 0.077650 | Weight: 0.528369 | Bias: 0.069595\n",
            "Iteration: 45482 | Cost/Loss: 0.077650 | Weight: 0.528369 | Bias: 0.069595\n",
            "Iteration: 45483 | Cost/Loss: 0.077650 | Weight: 0.528369 | Bias: 0.069596\n",
            "Iteration: 45484 | Cost/Loss: 0.077650 | Weight: 0.528370 | Bias: 0.069596\n",
            "Iteration: 45485 | Cost/Loss: 0.077650 | Weight: 0.528370 | Bias: 0.069596\n",
            "Iteration: 45486 | Cost/Loss: 0.077650 | Weight: 0.528370 | Bias: 0.069597\n",
            "Iteration: 45487 | Cost/Loss: 0.077650 | Weight: 0.528371 | Bias: 0.069597\n",
            "Iteration: 45488 | Cost/Loss: 0.077650 | Weight: 0.528371 | Bias: 0.069597\n",
            "Iteration: 45489 | Cost/Loss: 0.077650 | Weight: 0.528371 | Bias: 0.069598\n",
            "Iteration: 45490 | Cost/Loss: 0.077650 | Weight: 0.528371 | Bias: 0.069598\n",
            "Iteration: 45491 | Cost/Loss: 0.077650 | Weight: 0.528372 | Bias: 0.069598\n",
            "Iteration: 45492 | Cost/Loss: 0.077650 | Weight: 0.528372 | Bias: 0.069599\n",
            "Iteration: 45493 | Cost/Loss: 0.077650 | Weight: 0.528372 | Bias: 0.069599\n",
            "Iteration: 45494 | Cost/Loss: 0.077650 | Weight: 0.528373 | Bias: 0.069599\n",
            "Iteration: 45495 | Cost/Loss: 0.077650 | Weight: 0.528373 | Bias: 0.069600\n",
            "Iteration: 45496 | Cost/Loss: 0.077650 | Weight: 0.528373 | Bias: 0.069600\n",
            "Iteration: 45497 | Cost/Loss: 0.077650 | Weight: 0.528374 | Bias: 0.069600\n",
            "Iteration: 45498 | Cost/Loss: 0.077650 | Weight: 0.528374 | Bias: 0.069600\n",
            "Iteration: 45499 | Cost/Loss: 0.077650 | Weight: 0.528374 | Bias: 0.069601\n",
            "Iteration: 45500 | Cost/Loss: 0.077650 | Weight: 0.528374 | Bias: 0.069601\n",
            "Iteration: 45501 | Cost/Loss: 0.077650 | Weight: 0.528375 | Bias: 0.069601\n",
            "Iteration: 45502 | Cost/Loss: 0.077650 | Weight: 0.528375 | Bias: 0.069602\n",
            "Iteration: 45503 | Cost/Loss: 0.077650 | Weight: 0.528375 | Bias: 0.069602\n",
            "Iteration: 45504 | Cost/Loss: 0.077650 | Weight: 0.528376 | Bias: 0.069602\n",
            "Iteration: 45505 | Cost/Loss: 0.077650 | Weight: 0.528376 | Bias: 0.069603\n",
            "Iteration: 45506 | Cost/Loss: 0.077650 | Weight: 0.528376 | Bias: 0.069603\n",
            "Iteration: 45507 | Cost/Loss: 0.077650 | Weight: 0.528377 | Bias: 0.069603\n",
            "Iteration: 45508 | Cost/Loss: 0.077650 | Weight: 0.528377 | Bias: 0.069604\n",
            "Iteration: 45509 | Cost/Loss: 0.077650 | Weight: 0.528377 | Bias: 0.069604\n",
            "Iteration: 45510 | Cost/Loss: 0.077650 | Weight: 0.528377 | Bias: 0.069604\n",
            "Iteration: 45511 | Cost/Loss: 0.077650 | Weight: 0.528378 | Bias: 0.069605\n",
            "Iteration: 45512 | Cost/Loss: 0.077650 | Weight: 0.528378 | Bias: 0.069605\n",
            "Iteration: 45513 | Cost/Loss: 0.077650 | Weight: 0.528378 | Bias: 0.069605\n",
            "Iteration: 45514 | Cost/Loss: 0.077649 | Weight: 0.528379 | Bias: 0.069606\n",
            "Iteration: 45515 | Cost/Loss: 0.077649 | Weight: 0.528379 | Bias: 0.069606\n",
            "Iteration: 45516 | Cost/Loss: 0.077649 | Weight: 0.528379 | Bias: 0.069606\n",
            "Iteration: 45517 | Cost/Loss: 0.077649 | Weight: 0.528379 | Bias: 0.069607\n",
            "Iteration: 45518 | Cost/Loss: 0.077649 | Weight: 0.528380 | Bias: 0.069607\n",
            "Iteration: 45519 | Cost/Loss: 0.077649 | Weight: 0.528380 | Bias: 0.069607\n",
            "Iteration: 45520 | Cost/Loss: 0.077649 | Weight: 0.528380 | Bias: 0.069608\n",
            "Iteration: 45521 | Cost/Loss: 0.077649 | Weight: 0.528381 | Bias: 0.069608\n",
            "Iteration: 45522 | Cost/Loss: 0.077649 | Weight: 0.528381 | Bias: 0.069608\n",
            "Iteration: 45523 | Cost/Loss: 0.077649 | Weight: 0.528381 | Bias: 0.069608\n",
            "Iteration: 45524 | Cost/Loss: 0.077649 | Weight: 0.528382 | Bias: 0.069609\n",
            "Iteration: 45525 | Cost/Loss: 0.077649 | Weight: 0.528382 | Bias: 0.069609\n",
            "Iteration: 45526 | Cost/Loss: 0.077649 | Weight: 0.528382 | Bias: 0.069609\n",
            "Iteration: 45527 | Cost/Loss: 0.077649 | Weight: 0.528382 | Bias: 0.069610\n",
            "Iteration: 45528 | Cost/Loss: 0.077649 | Weight: 0.528383 | Bias: 0.069610\n",
            "Iteration: 45529 | Cost/Loss: 0.077649 | Weight: 0.528383 | Bias: 0.069610\n",
            "Iteration: 45530 | Cost/Loss: 0.077649 | Weight: 0.528383 | Bias: 0.069611\n",
            "Iteration: 45531 | Cost/Loss: 0.077649 | Weight: 0.528384 | Bias: 0.069611\n",
            "Iteration: 45532 | Cost/Loss: 0.077649 | Weight: 0.528384 | Bias: 0.069611\n",
            "Iteration: 45533 | Cost/Loss: 0.077649 | Weight: 0.528384 | Bias: 0.069612\n",
            "Iteration: 45534 | Cost/Loss: 0.077649 | Weight: 0.528385 | Bias: 0.069612\n",
            "Iteration: 45535 | Cost/Loss: 0.077649 | Weight: 0.528385 | Bias: 0.069612\n",
            "Iteration: 45536 | Cost/Loss: 0.077649 | Weight: 0.528385 | Bias: 0.069613\n",
            "Iteration: 45537 | Cost/Loss: 0.077649 | Weight: 0.528385 | Bias: 0.069613\n",
            "Iteration: 45538 | Cost/Loss: 0.077649 | Weight: 0.528386 | Bias: 0.069613\n",
            "Iteration: 45539 | Cost/Loss: 0.077649 | Weight: 0.528386 | Bias: 0.069614\n",
            "Iteration: 45540 | Cost/Loss: 0.077649 | Weight: 0.528386 | Bias: 0.069614\n",
            "Iteration: 45541 | Cost/Loss: 0.077649 | Weight: 0.528387 | Bias: 0.069614\n",
            "Iteration: 45542 | Cost/Loss: 0.077649 | Weight: 0.528387 | Bias: 0.069615\n",
            "Iteration: 45543 | Cost/Loss: 0.077649 | Weight: 0.528387 | Bias: 0.069615\n",
            "Iteration: 45544 | Cost/Loss: 0.077649 | Weight: 0.528388 | Bias: 0.069615\n",
            "Iteration: 45545 | Cost/Loss: 0.077649 | Weight: 0.528388 | Bias: 0.069616\n",
            "Iteration: 45546 | Cost/Loss: 0.077649 | Weight: 0.528388 | Bias: 0.069616\n",
            "Iteration: 45547 | Cost/Loss: 0.077649 | Weight: 0.528388 | Bias: 0.069616\n",
            "Iteration: 45548 | Cost/Loss: 0.077649 | Weight: 0.528389 | Bias: 0.069616\n",
            "Iteration: 45549 | Cost/Loss: 0.077649 | Weight: 0.528389 | Bias: 0.069617\n",
            "Iteration: 45550 | Cost/Loss: 0.077649 | Weight: 0.528389 | Bias: 0.069617\n",
            "Iteration: 45551 | Cost/Loss: 0.077649 | Weight: 0.528390 | Bias: 0.069617\n",
            "Iteration: 45552 | Cost/Loss: 0.077649 | Weight: 0.528390 | Bias: 0.069618\n",
            "Iteration: 45553 | Cost/Loss: 0.077649 | Weight: 0.528390 | Bias: 0.069618\n",
            "Iteration: 45554 | Cost/Loss: 0.077648 | Weight: 0.528391 | Bias: 0.069618\n",
            "Iteration: 45555 | Cost/Loss: 0.077648 | Weight: 0.528391 | Bias: 0.069619\n",
            "Iteration: 45556 | Cost/Loss: 0.077648 | Weight: 0.528391 | Bias: 0.069619\n",
            "Iteration: 45557 | Cost/Loss: 0.077648 | Weight: 0.528391 | Bias: 0.069619\n",
            "Iteration: 45558 | Cost/Loss: 0.077648 | Weight: 0.528392 | Bias: 0.069620\n",
            "Iteration: 45559 | Cost/Loss: 0.077648 | Weight: 0.528392 | Bias: 0.069620\n",
            "Iteration: 45560 | Cost/Loss: 0.077648 | Weight: 0.528392 | Bias: 0.069620\n",
            "Iteration: 45561 | Cost/Loss: 0.077648 | Weight: 0.528393 | Bias: 0.069621\n",
            "Iteration: 45562 | Cost/Loss: 0.077648 | Weight: 0.528393 | Bias: 0.069621\n",
            "Iteration: 45563 | Cost/Loss: 0.077648 | Weight: 0.528393 | Bias: 0.069621\n",
            "Iteration: 45564 | Cost/Loss: 0.077648 | Weight: 0.528394 | Bias: 0.069622\n",
            "Iteration: 45565 | Cost/Loss: 0.077648 | Weight: 0.528394 | Bias: 0.069622\n",
            "Iteration: 45566 | Cost/Loss: 0.077648 | Weight: 0.528394 | Bias: 0.069622\n",
            "Iteration: 45567 | Cost/Loss: 0.077648 | Weight: 0.528394 | Bias: 0.069623\n",
            "Iteration: 45568 | Cost/Loss: 0.077648 | Weight: 0.528395 | Bias: 0.069623\n",
            "Iteration: 45569 | Cost/Loss: 0.077648 | Weight: 0.528395 | Bias: 0.069623\n",
            "Iteration: 45570 | Cost/Loss: 0.077648 | Weight: 0.528395 | Bias: 0.069624\n",
            "Iteration: 45571 | Cost/Loss: 0.077648 | Weight: 0.528396 | Bias: 0.069624\n",
            "Iteration: 45572 | Cost/Loss: 0.077648 | Weight: 0.528396 | Bias: 0.069624\n",
            "Iteration: 45573 | Cost/Loss: 0.077648 | Weight: 0.528396 | Bias: 0.069624\n",
            "Iteration: 45574 | Cost/Loss: 0.077648 | Weight: 0.528396 | Bias: 0.069625\n",
            "Iteration: 45575 | Cost/Loss: 0.077648 | Weight: 0.528397 | Bias: 0.069625\n",
            "Iteration: 45576 | Cost/Loss: 0.077648 | Weight: 0.528397 | Bias: 0.069625\n",
            "Iteration: 45577 | Cost/Loss: 0.077648 | Weight: 0.528397 | Bias: 0.069626\n",
            "Iteration: 45578 | Cost/Loss: 0.077648 | Weight: 0.528398 | Bias: 0.069626\n",
            "Iteration: 45579 | Cost/Loss: 0.077648 | Weight: 0.528398 | Bias: 0.069626\n",
            "Iteration: 45580 | Cost/Loss: 0.077648 | Weight: 0.528398 | Bias: 0.069627\n",
            "Iteration: 45581 | Cost/Loss: 0.077648 | Weight: 0.528399 | Bias: 0.069627\n",
            "Iteration: 45582 | Cost/Loss: 0.077648 | Weight: 0.528399 | Bias: 0.069627\n",
            "Iteration: 45583 | Cost/Loss: 0.077648 | Weight: 0.528399 | Bias: 0.069628\n",
            "Iteration: 45584 | Cost/Loss: 0.077648 | Weight: 0.528399 | Bias: 0.069628\n",
            "Iteration: 45585 | Cost/Loss: 0.077648 | Weight: 0.528400 | Bias: 0.069628\n",
            "Iteration: 45586 | Cost/Loss: 0.077648 | Weight: 0.528400 | Bias: 0.069629\n",
            "Iteration: 45587 | Cost/Loss: 0.077648 | Weight: 0.528400 | Bias: 0.069629\n",
            "Iteration: 45588 | Cost/Loss: 0.077648 | Weight: 0.528401 | Bias: 0.069629\n",
            "Iteration: 45589 | Cost/Loss: 0.077648 | Weight: 0.528401 | Bias: 0.069630\n",
            "Iteration: 45590 | Cost/Loss: 0.077648 | Weight: 0.528401 | Bias: 0.069630\n",
            "Iteration: 45591 | Cost/Loss: 0.077648 | Weight: 0.528402 | Bias: 0.069630\n",
            "Iteration: 45592 | Cost/Loss: 0.077648 | Weight: 0.528402 | Bias: 0.069631\n",
            "Iteration: 45593 | Cost/Loss: 0.077647 | Weight: 0.528402 | Bias: 0.069631\n",
            "Iteration: 45594 | Cost/Loss: 0.077647 | Weight: 0.528402 | Bias: 0.069631\n",
            "Iteration: 45595 | Cost/Loss: 0.077647 | Weight: 0.528403 | Bias: 0.069632\n",
            "Iteration: 45596 | Cost/Loss: 0.077647 | Weight: 0.528403 | Bias: 0.069632\n",
            "Iteration: 45597 | Cost/Loss: 0.077647 | Weight: 0.528403 | Bias: 0.069632\n",
            "Iteration: 45598 | Cost/Loss: 0.077647 | Weight: 0.528404 | Bias: 0.069633\n",
            "Iteration: 45599 | Cost/Loss: 0.077647 | Weight: 0.528404 | Bias: 0.069633\n",
            "Iteration: 45600 | Cost/Loss: 0.077647 | Weight: 0.528404 | Bias: 0.069633\n",
            "Iteration: 45601 | Cost/Loss: 0.077647 | Weight: 0.528405 | Bias: 0.069633\n",
            "Iteration: 45602 | Cost/Loss: 0.077647 | Weight: 0.528405 | Bias: 0.069634\n",
            "Iteration: 45603 | Cost/Loss: 0.077647 | Weight: 0.528405 | Bias: 0.069634\n",
            "Iteration: 45604 | Cost/Loss: 0.077647 | Weight: 0.528405 | Bias: 0.069634\n",
            "Iteration: 45605 | Cost/Loss: 0.077647 | Weight: 0.528406 | Bias: 0.069635\n",
            "Iteration: 45606 | Cost/Loss: 0.077647 | Weight: 0.528406 | Bias: 0.069635\n",
            "Iteration: 45607 | Cost/Loss: 0.077647 | Weight: 0.528406 | Bias: 0.069635\n",
            "Iteration: 45608 | Cost/Loss: 0.077647 | Weight: 0.528407 | Bias: 0.069636\n",
            "Iteration: 45609 | Cost/Loss: 0.077647 | Weight: 0.528407 | Bias: 0.069636\n",
            "Iteration: 45610 | Cost/Loss: 0.077647 | Weight: 0.528407 | Bias: 0.069636\n",
            "Iteration: 45611 | Cost/Loss: 0.077647 | Weight: 0.528408 | Bias: 0.069637\n",
            "Iteration: 45612 | Cost/Loss: 0.077647 | Weight: 0.528408 | Bias: 0.069637\n",
            "Iteration: 45613 | Cost/Loss: 0.077647 | Weight: 0.528408 | Bias: 0.069637\n",
            "Iteration: 45614 | Cost/Loss: 0.077647 | Weight: 0.528408 | Bias: 0.069638\n",
            "Iteration: 45615 | Cost/Loss: 0.077647 | Weight: 0.528409 | Bias: 0.069638\n",
            "Iteration: 45616 | Cost/Loss: 0.077647 | Weight: 0.528409 | Bias: 0.069638\n",
            "Iteration: 45617 | Cost/Loss: 0.077647 | Weight: 0.528409 | Bias: 0.069639\n",
            "Iteration: 45618 | Cost/Loss: 0.077647 | Weight: 0.528410 | Bias: 0.069639\n",
            "Iteration: 45619 | Cost/Loss: 0.077647 | Weight: 0.528410 | Bias: 0.069639\n",
            "Iteration: 45620 | Cost/Loss: 0.077647 | Weight: 0.528410 | Bias: 0.069640\n",
            "Iteration: 45621 | Cost/Loss: 0.077647 | Weight: 0.528410 | Bias: 0.069640\n",
            "Iteration: 45622 | Cost/Loss: 0.077647 | Weight: 0.528411 | Bias: 0.069640\n",
            "Iteration: 45623 | Cost/Loss: 0.077647 | Weight: 0.528411 | Bias: 0.069641\n",
            "Iteration: 45624 | Cost/Loss: 0.077647 | Weight: 0.528411 | Bias: 0.069641\n",
            "Iteration: 45625 | Cost/Loss: 0.077647 | Weight: 0.528412 | Bias: 0.069641\n",
            "Iteration: 45626 | Cost/Loss: 0.077647 | Weight: 0.528412 | Bias: 0.069641\n",
            "Iteration: 45627 | Cost/Loss: 0.077647 | Weight: 0.528412 | Bias: 0.069642\n",
            "Iteration: 45628 | Cost/Loss: 0.077647 | Weight: 0.528413 | Bias: 0.069642\n",
            "Iteration: 45629 | Cost/Loss: 0.077647 | Weight: 0.528413 | Bias: 0.069642\n",
            "Iteration: 45630 | Cost/Loss: 0.077647 | Weight: 0.528413 | Bias: 0.069643\n",
            "Iteration: 45631 | Cost/Loss: 0.077647 | Weight: 0.528413 | Bias: 0.069643\n",
            "Iteration: 45632 | Cost/Loss: 0.077647 | Weight: 0.528414 | Bias: 0.069643\n",
            "Iteration: 45633 | Cost/Loss: 0.077646 | Weight: 0.528414 | Bias: 0.069644\n",
            "Iteration: 45634 | Cost/Loss: 0.077646 | Weight: 0.528414 | Bias: 0.069644\n",
            "Iteration: 45635 | Cost/Loss: 0.077646 | Weight: 0.528415 | Bias: 0.069644\n",
            "Iteration: 45636 | Cost/Loss: 0.077646 | Weight: 0.528415 | Bias: 0.069645\n",
            "Iteration: 45637 | Cost/Loss: 0.077646 | Weight: 0.528415 | Bias: 0.069645\n",
            "Iteration: 45638 | Cost/Loss: 0.077646 | Weight: 0.528416 | Bias: 0.069645\n",
            "Iteration: 45639 | Cost/Loss: 0.077646 | Weight: 0.528416 | Bias: 0.069646\n",
            "Iteration: 45640 | Cost/Loss: 0.077646 | Weight: 0.528416 | Bias: 0.069646\n",
            "Iteration: 45641 | Cost/Loss: 0.077646 | Weight: 0.528416 | Bias: 0.069646\n",
            "Iteration: 45642 | Cost/Loss: 0.077646 | Weight: 0.528417 | Bias: 0.069647\n",
            "Iteration: 45643 | Cost/Loss: 0.077646 | Weight: 0.528417 | Bias: 0.069647\n",
            "Iteration: 45644 | Cost/Loss: 0.077646 | Weight: 0.528417 | Bias: 0.069647\n",
            "Iteration: 45645 | Cost/Loss: 0.077646 | Weight: 0.528418 | Bias: 0.069648\n",
            "Iteration: 45646 | Cost/Loss: 0.077646 | Weight: 0.528418 | Bias: 0.069648\n",
            "Iteration: 45647 | Cost/Loss: 0.077646 | Weight: 0.528418 | Bias: 0.069648\n",
            "Iteration: 45648 | Cost/Loss: 0.077646 | Weight: 0.528419 | Bias: 0.069649\n",
            "Iteration: 45649 | Cost/Loss: 0.077646 | Weight: 0.528419 | Bias: 0.069649\n",
            "Iteration: 45650 | Cost/Loss: 0.077646 | Weight: 0.528419 | Bias: 0.069649\n",
            "Iteration: 45651 | Cost/Loss: 0.077646 | Weight: 0.528419 | Bias: 0.069649\n",
            "Iteration: 45652 | Cost/Loss: 0.077646 | Weight: 0.528420 | Bias: 0.069650\n",
            "Iteration: 45653 | Cost/Loss: 0.077646 | Weight: 0.528420 | Bias: 0.069650\n",
            "Iteration: 45654 | Cost/Loss: 0.077646 | Weight: 0.528420 | Bias: 0.069650\n",
            "Iteration: 45655 | Cost/Loss: 0.077646 | Weight: 0.528421 | Bias: 0.069651\n",
            "Iteration: 45656 | Cost/Loss: 0.077646 | Weight: 0.528421 | Bias: 0.069651\n",
            "Iteration: 45657 | Cost/Loss: 0.077646 | Weight: 0.528421 | Bias: 0.069651\n",
            "Iteration: 45658 | Cost/Loss: 0.077646 | Weight: 0.528422 | Bias: 0.069652\n",
            "Iteration: 45659 | Cost/Loss: 0.077646 | Weight: 0.528422 | Bias: 0.069652\n",
            "Iteration: 45660 | Cost/Loss: 0.077646 | Weight: 0.528422 | Bias: 0.069652\n",
            "Iteration: 45661 | Cost/Loss: 0.077646 | Weight: 0.528422 | Bias: 0.069653\n",
            "Iteration: 45662 | Cost/Loss: 0.077646 | Weight: 0.528423 | Bias: 0.069653\n",
            "Iteration: 45663 | Cost/Loss: 0.077646 | Weight: 0.528423 | Bias: 0.069653\n",
            "Iteration: 45664 | Cost/Loss: 0.077646 | Weight: 0.528423 | Bias: 0.069654\n",
            "Iteration: 45665 | Cost/Loss: 0.077646 | Weight: 0.528424 | Bias: 0.069654\n",
            "Iteration: 45666 | Cost/Loss: 0.077646 | Weight: 0.528424 | Bias: 0.069654\n",
            "Iteration: 45667 | Cost/Loss: 0.077646 | Weight: 0.528424 | Bias: 0.069655\n",
            "Iteration: 45668 | Cost/Loss: 0.077646 | Weight: 0.528425 | Bias: 0.069655\n",
            "Iteration: 45669 | Cost/Loss: 0.077646 | Weight: 0.528425 | Bias: 0.069655\n",
            "Iteration: 45670 | Cost/Loss: 0.077646 | Weight: 0.528425 | Bias: 0.069656\n",
            "Iteration: 45671 | Cost/Loss: 0.077646 | Weight: 0.528425 | Bias: 0.069656\n",
            "Iteration: 45672 | Cost/Loss: 0.077646 | Weight: 0.528426 | Bias: 0.069656\n",
            "Iteration: 45673 | Cost/Loss: 0.077645 | Weight: 0.528426 | Bias: 0.069657\n",
            "Iteration: 45674 | Cost/Loss: 0.077645 | Weight: 0.528426 | Bias: 0.069657\n",
            "Iteration: 45675 | Cost/Loss: 0.077645 | Weight: 0.528427 | Bias: 0.069657\n",
            "Iteration: 45676 | Cost/Loss: 0.077645 | Weight: 0.528427 | Bias: 0.069657\n",
            "Iteration: 45677 | Cost/Loss: 0.077645 | Weight: 0.528427 | Bias: 0.069658\n",
            "Iteration: 45678 | Cost/Loss: 0.077645 | Weight: 0.528427 | Bias: 0.069658\n",
            "Iteration: 45679 | Cost/Loss: 0.077645 | Weight: 0.528428 | Bias: 0.069658\n",
            "Iteration: 45680 | Cost/Loss: 0.077645 | Weight: 0.528428 | Bias: 0.069659\n",
            "Iteration: 45681 | Cost/Loss: 0.077645 | Weight: 0.528428 | Bias: 0.069659\n",
            "Iteration: 45682 | Cost/Loss: 0.077645 | Weight: 0.528429 | Bias: 0.069659\n",
            "Iteration: 45683 | Cost/Loss: 0.077645 | Weight: 0.528429 | Bias: 0.069660\n",
            "Iteration: 45684 | Cost/Loss: 0.077645 | Weight: 0.528429 | Bias: 0.069660\n",
            "Iteration: 45685 | Cost/Loss: 0.077645 | Weight: 0.528430 | Bias: 0.069660\n",
            "Iteration: 45686 | Cost/Loss: 0.077645 | Weight: 0.528430 | Bias: 0.069661\n",
            "Iteration: 45687 | Cost/Loss: 0.077645 | Weight: 0.528430 | Bias: 0.069661\n",
            "Iteration: 45688 | Cost/Loss: 0.077645 | Weight: 0.528430 | Bias: 0.069661\n",
            "Iteration: 45689 | Cost/Loss: 0.077645 | Weight: 0.528431 | Bias: 0.069662\n",
            "Iteration: 45690 | Cost/Loss: 0.077645 | Weight: 0.528431 | Bias: 0.069662\n",
            "Iteration: 45691 | Cost/Loss: 0.077645 | Weight: 0.528431 | Bias: 0.069662\n",
            "Iteration: 45692 | Cost/Loss: 0.077645 | Weight: 0.528432 | Bias: 0.069663\n",
            "Iteration: 45693 | Cost/Loss: 0.077645 | Weight: 0.528432 | Bias: 0.069663\n",
            "Iteration: 45694 | Cost/Loss: 0.077645 | Weight: 0.528432 | Bias: 0.069663\n",
            "Iteration: 45695 | Cost/Loss: 0.077645 | Weight: 0.528433 | Bias: 0.069664\n",
            "Iteration: 45696 | Cost/Loss: 0.077645 | Weight: 0.528433 | Bias: 0.069664\n",
            "Iteration: 45697 | Cost/Loss: 0.077645 | Weight: 0.528433 | Bias: 0.069664\n",
            "Iteration: 45698 | Cost/Loss: 0.077645 | Weight: 0.528433 | Bias: 0.069665\n",
            "Iteration: 45699 | Cost/Loss: 0.077645 | Weight: 0.528434 | Bias: 0.069665\n",
            "Iteration: 45700 | Cost/Loss: 0.077645 | Weight: 0.528434 | Bias: 0.069665\n",
            "Iteration: 45701 | Cost/Loss: 0.077645 | Weight: 0.528434 | Bias: 0.069666\n",
            "Iteration: 45702 | Cost/Loss: 0.077645 | Weight: 0.528435 | Bias: 0.069666\n",
            "Iteration: 45703 | Cost/Loss: 0.077645 | Weight: 0.528435 | Bias: 0.069666\n",
            "Iteration: 45704 | Cost/Loss: 0.077645 | Weight: 0.528435 | Bias: 0.069666\n",
            "Iteration: 45705 | Cost/Loss: 0.077645 | Weight: 0.528436 | Bias: 0.069667\n",
            "Iteration: 45706 | Cost/Loss: 0.077645 | Weight: 0.528436 | Bias: 0.069667\n",
            "Iteration: 45707 | Cost/Loss: 0.077645 | Weight: 0.528436 | Bias: 0.069667\n",
            "Iteration: 45708 | Cost/Loss: 0.077645 | Weight: 0.528436 | Bias: 0.069668\n",
            "Iteration: 45709 | Cost/Loss: 0.077645 | Weight: 0.528437 | Bias: 0.069668\n",
            "Iteration: 45710 | Cost/Loss: 0.077645 | Weight: 0.528437 | Bias: 0.069668\n",
            "Iteration: 45711 | Cost/Loss: 0.077645 | Weight: 0.528437 | Bias: 0.069669\n",
            "Iteration: 45712 | Cost/Loss: 0.077644 | Weight: 0.528438 | Bias: 0.069669\n",
            "Iteration: 45713 | Cost/Loss: 0.077644 | Weight: 0.528438 | Bias: 0.069669\n",
            "Iteration: 45714 | Cost/Loss: 0.077644 | Weight: 0.528438 | Bias: 0.069670\n",
            "Iteration: 45715 | Cost/Loss: 0.077644 | Weight: 0.528439 | Bias: 0.069670\n",
            "Iteration: 45716 | Cost/Loss: 0.077644 | Weight: 0.528439 | Bias: 0.069670\n",
            "Iteration: 45717 | Cost/Loss: 0.077644 | Weight: 0.528439 | Bias: 0.069671\n",
            "Iteration: 45718 | Cost/Loss: 0.077644 | Weight: 0.528439 | Bias: 0.069671\n",
            "Iteration: 45719 | Cost/Loss: 0.077644 | Weight: 0.528440 | Bias: 0.069671\n",
            "Iteration: 45720 | Cost/Loss: 0.077644 | Weight: 0.528440 | Bias: 0.069672\n",
            "Iteration: 45721 | Cost/Loss: 0.077644 | Weight: 0.528440 | Bias: 0.069672\n",
            "Iteration: 45722 | Cost/Loss: 0.077644 | Weight: 0.528441 | Bias: 0.069672\n",
            "Iteration: 45723 | Cost/Loss: 0.077644 | Weight: 0.528441 | Bias: 0.069673\n",
            "Iteration: 45724 | Cost/Loss: 0.077644 | Weight: 0.528441 | Bias: 0.069673\n",
            "Iteration: 45725 | Cost/Loss: 0.077644 | Weight: 0.528441 | Bias: 0.069673\n",
            "Iteration: 45726 | Cost/Loss: 0.077644 | Weight: 0.528442 | Bias: 0.069674\n",
            "Iteration: 45727 | Cost/Loss: 0.077644 | Weight: 0.528442 | Bias: 0.069674\n",
            "Iteration: 45728 | Cost/Loss: 0.077644 | Weight: 0.528442 | Bias: 0.069674\n",
            "Iteration: 45729 | Cost/Loss: 0.077644 | Weight: 0.528443 | Bias: 0.069674\n",
            "Iteration: 45730 | Cost/Loss: 0.077644 | Weight: 0.528443 | Bias: 0.069675\n",
            "Iteration: 45731 | Cost/Loss: 0.077644 | Weight: 0.528443 | Bias: 0.069675\n",
            "Iteration: 45732 | Cost/Loss: 0.077644 | Weight: 0.528444 | Bias: 0.069675\n",
            "Iteration: 45733 | Cost/Loss: 0.077644 | Weight: 0.528444 | Bias: 0.069676\n",
            "Iteration: 45734 | Cost/Loss: 0.077644 | Weight: 0.528444 | Bias: 0.069676\n",
            "Iteration: 45735 | Cost/Loss: 0.077644 | Weight: 0.528444 | Bias: 0.069676\n",
            "Iteration: 45736 | Cost/Loss: 0.077644 | Weight: 0.528445 | Bias: 0.069677\n",
            "Iteration: 45737 | Cost/Loss: 0.077644 | Weight: 0.528445 | Bias: 0.069677\n",
            "Iteration: 45738 | Cost/Loss: 0.077644 | Weight: 0.528445 | Bias: 0.069677\n",
            "Iteration: 45739 | Cost/Loss: 0.077644 | Weight: 0.528446 | Bias: 0.069678\n",
            "Iteration: 45740 | Cost/Loss: 0.077644 | Weight: 0.528446 | Bias: 0.069678\n",
            "Iteration: 45741 | Cost/Loss: 0.077644 | Weight: 0.528446 | Bias: 0.069678\n",
            "Iteration: 45742 | Cost/Loss: 0.077644 | Weight: 0.528447 | Bias: 0.069679\n",
            "Iteration: 45743 | Cost/Loss: 0.077644 | Weight: 0.528447 | Bias: 0.069679\n",
            "Iteration: 45744 | Cost/Loss: 0.077644 | Weight: 0.528447 | Bias: 0.069679\n",
            "Iteration: 45745 | Cost/Loss: 0.077644 | Weight: 0.528447 | Bias: 0.069680\n",
            "Iteration: 45746 | Cost/Loss: 0.077644 | Weight: 0.528448 | Bias: 0.069680\n",
            "Iteration: 45747 | Cost/Loss: 0.077644 | Weight: 0.528448 | Bias: 0.069680\n",
            "Iteration: 45748 | Cost/Loss: 0.077644 | Weight: 0.528448 | Bias: 0.069681\n",
            "Iteration: 45749 | Cost/Loss: 0.077644 | Weight: 0.528449 | Bias: 0.069681\n",
            "Iteration: 45750 | Cost/Loss: 0.077644 | Weight: 0.528449 | Bias: 0.069681\n",
            "Iteration: 45751 | Cost/Loss: 0.077644 | Weight: 0.528449 | Bias: 0.069682\n",
            "Iteration: 45752 | Cost/Loss: 0.077643 | Weight: 0.528450 | Bias: 0.069682\n",
            "Iteration: 45753 | Cost/Loss: 0.077643 | Weight: 0.528450 | Bias: 0.069682\n",
            "Iteration: 45754 | Cost/Loss: 0.077643 | Weight: 0.528450 | Bias: 0.069682\n",
            "Iteration: 45755 | Cost/Loss: 0.077643 | Weight: 0.528450 | Bias: 0.069683\n",
            "Iteration: 45756 | Cost/Loss: 0.077643 | Weight: 0.528451 | Bias: 0.069683\n",
            "Iteration: 45757 | Cost/Loss: 0.077643 | Weight: 0.528451 | Bias: 0.069683\n",
            "Iteration: 45758 | Cost/Loss: 0.077643 | Weight: 0.528451 | Bias: 0.069684\n",
            "Iteration: 45759 | Cost/Loss: 0.077643 | Weight: 0.528452 | Bias: 0.069684\n",
            "Iteration: 45760 | Cost/Loss: 0.077643 | Weight: 0.528452 | Bias: 0.069684\n",
            "Iteration: 45761 | Cost/Loss: 0.077643 | Weight: 0.528452 | Bias: 0.069685\n",
            "Iteration: 45762 | Cost/Loss: 0.077643 | Weight: 0.528453 | Bias: 0.069685\n",
            "Iteration: 45763 | Cost/Loss: 0.077643 | Weight: 0.528453 | Bias: 0.069685\n",
            "Iteration: 45764 | Cost/Loss: 0.077643 | Weight: 0.528453 | Bias: 0.069686\n",
            "Iteration: 45765 | Cost/Loss: 0.077643 | Weight: 0.528453 | Bias: 0.069686\n",
            "Iteration: 45766 | Cost/Loss: 0.077643 | Weight: 0.528454 | Bias: 0.069686\n",
            "Iteration: 45767 | Cost/Loss: 0.077643 | Weight: 0.528454 | Bias: 0.069687\n",
            "Iteration: 45768 | Cost/Loss: 0.077643 | Weight: 0.528454 | Bias: 0.069687\n",
            "Iteration: 45769 | Cost/Loss: 0.077643 | Weight: 0.528455 | Bias: 0.069687\n",
            "Iteration: 45770 | Cost/Loss: 0.077643 | Weight: 0.528455 | Bias: 0.069688\n",
            "Iteration: 45771 | Cost/Loss: 0.077643 | Weight: 0.528455 | Bias: 0.069688\n",
            "Iteration: 45772 | Cost/Loss: 0.077643 | Weight: 0.528455 | Bias: 0.069688\n",
            "Iteration: 45773 | Cost/Loss: 0.077643 | Weight: 0.528456 | Bias: 0.069689\n",
            "Iteration: 45774 | Cost/Loss: 0.077643 | Weight: 0.528456 | Bias: 0.069689\n",
            "Iteration: 45775 | Cost/Loss: 0.077643 | Weight: 0.528456 | Bias: 0.069689\n",
            "Iteration: 45776 | Cost/Loss: 0.077643 | Weight: 0.528457 | Bias: 0.069690\n",
            "Iteration: 45777 | Cost/Loss: 0.077643 | Weight: 0.528457 | Bias: 0.069690\n",
            "Iteration: 45778 | Cost/Loss: 0.077643 | Weight: 0.528457 | Bias: 0.069690\n",
            "Iteration: 45779 | Cost/Loss: 0.077643 | Weight: 0.528458 | Bias: 0.069690\n",
            "Iteration: 45780 | Cost/Loss: 0.077643 | Weight: 0.528458 | Bias: 0.069691\n",
            "Iteration: 45781 | Cost/Loss: 0.077643 | Weight: 0.528458 | Bias: 0.069691\n",
            "Iteration: 45782 | Cost/Loss: 0.077643 | Weight: 0.528458 | Bias: 0.069691\n",
            "Iteration: 45783 | Cost/Loss: 0.077643 | Weight: 0.528459 | Bias: 0.069692\n",
            "Iteration: 45784 | Cost/Loss: 0.077643 | Weight: 0.528459 | Bias: 0.069692\n",
            "Iteration: 45785 | Cost/Loss: 0.077643 | Weight: 0.528459 | Bias: 0.069692\n",
            "Iteration: 45786 | Cost/Loss: 0.077643 | Weight: 0.528460 | Bias: 0.069693\n",
            "Iteration: 45787 | Cost/Loss: 0.077643 | Weight: 0.528460 | Bias: 0.069693\n",
            "Iteration: 45788 | Cost/Loss: 0.077643 | Weight: 0.528460 | Bias: 0.069693\n",
            "Iteration: 45789 | Cost/Loss: 0.077643 | Weight: 0.528461 | Bias: 0.069694\n",
            "Iteration: 45790 | Cost/Loss: 0.077643 | Weight: 0.528461 | Bias: 0.069694\n",
            "Iteration: 45791 | Cost/Loss: 0.077643 | Weight: 0.528461 | Bias: 0.069694\n",
            "Iteration: 45792 | Cost/Loss: 0.077642 | Weight: 0.528461 | Bias: 0.069695\n",
            "Iteration: 45793 | Cost/Loss: 0.077642 | Weight: 0.528462 | Bias: 0.069695\n",
            "Iteration: 45794 | Cost/Loss: 0.077642 | Weight: 0.528462 | Bias: 0.069695\n",
            "Iteration: 45795 | Cost/Loss: 0.077642 | Weight: 0.528462 | Bias: 0.069696\n",
            "Iteration: 45796 | Cost/Loss: 0.077642 | Weight: 0.528463 | Bias: 0.069696\n",
            "Iteration: 45797 | Cost/Loss: 0.077642 | Weight: 0.528463 | Bias: 0.069696\n",
            "Iteration: 45798 | Cost/Loss: 0.077642 | Weight: 0.528463 | Bias: 0.069697\n",
            "Iteration: 45799 | Cost/Loss: 0.077642 | Weight: 0.528464 | Bias: 0.069697\n",
            "Iteration: 45800 | Cost/Loss: 0.077642 | Weight: 0.528464 | Bias: 0.069697\n",
            "Iteration: 45801 | Cost/Loss: 0.077642 | Weight: 0.528464 | Bias: 0.069698\n",
            "Iteration: 45802 | Cost/Loss: 0.077642 | Weight: 0.528464 | Bias: 0.069698\n",
            "Iteration: 45803 | Cost/Loss: 0.077642 | Weight: 0.528465 | Bias: 0.069698\n",
            "Iteration: 45804 | Cost/Loss: 0.077642 | Weight: 0.528465 | Bias: 0.069699\n",
            "Iteration: 45805 | Cost/Loss: 0.077642 | Weight: 0.528465 | Bias: 0.069699\n",
            "Iteration: 45806 | Cost/Loss: 0.077642 | Weight: 0.528466 | Bias: 0.069699\n",
            "Iteration: 45807 | Cost/Loss: 0.077642 | Weight: 0.528466 | Bias: 0.069699\n",
            "Iteration: 45808 | Cost/Loss: 0.077642 | Weight: 0.528466 | Bias: 0.069700\n",
            "Iteration: 45809 | Cost/Loss: 0.077642 | Weight: 0.528467 | Bias: 0.069700\n",
            "Iteration: 45810 | Cost/Loss: 0.077642 | Weight: 0.528467 | Bias: 0.069700\n",
            "Iteration: 45811 | Cost/Loss: 0.077642 | Weight: 0.528467 | Bias: 0.069701\n",
            "Iteration: 45812 | Cost/Loss: 0.077642 | Weight: 0.528467 | Bias: 0.069701\n",
            "Iteration: 45813 | Cost/Loss: 0.077642 | Weight: 0.528468 | Bias: 0.069701\n",
            "Iteration: 45814 | Cost/Loss: 0.077642 | Weight: 0.528468 | Bias: 0.069702\n",
            "Iteration: 45815 | Cost/Loss: 0.077642 | Weight: 0.528468 | Bias: 0.069702\n",
            "Iteration: 45816 | Cost/Loss: 0.077642 | Weight: 0.528469 | Bias: 0.069702\n",
            "Iteration: 45817 | Cost/Loss: 0.077642 | Weight: 0.528469 | Bias: 0.069703\n",
            "Iteration: 45818 | Cost/Loss: 0.077642 | Weight: 0.528469 | Bias: 0.069703\n",
            "Iteration: 45819 | Cost/Loss: 0.077642 | Weight: 0.528470 | Bias: 0.069703\n",
            "Iteration: 45820 | Cost/Loss: 0.077642 | Weight: 0.528470 | Bias: 0.069704\n",
            "Iteration: 45821 | Cost/Loss: 0.077642 | Weight: 0.528470 | Bias: 0.069704\n",
            "Iteration: 45822 | Cost/Loss: 0.077642 | Weight: 0.528470 | Bias: 0.069704\n",
            "Iteration: 45823 | Cost/Loss: 0.077642 | Weight: 0.528471 | Bias: 0.069705\n",
            "Iteration: 45824 | Cost/Loss: 0.077642 | Weight: 0.528471 | Bias: 0.069705\n",
            "Iteration: 45825 | Cost/Loss: 0.077642 | Weight: 0.528471 | Bias: 0.069705\n",
            "Iteration: 45826 | Cost/Loss: 0.077642 | Weight: 0.528472 | Bias: 0.069706\n",
            "Iteration: 45827 | Cost/Loss: 0.077642 | Weight: 0.528472 | Bias: 0.069706\n",
            "Iteration: 45828 | Cost/Loss: 0.077642 | Weight: 0.528472 | Bias: 0.069706\n",
            "Iteration: 45829 | Cost/Loss: 0.077642 | Weight: 0.528472 | Bias: 0.069707\n",
            "Iteration: 45830 | Cost/Loss: 0.077642 | Weight: 0.528473 | Bias: 0.069707\n",
            "Iteration: 45831 | Cost/Loss: 0.077641 | Weight: 0.528473 | Bias: 0.069707\n",
            "Iteration: 45832 | Cost/Loss: 0.077641 | Weight: 0.528473 | Bias: 0.069707\n",
            "Iteration: 45833 | Cost/Loss: 0.077641 | Weight: 0.528474 | Bias: 0.069708\n",
            "Iteration: 45834 | Cost/Loss: 0.077641 | Weight: 0.528474 | Bias: 0.069708\n",
            "Iteration: 45835 | Cost/Loss: 0.077641 | Weight: 0.528474 | Bias: 0.069708\n",
            "Iteration: 45836 | Cost/Loss: 0.077641 | Weight: 0.528475 | Bias: 0.069709\n",
            "Iteration: 45837 | Cost/Loss: 0.077641 | Weight: 0.528475 | Bias: 0.069709\n",
            "Iteration: 45838 | Cost/Loss: 0.077641 | Weight: 0.528475 | Bias: 0.069709\n",
            "Iteration: 45839 | Cost/Loss: 0.077641 | Weight: 0.528475 | Bias: 0.069710\n",
            "Iteration: 45840 | Cost/Loss: 0.077641 | Weight: 0.528476 | Bias: 0.069710\n",
            "Iteration: 45841 | Cost/Loss: 0.077641 | Weight: 0.528476 | Bias: 0.069710\n",
            "Iteration: 45842 | Cost/Loss: 0.077641 | Weight: 0.528476 | Bias: 0.069711\n",
            "Iteration: 45843 | Cost/Loss: 0.077641 | Weight: 0.528477 | Bias: 0.069711\n",
            "Iteration: 45844 | Cost/Loss: 0.077641 | Weight: 0.528477 | Bias: 0.069711\n",
            "Iteration: 45845 | Cost/Loss: 0.077641 | Weight: 0.528477 | Bias: 0.069712\n",
            "Iteration: 45846 | Cost/Loss: 0.077641 | Weight: 0.528478 | Bias: 0.069712\n",
            "Iteration: 45847 | Cost/Loss: 0.077641 | Weight: 0.528478 | Bias: 0.069712\n",
            "Iteration: 45848 | Cost/Loss: 0.077641 | Weight: 0.528478 | Bias: 0.069713\n",
            "Iteration: 45849 | Cost/Loss: 0.077641 | Weight: 0.528478 | Bias: 0.069713\n",
            "Iteration: 45850 | Cost/Loss: 0.077641 | Weight: 0.528479 | Bias: 0.069713\n",
            "Iteration: 45851 | Cost/Loss: 0.077641 | Weight: 0.528479 | Bias: 0.069714\n",
            "Iteration: 45852 | Cost/Loss: 0.077641 | Weight: 0.528479 | Bias: 0.069714\n",
            "Iteration: 45853 | Cost/Loss: 0.077641 | Weight: 0.528480 | Bias: 0.069714\n",
            "Iteration: 45854 | Cost/Loss: 0.077641 | Weight: 0.528480 | Bias: 0.069715\n",
            "Iteration: 45855 | Cost/Loss: 0.077641 | Weight: 0.528480 | Bias: 0.069715\n",
            "Iteration: 45856 | Cost/Loss: 0.077641 | Weight: 0.528481 | Bias: 0.069715\n",
            "Iteration: 45857 | Cost/Loss: 0.077641 | Weight: 0.528481 | Bias: 0.069715\n",
            "Iteration: 45858 | Cost/Loss: 0.077641 | Weight: 0.528481 | Bias: 0.069716\n",
            "Iteration: 45859 | Cost/Loss: 0.077641 | Weight: 0.528481 | Bias: 0.069716\n",
            "Iteration: 45860 | Cost/Loss: 0.077641 | Weight: 0.528482 | Bias: 0.069716\n",
            "Iteration: 45861 | Cost/Loss: 0.077641 | Weight: 0.528482 | Bias: 0.069717\n",
            "Iteration: 45862 | Cost/Loss: 0.077641 | Weight: 0.528482 | Bias: 0.069717\n",
            "Iteration: 45863 | Cost/Loss: 0.077641 | Weight: 0.528483 | Bias: 0.069717\n",
            "Iteration: 45864 | Cost/Loss: 0.077641 | Weight: 0.528483 | Bias: 0.069718\n",
            "Iteration: 45865 | Cost/Loss: 0.077641 | Weight: 0.528483 | Bias: 0.069718\n",
            "Iteration: 45866 | Cost/Loss: 0.077641 | Weight: 0.528484 | Bias: 0.069718\n",
            "Iteration: 45867 | Cost/Loss: 0.077641 | Weight: 0.528484 | Bias: 0.069719\n",
            "Iteration: 45868 | Cost/Loss: 0.077641 | Weight: 0.528484 | Bias: 0.069719\n",
            "Iteration: 45869 | Cost/Loss: 0.077641 | Weight: 0.528484 | Bias: 0.069719\n",
            "Iteration: 45870 | Cost/Loss: 0.077641 | Weight: 0.528485 | Bias: 0.069720\n",
            "Iteration: 45871 | Cost/Loss: 0.077640 | Weight: 0.528485 | Bias: 0.069720\n",
            "Iteration: 45872 | Cost/Loss: 0.077640 | Weight: 0.528485 | Bias: 0.069720\n",
            "Iteration: 45873 | Cost/Loss: 0.077640 | Weight: 0.528486 | Bias: 0.069721\n",
            "Iteration: 45874 | Cost/Loss: 0.077640 | Weight: 0.528486 | Bias: 0.069721\n",
            "Iteration: 45875 | Cost/Loss: 0.077640 | Weight: 0.528486 | Bias: 0.069721\n",
            "Iteration: 45876 | Cost/Loss: 0.077640 | Weight: 0.528486 | Bias: 0.069722\n",
            "Iteration: 45877 | Cost/Loss: 0.077640 | Weight: 0.528487 | Bias: 0.069722\n",
            "Iteration: 45878 | Cost/Loss: 0.077640 | Weight: 0.528487 | Bias: 0.069722\n",
            "Iteration: 45879 | Cost/Loss: 0.077640 | Weight: 0.528487 | Bias: 0.069723\n",
            "Iteration: 45880 | Cost/Loss: 0.077640 | Weight: 0.528488 | Bias: 0.069723\n",
            "Iteration: 45881 | Cost/Loss: 0.077640 | Weight: 0.528488 | Bias: 0.069723\n",
            "Iteration: 45882 | Cost/Loss: 0.077640 | Weight: 0.528488 | Bias: 0.069723\n",
            "Iteration: 45883 | Cost/Loss: 0.077640 | Weight: 0.528489 | Bias: 0.069724\n",
            "Iteration: 45884 | Cost/Loss: 0.077640 | Weight: 0.528489 | Bias: 0.069724\n",
            "Iteration: 45885 | Cost/Loss: 0.077640 | Weight: 0.528489 | Bias: 0.069724\n",
            "Iteration: 45886 | Cost/Loss: 0.077640 | Weight: 0.528489 | Bias: 0.069725\n",
            "Iteration: 45887 | Cost/Loss: 0.077640 | Weight: 0.528490 | Bias: 0.069725\n",
            "Iteration: 45888 | Cost/Loss: 0.077640 | Weight: 0.528490 | Bias: 0.069725\n",
            "Iteration: 45889 | Cost/Loss: 0.077640 | Weight: 0.528490 | Bias: 0.069726\n",
            "Iteration: 45890 | Cost/Loss: 0.077640 | Weight: 0.528491 | Bias: 0.069726\n",
            "Iteration: 45891 | Cost/Loss: 0.077640 | Weight: 0.528491 | Bias: 0.069726\n",
            "Iteration: 45892 | Cost/Loss: 0.077640 | Weight: 0.528491 | Bias: 0.069727\n",
            "Iteration: 45893 | Cost/Loss: 0.077640 | Weight: 0.528492 | Bias: 0.069727\n",
            "Iteration: 45894 | Cost/Loss: 0.077640 | Weight: 0.528492 | Bias: 0.069727\n",
            "Iteration: 45895 | Cost/Loss: 0.077640 | Weight: 0.528492 | Bias: 0.069728\n",
            "Iteration: 45896 | Cost/Loss: 0.077640 | Weight: 0.528492 | Bias: 0.069728\n",
            "Iteration: 45897 | Cost/Loss: 0.077640 | Weight: 0.528493 | Bias: 0.069728\n",
            "Iteration: 45898 | Cost/Loss: 0.077640 | Weight: 0.528493 | Bias: 0.069729\n",
            "Iteration: 45899 | Cost/Loss: 0.077640 | Weight: 0.528493 | Bias: 0.069729\n",
            "Iteration: 45900 | Cost/Loss: 0.077640 | Weight: 0.528494 | Bias: 0.069729\n",
            "Iteration: 45901 | Cost/Loss: 0.077640 | Weight: 0.528494 | Bias: 0.069730\n",
            "Iteration: 45902 | Cost/Loss: 0.077640 | Weight: 0.528494 | Bias: 0.069730\n",
            "Iteration: 45903 | Cost/Loss: 0.077640 | Weight: 0.528495 | Bias: 0.069730\n",
            "Iteration: 45904 | Cost/Loss: 0.077640 | Weight: 0.528495 | Bias: 0.069731\n",
            "Iteration: 45905 | Cost/Loss: 0.077640 | Weight: 0.528495 | Bias: 0.069731\n",
            "Iteration: 45906 | Cost/Loss: 0.077640 | Weight: 0.528495 | Bias: 0.069731\n",
            "Iteration: 45907 | Cost/Loss: 0.077640 | Weight: 0.528496 | Bias: 0.069732\n",
            "Iteration: 45908 | Cost/Loss: 0.077640 | Weight: 0.528496 | Bias: 0.069732\n",
            "Iteration: 45909 | Cost/Loss: 0.077640 | Weight: 0.528496 | Bias: 0.069732\n",
            "Iteration: 45910 | Cost/Loss: 0.077639 | Weight: 0.528497 | Bias: 0.069732\n",
            "Iteration: 45911 | Cost/Loss: 0.077639 | Weight: 0.528497 | Bias: 0.069733\n",
            "Iteration: 45912 | Cost/Loss: 0.077639 | Weight: 0.528497 | Bias: 0.069733\n",
            "Iteration: 45913 | Cost/Loss: 0.077639 | Weight: 0.528498 | Bias: 0.069733\n",
            "Iteration: 45914 | Cost/Loss: 0.077639 | Weight: 0.528498 | Bias: 0.069734\n",
            "Iteration: 45915 | Cost/Loss: 0.077639 | Weight: 0.528498 | Bias: 0.069734\n",
            "Iteration: 45916 | Cost/Loss: 0.077639 | Weight: 0.528498 | Bias: 0.069734\n",
            "Iteration: 45917 | Cost/Loss: 0.077639 | Weight: 0.528499 | Bias: 0.069735\n",
            "Iteration: 45918 | Cost/Loss: 0.077639 | Weight: 0.528499 | Bias: 0.069735\n",
            "Iteration: 45919 | Cost/Loss: 0.077639 | Weight: 0.528499 | Bias: 0.069735\n",
            "Iteration: 45920 | Cost/Loss: 0.077639 | Weight: 0.528500 | Bias: 0.069736\n",
            "Iteration: 45921 | Cost/Loss: 0.077639 | Weight: 0.528500 | Bias: 0.069736\n",
            "Iteration: 45922 | Cost/Loss: 0.077639 | Weight: 0.528500 | Bias: 0.069736\n",
            "Iteration: 45923 | Cost/Loss: 0.077639 | Weight: 0.528500 | Bias: 0.069737\n",
            "Iteration: 45924 | Cost/Loss: 0.077639 | Weight: 0.528501 | Bias: 0.069737\n",
            "Iteration: 45925 | Cost/Loss: 0.077639 | Weight: 0.528501 | Bias: 0.069737\n",
            "Iteration: 45926 | Cost/Loss: 0.077639 | Weight: 0.528501 | Bias: 0.069738\n",
            "Iteration: 45927 | Cost/Loss: 0.077639 | Weight: 0.528502 | Bias: 0.069738\n",
            "Iteration: 45928 | Cost/Loss: 0.077639 | Weight: 0.528502 | Bias: 0.069738\n",
            "Iteration: 45929 | Cost/Loss: 0.077639 | Weight: 0.528502 | Bias: 0.069739\n",
            "Iteration: 45930 | Cost/Loss: 0.077639 | Weight: 0.528503 | Bias: 0.069739\n",
            "Iteration: 45931 | Cost/Loss: 0.077639 | Weight: 0.528503 | Bias: 0.069739\n",
            "Iteration: 45932 | Cost/Loss: 0.077639 | Weight: 0.528503 | Bias: 0.069740\n",
            "Iteration: 45933 | Cost/Loss: 0.077639 | Weight: 0.528503 | Bias: 0.069740\n",
            "Iteration: 45934 | Cost/Loss: 0.077639 | Weight: 0.528504 | Bias: 0.069740\n",
            "Iteration: 45935 | Cost/Loss: 0.077639 | Weight: 0.528504 | Bias: 0.069740\n",
            "Iteration: 45936 | Cost/Loss: 0.077639 | Weight: 0.528504 | Bias: 0.069741\n",
            "Iteration: 45937 | Cost/Loss: 0.077639 | Weight: 0.528505 | Bias: 0.069741\n",
            "Iteration: 45938 | Cost/Loss: 0.077639 | Weight: 0.528505 | Bias: 0.069741\n",
            "Iteration: 45939 | Cost/Loss: 0.077639 | Weight: 0.528505 | Bias: 0.069742\n",
            "Iteration: 45940 | Cost/Loss: 0.077639 | Weight: 0.528506 | Bias: 0.069742\n",
            "Iteration: 45941 | Cost/Loss: 0.077639 | Weight: 0.528506 | Bias: 0.069742\n",
            "Iteration: 45942 | Cost/Loss: 0.077639 | Weight: 0.528506 | Bias: 0.069743\n",
            "Iteration: 45943 | Cost/Loss: 0.077639 | Weight: 0.528506 | Bias: 0.069743\n",
            "Iteration: 45944 | Cost/Loss: 0.077639 | Weight: 0.528507 | Bias: 0.069743\n",
            "Iteration: 45945 | Cost/Loss: 0.077639 | Weight: 0.528507 | Bias: 0.069744\n",
            "Iteration: 45946 | Cost/Loss: 0.077639 | Weight: 0.528507 | Bias: 0.069744\n",
            "Iteration: 45947 | Cost/Loss: 0.077639 | Weight: 0.528508 | Bias: 0.069744\n",
            "Iteration: 45948 | Cost/Loss: 0.077639 | Weight: 0.528508 | Bias: 0.069745\n",
            "Iteration: 45949 | Cost/Loss: 0.077639 | Weight: 0.528508 | Bias: 0.069745\n",
            "Iteration: 45950 | Cost/Loss: 0.077638 | Weight: 0.528509 | Bias: 0.069745\n",
            "Iteration: 45951 | Cost/Loss: 0.077638 | Weight: 0.528509 | Bias: 0.069746\n",
            "Iteration: 45952 | Cost/Loss: 0.077638 | Weight: 0.528509 | Bias: 0.069746\n",
            "Iteration: 45953 | Cost/Loss: 0.077638 | Weight: 0.528509 | Bias: 0.069746\n",
            "Iteration: 45954 | Cost/Loss: 0.077638 | Weight: 0.528510 | Bias: 0.069747\n",
            "Iteration: 45955 | Cost/Loss: 0.077638 | Weight: 0.528510 | Bias: 0.069747\n",
            "Iteration: 45956 | Cost/Loss: 0.077638 | Weight: 0.528510 | Bias: 0.069747\n",
            "Iteration: 45957 | Cost/Loss: 0.077638 | Weight: 0.528511 | Bias: 0.069748\n",
            "Iteration: 45958 | Cost/Loss: 0.077638 | Weight: 0.528511 | Bias: 0.069748\n",
            "Iteration: 45959 | Cost/Loss: 0.077638 | Weight: 0.528511 | Bias: 0.069748\n",
            "Iteration: 45960 | Cost/Loss: 0.077638 | Weight: 0.528512 | Bias: 0.069748\n",
            "Iteration: 45961 | Cost/Loss: 0.077638 | Weight: 0.528512 | Bias: 0.069749\n",
            "Iteration: 45962 | Cost/Loss: 0.077638 | Weight: 0.528512 | Bias: 0.069749\n",
            "Iteration: 45963 | Cost/Loss: 0.077638 | Weight: 0.528512 | Bias: 0.069749\n",
            "Iteration: 45964 | Cost/Loss: 0.077638 | Weight: 0.528513 | Bias: 0.069750\n",
            "Iteration: 45965 | Cost/Loss: 0.077638 | Weight: 0.528513 | Bias: 0.069750\n",
            "Iteration: 45966 | Cost/Loss: 0.077638 | Weight: 0.528513 | Bias: 0.069750\n",
            "Iteration: 45967 | Cost/Loss: 0.077638 | Weight: 0.528514 | Bias: 0.069751\n",
            "Iteration: 45968 | Cost/Loss: 0.077638 | Weight: 0.528514 | Bias: 0.069751\n",
            "Iteration: 45969 | Cost/Loss: 0.077638 | Weight: 0.528514 | Bias: 0.069751\n",
            "Iteration: 45970 | Cost/Loss: 0.077638 | Weight: 0.528515 | Bias: 0.069752\n",
            "Iteration: 45971 | Cost/Loss: 0.077638 | Weight: 0.528515 | Bias: 0.069752\n",
            "Iteration: 45972 | Cost/Loss: 0.077638 | Weight: 0.528515 | Bias: 0.069752\n",
            "Iteration: 45973 | Cost/Loss: 0.077638 | Weight: 0.528515 | Bias: 0.069753\n",
            "Iteration: 45974 | Cost/Loss: 0.077638 | Weight: 0.528516 | Bias: 0.069753\n",
            "Iteration: 45975 | Cost/Loss: 0.077638 | Weight: 0.528516 | Bias: 0.069753\n",
            "Iteration: 45976 | Cost/Loss: 0.077638 | Weight: 0.528516 | Bias: 0.069754\n",
            "Iteration: 45977 | Cost/Loss: 0.077638 | Weight: 0.528517 | Bias: 0.069754\n",
            "Iteration: 45978 | Cost/Loss: 0.077638 | Weight: 0.528517 | Bias: 0.069754\n",
            "Iteration: 45979 | Cost/Loss: 0.077638 | Weight: 0.528517 | Bias: 0.069755\n",
            "Iteration: 45980 | Cost/Loss: 0.077638 | Weight: 0.528517 | Bias: 0.069755\n",
            "Iteration: 45981 | Cost/Loss: 0.077638 | Weight: 0.528518 | Bias: 0.069755\n",
            "Iteration: 45982 | Cost/Loss: 0.077638 | Weight: 0.528518 | Bias: 0.069756\n",
            "Iteration: 45983 | Cost/Loss: 0.077638 | Weight: 0.528518 | Bias: 0.069756\n",
            "Iteration: 45984 | Cost/Loss: 0.077638 | Weight: 0.528519 | Bias: 0.069756\n",
            "Iteration: 45985 | Cost/Loss: 0.077638 | Weight: 0.528519 | Bias: 0.069756\n",
            "Iteration: 45986 | Cost/Loss: 0.077638 | Weight: 0.528519 | Bias: 0.069757\n",
            "Iteration: 45987 | Cost/Loss: 0.077638 | Weight: 0.528520 | Bias: 0.069757\n",
            "Iteration: 45988 | Cost/Loss: 0.077638 | Weight: 0.528520 | Bias: 0.069757\n",
            "Iteration: 45989 | Cost/Loss: 0.077638 | Weight: 0.528520 | Bias: 0.069758\n",
            "Iteration: 45990 | Cost/Loss: 0.077637 | Weight: 0.528520 | Bias: 0.069758\n",
            "Iteration: 45991 | Cost/Loss: 0.077637 | Weight: 0.528521 | Bias: 0.069758\n",
            "Iteration: 45992 | Cost/Loss: 0.077637 | Weight: 0.528521 | Bias: 0.069759\n",
            "Iteration: 45993 | Cost/Loss: 0.077637 | Weight: 0.528521 | Bias: 0.069759\n",
            "Iteration: 45994 | Cost/Loss: 0.077637 | Weight: 0.528522 | Bias: 0.069759\n",
            "Iteration: 45995 | Cost/Loss: 0.077637 | Weight: 0.528522 | Bias: 0.069760\n",
            "Iteration: 45996 | Cost/Loss: 0.077637 | Weight: 0.528522 | Bias: 0.069760\n",
            "Iteration: 45997 | Cost/Loss: 0.077637 | Weight: 0.528523 | Bias: 0.069760\n",
            "Iteration: 45998 | Cost/Loss: 0.077637 | Weight: 0.528523 | Bias: 0.069761\n",
            "Iteration: 45999 | Cost/Loss: 0.077637 | Weight: 0.528523 | Bias: 0.069761\n",
            "Iteration: 46000 | Cost/Loss: 0.077637 | Weight: 0.528523 | Bias: 0.069761\n",
            "Iteration: 46001 | Cost/Loss: 0.077637 | Weight: 0.528524 | Bias: 0.069762\n",
            "Iteration: 46002 | Cost/Loss: 0.077637 | Weight: 0.528524 | Bias: 0.069762\n",
            "Iteration: 46003 | Cost/Loss: 0.077637 | Weight: 0.528524 | Bias: 0.069762\n",
            "Iteration: 46004 | Cost/Loss: 0.077637 | Weight: 0.528525 | Bias: 0.069763\n",
            "Iteration: 46005 | Cost/Loss: 0.077637 | Weight: 0.528525 | Bias: 0.069763\n",
            "Iteration: 46006 | Cost/Loss: 0.077637 | Weight: 0.528525 | Bias: 0.069763\n",
            "Iteration: 46007 | Cost/Loss: 0.077637 | Weight: 0.528526 | Bias: 0.069764\n",
            "Iteration: 46008 | Cost/Loss: 0.077637 | Weight: 0.528526 | Bias: 0.069764\n",
            "Iteration: 46009 | Cost/Loss: 0.077637 | Weight: 0.528526 | Bias: 0.069764\n",
            "Iteration: 46010 | Cost/Loss: 0.077637 | Weight: 0.528526 | Bias: 0.069765\n",
            "Iteration: 46011 | Cost/Loss: 0.077637 | Weight: 0.528527 | Bias: 0.069765\n",
            "Iteration: 46012 | Cost/Loss: 0.077637 | Weight: 0.528527 | Bias: 0.069765\n",
            "Iteration: 46013 | Cost/Loss: 0.077637 | Weight: 0.528527 | Bias: 0.069765\n",
            "Iteration: 46014 | Cost/Loss: 0.077637 | Weight: 0.528528 | Bias: 0.069766\n",
            "Iteration: 46015 | Cost/Loss: 0.077637 | Weight: 0.528528 | Bias: 0.069766\n",
            "Iteration: 46016 | Cost/Loss: 0.077637 | Weight: 0.528528 | Bias: 0.069766\n",
            "Iteration: 46017 | Cost/Loss: 0.077637 | Weight: 0.528529 | Bias: 0.069767\n",
            "Iteration: 46018 | Cost/Loss: 0.077637 | Weight: 0.528529 | Bias: 0.069767\n",
            "Iteration: 46019 | Cost/Loss: 0.077637 | Weight: 0.528529 | Bias: 0.069767\n",
            "Iteration: 46020 | Cost/Loss: 0.077637 | Weight: 0.528529 | Bias: 0.069768\n",
            "Iteration: 46021 | Cost/Loss: 0.077637 | Weight: 0.528530 | Bias: 0.069768\n",
            "Iteration: 46022 | Cost/Loss: 0.077637 | Weight: 0.528530 | Bias: 0.069768\n",
            "Iteration: 46023 | Cost/Loss: 0.077637 | Weight: 0.528530 | Bias: 0.069769\n",
            "Iteration: 46024 | Cost/Loss: 0.077637 | Weight: 0.528531 | Bias: 0.069769\n",
            "Iteration: 46025 | Cost/Loss: 0.077637 | Weight: 0.528531 | Bias: 0.069769\n",
            "Iteration: 46026 | Cost/Loss: 0.077637 | Weight: 0.528531 | Bias: 0.069770\n",
            "Iteration: 46027 | Cost/Loss: 0.077637 | Weight: 0.528531 | Bias: 0.069770\n",
            "Iteration: 46028 | Cost/Loss: 0.077637 | Weight: 0.528532 | Bias: 0.069770\n",
            "Iteration: 46029 | Cost/Loss: 0.077636 | Weight: 0.528532 | Bias: 0.069771\n",
            "Iteration: 46030 | Cost/Loss: 0.077636 | Weight: 0.528532 | Bias: 0.069771\n",
            "Iteration: 46031 | Cost/Loss: 0.077636 | Weight: 0.528533 | Bias: 0.069771\n",
            "Iteration: 46032 | Cost/Loss: 0.077636 | Weight: 0.528533 | Bias: 0.069772\n",
            "Iteration: 46033 | Cost/Loss: 0.077636 | Weight: 0.528533 | Bias: 0.069772\n",
            "Iteration: 46034 | Cost/Loss: 0.077636 | Weight: 0.528534 | Bias: 0.069772\n",
            "Iteration: 46035 | Cost/Loss: 0.077636 | Weight: 0.528534 | Bias: 0.069773\n",
            "Iteration: 46036 | Cost/Loss: 0.077636 | Weight: 0.528534 | Bias: 0.069773\n",
            "Iteration: 46037 | Cost/Loss: 0.077636 | Weight: 0.528534 | Bias: 0.069773\n",
            "Iteration: 46038 | Cost/Loss: 0.077636 | Weight: 0.528535 | Bias: 0.069773\n",
            "Iteration: 46039 | Cost/Loss: 0.077636 | Weight: 0.528535 | Bias: 0.069774\n",
            "Iteration: 46040 | Cost/Loss: 0.077636 | Weight: 0.528535 | Bias: 0.069774\n",
            "Iteration: 46041 | Cost/Loss: 0.077636 | Weight: 0.528536 | Bias: 0.069774\n",
            "Iteration: 46042 | Cost/Loss: 0.077636 | Weight: 0.528536 | Bias: 0.069775\n",
            "Iteration: 46043 | Cost/Loss: 0.077636 | Weight: 0.528536 | Bias: 0.069775\n",
            "Iteration: 46044 | Cost/Loss: 0.077636 | Weight: 0.528537 | Bias: 0.069775\n",
            "Iteration: 46045 | Cost/Loss: 0.077636 | Weight: 0.528537 | Bias: 0.069776\n",
            "Iteration: 46046 | Cost/Loss: 0.077636 | Weight: 0.528537 | Bias: 0.069776\n",
            "Iteration: 46047 | Cost/Loss: 0.077636 | Weight: 0.528537 | Bias: 0.069776\n",
            "Iteration: 46048 | Cost/Loss: 0.077636 | Weight: 0.528538 | Bias: 0.069777\n",
            "Iteration: 46049 | Cost/Loss: 0.077636 | Weight: 0.528538 | Bias: 0.069777\n",
            "Iteration: 46050 | Cost/Loss: 0.077636 | Weight: 0.528538 | Bias: 0.069777\n",
            "Iteration: 46051 | Cost/Loss: 0.077636 | Weight: 0.528539 | Bias: 0.069778\n",
            "Iteration: 46052 | Cost/Loss: 0.077636 | Weight: 0.528539 | Bias: 0.069778\n",
            "Iteration: 46053 | Cost/Loss: 0.077636 | Weight: 0.528539 | Bias: 0.069778\n",
            "Iteration: 46054 | Cost/Loss: 0.077636 | Weight: 0.528540 | Bias: 0.069779\n",
            "Iteration: 46055 | Cost/Loss: 0.077636 | Weight: 0.528540 | Bias: 0.069779\n",
            "Iteration: 46056 | Cost/Loss: 0.077636 | Weight: 0.528540 | Bias: 0.069779\n",
            "Iteration: 46057 | Cost/Loss: 0.077636 | Weight: 0.528540 | Bias: 0.069780\n",
            "Iteration: 46058 | Cost/Loss: 0.077636 | Weight: 0.528541 | Bias: 0.069780\n",
            "Iteration: 46059 | Cost/Loss: 0.077636 | Weight: 0.528541 | Bias: 0.069780\n",
            "Iteration: 46060 | Cost/Loss: 0.077636 | Weight: 0.528541 | Bias: 0.069781\n",
            "Iteration: 46061 | Cost/Loss: 0.077636 | Weight: 0.528542 | Bias: 0.069781\n",
            "Iteration: 46062 | Cost/Loss: 0.077636 | Weight: 0.528542 | Bias: 0.069781\n",
            "Iteration: 46063 | Cost/Loss: 0.077636 | Weight: 0.528542 | Bias: 0.069781\n",
            "Iteration: 46064 | Cost/Loss: 0.077636 | Weight: 0.528543 | Bias: 0.069782\n",
            "Iteration: 46065 | Cost/Loss: 0.077636 | Weight: 0.528543 | Bias: 0.069782\n",
            "Iteration: 46066 | Cost/Loss: 0.077636 | Weight: 0.528543 | Bias: 0.069782\n",
            "Iteration: 46067 | Cost/Loss: 0.077636 | Weight: 0.528543 | Bias: 0.069783\n",
            "Iteration: 46068 | Cost/Loss: 0.077636 | Weight: 0.528544 | Bias: 0.069783\n",
            "Iteration: 46069 | Cost/Loss: 0.077635 | Weight: 0.528544 | Bias: 0.069783\n",
            "Iteration: 46070 | Cost/Loss: 0.077635 | Weight: 0.528544 | Bias: 0.069784\n",
            "Iteration: 46071 | Cost/Loss: 0.077635 | Weight: 0.528545 | Bias: 0.069784\n",
            "Iteration: 46072 | Cost/Loss: 0.077635 | Weight: 0.528545 | Bias: 0.069784\n",
            "Iteration: 46073 | Cost/Loss: 0.077635 | Weight: 0.528545 | Bias: 0.069785\n",
            "Iteration: 46074 | Cost/Loss: 0.077635 | Weight: 0.528545 | Bias: 0.069785\n",
            "Iteration: 46075 | Cost/Loss: 0.077635 | Weight: 0.528546 | Bias: 0.069785\n",
            "Iteration: 46076 | Cost/Loss: 0.077635 | Weight: 0.528546 | Bias: 0.069786\n",
            "Iteration: 46077 | Cost/Loss: 0.077635 | Weight: 0.528546 | Bias: 0.069786\n",
            "Iteration: 46078 | Cost/Loss: 0.077635 | Weight: 0.528547 | Bias: 0.069786\n",
            "Iteration: 46079 | Cost/Loss: 0.077635 | Weight: 0.528547 | Bias: 0.069787\n",
            "Iteration: 46080 | Cost/Loss: 0.077635 | Weight: 0.528547 | Bias: 0.069787\n",
            "Iteration: 46081 | Cost/Loss: 0.077635 | Weight: 0.528548 | Bias: 0.069787\n",
            "Iteration: 46082 | Cost/Loss: 0.077635 | Weight: 0.528548 | Bias: 0.069788\n",
            "Iteration: 46083 | Cost/Loss: 0.077635 | Weight: 0.528548 | Bias: 0.069788\n",
            "Iteration: 46084 | Cost/Loss: 0.077635 | Weight: 0.528548 | Bias: 0.069788\n",
            "Iteration: 46085 | Cost/Loss: 0.077635 | Weight: 0.528549 | Bias: 0.069789\n",
            "Iteration: 46086 | Cost/Loss: 0.077635 | Weight: 0.528549 | Bias: 0.069789\n",
            "Iteration: 46087 | Cost/Loss: 0.077635 | Weight: 0.528549 | Bias: 0.069789\n",
            "Iteration: 46088 | Cost/Loss: 0.077635 | Weight: 0.528550 | Bias: 0.069789\n",
            "Iteration: 46089 | Cost/Loss: 0.077635 | Weight: 0.528550 | Bias: 0.069790\n",
            "Iteration: 46090 | Cost/Loss: 0.077635 | Weight: 0.528550 | Bias: 0.069790\n",
            "Iteration: 46091 | Cost/Loss: 0.077635 | Weight: 0.528551 | Bias: 0.069790\n",
            "Iteration: 46092 | Cost/Loss: 0.077635 | Weight: 0.528551 | Bias: 0.069791\n",
            "Iteration: 46093 | Cost/Loss: 0.077635 | Weight: 0.528551 | Bias: 0.069791\n",
            "Iteration: 46094 | Cost/Loss: 0.077635 | Weight: 0.528551 | Bias: 0.069791\n",
            "Iteration: 46095 | Cost/Loss: 0.077635 | Weight: 0.528552 | Bias: 0.069792\n",
            "Iteration: 46096 | Cost/Loss: 0.077635 | Weight: 0.528552 | Bias: 0.069792\n",
            "Iteration: 46097 | Cost/Loss: 0.077635 | Weight: 0.528552 | Bias: 0.069792\n",
            "Iteration: 46098 | Cost/Loss: 0.077635 | Weight: 0.528553 | Bias: 0.069793\n",
            "Iteration: 46099 | Cost/Loss: 0.077635 | Weight: 0.528553 | Bias: 0.069793\n",
            "Iteration: 46100 | Cost/Loss: 0.077635 | Weight: 0.528553 | Bias: 0.069793\n",
            "Iteration: 46101 | Cost/Loss: 0.077635 | Weight: 0.528554 | Bias: 0.069794\n",
            "Iteration: 46102 | Cost/Loss: 0.077635 | Weight: 0.528554 | Bias: 0.069794\n",
            "Iteration: 46103 | Cost/Loss: 0.077635 | Weight: 0.528554 | Bias: 0.069794\n",
            "Iteration: 46104 | Cost/Loss: 0.077635 | Weight: 0.528554 | Bias: 0.069795\n",
            "Iteration: 46105 | Cost/Loss: 0.077635 | Weight: 0.528555 | Bias: 0.069795\n",
            "Iteration: 46106 | Cost/Loss: 0.077635 | Weight: 0.528555 | Bias: 0.069795\n",
            "Iteration: 46107 | Cost/Loss: 0.077635 | Weight: 0.528555 | Bias: 0.069796\n",
            "Iteration: 46108 | Cost/Loss: 0.077634 | Weight: 0.528556 | Bias: 0.069796\n",
            "Iteration: 46109 | Cost/Loss: 0.077634 | Weight: 0.528556 | Bias: 0.069796\n",
            "Iteration: 46110 | Cost/Loss: 0.077634 | Weight: 0.528556 | Bias: 0.069797\n",
            "Iteration: 46111 | Cost/Loss: 0.077634 | Weight: 0.528557 | Bias: 0.069797\n",
            "Iteration: 46112 | Cost/Loss: 0.077634 | Weight: 0.528557 | Bias: 0.069797\n",
            "Iteration: 46113 | Cost/Loss: 0.077634 | Weight: 0.528557 | Bias: 0.069798\n",
            "Iteration: 46114 | Cost/Loss: 0.077634 | Weight: 0.528557 | Bias: 0.069798\n",
            "Iteration: 46115 | Cost/Loss: 0.077634 | Weight: 0.528558 | Bias: 0.069798\n",
            "Iteration: 46116 | Cost/Loss: 0.077634 | Weight: 0.528558 | Bias: 0.069798\n",
            "Iteration: 46117 | Cost/Loss: 0.077634 | Weight: 0.528558 | Bias: 0.069799\n",
            "Iteration: 46118 | Cost/Loss: 0.077634 | Weight: 0.528559 | Bias: 0.069799\n",
            "Iteration: 46119 | Cost/Loss: 0.077634 | Weight: 0.528559 | Bias: 0.069799\n",
            "Iteration: 46120 | Cost/Loss: 0.077634 | Weight: 0.528559 | Bias: 0.069800\n",
            "Iteration: 46121 | Cost/Loss: 0.077634 | Weight: 0.528560 | Bias: 0.069800\n",
            "Iteration: 46122 | Cost/Loss: 0.077634 | Weight: 0.528560 | Bias: 0.069800\n",
            "Iteration: 46123 | Cost/Loss: 0.077634 | Weight: 0.528560 | Bias: 0.069801\n",
            "Iteration: 46124 | Cost/Loss: 0.077634 | Weight: 0.528560 | Bias: 0.069801\n",
            "Iteration: 46125 | Cost/Loss: 0.077634 | Weight: 0.528561 | Bias: 0.069801\n",
            "Iteration: 46126 | Cost/Loss: 0.077634 | Weight: 0.528561 | Bias: 0.069802\n",
            "Iteration: 46127 | Cost/Loss: 0.077634 | Weight: 0.528561 | Bias: 0.069802\n",
            "Iteration: 46128 | Cost/Loss: 0.077634 | Weight: 0.528562 | Bias: 0.069802\n",
            "Iteration: 46129 | Cost/Loss: 0.077634 | Weight: 0.528562 | Bias: 0.069803\n",
            "Iteration: 46130 | Cost/Loss: 0.077634 | Weight: 0.528562 | Bias: 0.069803\n",
            "Iteration: 46131 | Cost/Loss: 0.077634 | Weight: 0.528562 | Bias: 0.069803\n",
            "Iteration: 46132 | Cost/Loss: 0.077634 | Weight: 0.528563 | Bias: 0.069804\n",
            "Iteration: 46133 | Cost/Loss: 0.077634 | Weight: 0.528563 | Bias: 0.069804\n",
            "Iteration: 46134 | Cost/Loss: 0.077634 | Weight: 0.528563 | Bias: 0.069804\n",
            "Iteration: 46135 | Cost/Loss: 0.077634 | Weight: 0.528564 | Bias: 0.069805\n",
            "Iteration: 46136 | Cost/Loss: 0.077634 | Weight: 0.528564 | Bias: 0.069805\n",
            "Iteration: 46137 | Cost/Loss: 0.077634 | Weight: 0.528564 | Bias: 0.069805\n",
            "Iteration: 46138 | Cost/Loss: 0.077634 | Weight: 0.528565 | Bias: 0.069806\n",
            "Iteration: 46139 | Cost/Loss: 0.077634 | Weight: 0.528565 | Bias: 0.069806\n",
            "Iteration: 46140 | Cost/Loss: 0.077634 | Weight: 0.528565 | Bias: 0.069806\n",
            "Iteration: 46141 | Cost/Loss: 0.077634 | Weight: 0.528565 | Bias: 0.069806\n",
            "Iteration: 46142 | Cost/Loss: 0.077634 | Weight: 0.528566 | Bias: 0.069807\n",
            "Iteration: 46143 | Cost/Loss: 0.077634 | Weight: 0.528566 | Bias: 0.069807\n",
            "Iteration: 46144 | Cost/Loss: 0.077634 | Weight: 0.528566 | Bias: 0.069807\n",
            "Iteration: 46145 | Cost/Loss: 0.077634 | Weight: 0.528567 | Bias: 0.069808\n",
            "Iteration: 46146 | Cost/Loss: 0.077634 | Weight: 0.528567 | Bias: 0.069808\n",
            "Iteration: 46147 | Cost/Loss: 0.077634 | Weight: 0.528567 | Bias: 0.069808\n",
            "Iteration: 46148 | Cost/Loss: 0.077633 | Weight: 0.528568 | Bias: 0.069809\n",
            "Iteration: 46149 | Cost/Loss: 0.077633 | Weight: 0.528568 | Bias: 0.069809\n",
            "Iteration: 46150 | Cost/Loss: 0.077633 | Weight: 0.528568 | Bias: 0.069809\n",
            "Iteration: 46151 | Cost/Loss: 0.077633 | Weight: 0.528568 | Bias: 0.069810\n",
            "Iteration: 46152 | Cost/Loss: 0.077633 | Weight: 0.528569 | Bias: 0.069810\n",
            "Iteration: 46153 | Cost/Loss: 0.077633 | Weight: 0.528569 | Bias: 0.069810\n",
            "Iteration: 46154 | Cost/Loss: 0.077633 | Weight: 0.528569 | Bias: 0.069811\n",
            "Iteration: 46155 | Cost/Loss: 0.077633 | Weight: 0.528570 | Bias: 0.069811\n",
            "Iteration: 46156 | Cost/Loss: 0.077633 | Weight: 0.528570 | Bias: 0.069811\n",
            "Iteration: 46157 | Cost/Loss: 0.077633 | Weight: 0.528570 | Bias: 0.069812\n",
            "Iteration: 46158 | Cost/Loss: 0.077633 | Weight: 0.528571 | Bias: 0.069812\n",
            "Iteration: 46159 | Cost/Loss: 0.077633 | Weight: 0.528571 | Bias: 0.069812\n",
            "Iteration: 46160 | Cost/Loss: 0.077633 | Weight: 0.528571 | Bias: 0.069813\n",
            "Iteration: 46161 | Cost/Loss: 0.077633 | Weight: 0.528571 | Bias: 0.069813\n",
            "Iteration: 46162 | Cost/Loss: 0.077633 | Weight: 0.528572 | Bias: 0.069813\n",
            "Iteration: 46163 | Cost/Loss: 0.077633 | Weight: 0.528572 | Bias: 0.069814\n",
            "Iteration: 46164 | Cost/Loss: 0.077633 | Weight: 0.528572 | Bias: 0.069814\n",
            "Iteration: 46165 | Cost/Loss: 0.077633 | Weight: 0.528573 | Bias: 0.069814\n",
            "Iteration: 46166 | Cost/Loss: 0.077633 | Weight: 0.528573 | Bias: 0.069814\n",
            "Iteration: 46167 | Cost/Loss: 0.077633 | Weight: 0.528573 | Bias: 0.069815\n",
            "Iteration: 46168 | Cost/Loss: 0.077633 | Weight: 0.528574 | Bias: 0.069815\n",
            "Iteration: 46169 | Cost/Loss: 0.077633 | Weight: 0.528574 | Bias: 0.069815\n",
            "Iteration: 46170 | Cost/Loss: 0.077633 | Weight: 0.528574 | Bias: 0.069816\n",
            "Iteration: 46171 | Cost/Loss: 0.077633 | Weight: 0.528574 | Bias: 0.069816\n",
            "Iteration: 46172 | Cost/Loss: 0.077633 | Weight: 0.528575 | Bias: 0.069816\n",
            "Iteration: 46173 | Cost/Loss: 0.077633 | Weight: 0.528575 | Bias: 0.069817\n",
            "Iteration: 46174 | Cost/Loss: 0.077633 | Weight: 0.528575 | Bias: 0.069817\n",
            "Iteration: 46175 | Cost/Loss: 0.077633 | Weight: 0.528576 | Bias: 0.069817\n",
            "Iteration: 46176 | Cost/Loss: 0.077633 | Weight: 0.528576 | Bias: 0.069818\n",
            "Iteration: 46177 | Cost/Loss: 0.077633 | Weight: 0.528576 | Bias: 0.069818\n",
            "Iteration: 46178 | Cost/Loss: 0.077633 | Weight: 0.528576 | Bias: 0.069818\n",
            "Iteration: 46179 | Cost/Loss: 0.077633 | Weight: 0.528577 | Bias: 0.069819\n",
            "Iteration: 46180 | Cost/Loss: 0.077633 | Weight: 0.528577 | Bias: 0.069819\n",
            "Iteration: 46181 | Cost/Loss: 0.077633 | Weight: 0.528577 | Bias: 0.069819\n",
            "Iteration: 46182 | Cost/Loss: 0.077633 | Weight: 0.528578 | Bias: 0.069820\n",
            "Iteration: 46183 | Cost/Loss: 0.077633 | Weight: 0.528578 | Bias: 0.069820\n",
            "Iteration: 46184 | Cost/Loss: 0.077633 | Weight: 0.528578 | Bias: 0.069820\n",
            "Iteration: 46185 | Cost/Loss: 0.077633 | Weight: 0.528579 | Bias: 0.069821\n",
            "Iteration: 46186 | Cost/Loss: 0.077633 | Weight: 0.528579 | Bias: 0.069821\n",
            "Iteration: 46187 | Cost/Loss: 0.077633 | Weight: 0.528579 | Bias: 0.069821\n",
            "Iteration: 46188 | Cost/Loss: 0.077632 | Weight: 0.528579 | Bias: 0.069822\n",
            "Iteration: 46189 | Cost/Loss: 0.077632 | Weight: 0.528580 | Bias: 0.069822\n",
            "Iteration: 46190 | Cost/Loss: 0.077632 | Weight: 0.528580 | Bias: 0.069822\n",
            "Iteration: 46191 | Cost/Loss: 0.077632 | Weight: 0.528580 | Bias: 0.069822\n",
            "Iteration: 46192 | Cost/Loss: 0.077632 | Weight: 0.528581 | Bias: 0.069823\n",
            "Iteration: 46193 | Cost/Loss: 0.077632 | Weight: 0.528581 | Bias: 0.069823\n",
            "Iteration: 46194 | Cost/Loss: 0.077632 | Weight: 0.528581 | Bias: 0.069823\n",
            "Iteration: 46195 | Cost/Loss: 0.077632 | Weight: 0.528582 | Bias: 0.069824\n",
            "Iteration: 46196 | Cost/Loss: 0.077632 | Weight: 0.528582 | Bias: 0.069824\n",
            "Iteration: 46197 | Cost/Loss: 0.077632 | Weight: 0.528582 | Bias: 0.069824\n",
            "Iteration: 46198 | Cost/Loss: 0.077632 | Weight: 0.528582 | Bias: 0.069825\n",
            "Iteration: 46199 | Cost/Loss: 0.077632 | Weight: 0.528583 | Bias: 0.069825\n",
            "Iteration: 46200 | Cost/Loss: 0.077632 | Weight: 0.528583 | Bias: 0.069825\n",
            "Iteration: 46201 | Cost/Loss: 0.077632 | Weight: 0.528583 | Bias: 0.069826\n",
            "Iteration: 46202 | Cost/Loss: 0.077632 | Weight: 0.528584 | Bias: 0.069826\n",
            "Iteration: 46203 | Cost/Loss: 0.077632 | Weight: 0.528584 | Bias: 0.069826\n",
            "Iteration: 46204 | Cost/Loss: 0.077632 | Weight: 0.528584 | Bias: 0.069827\n",
            "Iteration: 46205 | Cost/Loss: 0.077632 | Weight: 0.528585 | Bias: 0.069827\n",
            "Iteration: 46206 | Cost/Loss: 0.077632 | Weight: 0.528585 | Bias: 0.069827\n",
            "Iteration: 46207 | Cost/Loss: 0.077632 | Weight: 0.528585 | Bias: 0.069828\n",
            "Iteration: 46208 | Cost/Loss: 0.077632 | Weight: 0.528585 | Bias: 0.069828\n",
            "Iteration: 46209 | Cost/Loss: 0.077632 | Weight: 0.528586 | Bias: 0.069828\n",
            "Iteration: 46210 | Cost/Loss: 0.077632 | Weight: 0.528586 | Bias: 0.069829\n",
            "Iteration: 46211 | Cost/Loss: 0.077632 | Weight: 0.528586 | Bias: 0.069829\n",
            "Iteration: 46212 | Cost/Loss: 0.077632 | Weight: 0.528587 | Bias: 0.069829\n",
            "Iteration: 46213 | Cost/Loss: 0.077632 | Weight: 0.528587 | Bias: 0.069830\n",
            "Iteration: 46214 | Cost/Loss: 0.077632 | Weight: 0.528587 | Bias: 0.069830\n",
            "Iteration: 46215 | Cost/Loss: 0.077632 | Weight: 0.528588 | Bias: 0.069830\n",
            "Iteration: 46216 | Cost/Loss: 0.077632 | Weight: 0.528588 | Bias: 0.069830\n",
            "Iteration: 46217 | Cost/Loss: 0.077632 | Weight: 0.528588 | Bias: 0.069831\n",
            "Iteration: 46218 | Cost/Loss: 0.077632 | Weight: 0.528588 | Bias: 0.069831\n",
            "Iteration: 46219 | Cost/Loss: 0.077632 | Weight: 0.528589 | Bias: 0.069831\n",
            "Iteration: 46220 | Cost/Loss: 0.077632 | Weight: 0.528589 | Bias: 0.069832\n",
            "Iteration: 46221 | Cost/Loss: 0.077632 | Weight: 0.528589 | Bias: 0.069832\n",
            "Iteration: 46222 | Cost/Loss: 0.077632 | Weight: 0.528590 | Bias: 0.069832\n",
            "Iteration: 46223 | Cost/Loss: 0.077632 | Weight: 0.528590 | Bias: 0.069833\n",
            "Iteration: 46224 | Cost/Loss: 0.077632 | Weight: 0.528590 | Bias: 0.069833\n",
            "Iteration: 46225 | Cost/Loss: 0.077632 | Weight: 0.528591 | Bias: 0.069833\n",
            "Iteration: 46226 | Cost/Loss: 0.077632 | Weight: 0.528591 | Bias: 0.069834\n",
            "Iteration: 46227 | Cost/Loss: 0.077631 | Weight: 0.528591 | Bias: 0.069834\n",
            "Iteration: 46228 | Cost/Loss: 0.077631 | Weight: 0.528591 | Bias: 0.069834\n",
            "Iteration: 46229 | Cost/Loss: 0.077631 | Weight: 0.528592 | Bias: 0.069835\n",
            "Iteration: 46230 | Cost/Loss: 0.077631 | Weight: 0.528592 | Bias: 0.069835\n",
            "Iteration: 46231 | Cost/Loss: 0.077631 | Weight: 0.528592 | Bias: 0.069835\n",
            "Iteration: 46232 | Cost/Loss: 0.077631 | Weight: 0.528593 | Bias: 0.069836\n",
            "Iteration: 46233 | Cost/Loss: 0.077631 | Weight: 0.528593 | Bias: 0.069836\n",
            "Iteration: 46234 | Cost/Loss: 0.077631 | Weight: 0.528593 | Bias: 0.069836\n",
            "Iteration: 46235 | Cost/Loss: 0.077631 | Weight: 0.528593 | Bias: 0.069837\n",
            "Iteration: 46236 | Cost/Loss: 0.077631 | Weight: 0.528594 | Bias: 0.069837\n",
            "Iteration: 46237 | Cost/Loss: 0.077631 | Weight: 0.528594 | Bias: 0.069837\n",
            "Iteration: 46238 | Cost/Loss: 0.077631 | Weight: 0.528594 | Bias: 0.069838\n",
            "Iteration: 46239 | Cost/Loss: 0.077631 | Weight: 0.528595 | Bias: 0.069838\n",
            "Iteration: 46240 | Cost/Loss: 0.077631 | Weight: 0.528595 | Bias: 0.069838\n",
            "Iteration: 46241 | Cost/Loss: 0.077631 | Weight: 0.528595 | Bias: 0.069839\n",
            "Iteration: 46242 | Cost/Loss: 0.077631 | Weight: 0.528596 | Bias: 0.069839\n",
            "Iteration: 46243 | Cost/Loss: 0.077631 | Weight: 0.528596 | Bias: 0.069839\n",
            "Iteration: 46244 | Cost/Loss: 0.077631 | Weight: 0.528596 | Bias: 0.069839\n",
            "Iteration: 46245 | Cost/Loss: 0.077631 | Weight: 0.528596 | Bias: 0.069840\n",
            "Iteration: 46246 | Cost/Loss: 0.077631 | Weight: 0.528597 | Bias: 0.069840\n",
            "Iteration: 46247 | Cost/Loss: 0.077631 | Weight: 0.528597 | Bias: 0.069840\n",
            "Iteration: 46248 | Cost/Loss: 0.077631 | Weight: 0.528597 | Bias: 0.069841\n",
            "Iteration: 46249 | Cost/Loss: 0.077631 | Weight: 0.528598 | Bias: 0.069841\n",
            "Iteration: 46250 | Cost/Loss: 0.077631 | Weight: 0.528598 | Bias: 0.069841\n",
            "Iteration: 46251 | Cost/Loss: 0.077631 | Weight: 0.528598 | Bias: 0.069842\n",
            "Iteration: 46252 | Cost/Loss: 0.077631 | Weight: 0.528599 | Bias: 0.069842\n",
            "Iteration: 46253 | Cost/Loss: 0.077631 | Weight: 0.528599 | Bias: 0.069842\n",
            "Iteration: 46254 | Cost/Loss: 0.077631 | Weight: 0.528599 | Bias: 0.069843\n",
            "Iteration: 46255 | Cost/Loss: 0.077631 | Weight: 0.528599 | Bias: 0.069843\n",
            "Iteration: 46256 | Cost/Loss: 0.077631 | Weight: 0.528600 | Bias: 0.069843\n",
            "Iteration: 46257 | Cost/Loss: 0.077631 | Weight: 0.528600 | Bias: 0.069844\n",
            "Iteration: 46258 | Cost/Loss: 0.077631 | Weight: 0.528600 | Bias: 0.069844\n",
            "Iteration: 46259 | Cost/Loss: 0.077631 | Weight: 0.528601 | Bias: 0.069844\n",
            "Iteration: 46260 | Cost/Loss: 0.077631 | Weight: 0.528601 | Bias: 0.069845\n",
            "Iteration: 46261 | Cost/Loss: 0.077631 | Weight: 0.528601 | Bias: 0.069845\n",
            "Iteration: 46262 | Cost/Loss: 0.077631 | Weight: 0.528602 | Bias: 0.069845\n",
            "Iteration: 46263 | Cost/Loss: 0.077631 | Weight: 0.528602 | Bias: 0.069846\n",
            "Iteration: 46264 | Cost/Loss: 0.077631 | Weight: 0.528602 | Bias: 0.069846\n",
            "Iteration: 46265 | Cost/Loss: 0.077631 | Weight: 0.528602 | Bias: 0.069846\n",
            "Iteration: 46266 | Cost/Loss: 0.077631 | Weight: 0.528603 | Bias: 0.069847\n",
            "Iteration: 46267 | Cost/Loss: 0.077630 | Weight: 0.528603 | Bias: 0.069847\n",
            "Iteration: 46268 | Cost/Loss: 0.077630 | Weight: 0.528603 | Bias: 0.069847\n",
            "Iteration: 46269 | Cost/Loss: 0.077630 | Weight: 0.528604 | Bias: 0.069847\n",
            "Iteration: 46270 | Cost/Loss: 0.077630 | Weight: 0.528604 | Bias: 0.069848\n",
            "Iteration: 46271 | Cost/Loss: 0.077630 | Weight: 0.528604 | Bias: 0.069848\n",
            "Iteration: 46272 | Cost/Loss: 0.077630 | Weight: 0.528605 | Bias: 0.069848\n",
            "Iteration: 46273 | Cost/Loss: 0.077630 | Weight: 0.528605 | Bias: 0.069849\n",
            "Iteration: 46274 | Cost/Loss: 0.077630 | Weight: 0.528605 | Bias: 0.069849\n",
            "Iteration: 46275 | Cost/Loss: 0.077630 | Weight: 0.528605 | Bias: 0.069849\n",
            "Iteration: 46276 | Cost/Loss: 0.077630 | Weight: 0.528606 | Bias: 0.069850\n",
            "Iteration: 46277 | Cost/Loss: 0.077630 | Weight: 0.528606 | Bias: 0.069850\n",
            "Iteration: 46278 | Cost/Loss: 0.077630 | Weight: 0.528606 | Bias: 0.069850\n",
            "Iteration: 46279 | Cost/Loss: 0.077630 | Weight: 0.528607 | Bias: 0.069851\n",
            "Iteration: 46280 | Cost/Loss: 0.077630 | Weight: 0.528607 | Bias: 0.069851\n",
            "Iteration: 46281 | Cost/Loss: 0.077630 | Weight: 0.528607 | Bias: 0.069851\n",
            "Iteration: 46282 | Cost/Loss: 0.077630 | Weight: 0.528607 | Bias: 0.069852\n",
            "Iteration: 46283 | Cost/Loss: 0.077630 | Weight: 0.528608 | Bias: 0.069852\n",
            "Iteration: 46284 | Cost/Loss: 0.077630 | Weight: 0.528608 | Bias: 0.069852\n",
            "Iteration: 46285 | Cost/Loss: 0.077630 | Weight: 0.528608 | Bias: 0.069853\n",
            "Iteration: 46286 | Cost/Loss: 0.077630 | Weight: 0.528609 | Bias: 0.069853\n",
            "Iteration: 46287 | Cost/Loss: 0.077630 | Weight: 0.528609 | Bias: 0.069853\n",
            "Iteration: 46288 | Cost/Loss: 0.077630 | Weight: 0.528609 | Bias: 0.069854\n",
            "Iteration: 46289 | Cost/Loss: 0.077630 | Weight: 0.528610 | Bias: 0.069854\n",
            "Iteration: 46290 | Cost/Loss: 0.077630 | Weight: 0.528610 | Bias: 0.069854\n",
            "Iteration: 46291 | Cost/Loss: 0.077630 | Weight: 0.528610 | Bias: 0.069855\n",
            "Iteration: 46292 | Cost/Loss: 0.077630 | Weight: 0.528610 | Bias: 0.069855\n",
            "Iteration: 46293 | Cost/Loss: 0.077630 | Weight: 0.528611 | Bias: 0.069855\n",
            "Iteration: 46294 | Cost/Loss: 0.077630 | Weight: 0.528611 | Bias: 0.069855\n",
            "Iteration: 46295 | Cost/Loss: 0.077630 | Weight: 0.528611 | Bias: 0.069856\n",
            "Iteration: 46296 | Cost/Loss: 0.077630 | Weight: 0.528612 | Bias: 0.069856\n",
            "Iteration: 46297 | Cost/Loss: 0.077630 | Weight: 0.528612 | Bias: 0.069856\n",
            "Iteration: 46298 | Cost/Loss: 0.077630 | Weight: 0.528612 | Bias: 0.069857\n",
            "Iteration: 46299 | Cost/Loss: 0.077630 | Weight: 0.528613 | Bias: 0.069857\n",
            "Iteration: 46300 | Cost/Loss: 0.077630 | Weight: 0.528613 | Bias: 0.069857\n",
            "Iteration: 46301 | Cost/Loss: 0.077630 | Weight: 0.528613 | Bias: 0.069858\n",
            "Iteration: 46302 | Cost/Loss: 0.077630 | Weight: 0.528613 | Bias: 0.069858\n",
            "Iteration: 46303 | Cost/Loss: 0.077630 | Weight: 0.528614 | Bias: 0.069858\n",
            "Iteration: 46304 | Cost/Loss: 0.077630 | Weight: 0.528614 | Bias: 0.069859\n",
            "Iteration: 46305 | Cost/Loss: 0.077630 | Weight: 0.528614 | Bias: 0.069859\n",
            "Iteration: 46306 | Cost/Loss: 0.077630 | Weight: 0.528615 | Bias: 0.069859\n",
            "Iteration: 46307 | Cost/Loss: 0.077629 | Weight: 0.528615 | Bias: 0.069860\n",
            "Iteration: 46308 | Cost/Loss: 0.077629 | Weight: 0.528615 | Bias: 0.069860\n",
            "Iteration: 46309 | Cost/Loss: 0.077629 | Weight: 0.528616 | Bias: 0.069860\n",
            "Iteration: 46310 | Cost/Loss: 0.077629 | Weight: 0.528616 | Bias: 0.069861\n",
            "Iteration: 46311 | Cost/Loss: 0.077629 | Weight: 0.528616 | Bias: 0.069861\n",
            "Iteration: 46312 | Cost/Loss: 0.077629 | Weight: 0.528616 | Bias: 0.069861\n",
            "Iteration: 46313 | Cost/Loss: 0.077629 | Weight: 0.528617 | Bias: 0.069862\n",
            "Iteration: 46314 | Cost/Loss: 0.077629 | Weight: 0.528617 | Bias: 0.069862\n",
            "Iteration: 46315 | Cost/Loss: 0.077629 | Weight: 0.528617 | Bias: 0.069862\n",
            "Iteration: 46316 | Cost/Loss: 0.077629 | Weight: 0.528618 | Bias: 0.069863\n",
            "Iteration: 46317 | Cost/Loss: 0.077629 | Weight: 0.528618 | Bias: 0.069863\n",
            "Iteration: 46318 | Cost/Loss: 0.077629 | Weight: 0.528618 | Bias: 0.069863\n",
            "Iteration: 46319 | Cost/Loss: 0.077629 | Weight: 0.528619 | Bias: 0.069863\n",
            "Iteration: 46320 | Cost/Loss: 0.077629 | Weight: 0.528619 | Bias: 0.069864\n",
            "Iteration: 46321 | Cost/Loss: 0.077629 | Weight: 0.528619 | Bias: 0.069864\n",
            "Iteration: 46322 | Cost/Loss: 0.077629 | Weight: 0.528619 | Bias: 0.069864\n",
            "Iteration: 46323 | Cost/Loss: 0.077629 | Weight: 0.528620 | Bias: 0.069865\n",
            "Iteration: 46324 | Cost/Loss: 0.077629 | Weight: 0.528620 | Bias: 0.069865\n",
            "Iteration: 46325 | Cost/Loss: 0.077629 | Weight: 0.528620 | Bias: 0.069865\n",
            "Iteration: 46326 | Cost/Loss: 0.077629 | Weight: 0.528621 | Bias: 0.069866\n",
            "Iteration: 46327 | Cost/Loss: 0.077629 | Weight: 0.528621 | Bias: 0.069866\n",
            "Iteration: 46328 | Cost/Loss: 0.077629 | Weight: 0.528621 | Bias: 0.069866\n",
            "Iteration: 46329 | Cost/Loss: 0.077629 | Weight: 0.528621 | Bias: 0.069867\n",
            "Iteration: 46330 | Cost/Loss: 0.077629 | Weight: 0.528622 | Bias: 0.069867\n",
            "Iteration: 46331 | Cost/Loss: 0.077629 | Weight: 0.528622 | Bias: 0.069867\n",
            "Iteration: 46332 | Cost/Loss: 0.077629 | Weight: 0.528622 | Bias: 0.069868\n",
            "Iteration: 46333 | Cost/Loss: 0.077629 | Weight: 0.528623 | Bias: 0.069868\n",
            "Iteration: 46334 | Cost/Loss: 0.077629 | Weight: 0.528623 | Bias: 0.069868\n",
            "Iteration: 46335 | Cost/Loss: 0.077629 | Weight: 0.528623 | Bias: 0.069869\n",
            "Iteration: 46336 | Cost/Loss: 0.077629 | Weight: 0.528624 | Bias: 0.069869\n",
            "Iteration: 46337 | Cost/Loss: 0.077629 | Weight: 0.528624 | Bias: 0.069869\n",
            "Iteration: 46338 | Cost/Loss: 0.077629 | Weight: 0.528624 | Bias: 0.069870\n",
            "Iteration: 46339 | Cost/Loss: 0.077629 | Weight: 0.528624 | Bias: 0.069870\n",
            "Iteration: 46340 | Cost/Loss: 0.077629 | Weight: 0.528625 | Bias: 0.069870\n",
            "Iteration: 46341 | Cost/Loss: 0.077629 | Weight: 0.528625 | Bias: 0.069871\n",
            "Iteration: 46342 | Cost/Loss: 0.077629 | Weight: 0.528625 | Bias: 0.069871\n",
            "Iteration: 46343 | Cost/Loss: 0.077629 | Weight: 0.528626 | Bias: 0.069871\n",
            "Iteration: 46344 | Cost/Loss: 0.077629 | Weight: 0.528626 | Bias: 0.069872\n",
            "Iteration: 46345 | Cost/Loss: 0.077629 | Weight: 0.528626 | Bias: 0.069872\n",
            "Iteration: 46346 | Cost/Loss: 0.077628 | Weight: 0.528627 | Bias: 0.069872\n",
            "Iteration: 46347 | Cost/Loss: 0.077628 | Weight: 0.528627 | Bias: 0.069872\n",
            "Iteration: 46348 | Cost/Loss: 0.077628 | Weight: 0.528627 | Bias: 0.069873\n",
            "Iteration: 46349 | Cost/Loss: 0.077628 | Weight: 0.528627 | Bias: 0.069873\n",
            "Iteration: 46350 | Cost/Loss: 0.077628 | Weight: 0.528628 | Bias: 0.069873\n",
            "Iteration: 46351 | Cost/Loss: 0.077628 | Weight: 0.528628 | Bias: 0.069874\n",
            "Iteration: 46352 | Cost/Loss: 0.077628 | Weight: 0.528628 | Bias: 0.069874\n",
            "Iteration: 46353 | Cost/Loss: 0.077628 | Weight: 0.528629 | Bias: 0.069874\n",
            "Iteration: 46354 | Cost/Loss: 0.077628 | Weight: 0.528629 | Bias: 0.069875\n",
            "Iteration: 46355 | Cost/Loss: 0.077628 | Weight: 0.528629 | Bias: 0.069875\n",
            "Iteration: 46356 | Cost/Loss: 0.077628 | Weight: 0.528630 | Bias: 0.069875\n",
            "Iteration: 46357 | Cost/Loss: 0.077628 | Weight: 0.528630 | Bias: 0.069876\n",
            "Iteration: 46358 | Cost/Loss: 0.077628 | Weight: 0.528630 | Bias: 0.069876\n",
            "Iteration: 46359 | Cost/Loss: 0.077628 | Weight: 0.528630 | Bias: 0.069876\n",
            "Iteration: 46360 | Cost/Loss: 0.077628 | Weight: 0.528631 | Bias: 0.069877\n",
            "Iteration: 46361 | Cost/Loss: 0.077628 | Weight: 0.528631 | Bias: 0.069877\n",
            "Iteration: 46362 | Cost/Loss: 0.077628 | Weight: 0.528631 | Bias: 0.069877\n",
            "Iteration: 46363 | Cost/Loss: 0.077628 | Weight: 0.528632 | Bias: 0.069878\n",
            "Iteration: 46364 | Cost/Loss: 0.077628 | Weight: 0.528632 | Bias: 0.069878\n",
            "Iteration: 46365 | Cost/Loss: 0.077628 | Weight: 0.528632 | Bias: 0.069878\n",
            "Iteration: 46366 | Cost/Loss: 0.077628 | Weight: 0.528633 | Bias: 0.069879\n",
            "Iteration: 46367 | Cost/Loss: 0.077628 | Weight: 0.528633 | Bias: 0.069879\n",
            "Iteration: 46368 | Cost/Loss: 0.077628 | Weight: 0.528633 | Bias: 0.069879\n",
            "Iteration: 46369 | Cost/Loss: 0.077628 | Weight: 0.528633 | Bias: 0.069880\n",
            "Iteration: 46370 | Cost/Loss: 0.077628 | Weight: 0.528634 | Bias: 0.069880\n",
            "Iteration: 46371 | Cost/Loss: 0.077628 | Weight: 0.528634 | Bias: 0.069880\n",
            "Iteration: 46372 | Cost/Loss: 0.077628 | Weight: 0.528634 | Bias: 0.069880\n",
            "Iteration: 46373 | Cost/Loss: 0.077628 | Weight: 0.528635 | Bias: 0.069881\n",
            "Iteration: 46374 | Cost/Loss: 0.077628 | Weight: 0.528635 | Bias: 0.069881\n",
            "Iteration: 46375 | Cost/Loss: 0.077628 | Weight: 0.528635 | Bias: 0.069881\n",
            "Iteration: 46376 | Cost/Loss: 0.077628 | Weight: 0.528636 | Bias: 0.069882\n",
            "Iteration: 46377 | Cost/Loss: 0.077628 | Weight: 0.528636 | Bias: 0.069882\n",
            "Iteration: 46378 | Cost/Loss: 0.077628 | Weight: 0.528636 | Bias: 0.069882\n",
            "Iteration: 46379 | Cost/Loss: 0.077628 | Weight: 0.528636 | Bias: 0.069883\n",
            "Iteration: 46380 | Cost/Loss: 0.077628 | Weight: 0.528637 | Bias: 0.069883\n",
            "Iteration: 46381 | Cost/Loss: 0.077628 | Weight: 0.528637 | Bias: 0.069883\n",
            "Iteration: 46382 | Cost/Loss: 0.077628 | Weight: 0.528637 | Bias: 0.069884\n",
            "Iteration: 46383 | Cost/Loss: 0.077628 | Weight: 0.528638 | Bias: 0.069884\n",
            "Iteration: 46384 | Cost/Loss: 0.077628 | Weight: 0.528638 | Bias: 0.069884\n",
            "Iteration: 46385 | Cost/Loss: 0.077628 | Weight: 0.528638 | Bias: 0.069885\n",
            "Iteration: 46386 | Cost/Loss: 0.077627 | Weight: 0.528638 | Bias: 0.069885\n",
            "Iteration: 46387 | Cost/Loss: 0.077627 | Weight: 0.528639 | Bias: 0.069885\n",
            "Iteration: 46388 | Cost/Loss: 0.077627 | Weight: 0.528639 | Bias: 0.069886\n",
            "Iteration: 46389 | Cost/Loss: 0.077627 | Weight: 0.528639 | Bias: 0.069886\n",
            "Iteration: 46390 | Cost/Loss: 0.077627 | Weight: 0.528640 | Bias: 0.069886\n",
            "Iteration: 46391 | Cost/Loss: 0.077627 | Weight: 0.528640 | Bias: 0.069887\n",
            "Iteration: 46392 | Cost/Loss: 0.077627 | Weight: 0.528640 | Bias: 0.069887\n",
            "Iteration: 46393 | Cost/Loss: 0.077627 | Weight: 0.528641 | Bias: 0.069887\n",
            "Iteration: 46394 | Cost/Loss: 0.077627 | Weight: 0.528641 | Bias: 0.069888\n",
            "Iteration: 46395 | Cost/Loss: 0.077627 | Weight: 0.528641 | Bias: 0.069888\n",
            "Iteration: 46396 | Cost/Loss: 0.077627 | Weight: 0.528641 | Bias: 0.069888\n",
            "Iteration: 46397 | Cost/Loss: 0.077627 | Weight: 0.528642 | Bias: 0.069888\n",
            "Iteration: 46398 | Cost/Loss: 0.077627 | Weight: 0.528642 | Bias: 0.069889\n",
            "Iteration: 46399 | Cost/Loss: 0.077627 | Weight: 0.528642 | Bias: 0.069889\n",
            "Iteration: 46400 | Cost/Loss: 0.077627 | Weight: 0.528643 | Bias: 0.069889\n",
            "Iteration: 46401 | Cost/Loss: 0.077627 | Weight: 0.528643 | Bias: 0.069890\n",
            "Iteration: 46402 | Cost/Loss: 0.077627 | Weight: 0.528643 | Bias: 0.069890\n",
            "Iteration: 46403 | Cost/Loss: 0.077627 | Weight: 0.528644 | Bias: 0.069890\n",
            "Iteration: 46404 | Cost/Loss: 0.077627 | Weight: 0.528644 | Bias: 0.069891\n",
            "Iteration: 46405 | Cost/Loss: 0.077627 | Weight: 0.528644 | Bias: 0.069891\n",
            "Iteration: 46406 | Cost/Loss: 0.077627 | Weight: 0.528644 | Bias: 0.069891\n",
            "Iteration: 46407 | Cost/Loss: 0.077627 | Weight: 0.528645 | Bias: 0.069892\n",
            "Iteration: 46408 | Cost/Loss: 0.077627 | Weight: 0.528645 | Bias: 0.069892\n",
            "Iteration: 46409 | Cost/Loss: 0.077627 | Weight: 0.528645 | Bias: 0.069892\n",
            "Iteration: 46410 | Cost/Loss: 0.077627 | Weight: 0.528646 | Bias: 0.069893\n",
            "Iteration: 46411 | Cost/Loss: 0.077627 | Weight: 0.528646 | Bias: 0.069893\n",
            "Iteration: 46412 | Cost/Loss: 0.077627 | Weight: 0.528646 | Bias: 0.069893\n",
            "Iteration: 46413 | Cost/Loss: 0.077627 | Weight: 0.528647 | Bias: 0.069894\n",
            "Iteration: 46414 | Cost/Loss: 0.077627 | Weight: 0.528647 | Bias: 0.069894\n",
            "Iteration: 46415 | Cost/Loss: 0.077627 | Weight: 0.528647 | Bias: 0.069894\n",
            "Iteration: 46416 | Cost/Loss: 0.077627 | Weight: 0.528647 | Bias: 0.069895\n",
            "Iteration: 46417 | Cost/Loss: 0.077627 | Weight: 0.528648 | Bias: 0.069895\n",
            "Iteration: 46418 | Cost/Loss: 0.077627 | Weight: 0.528648 | Bias: 0.069895\n",
            "Iteration: 46419 | Cost/Loss: 0.077627 | Weight: 0.528648 | Bias: 0.069896\n",
            "Iteration: 46420 | Cost/Loss: 0.077627 | Weight: 0.528649 | Bias: 0.069896\n",
            "Iteration: 46421 | Cost/Loss: 0.077627 | Weight: 0.528649 | Bias: 0.069896\n",
            "Iteration: 46422 | Cost/Loss: 0.077627 | Weight: 0.528649 | Bias: 0.069896\n",
            "Iteration: 46423 | Cost/Loss: 0.077627 | Weight: 0.528650 | Bias: 0.069897\n",
            "Iteration: 46424 | Cost/Loss: 0.077627 | Weight: 0.528650 | Bias: 0.069897\n",
            "Iteration: 46425 | Cost/Loss: 0.077626 | Weight: 0.528650 | Bias: 0.069897\n",
            "Iteration: 46426 | Cost/Loss: 0.077626 | Weight: 0.528650 | Bias: 0.069898\n",
            "Iteration: 46427 | Cost/Loss: 0.077626 | Weight: 0.528651 | Bias: 0.069898\n",
            "Iteration: 46428 | Cost/Loss: 0.077626 | Weight: 0.528651 | Bias: 0.069898\n",
            "Iteration: 46429 | Cost/Loss: 0.077626 | Weight: 0.528651 | Bias: 0.069899\n",
            "Iteration: 46430 | Cost/Loss: 0.077626 | Weight: 0.528652 | Bias: 0.069899\n",
            "Iteration: 46431 | Cost/Loss: 0.077626 | Weight: 0.528652 | Bias: 0.069899\n",
            "Iteration: 46432 | Cost/Loss: 0.077626 | Weight: 0.528652 | Bias: 0.069900\n",
            "Iteration: 46433 | Cost/Loss: 0.077626 | Weight: 0.528652 | Bias: 0.069900\n",
            "Iteration: 46434 | Cost/Loss: 0.077626 | Weight: 0.528653 | Bias: 0.069900\n",
            "Iteration: 46435 | Cost/Loss: 0.077626 | Weight: 0.528653 | Bias: 0.069901\n",
            "Iteration: 46436 | Cost/Loss: 0.077626 | Weight: 0.528653 | Bias: 0.069901\n",
            "Iteration: 46437 | Cost/Loss: 0.077626 | Weight: 0.528654 | Bias: 0.069901\n",
            "Iteration: 46438 | Cost/Loss: 0.077626 | Weight: 0.528654 | Bias: 0.069902\n",
            "Iteration: 46439 | Cost/Loss: 0.077626 | Weight: 0.528654 | Bias: 0.069902\n",
            "Iteration: 46440 | Cost/Loss: 0.077626 | Weight: 0.528655 | Bias: 0.069902\n",
            "Iteration: 46441 | Cost/Loss: 0.077626 | Weight: 0.528655 | Bias: 0.069903\n",
            "Iteration: 46442 | Cost/Loss: 0.077626 | Weight: 0.528655 | Bias: 0.069903\n",
            "Iteration: 46443 | Cost/Loss: 0.077626 | Weight: 0.528655 | Bias: 0.069903\n",
            "Iteration: 46444 | Cost/Loss: 0.077626 | Weight: 0.528656 | Bias: 0.069904\n",
            "Iteration: 46445 | Cost/Loss: 0.077626 | Weight: 0.528656 | Bias: 0.069904\n",
            "Iteration: 46446 | Cost/Loss: 0.077626 | Weight: 0.528656 | Bias: 0.069904\n",
            "Iteration: 46447 | Cost/Loss: 0.077626 | Weight: 0.528657 | Bias: 0.069905\n",
            "Iteration: 46448 | Cost/Loss: 0.077626 | Weight: 0.528657 | Bias: 0.069905\n",
            "Iteration: 46449 | Cost/Loss: 0.077626 | Weight: 0.528657 | Bias: 0.069905\n",
            "Iteration: 46450 | Cost/Loss: 0.077626 | Weight: 0.528658 | Bias: 0.069905\n",
            "Iteration: 46451 | Cost/Loss: 0.077626 | Weight: 0.528658 | Bias: 0.069906\n",
            "Iteration: 46452 | Cost/Loss: 0.077626 | Weight: 0.528658 | Bias: 0.069906\n",
            "Iteration: 46453 | Cost/Loss: 0.077626 | Weight: 0.528658 | Bias: 0.069906\n",
            "Iteration: 46454 | Cost/Loss: 0.077626 | Weight: 0.528659 | Bias: 0.069907\n",
            "Iteration: 46455 | Cost/Loss: 0.077626 | Weight: 0.528659 | Bias: 0.069907\n",
            "Iteration: 46456 | Cost/Loss: 0.077626 | Weight: 0.528659 | Bias: 0.069907\n",
            "Iteration: 46457 | Cost/Loss: 0.077626 | Weight: 0.528660 | Bias: 0.069908\n",
            "Iteration: 46458 | Cost/Loss: 0.077626 | Weight: 0.528660 | Bias: 0.069908\n",
            "Iteration: 46459 | Cost/Loss: 0.077626 | Weight: 0.528660 | Bias: 0.069908\n",
            "Iteration: 46460 | Cost/Loss: 0.077626 | Weight: 0.528661 | Bias: 0.069909\n",
            "Iteration: 46461 | Cost/Loss: 0.077626 | Weight: 0.528661 | Bias: 0.069909\n",
            "Iteration: 46462 | Cost/Loss: 0.077626 | Weight: 0.528661 | Bias: 0.069909\n",
            "Iteration: 46463 | Cost/Loss: 0.077626 | Weight: 0.528661 | Bias: 0.069910\n",
            "Iteration: 46464 | Cost/Loss: 0.077626 | Weight: 0.528662 | Bias: 0.069910\n",
            "Iteration: 46465 | Cost/Loss: 0.077625 | Weight: 0.528662 | Bias: 0.069910\n",
            "Iteration: 46466 | Cost/Loss: 0.077625 | Weight: 0.528662 | Bias: 0.069911\n",
            "Iteration: 46467 | Cost/Loss: 0.077625 | Weight: 0.528663 | Bias: 0.069911\n",
            "Iteration: 46468 | Cost/Loss: 0.077625 | Weight: 0.528663 | Bias: 0.069911\n",
            "Iteration: 46469 | Cost/Loss: 0.077625 | Weight: 0.528663 | Bias: 0.069912\n",
            "Iteration: 46470 | Cost/Loss: 0.077625 | Weight: 0.528664 | Bias: 0.069912\n",
            "Iteration: 46471 | Cost/Loss: 0.077625 | Weight: 0.528664 | Bias: 0.069912\n",
            "Iteration: 46472 | Cost/Loss: 0.077625 | Weight: 0.528664 | Bias: 0.069913\n",
            "Iteration: 46473 | Cost/Loss: 0.077625 | Weight: 0.528664 | Bias: 0.069913\n",
            "Iteration: 46474 | Cost/Loss: 0.077625 | Weight: 0.528665 | Bias: 0.069913\n",
            "Iteration: 46475 | Cost/Loss: 0.077625 | Weight: 0.528665 | Bias: 0.069913\n",
            "Iteration: 46476 | Cost/Loss: 0.077625 | Weight: 0.528665 | Bias: 0.069914\n",
            "Iteration: 46477 | Cost/Loss: 0.077625 | Weight: 0.528666 | Bias: 0.069914\n",
            "Iteration: 46478 | Cost/Loss: 0.077625 | Weight: 0.528666 | Bias: 0.069914\n",
            "Iteration: 46479 | Cost/Loss: 0.077625 | Weight: 0.528666 | Bias: 0.069915\n",
            "Iteration: 46480 | Cost/Loss: 0.077625 | Weight: 0.528666 | Bias: 0.069915\n",
            "Iteration: 46481 | Cost/Loss: 0.077625 | Weight: 0.528667 | Bias: 0.069915\n",
            "Iteration: 46482 | Cost/Loss: 0.077625 | Weight: 0.528667 | Bias: 0.069916\n",
            "Iteration: 46483 | Cost/Loss: 0.077625 | Weight: 0.528667 | Bias: 0.069916\n",
            "Iteration: 46484 | Cost/Loss: 0.077625 | Weight: 0.528668 | Bias: 0.069916\n",
            "Iteration: 46485 | Cost/Loss: 0.077625 | Weight: 0.528668 | Bias: 0.069917\n",
            "Iteration: 46486 | Cost/Loss: 0.077625 | Weight: 0.528668 | Bias: 0.069917\n",
            "Iteration: 46487 | Cost/Loss: 0.077625 | Weight: 0.528669 | Bias: 0.069917\n",
            "Iteration: 46488 | Cost/Loss: 0.077625 | Weight: 0.528669 | Bias: 0.069918\n",
            "Iteration: 46489 | Cost/Loss: 0.077625 | Weight: 0.528669 | Bias: 0.069918\n",
            "Iteration: 46490 | Cost/Loss: 0.077625 | Weight: 0.528669 | Bias: 0.069918\n",
            "Iteration: 46491 | Cost/Loss: 0.077625 | Weight: 0.528670 | Bias: 0.069919\n",
            "Iteration: 46492 | Cost/Loss: 0.077625 | Weight: 0.528670 | Bias: 0.069919\n",
            "Iteration: 46493 | Cost/Loss: 0.077625 | Weight: 0.528670 | Bias: 0.069919\n",
            "Iteration: 46494 | Cost/Loss: 0.077625 | Weight: 0.528671 | Bias: 0.069920\n",
            "Iteration: 46495 | Cost/Loss: 0.077625 | Weight: 0.528671 | Bias: 0.069920\n",
            "Iteration: 46496 | Cost/Loss: 0.077625 | Weight: 0.528671 | Bias: 0.069920\n",
            "Iteration: 46497 | Cost/Loss: 0.077625 | Weight: 0.528672 | Bias: 0.069921\n",
            "Iteration: 46498 | Cost/Loss: 0.077625 | Weight: 0.528672 | Bias: 0.069921\n",
            "Iteration: 46499 | Cost/Loss: 0.077625 | Weight: 0.528672 | Bias: 0.069921\n",
            "Iteration: 46500 | Cost/Loss: 0.077625 | Weight: 0.528672 | Bias: 0.069921\n",
            "Iteration: 46501 | Cost/Loss: 0.077625 | Weight: 0.528673 | Bias: 0.069922\n",
            "Iteration: 46502 | Cost/Loss: 0.077625 | Weight: 0.528673 | Bias: 0.069922\n",
            "Iteration: 46503 | Cost/Loss: 0.077625 | Weight: 0.528673 | Bias: 0.069922\n",
            "Iteration: 46504 | Cost/Loss: 0.077624 | Weight: 0.528674 | Bias: 0.069923\n",
            "Iteration: 46505 | Cost/Loss: 0.077624 | Weight: 0.528674 | Bias: 0.069923\n",
            "Iteration: 46506 | Cost/Loss: 0.077624 | Weight: 0.528674 | Bias: 0.069923\n",
            "Iteration: 46507 | Cost/Loss: 0.077624 | Weight: 0.528675 | Bias: 0.069924\n",
            "Iteration: 46508 | Cost/Loss: 0.077624 | Weight: 0.528675 | Bias: 0.069924\n",
            "Iteration: 46509 | Cost/Loss: 0.077624 | Weight: 0.528675 | Bias: 0.069924\n",
            "Iteration: 46510 | Cost/Loss: 0.077624 | Weight: 0.528675 | Bias: 0.069925\n",
            "Iteration: 46511 | Cost/Loss: 0.077624 | Weight: 0.528676 | Bias: 0.069925\n",
            "Iteration: 46512 | Cost/Loss: 0.077624 | Weight: 0.528676 | Bias: 0.069925\n",
            "Iteration: 46513 | Cost/Loss: 0.077624 | Weight: 0.528676 | Bias: 0.069926\n",
            "Iteration: 46514 | Cost/Loss: 0.077624 | Weight: 0.528677 | Bias: 0.069926\n",
            "Iteration: 46515 | Cost/Loss: 0.077624 | Weight: 0.528677 | Bias: 0.069926\n",
            "Iteration: 46516 | Cost/Loss: 0.077624 | Weight: 0.528677 | Bias: 0.069927\n",
            "Iteration: 46517 | Cost/Loss: 0.077624 | Weight: 0.528678 | Bias: 0.069927\n",
            "Iteration: 46518 | Cost/Loss: 0.077624 | Weight: 0.528678 | Bias: 0.069927\n",
            "Iteration: 46519 | Cost/Loss: 0.077624 | Weight: 0.528678 | Bias: 0.069928\n",
            "Iteration: 46520 | Cost/Loss: 0.077624 | Weight: 0.528678 | Bias: 0.069928\n",
            "Iteration: 46521 | Cost/Loss: 0.077624 | Weight: 0.528679 | Bias: 0.069928\n",
            "Iteration: 46522 | Cost/Loss: 0.077624 | Weight: 0.528679 | Bias: 0.069929\n",
            "Iteration: 46523 | Cost/Loss: 0.077624 | Weight: 0.528679 | Bias: 0.069929\n",
            "Iteration: 46524 | Cost/Loss: 0.077624 | Weight: 0.528680 | Bias: 0.069929\n",
            "Iteration: 46525 | Cost/Loss: 0.077624 | Weight: 0.528680 | Bias: 0.069929\n",
            "Iteration: 46526 | Cost/Loss: 0.077624 | Weight: 0.528680 | Bias: 0.069930\n",
            "Iteration: 46527 | Cost/Loss: 0.077624 | Weight: 0.528681 | Bias: 0.069930\n",
            "Iteration: 46528 | Cost/Loss: 0.077624 | Weight: 0.528681 | Bias: 0.069930\n",
            "Iteration: 46529 | Cost/Loss: 0.077624 | Weight: 0.528681 | Bias: 0.069931\n",
            "Iteration: 46530 | Cost/Loss: 0.077624 | Weight: 0.528681 | Bias: 0.069931\n",
            "Iteration: 46531 | Cost/Loss: 0.077624 | Weight: 0.528682 | Bias: 0.069931\n",
            "Iteration: 46532 | Cost/Loss: 0.077624 | Weight: 0.528682 | Bias: 0.069932\n",
            "Iteration: 46533 | Cost/Loss: 0.077624 | Weight: 0.528682 | Bias: 0.069932\n",
            "Iteration: 46534 | Cost/Loss: 0.077624 | Weight: 0.528683 | Bias: 0.069932\n",
            "Iteration: 46535 | Cost/Loss: 0.077624 | Weight: 0.528683 | Bias: 0.069933\n",
            "Iteration: 46536 | Cost/Loss: 0.077624 | Weight: 0.528683 | Bias: 0.069933\n",
            "Iteration: 46537 | Cost/Loss: 0.077624 | Weight: 0.528683 | Bias: 0.069933\n",
            "Iteration: 46538 | Cost/Loss: 0.077624 | Weight: 0.528684 | Bias: 0.069934\n",
            "Iteration: 46539 | Cost/Loss: 0.077624 | Weight: 0.528684 | Bias: 0.069934\n",
            "Iteration: 46540 | Cost/Loss: 0.077624 | Weight: 0.528684 | Bias: 0.069934\n",
            "Iteration: 46541 | Cost/Loss: 0.077624 | Weight: 0.528685 | Bias: 0.069935\n",
            "Iteration: 46542 | Cost/Loss: 0.077624 | Weight: 0.528685 | Bias: 0.069935\n",
            "Iteration: 46543 | Cost/Loss: 0.077624 | Weight: 0.528685 | Bias: 0.069935\n",
            "Iteration: 46544 | Cost/Loss: 0.077623 | Weight: 0.528686 | Bias: 0.069936\n",
            "Iteration: 46545 | Cost/Loss: 0.077623 | Weight: 0.528686 | Bias: 0.069936\n",
            "Iteration: 46546 | Cost/Loss: 0.077623 | Weight: 0.528686 | Bias: 0.069936\n",
            "Iteration: 46547 | Cost/Loss: 0.077623 | Weight: 0.528686 | Bias: 0.069937\n",
            "Iteration: 46548 | Cost/Loss: 0.077623 | Weight: 0.528687 | Bias: 0.069937\n",
            "Iteration: 46549 | Cost/Loss: 0.077623 | Weight: 0.528687 | Bias: 0.069937\n",
            "Iteration: 46550 | Cost/Loss: 0.077623 | Weight: 0.528687 | Bias: 0.069938\n",
            "Iteration: 46551 | Cost/Loss: 0.077623 | Weight: 0.528688 | Bias: 0.069938\n",
            "Iteration: 46552 | Cost/Loss: 0.077623 | Weight: 0.528688 | Bias: 0.069938\n",
            "Iteration: 46553 | Cost/Loss: 0.077623 | Weight: 0.528688 | Bias: 0.069938\n",
            "Iteration: 46554 | Cost/Loss: 0.077623 | Weight: 0.528689 | Bias: 0.069939\n",
            "Iteration: 46555 | Cost/Loss: 0.077623 | Weight: 0.528689 | Bias: 0.069939\n",
            "Iteration: 46556 | Cost/Loss: 0.077623 | Weight: 0.528689 | Bias: 0.069939\n",
            "Iteration: 46557 | Cost/Loss: 0.077623 | Weight: 0.528689 | Bias: 0.069940\n",
            "Iteration: 46558 | Cost/Loss: 0.077623 | Weight: 0.528690 | Bias: 0.069940\n",
            "Iteration: 46559 | Cost/Loss: 0.077623 | Weight: 0.528690 | Bias: 0.069940\n",
            "Iteration: 46560 | Cost/Loss: 0.077623 | Weight: 0.528690 | Bias: 0.069941\n",
            "Iteration: 46561 | Cost/Loss: 0.077623 | Weight: 0.528691 | Bias: 0.069941\n",
            "Iteration: 46562 | Cost/Loss: 0.077623 | Weight: 0.528691 | Bias: 0.069941\n",
            "Iteration: 46563 | Cost/Loss: 0.077623 | Weight: 0.528691 | Bias: 0.069942\n",
            "Iteration: 46564 | Cost/Loss: 0.077623 | Weight: 0.528692 | Bias: 0.069942\n",
            "Iteration: 46565 | Cost/Loss: 0.077623 | Weight: 0.528692 | Bias: 0.069942\n",
            "Iteration: 46566 | Cost/Loss: 0.077623 | Weight: 0.528692 | Bias: 0.069943\n",
            "Iteration: 46567 | Cost/Loss: 0.077623 | Weight: 0.528692 | Bias: 0.069943\n",
            "Iteration: 46568 | Cost/Loss: 0.077623 | Weight: 0.528693 | Bias: 0.069943\n",
            "Iteration: 46569 | Cost/Loss: 0.077623 | Weight: 0.528693 | Bias: 0.069944\n",
            "Iteration: 46570 | Cost/Loss: 0.077623 | Weight: 0.528693 | Bias: 0.069944\n",
            "Iteration: 46571 | Cost/Loss: 0.077623 | Weight: 0.528694 | Bias: 0.069944\n",
            "Iteration: 46572 | Cost/Loss: 0.077623 | Weight: 0.528694 | Bias: 0.069945\n",
            "Iteration: 46573 | Cost/Loss: 0.077623 | Weight: 0.528694 | Bias: 0.069945\n",
            "Iteration: 46574 | Cost/Loss: 0.077623 | Weight: 0.528695 | Bias: 0.069945\n",
            "Iteration: 46575 | Cost/Loss: 0.077623 | Weight: 0.528695 | Bias: 0.069946\n",
            "Iteration: 46576 | Cost/Loss: 0.077623 | Weight: 0.528695 | Bias: 0.069946\n",
            "Iteration: 46577 | Cost/Loss: 0.077623 | Weight: 0.528695 | Bias: 0.069946\n",
            "Iteration: 46578 | Cost/Loss: 0.077623 | Weight: 0.528696 | Bias: 0.069946\n",
            "Iteration: 46579 | Cost/Loss: 0.077623 | Weight: 0.528696 | Bias: 0.069947\n",
            "Iteration: 46580 | Cost/Loss: 0.077623 | Weight: 0.528696 | Bias: 0.069947\n",
            "Iteration: 46581 | Cost/Loss: 0.077623 | Weight: 0.528697 | Bias: 0.069947\n",
            "Iteration: 46582 | Cost/Loss: 0.077623 | Weight: 0.528697 | Bias: 0.069948\n",
            "Iteration: 46583 | Cost/Loss: 0.077623 | Weight: 0.528697 | Bias: 0.069948\n",
            "Iteration: 46584 | Cost/Loss: 0.077622 | Weight: 0.528697 | Bias: 0.069948\n",
            "Iteration: 46585 | Cost/Loss: 0.077622 | Weight: 0.528698 | Bias: 0.069949\n",
            "Iteration: 46586 | Cost/Loss: 0.077622 | Weight: 0.528698 | Bias: 0.069949\n",
            "Iteration: 46587 | Cost/Loss: 0.077622 | Weight: 0.528698 | Bias: 0.069949\n",
            "Iteration: 46588 | Cost/Loss: 0.077622 | Weight: 0.528699 | Bias: 0.069950\n",
            "Iteration: 46589 | Cost/Loss: 0.077622 | Weight: 0.528699 | Bias: 0.069950\n",
            "Iteration: 46590 | Cost/Loss: 0.077622 | Weight: 0.528699 | Bias: 0.069950\n",
            "Iteration: 46591 | Cost/Loss: 0.077622 | Weight: 0.528700 | Bias: 0.069951\n",
            "Iteration: 46592 | Cost/Loss: 0.077622 | Weight: 0.528700 | Bias: 0.069951\n",
            "Iteration: 46593 | Cost/Loss: 0.077622 | Weight: 0.528700 | Bias: 0.069951\n",
            "Iteration: 46594 | Cost/Loss: 0.077622 | Weight: 0.528700 | Bias: 0.069952\n",
            "Iteration: 46595 | Cost/Loss: 0.077622 | Weight: 0.528701 | Bias: 0.069952\n",
            "Iteration: 46596 | Cost/Loss: 0.077622 | Weight: 0.528701 | Bias: 0.069952\n",
            "Iteration: 46597 | Cost/Loss: 0.077622 | Weight: 0.528701 | Bias: 0.069953\n",
            "Iteration: 46598 | Cost/Loss: 0.077622 | Weight: 0.528702 | Bias: 0.069953\n",
            "Iteration: 46599 | Cost/Loss: 0.077622 | Weight: 0.528702 | Bias: 0.069953\n",
            "Iteration: 46600 | Cost/Loss: 0.077622 | Weight: 0.528702 | Bias: 0.069954\n",
            "Iteration: 46601 | Cost/Loss: 0.077622 | Weight: 0.528703 | Bias: 0.069954\n",
            "Iteration: 46602 | Cost/Loss: 0.077622 | Weight: 0.528703 | Bias: 0.069954\n",
            "Iteration: 46603 | Cost/Loss: 0.077622 | Weight: 0.528703 | Bias: 0.069954\n",
            "Iteration: 46604 | Cost/Loss: 0.077622 | Weight: 0.528703 | Bias: 0.069955\n",
            "Iteration: 46605 | Cost/Loss: 0.077622 | Weight: 0.528704 | Bias: 0.069955\n",
            "Iteration: 46606 | Cost/Loss: 0.077622 | Weight: 0.528704 | Bias: 0.069955\n",
            "Iteration: 46607 | Cost/Loss: 0.077622 | Weight: 0.528704 | Bias: 0.069956\n",
            "Iteration: 46608 | Cost/Loss: 0.077622 | Weight: 0.528705 | Bias: 0.069956\n",
            "Iteration: 46609 | Cost/Loss: 0.077622 | Weight: 0.528705 | Bias: 0.069956\n",
            "Iteration: 46610 | Cost/Loss: 0.077622 | Weight: 0.528705 | Bias: 0.069957\n",
            "Iteration: 46611 | Cost/Loss: 0.077622 | Weight: 0.528706 | Bias: 0.069957\n",
            "Iteration: 46612 | Cost/Loss: 0.077622 | Weight: 0.528706 | Bias: 0.069957\n",
            "Iteration: 46613 | Cost/Loss: 0.077622 | Weight: 0.528706 | Bias: 0.069958\n",
            "Iteration: 46614 | Cost/Loss: 0.077622 | Weight: 0.528706 | Bias: 0.069958\n",
            "Iteration: 46615 | Cost/Loss: 0.077622 | Weight: 0.528707 | Bias: 0.069958\n",
            "Iteration: 46616 | Cost/Loss: 0.077622 | Weight: 0.528707 | Bias: 0.069959\n",
            "Iteration: 46617 | Cost/Loss: 0.077622 | Weight: 0.528707 | Bias: 0.069959\n",
            "Iteration: 46618 | Cost/Loss: 0.077622 | Weight: 0.528708 | Bias: 0.069959\n",
            "Iteration: 46619 | Cost/Loss: 0.077622 | Weight: 0.528708 | Bias: 0.069960\n",
            "Iteration: 46620 | Cost/Loss: 0.077622 | Weight: 0.528708 | Bias: 0.069960\n",
            "Iteration: 46621 | Cost/Loss: 0.077622 | Weight: 0.528709 | Bias: 0.069960\n",
            "Iteration: 46622 | Cost/Loss: 0.077622 | Weight: 0.528709 | Bias: 0.069961\n",
            "Iteration: 46623 | Cost/Loss: 0.077621 | Weight: 0.528709 | Bias: 0.069961\n",
            "Iteration: 46624 | Cost/Loss: 0.077621 | Weight: 0.528709 | Bias: 0.069961\n",
            "Iteration: 46625 | Cost/Loss: 0.077621 | Weight: 0.528710 | Bias: 0.069962\n",
            "Iteration: 46626 | Cost/Loss: 0.077621 | Weight: 0.528710 | Bias: 0.069962\n",
            "Iteration: 46627 | Cost/Loss: 0.077621 | Weight: 0.528710 | Bias: 0.069962\n",
            "Iteration: 46628 | Cost/Loss: 0.077621 | Weight: 0.528711 | Bias: 0.069962\n",
            "Iteration: 46629 | Cost/Loss: 0.077621 | Weight: 0.528711 | Bias: 0.069963\n",
            "Iteration: 46630 | Cost/Loss: 0.077621 | Weight: 0.528711 | Bias: 0.069963\n",
            "Iteration: 46631 | Cost/Loss: 0.077621 | Weight: 0.528711 | Bias: 0.069963\n",
            "Iteration: 46632 | Cost/Loss: 0.077621 | Weight: 0.528712 | Bias: 0.069964\n",
            "Iteration: 46633 | Cost/Loss: 0.077621 | Weight: 0.528712 | Bias: 0.069964\n",
            "Iteration: 46634 | Cost/Loss: 0.077621 | Weight: 0.528712 | Bias: 0.069964\n",
            "Iteration: 46635 | Cost/Loss: 0.077621 | Weight: 0.528713 | Bias: 0.069965\n",
            "Iteration: 46636 | Cost/Loss: 0.077621 | Weight: 0.528713 | Bias: 0.069965\n",
            "Iteration: 46637 | Cost/Loss: 0.077621 | Weight: 0.528713 | Bias: 0.069965\n",
            "Iteration: 46638 | Cost/Loss: 0.077621 | Weight: 0.528714 | Bias: 0.069966\n",
            "Iteration: 46639 | Cost/Loss: 0.077621 | Weight: 0.528714 | Bias: 0.069966\n",
            "Iteration: 46640 | Cost/Loss: 0.077621 | Weight: 0.528714 | Bias: 0.069966\n",
            "Iteration: 46641 | Cost/Loss: 0.077621 | Weight: 0.528714 | Bias: 0.069967\n",
            "Iteration: 46642 | Cost/Loss: 0.077621 | Weight: 0.528715 | Bias: 0.069967\n",
            "Iteration: 46643 | Cost/Loss: 0.077621 | Weight: 0.528715 | Bias: 0.069967\n",
            "Iteration: 46644 | Cost/Loss: 0.077621 | Weight: 0.528715 | Bias: 0.069968\n",
            "Iteration: 46645 | Cost/Loss: 0.077621 | Weight: 0.528716 | Bias: 0.069968\n",
            "Iteration: 46646 | Cost/Loss: 0.077621 | Weight: 0.528716 | Bias: 0.069968\n",
            "Iteration: 46647 | Cost/Loss: 0.077621 | Weight: 0.528716 | Bias: 0.069969\n",
            "Iteration: 46648 | Cost/Loss: 0.077621 | Weight: 0.528717 | Bias: 0.069969\n",
            "Iteration: 46649 | Cost/Loss: 0.077621 | Weight: 0.528717 | Bias: 0.069969\n",
            "Iteration: 46650 | Cost/Loss: 0.077621 | Weight: 0.528717 | Bias: 0.069970\n",
            "Iteration: 46651 | Cost/Loss: 0.077621 | Weight: 0.528717 | Bias: 0.069970\n",
            "Iteration: 46652 | Cost/Loss: 0.077621 | Weight: 0.528718 | Bias: 0.069970\n",
            "Iteration: 46653 | Cost/Loss: 0.077621 | Weight: 0.528718 | Bias: 0.069971\n",
            "Iteration: 46654 | Cost/Loss: 0.077621 | Weight: 0.528718 | Bias: 0.069971\n",
            "Iteration: 46655 | Cost/Loss: 0.077621 | Weight: 0.528719 | Bias: 0.069971\n",
            "Iteration: 46656 | Cost/Loss: 0.077621 | Weight: 0.528719 | Bias: 0.069971\n",
            "Iteration: 46657 | Cost/Loss: 0.077621 | Weight: 0.528719 | Bias: 0.069972\n",
            "Iteration: 46658 | Cost/Loss: 0.077621 | Weight: 0.528720 | Bias: 0.069972\n",
            "Iteration: 46659 | Cost/Loss: 0.077621 | Weight: 0.528720 | Bias: 0.069972\n",
            "Iteration: 46660 | Cost/Loss: 0.077621 | Weight: 0.528720 | Bias: 0.069973\n",
            "Iteration: 46661 | Cost/Loss: 0.077621 | Weight: 0.528720 | Bias: 0.069973\n",
            "Iteration: 46662 | Cost/Loss: 0.077621 | Weight: 0.528721 | Bias: 0.069973\n",
            "Iteration: 46663 | Cost/Loss: 0.077620 | Weight: 0.528721 | Bias: 0.069974\n",
            "Iteration: 46664 | Cost/Loss: 0.077620 | Weight: 0.528721 | Bias: 0.069974\n",
            "Iteration: 46665 | Cost/Loss: 0.077620 | Weight: 0.528722 | Bias: 0.069974\n",
            "Iteration: 46666 | Cost/Loss: 0.077620 | Weight: 0.528722 | Bias: 0.069975\n",
            "Iteration: 46667 | Cost/Loss: 0.077620 | Weight: 0.528722 | Bias: 0.069975\n",
            "Iteration: 46668 | Cost/Loss: 0.077620 | Weight: 0.528723 | Bias: 0.069975\n",
            "Iteration: 46669 | Cost/Loss: 0.077620 | Weight: 0.528723 | Bias: 0.069976\n",
            "Iteration: 46670 | Cost/Loss: 0.077620 | Weight: 0.528723 | Bias: 0.069976\n",
            "Iteration: 46671 | Cost/Loss: 0.077620 | Weight: 0.528723 | Bias: 0.069976\n",
            "Iteration: 46672 | Cost/Loss: 0.077620 | Weight: 0.528724 | Bias: 0.069977\n",
            "Iteration: 46673 | Cost/Loss: 0.077620 | Weight: 0.528724 | Bias: 0.069977\n",
            "Iteration: 46674 | Cost/Loss: 0.077620 | Weight: 0.528724 | Bias: 0.069977\n",
            "Iteration: 46675 | Cost/Loss: 0.077620 | Weight: 0.528725 | Bias: 0.069978\n",
            "Iteration: 46676 | Cost/Loss: 0.077620 | Weight: 0.528725 | Bias: 0.069978\n",
            "Iteration: 46677 | Cost/Loss: 0.077620 | Weight: 0.528725 | Bias: 0.069978\n",
            "Iteration: 46678 | Cost/Loss: 0.077620 | Weight: 0.528726 | Bias: 0.069979\n",
            "Iteration: 46679 | Cost/Loss: 0.077620 | Weight: 0.528726 | Bias: 0.069979\n",
            "Iteration: 46680 | Cost/Loss: 0.077620 | Weight: 0.528726 | Bias: 0.069979\n",
            "Iteration: 46681 | Cost/Loss: 0.077620 | Weight: 0.528726 | Bias: 0.069979\n",
            "Iteration: 46682 | Cost/Loss: 0.077620 | Weight: 0.528727 | Bias: 0.069980\n",
            "Iteration: 46683 | Cost/Loss: 0.077620 | Weight: 0.528727 | Bias: 0.069980\n",
            "Iteration: 46684 | Cost/Loss: 0.077620 | Weight: 0.528727 | Bias: 0.069980\n",
            "Iteration: 46685 | Cost/Loss: 0.077620 | Weight: 0.528728 | Bias: 0.069981\n",
            "Iteration: 46686 | Cost/Loss: 0.077620 | Weight: 0.528728 | Bias: 0.069981\n",
            "Iteration: 46687 | Cost/Loss: 0.077620 | Weight: 0.528728 | Bias: 0.069981\n",
            "Iteration: 46688 | Cost/Loss: 0.077620 | Weight: 0.528728 | Bias: 0.069982\n",
            "Iteration: 46689 | Cost/Loss: 0.077620 | Weight: 0.528729 | Bias: 0.069982\n",
            "Iteration: 46690 | Cost/Loss: 0.077620 | Weight: 0.528729 | Bias: 0.069982\n",
            "Iteration: 46691 | Cost/Loss: 0.077620 | Weight: 0.528729 | Bias: 0.069983\n",
            "Iteration: 46692 | Cost/Loss: 0.077620 | Weight: 0.528730 | Bias: 0.069983\n",
            "Iteration: 46693 | Cost/Loss: 0.077620 | Weight: 0.528730 | Bias: 0.069983\n",
            "Iteration: 46694 | Cost/Loss: 0.077620 | Weight: 0.528730 | Bias: 0.069984\n",
            "Iteration: 46695 | Cost/Loss: 0.077620 | Weight: 0.528731 | Bias: 0.069984\n",
            "Iteration: 46696 | Cost/Loss: 0.077620 | Weight: 0.528731 | Bias: 0.069984\n",
            "Iteration: 46697 | Cost/Loss: 0.077620 | Weight: 0.528731 | Bias: 0.069985\n",
            "Iteration: 46698 | Cost/Loss: 0.077620 | Weight: 0.528731 | Bias: 0.069985\n",
            "Iteration: 46699 | Cost/Loss: 0.077620 | Weight: 0.528732 | Bias: 0.069985\n",
            "Iteration: 46700 | Cost/Loss: 0.077620 | Weight: 0.528732 | Bias: 0.069986\n",
            "Iteration: 46701 | Cost/Loss: 0.077620 | Weight: 0.528732 | Bias: 0.069986\n",
            "Iteration: 46702 | Cost/Loss: 0.077620 | Weight: 0.528733 | Bias: 0.069986\n",
            "Iteration: 46703 | Cost/Loss: 0.077619 | Weight: 0.528733 | Bias: 0.069987\n",
            "Iteration: 46704 | Cost/Loss: 0.077619 | Weight: 0.528733 | Bias: 0.069987\n",
            "Iteration: 46705 | Cost/Loss: 0.077619 | Weight: 0.528734 | Bias: 0.069987\n",
            "Iteration: 46706 | Cost/Loss: 0.077619 | Weight: 0.528734 | Bias: 0.069987\n",
            "Iteration: 46707 | Cost/Loss: 0.077619 | Weight: 0.528734 | Bias: 0.069988\n",
            "Iteration: 46708 | Cost/Loss: 0.077619 | Weight: 0.528734 | Bias: 0.069988\n",
            "Iteration: 46709 | Cost/Loss: 0.077619 | Weight: 0.528735 | Bias: 0.069988\n",
            "Iteration: 46710 | Cost/Loss: 0.077619 | Weight: 0.528735 | Bias: 0.069989\n",
            "Iteration: 46711 | Cost/Loss: 0.077619 | Weight: 0.528735 | Bias: 0.069989\n",
            "Iteration: 46712 | Cost/Loss: 0.077619 | Weight: 0.528736 | Bias: 0.069989\n",
            "Iteration: 46713 | Cost/Loss: 0.077619 | Weight: 0.528736 | Bias: 0.069990\n",
            "Iteration: 46714 | Cost/Loss: 0.077619 | Weight: 0.528736 | Bias: 0.069990\n",
            "Iteration: 46715 | Cost/Loss: 0.077619 | Weight: 0.528737 | Bias: 0.069990\n",
            "Iteration: 46716 | Cost/Loss: 0.077619 | Weight: 0.528737 | Bias: 0.069991\n",
            "Iteration: 46717 | Cost/Loss: 0.077619 | Weight: 0.528737 | Bias: 0.069991\n",
            "Iteration: 46718 | Cost/Loss: 0.077619 | Weight: 0.528737 | Bias: 0.069991\n",
            "Iteration: 46719 | Cost/Loss: 0.077619 | Weight: 0.528738 | Bias: 0.069992\n",
            "Iteration: 46720 | Cost/Loss: 0.077619 | Weight: 0.528738 | Bias: 0.069992\n",
            "Iteration: 46721 | Cost/Loss: 0.077619 | Weight: 0.528738 | Bias: 0.069992\n",
            "Iteration: 46722 | Cost/Loss: 0.077619 | Weight: 0.528739 | Bias: 0.069993\n",
            "Iteration: 46723 | Cost/Loss: 0.077619 | Weight: 0.528739 | Bias: 0.069993\n",
            "Iteration: 46724 | Cost/Loss: 0.077619 | Weight: 0.528739 | Bias: 0.069993\n",
            "Iteration: 46725 | Cost/Loss: 0.077619 | Weight: 0.528740 | Bias: 0.069994\n",
            "Iteration: 46726 | Cost/Loss: 0.077619 | Weight: 0.528740 | Bias: 0.069994\n",
            "Iteration: 46727 | Cost/Loss: 0.077619 | Weight: 0.528740 | Bias: 0.069994\n",
            "Iteration: 46728 | Cost/Loss: 0.077619 | Weight: 0.528740 | Bias: 0.069995\n",
            "Iteration: 46729 | Cost/Loss: 0.077619 | Weight: 0.528741 | Bias: 0.069995\n",
            "Iteration: 46730 | Cost/Loss: 0.077619 | Weight: 0.528741 | Bias: 0.069995\n",
            "Iteration: 46731 | Cost/Loss: 0.077619 | Weight: 0.528741 | Bias: 0.069995\n",
            "Iteration: 46732 | Cost/Loss: 0.077619 | Weight: 0.528742 | Bias: 0.069996\n",
            "Iteration: 46733 | Cost/Loss: 0.077619 | Weight: 0.528742 | Bias: 0.069996\n",
            "Iteration: 46734 | Cost/Loss: 0.077619 | Weight: 0.528742 | Bias: 0.069996\n",
            "Iteration: 46735 | Cost/Loss: 0.077619 | Weight: 0.528742 | Bias: 0.069997\n",
            "Iteration: 46736 | Cost/Loss: 0.077619 | Weight: 0.528743 | Bias: 0.069997\n",
            "Iteration: 46737 | Cost/Loss: 0.077619 | Weight: 0.528743 | Bias: 0.069997\n",
            "Iteration: 46738 | Cost/Loss: 0.077619 | Weight: 0.528743 | Bias: 0.069998\n",
            "Iteration: 46739 | Cost/Loss: 0.077619 | Weight: 0.528744 | Bias: 0.069998\n",
            "Iteration: 46740 | Cost/Loss: 0.077619 | Weight: 0.528744 | Bias: 0.069998\n",
            "Iteration: 46741 | Cost/Loss: 0.077619 | Weight: 0.528744 | Bias: 0.069999\n",
            "Iteration: 46742 | Cost/Loss: 0.077618 | Weight: 0.528745 | Bias: 0.069999\n",
            "Iteration: 46743 | Cost/Loss: 0.077618 | Weight: 0.528745 | Bias: 0.069999\n",
            "Iteration: 46744 | Cost/Loss: 0.077618 | Weight: 0.528745 | Bias: 0.070000\n",
            "Iteration: 46745 | Cost/Loss: 0.077618 | Weight: 0.528745 | Bias: 0.070000\n",
            "Iteration: 46746 | Cost/Loss: 0.077618 | Weight: 0.528746 | Bias: 0.070000\n",
            "Iteration: 46747 | Cost/Loss: 0.077618 | Weight: 0.528746 | Bias: 0.070001\n",
            "Iteration: 46748 | Cost/Loss: 0.077618 | Weight: 0.528746 | Bias: 0.070001\n",
            "Iteration: 46749 | Cost/Loss: 0.077618 | Weight: 0.528747 | Bias: 0.070001\n",
            "Iteration: 46750 | Cost/Loss: 0.077618 | Weight: 0.528747 | Bias: 0.070002\n",
            "Iteration: 46751 | Cost/Loss: 0.077618 | Weight: 0.528747 | Bias: 0.070002\n",
            "Iteration: 46752 | Cost/Loss: 0.077618 | Weight: 0.528748 | Bias: 0.070002\n",
            "Iteration: 46753 | Cost/Loss: 0.077618 | Weight: 0.528748 | Bias: 0.070003\n",
            "Iteration: 46754 | Cost/Loss: 0.077618 | Weight: 0.528748 | Bias: 0.070003\n",
            "Iteration: 46755 | Cost/Loss: 0.077618 | Weight: 0.528748 | Bias: 0.070003\n",
            "Iteration: 46756 | Cost/Loss: 0.077618 | Weight: 0.528749 | Bias: 0.070004\n",
            "Iteration: 46757 | Cost/Loss: 0.077618 | Weight: 0.528749 | Bias: 0.070004\n",
            "Iteration: 46758 | Cost/Loss: 0.077618 | Weight: 0.528749 | Bias: 0.070004\n",
            "Iteration: 46759 | Cost/Loss: 0.077618 | Weight: 0.528750 | Bias: 0.070004\n",
            "Iteration: 46760 | Cost/Loss: 0.077618 | Weight: 0.528750 | Bias: 0.070005\n",
            "Iteration: 46761 | Cost/Loss: 0.077618 | Weight: 0.528750 | Bias: 0.070005\n",
            "Iteration: 46762 | Cost/Loss: 0.077618 | Weight: 0.528751 | Bias: 0.070005\n",
            "Iteration: 46763 | Cost/Loss: 0.077618 | Weight: 0.528751 | Bias: 0.070006\n",
            "Iteration: 46764 | Cost/Loss: 0.077618 | Weight: 0.528751 | Bias: 0.070006\n",
            "Iteration: 46765 | Cost/Loss: 0.077618 | Weight: 0.528751 | Bias: 0.070006\n",
            "Iteration: 46766 | Cost/Loss: 0.077618 | Weight: 0.528752 | Bias: 0.070007\n",
            "Iteration: 46767 | Cost/Loss: 0.077618 | Weight: 0.528752 | Bias: 0.070007\n",
            "Iteration: 46768 | Cost/Loss: 0.077618 | Weight: 0.528752 | Bias: 0.070007\n",
            "Iteration: 46769 | Cost/Loss: 0.077618 | Weight: 0.528753 | Bias: 0.070008\n",
            "Iteration: 46770 | Cost/Loss: 0.077618 | Weight: 0.528753 | Bias: 0.070008\n",
            "Iteration: 46771 | Cost/Loss: 0.077618 | Weight: 0.528753 | Bias: 0.070008\n",
            "Iteration: 46772 | Cost/Loss: 0.077618 | Weight: 0.528754 | Bias: 0.070009\n",
            "Iteration: 46773 | Cost/Loss: 0.077618 | Weight: 0.528754 | Bias: 0.070009\n",
            "Iteration: 46774 | Cost/Loss: 0.077618 | Weight: 0.528754 | Bias: 0.070009\n",
            "Iteration: 46775 | Cost/Loss: 0.077618 | Weight: 0.528754 | Bias: 0.070010\n",
            "Iteration: 46776 | Cost/Loss: 0.077618 | Weight: 0.528755 | Bias: 0.070010\n",
            "Iteration: 46777 | Cost/Loss: 0.077618 | Weight: 0.528755 | Bias: 0.070010\n",
            "Iteration: 46778 | Cost/Loss: 0.077618 | Weight: 0.528755 | Bias: 0.070011\n",
            "Iteration: 46779 | Cost/Loss: 0.077618 | Weight: 0.528756 | Bias: 0.070011\n",
            "Iteration: 46780 | Cost/Loss: 0.077618 | Weight: 0.528756 | Bias: 0.070011\n",
            "Iteration: 46781 | Cost/Loss: 0.077618 | Weight: 0.528756 | Bias: 0.070012\n",
            "Iteration: 46782 | Cost/Loss: 0.077617 | Weight: 0.528756 | Bias: 0.070012\n",
            "Iteration: 46783 | Cost/Loss: 0.077617 | Weight: 0.528757 | Bias: 0.070012\n",
            "Iteration: 46784 | Cost/Loss: 0.077617 | Weight: 0.528757 | Bias: 0.070012\n",
            "Iteration: 46785 | Cost/Loss: 0.077617 | Weight: 0.528757 | Bias: 0.070013\n",
            "Iteration: 46786 | Cost/Loss: 0.077617 | Weight: 0.528758 | Bias: 0.070013\n",
            "Iteration: 46787 | Cost/Loss: 0.077617 | Weight: 0.528758 | Bias: 0.070013\n",
            "Iteration: 46788 | Cost/Loss: 0.077617 | Weight: 0.528758 | Bias: 0.070014\n",
            "Iteration: 46789 | Cost/Loss: 0.077617 | Weight: 0.528759 | Bias: 0.070014\n",
            "Iteration: 46790 | Cost/Loss: 0.077617 | Weight: 0.528759 | Bias: 0.070014\n",
            "Iteration: 46791 | Cost/Loss: 0.077617 | Weight: 0.528759 | Bias: 0.070015\n",
            "Iteration: 46792 | Cost/Loss: 0.077617 | Weight: 0.528759 | Bias: 0.070015\n",
            "Iteration: 46793 | Cost/Loss: 0.077617 | Weight: 0.528760 | Bias: 0.070015\n",
            "Iteration: 46794 | Cost/Loss: 0.077617 | Weight: 0.528760 | Bias: 0.070016\n",
            "Iteration: 46795 | Cost/Loss: 0.077617 | Weight: 0.528760 | Bias: 0.070016\n",
            "Iteration: 46796 | Cost/Loss: 0.077617 | Weight: 0.528761 | Bias: 0.070016\n",
            "Iteration: 46797 | Cost/Loss: 0.077617 | Weight: 0.528761 | Bias: 0.070017\n",
            "Iteration: 46798 | Cost/Loss: 0.077617 | Weight: 0.528761 | Bias: 0.070017\n",
            "Iteration: 46799 | Cost/Loss: 0.077617 | Weight: 0.528762 | Bias: 0.070017\n",
            "Iteration: 46800 | Cost/Loss: 0.077617 | Weight: 0.528762 | Bias: 0.070018\n",
            "Iteration: 46801 | Cost/Loss: 0.077617 | Weight: 0.528762 | Bias: 0.070018\n",
            "Iteration: 46802 | Cost/Loss: 0.077617 | Weight: 0.528762 | Bias: 0.070018\n",
            "Iteration: 46803 | Cost/Loss: 0.077617 | Weight: 0.528763 | Bias: 0.070019\n",
            "Iteration: 46804 | Cost/Loss: 0.077617 | Weight: 0.528763 | Bias: 0.070019\n",
            "Iteration: 46805 | Cost/Loss: 0.077617 | Weight: 0.528763 | Bias: 0.070019\n",
            "Iteration: 46806 | Cost/Loss: 0.077617 | Weight: 0.528764 | Bias: 0.070020\n",
            "Iteration: 46807 | Cost/Loss: 0.077617 | Weight: 0.528764 | Bias: 0.070020\n",
            "Iteration: 46808 | Cost/Loss: 0.077617 | Weight: 0.528764 | Bias: 0.070020\n",
            "Iteration: 46809 | Cost/Loss: 0.077617 | Weight: 0.528765 | Bias: 0.070020\n",
            "Iteration: 46810 | Cost/Loss: 0.077617 | Weight: 0.528765 | Bias: 0.070021\n",
            "Iteration: 46811 | Cost/Loss: 0.077617 | Weight: 0.528765 | Bias: 0.070021\n",
            "Iteration: 46812 | Cost/Loss: 0.077617 | Weight: 0.528765 | Bias: 0.070021\n",
            "Iteration: 46813 | Cost/Loss: 0.077617 | Weight: 0.528766 | Bias: 0.070022\n",
            "Iteration: 46814 | Cost/Loss: 0.077617 | Weight: 0.528766 | Bias: 0.070022\n",
            "Iteration: 46815 | Cost/Loss: 0.077617 | Weight: 0.528766 | Bias: 0.070022\n",
            "Iteration: 46816 | Cost/Loss: 0.077617 | Weight: 0.528767 | Bias: 0.070023\n",
            "Iteration: 46817 | Cost/Loss: 0.077617 | Weight: 0.528767 | Bias: 0.070023\n",
            "Iteration: 46818 | Cost/Loss: 0.077617 | Weight: 0.528767 | Bias: 0.070023\n",
            "Iteration: 46819 | Cost/Loss: 0.077617 | Weight: 0.528768 | Bias: 0.070024\n",
            "Iteration: 46820 | Cost/Loss: 0.077617 | Weight: 0.528768 | Bias: 0.070024\n",
            "Iteration: 46821 | Cost/Loss: 0.077616 | Weight: 0.528768 | Bias: 0.070024\n",
            "Iteration: 46822 | Cost/Loss: 0.077616 | Weight: 0.528768 | Bias: 0.070025\n",
            "Iteration: 46823 | Cost/Loss: 0.077616 | Weight: 0.528769 | Bias: 0.070025\n",
            "Iteration: 46824 | Cost/Loss: 0.077616 | Weight: 0.528769 | Bias: 0.070025\n",
            "Iteration: 46825 | Cost/Loss: 0.077616 | Weight: 0.528769 | Bias: 0.070026\n",
            "Iteration: 46826 | Cost/Loss: 0.077616 | Weight: 0.528770 | Bias: 0.070026\n",
            "Iteration: 46827 | Cost/Loss: 0.077616 | Weight: 0.528770 | Bias: 0.070026\n",
            "Iteration: 46828 | Cost/Loss: 0.077616 | Weight: 0.528770 | Bias: 0.070027\n",
            "Iteration: 46829 | Cost/Loss: 0.077616 | Weight: 0.528771 | Bias: 0.070027\n",
            "Iteration: 46830 | Cost/Loss: 0.077616 | Weight: 0.528771 | Bias: 0.070027\n",
            "Iteration: 46831 | Cost/Loss: 0.077616 | Weight: 0.528771 | Bias: 0.070028\n",
            "Iteration: 46832 | Cost/Loss: 0.077616 | Weight: 0.528771 | Bias: 0.070028\n",
            "Iteration: 46833 | Cost/Loss: 0.077616 | Weight: 0.528772 | Bias: 0.070028\n",
            "Iteration: 46834 | Cost/Loss: 0.077616 | Weight: 0.528772 | Bias: 0.070028\n",
            "Iteration: 46835 | Cost/Loss: 0.077616 | Weight: 0.528772 | Bias: 0.070029\n",
            "Iteration: 46836 | Cost/Loss: 0.077616 | Weight: 0.528773 | Bias: 0.070029\n",
            "Iteration: 46837 | Cost/Loss: 0.077616 | Weight: 0.528773 | Bias: 0.070029\n",
            "Iteration: 46838 | Cost/Loss: 0.077616 | Weight: 0.528773 | Bias: 0.070030\n",
            "Iteration: 46839 | Cost/Loss: 0.077616 | Weight: 0.528773 | Bias: 0.070030\n",
            "Iteration: 46840 | Cost/Loss: 0.077616 | Weight: 0.528774 | Bias: 0.070030\n",
            "Iteration: 46841 | Cost/Loss: 0.077616 | Weight: 0.528774 | Bias: 0.070031\n",
            "Iteration: 46842 | Cost/Loss: 0.077616 | Weight: 0.528774 | Bias: 0.070031\n",
            "Iteration: 46843 | Cost/Loss: 0.077616 | Weight: 0.528775 | Bias: 0.070031\n",
            "Iteration: 46844 | Cost/Loss: 0.077616 | Weight: 0.528775 | Bias: 0.070032\n",
            "Iteration: 46845 | Cost/Loss: 0.077616 | Weight: 0.528775 | Bias: 0.070032\n",
            "Iteration: 46846 | Cost/Loss: 0.077616 | Weight: 0.528776 | Bias: 0.070032\n",
            "Iteration: 46847 | Cost/Loss: 0.077616 | Weight: 0.528776 | Bias: 0.070033\n",
            "Iteration: 46848 | Cost/Loss: 0.077616 | Weight: 0.528776 | Bias: 0.070033\n",
            "Iteration: 46849 | Cost/Loss: 0.077616 | Weight: 0.528776 | Bias: 0.070033\n",
            "Iteration: 46850 | Cost/Loss: 0.077616 | Weight: 0.528777 | Bias: 0.070034\n",
            "Iteration: 46851 | Cost/Loss: 0.077616 | Weight: 0.528777 | Bias: 0.070034\n",
            "Iteration: 46852 | Cost/Loss: 0.077616 | Weight: 0.528777 | Bias: 0.070034\n",
            "Iteration: 46853 | Cost/Loss: 0.077616 | Weight: 0.528778 | Bias: 0.070035\n",
            "Iteration: 46854 | Cost/Loss: 0.077616 | Weight: 0.528778 | Bias: 0.070035\n",
            "Iteration: 46855 | Cost/Loss: 0.077616 | Weight: 0.528778 | Bias: 0.070035\n",
            "Iteration: 46856 | Cost/Loss: 0.077616 | Weight: 0.528779 | Bias: 0.070036\n",
            "Iteration: 46857 | Cost/Loss: 0.077616 | Weight: 0.528779 | Bias: 0.070036\n",
            "Iteration: 46858 | Cost/Loss: 0.077616 | Weight: 0.528779 | Bias: 0.070036\n",
            "Iteration: 46859 | Cost/Loss: 0.077616 | Weight: 0.528779 | Bias: 0.070037\n",
            "Iteration: 46860 | Cost/Loss: 0.077616 | Weight: 0.528780 | Bias: 0.070037\n",
            "Iteration: 46861 | Cost/Loss: 0.077615 | Weight: 0.528780 | Bias: 0.070037\n",
            "Iteration: 46862 | Cost/Loss: 0.077615 | Weight: 0.528780 | Bias: 0.070037\n",
            "Iteration: 46863 | Cost/Loss: 0.077615 | Weight: 0.528781 | Bias: 0.070038\n",
            "Iteration: 46864 | Cost/Loss: 0.077615 | Weight: 0.528781 | Bias: 0.070038\n",
            "Iteration: 46865 | Cost/Loss: 0.077615 | Weight: 0.528781 | Bias: 0.070038\n",
            "Iteration: 46866 | Cost/Loss: 0.077615 | Weight: 0.528782 | Bias: 0.070039\n",
            "Iteration: 46867 | Cost/Loss: 0.077615 | Weight: 0.528782 | Bias: 0.070039\n",
            "Iteration: 46868 | Cost/Loss: 0.077615 | Weight: 0.528782 | Bias: 0.070039\n",
            "Iteration: 46869 | Cost/Loss: 0.077615 | Weight: 0.528782 | Bias: 0.070040\n",
            "Iteration: 46870 | Cost/Loss: 0.077615 | Weight: 0.528783 | Bias: 0.070040\n",
            "Iteration: 46871 | Cost/Loss: 0.077615 | Weight: 0.528783 | Bias: 0.070040\n",
            "Iteration: 46872 | Cost/Loss: 0.077615 | Weight: 0.528783 | Bias: 0.070041\n",
            "Iteration: 46873 | Cost/Loss: 0.077615 | Weight: 0.528784 | Bias: 0.070041\n",
            "Iteration: 46874 | Cost/Loss: 0.077615 | Weight: 0.528784 | Bias: 0.070041\n",
            "Iteration: 46875 | Cost/Loss: 0.077615 | Weight: 0.528784 | Bias: 0.070042\n",
            "Iteration: 46876 | Cost/Loss: 0.077615 | Weight: 0.528785 | Bias: 0.070042\n",
            "Iteration: 46877 | Cost/Loss: 0.077615 | Weight: 0.528785 | Bias: 0.070042\n",
            "Iteration: 46878 | Cost/Loss: 0.077615 | Weight: 0.528785 | Bias: 0.070043\n",
            "Iteration: 46879 | Cost/Loss: 0.077615 | Weight: 0.528785 | Bias: 0.070043\n",
            "Iteration: 46880 | Cost/Loss: 0.077615 | Weight: 0.528786 | Bias: 0.070043\n",
            "Iteration: 46881 | Cost/Loss: 0.077615 | Weight: 0.528786 | Bias: 0.070044\n",
            "Iteration: 46882 | Cost/Loss: 0.077615 | Weight: 0.528786 | Bias: 0.070044\n",
            "Iteration: 46883 | Cost/Loss: 0.077615 | Weight: 0.528787 | Bias: 0.070044\n",
            "Iteration: 46884 | Cost/Loss: 0.077615 | Weight: 0.528787 | Bias: 0.070045\n",
            "Iteration: 46885 | Cost/Loss: 0.077615 | Weight: 0.528787 | Bias: 0.070045\n",
            "Iteration: 46886 | Cost/Loss: 0.077615 | Weight: 0.528787 | Bias: 0.070045\n",
            "Iteration: 46887 | Cost/Loss: 0.077615 | Weight: 0.528788 | Bias: 0.070045\n",
            "Iteration: 46888 | Cost/Loss: 0.077615 | Weight: 0.528788 | Bias: 0.070046\n",
            "Iteration: 46889 | Cost/Loss: 0.077615 | Weight: 0.528788 | Bias: 0.070046\n",
            "Iteration: 46890 | Cost/Loss: 0.077615 | Weight: 0.528789 | Bias: 0.070046\n",
            "Iteration: 46891 | Cost/Loss: 0.077615 | Weight: 0.528789 | Bias: 0.070047\n",
            "Iteration: 46892 | Cost/Loss: 0.077615 | Weight: 0.528789 | Bias: 0.070047\n",
            "Iteration: 46893 | Cost/Loss: 0.077615 | Weight: 0.528790 | Bias: 0.070047\n",
            "Iteration: 46894 | Cost/Loss: 0.077615 | Weight: 0.528790 | Bias: 0.070048\n",
            "Iteration: 46895 | Cost/Loss: 0.077615 | Weight: 0.528790 | Bias: 0.070048\n",
            "Iteration: 46896 | Cost/Loss: 0.077615 | Weight: 0.528790 | Bias: 0.070048\n",
            "Iteration: 46897 | Cost/Loss: 0.077615 | Weight: 0.528791 | Bias: 0.070049\n",
            "Iteration: 46898 | Cost/Loss: 0.077615 | Weight: 0.528791 | Bias: 0.070049\n",
            "Iteration: 46899 | Cost/Loss: 0.077615 | Weight: 0.528791 | Bias: 0.070049\n",
            "Iteration: 46900 | Cost/Loss: 0.077615 | Weight: 0.528792 | Bias: 0.070050\n",
            "Iteration: 46901 | Cost/Loss: 0.077614 | Weight: 0.528792 | Bias: 0.070050\n",
            "Iteration: 46902 | Cost/Loss: 0.077614 | Weight: 0.528792 | Bias: 0.070050\n",
            "Iteration: 46903 | Cost/Loss: 0.077614 | Weight: 0.528793 | Bias: 0.070051\n",
            "Iteration: 46904 | Cost/Loss: 0.077614 | Weight: 0.528793 | Bias: 0.070051\n",
            "Iteration: 46905 | Cost/Loss: 0.077614 | Weight: 0.528793 | Bias: 0.070051\n",
            "Iteration: 46906 | Cost/Loss: 0.077614 | Weight: 0.528793 | Bias: 0.070052\n",
            "Iteration: 46907 | Cost/Loss: 0.077614 | Weight: 0.528794 | Bias: 0.070052\n",
            "Iteration: 46908 | Cost/Loss: 0.077614 | Weight: 0.528794 | Bias: 0.070052\n",
            "Iteration: 46909 | Cost/Loss: 0.077614 | Weight: 0.528794 | Bias: 0.070053\n",
            "Iteration: 46910 | Cost/Loss: 0.077614 | Weight: 0.528795 | Bias: 0.070053\n",
            "Iteration: 46911 | Cost/Loss: 0.077614 | Weight: 0.528795 | Bias: 0.070053\n",
            "Iteration: 46912 | Cost/Loss: 0.077614 | Weight: 0.528795 | Bias: 0.070053\n",
            "Iteration: 46913 | Cost/Loss: 0.077614 | Weight: 0.528796 | Bias: 0.070054\n",
            "Iteration: 46914 | Cost/Loss: 0.077614 | Weight: 0.528796 | Bias: 0.070054\n",
            "Iteration: 46915 | Cost/Loss: 0.077614 | Weight: 0.528796 | Bias: 0.070054\n",
            "Iteration: 46916 | Cost/Loss: 0.077614 | Weight: 0.528796 | Bias: 0.070055\n",
            "Iteration: 46917 | Cost/Loss: 0.077614 | Weight: 0.528797 | Bias: 0.070055\n",
            "Iteration: 46918 | Cost/Loss: 0.077614 | Weight: 0.528797 | Bias: 0.070055\n",
            "Iteration: 46919 | Cost/Loss: 0.077614 | Weight: 0.528797 | Bias: 0.070056\n",
            "Iteration: 46920 | Cost/Loss: 0.077614 | Weight: 0.528798 | Bias: 0.070056\n",
            "Iteration: 46921 | Cost/Loss: 0.077614 | Weight: 0.528798 | Bias: 0.070056\n",
            "Iteration: 46922 | Cost/Loss: 0.077614 | Weight: 0.528798 | Bias: 0.070057\n",
            "Iteration: 46923 | Cost/Loss: 0.077614 | Weight: 0.528799 | Bias: 0.070057\n",
            "Iteration: 46924 | Cost/Loss: 0.077614 | Weight: 0.528799 | Bias: 0.070057\n",
            "Iteration: 46925 | Cost/Loss: 0.077614 | Weight: 0.528799 | Bias: 0.070058\n",
            "Iteration: 46926 | Cost/Loss: 0.077614 | Weight: 0.528799 | Bias: 0.070058\n",
            "Iteration: 46927 | Cost/Loss: 0.077614 | Weight: 0.528800 | Bias: 0.070058\n",
            "Iteration: 46928 | Cost/Loss: 0.077614 | Weight: 0.528800 | Bias: 0.070059\n",
            "Iteration: 46929 | Cost/Loss: 0.077614 | Weight: 0.528800 | Bias: 0.070059\n",
            "Iteration: 46930 | Cost/Loss: 0.077614 | Weight: 0.528801 | Bias: 0.070059\n",
            "Iteration: 46931 | Cost/Loss: 0.077614 | Weight: 0.528801 | Bias: 0.070060\n",
            "Iteration: 46932 | Cost/Loss: 0.077614 | Weight: 0.528801 | Bias: 0.070060\n",
            "Iteration: 46933 | Cost/Loss: 0.077614 | Weight: 0.528802 | Bias: 0.070060\n",
            "Iteration: 46934 | Cost/Loss: 0.077614 | Weight: 0.528802 | Bias: 0.070061\n",
            "Iteration: 46935 | Cost/Loss: 0.077614 | Weight: 0.528802 | Bias: 0.070061\n",
            "Iteration: 46936 | Cost/Loss: 0.077614 | Weight: 0.528802 | Bias: 0.070061\n",
            "Iteration: 46937 | Cost/Loss: 0.077614 | Weight: 0.528803 | Bias: 0.070061\n",
            "Iteration: 46938 | Cost/Loss: 0.077614 | Weight: 0.528803 | Bias: 0.070062\n",
            "Iteration: 46939 | Cost/Loss: 0.077614 | Weight: 0.528803 | Bias: 0.070062\n",
            "Iteration: 46940 | Cost/Loss: 0.077613 | Weight: 0.528804 | Bias: 0.070062\n",
            "Iteration: 46941 | Cost/Loss: 0.077613 | Weight: 0.528804 | Bias: 0.070063\n",
            "Iteration: 46942 | Cost/Loss: 0.077613 | Weight: 0.528804 | Bias: 0.070063\n",
            "Iteration: 46943 | Cost/Loss: 0.077613 | Weight: 0.528804 | Bias: 0.070063\n",
            "Iteration: 46944 | Cost/Loss: 0.077613 | Weight: 0.528805 | Bias: 0.070064\n",
            "Iteration: 46945 | Cost/Loss: 0.077613 | Weight: 0.528805 | Bias: 0.070064\n",
            "Iteration: 46946 | Cost/Loss: 0.077613 | Weight: 0.528805 | Bias: 0.070064\n",
            "Iteration: 46947 | Cost/Loss: 0.077613 | Weight: 0.528806 | Bias: 0.070065\n",
            "Iteration: 46948 | Cost/Loss: 0.077613 | Weight: 0.528806 | Bias: 0.070065\n",
            "Iteration: 46949 | Cost/Loss: 0.077613 | Weight: 0.528806 | Bias: 0.070065\n",
            "Iteration: 46950 | Cost/Loss: 0.077613 | Weight: 0.528807 | Bias: 0.070066\n",
            "Iteration: 46951 | Cost/Loss: 0.077613 | Weight: 0.528807 | Bias: 0.070066\n",
            "Iteration: 46952 | Cost/Loss: 0.077613 | Weight: 0.528807 | Bias: 0.070066\n",
            "Iteration: 46953 | Cost/Loss: 0.077613 | Weight: 0.528807 | Bias: 0.070067\n",
            "Iteration: 46954 | Cost/Loss: 0.077613 | Weight: 0.528808 | Bias: 0.070067\n",
            "Iteration: 46955 | Cost/Loss: 0.077613 | Weight: 0.528808 | Bias: 0.070067\n",
            "Iteration: 46956 | Cost/Loss: 0.077613 | Weight: 0.528808 | Bias: 0.070068\n",
            "Iteration: 46957 | Cost/Loss: 0.077613 | Weight: 0.528809 | Bias: 0.070068\n",
            "Iteration: 46958 | Cost/Loss: 0.077613 | Weight: 0.528809 | Bias: 0.070068\n",
            "Iteration: 46959 | Cost/Loss: 0.077613 | Weight: 0.528809 | Bias: 0.070069\n",
            "Iteration: 46960 | Cost/Loss: 0.077613 | Weight: 0.528810 | Bias: 0.070069\n",
            "Iteration: 46961 | Cost/Loss: 0.077613 | Weight: 0.528810 | Bias: 0.070069\n",
            "Iteration: 46962 | Cost/Loss: 0.077613 | Weight: 0.528810 | Bias: 0.070069\n",
            "Iteration: 46963 | Cost/Loss: 0.077613 | Weight: 0.528810 | Bias: 0.070070\n",
            "Iteration: 46964 | Cost/Loss: 0.077613 | Weight: 0.528811 | Bias: 0.070070\n",
            "Iteration: 46965 | Cost/Loss: 0.077613 | Weight: 0.528811 | Bias: 0.070070\n",
            "Iteration: 46966 | Cost/Loss: 0.077613 | Weight: 0.528811 | Bias: 0.070071\n",
            "Iteration: 46967 | Cost/Loss: 0.077613 | Weight: 0.528812 | Bias: 0.070071\n",
            "Iteration: 46968 | Cost/Loss: 0.077613 | Weight: 0.528812 | Bias: 0.070071\n",
            "Iteration: 46969 | Cost/Loss: 0.077613 | Weight: 0.528812 | Bias: 0.070072\n",
            "Iteration: 46970 | Cost/Loss: 0.077613 | Weight: 0.528813 | Bias: 0.070072\n",
            "Iteration: 46971 | Cost/Loss: 0.077613 | Weight: 0.528813 | Bias: 0.070072\n",
            "Iteration: 46972 | Cost/Loss: 0.077613 | Weight: 0.528813 | Bias: 0.070073\n",
            "Iteration: 46973 | Cost/Loss: 0.077613 | Weight: 0.528813 | Bias: 0.070073\n",
            "Iteration: 46974 | Cost/Loss: 0.077613 | Weight: 0.528814 | Bias: 0.070073\n",
            "Iteration: 46975 | Cost/Loss: 0.077613 | Weight: 0.528814 | Bias: 0.070074\n",
            "Iteration: 46976 | Cost/Loss: 0.077613 | Weight: 0.528814 | Bias: 0.070074\n",
            "Iteration: 46977 | Cost/Loss: 0.077613 | Weight: 0.528815 | Bias: 0.070074\n",
            "Iteration: 46978 | Cost/Loss: 0.077613 | Weight: 0.528815 | Bias: 0.070075\n",
            "Iteration: 46979 | Cost/Loss: 0.077613 | Weight: 0.528815 | Bias: 0.070075\n",
            "Iteration: 46980 | Cost/Loss: 0.077612 | Weight: 0.528816 | Bias: 0.070075\n",
            "Iteration: 46981 | Cost/Loss: 0.077612 | Weight: 0.528816 | Bias: 0.070076\n",
            "Iteration: 46982 | Cost/Loss: 0.077612 | Weight: 0.528816 | Bias: 0.070076\n",
            "Iteration: 46983 | Cost/Loss: 0.077612 | Weight: 0.528816 | Bias: 0.070076\n",
            "Iteration: 46984 | Cost/Loss: 0.077612 | Weight: 0.528817 | Bias: 0.070077\n",
            "Iteration: 46985 | Cost/Loss: 0.077612 | Weight: 0.528817 | Bias: 0.070077\n",
            "Iteration: 46986 | Cost/Loss: 0.077612 | Weight: 0.528817 | Bias: 0.070077\n",
            "Iteration: 46987 | Cost/Loss: 0.077612 | Weight: 0.528818 | Bias: 0.070078\n",
            "Iteration: 46988 | Cost/Loss: 0.077612 | Weight: 0.528818 | Bias: 0.070078\n",
            "Iteration: 46989 | Cost/Loss: 0.077612 | Weight: 0.528818 | Bias: 0.070078\n",
            "Iteration: 46990 | Cost/Loss: 0.077612 | Weight: 0.528818 | Bias: 0.070078\n",
            "Iteration: 46991 | Cost/Loss: 0.077612 | Weight: 0.528819 | Bias: 0.070079\n",
            "Iteration: 46992 | Cost/Loss: 0.077612 | Weight: 0.528819 | Bias: 0.070079\n",
            "Iteration: 46993 | Cost/Loss: 0.077612 | Weight: 0.528819 | Bias: 0.070079\n",
            "Iteration: 46994 | Cost/Loss: 0.077612 | Weight: 0.528820 | Bias: 0.070080\n",
            "Iteration: 46995 | Cost/Loss: 0.077612 | Weight: 0.528820 | Bias: 0.070080\n",
            "Iteration: 46996 | Cost/Loss: 0.077612 | Weight: 0.528820 | Bias: 0.070080\n",
            "Iteration: 46997 | Cost/Loss: 0.077612 | Weight: 0.528821 | Bias: 0.070081\n",
            "Iteration: 46998 | Cost/Loss: 0.077612 | Weight: 0.528821 | Bias: 0.070081\n",
            "Iteration: 46999 | Cost/Loss: 0.077612 | Weight: 0.528821 | Bias: 0.070081\n",
            "Iteration: 47000 | Cost/Loss: 0.077612 | Weight: 0.528821 | Bias: 0.070082\n",
            "Iteration: 47001 | Cost/Loss: 0.077612 | Weight: 0.528822 | Bias: 0.070082\n",
            "Iteration: 47002 | Cost/Loss: 0.077612 | Weight: 0.528822 | Bias: 0.070082\n",
            "Iteration: 47003 | Cost/Loss: 0.077612 | Weight: 0.528822 | Bias: 0.070083\n",
            "Iteration: 47004 | Cost/Loss: 0.077612 | Weight: 0.528823 | Bias: 0.070083\n",
            "Iteration: 47005 | Cost/Loss: 0.077612 | Weight: 0.528823 | Bias: 0.070083\n",
            "Iteration: 47006 | Cost/Loss: 0.077612 | Weight: 0.528823 | Bias: 0.070084\n",
            "Iteration: 47007 | Cost/Loss: 0.077612 | Weight: 0.528824 | Bias: 0.070084\n",
            "Iteration: 47008 | Cost/Loss: 0.077612 | Weight: 0.528824 | Bias: 0.070084\n",
            "Iteration: 47009 | Cost/Loss: 0.077612 | Weight: 0.528824 | Bias: 0.070085\n",
            "Iteration: 47010 | Cost/Loss: 0.077612 | Weight: 0.528824 | Bias: 0.070085\n",
            "Iteration: 47011 | Cost/Loss: 0.077612 | Weight: 0.528825 | Bias: 0.070085\n",
            "Iteration: 47012 | Cost/Loss: 0.077612 | Weight: 0.528825 | Bias: 0.070086\n",
            "Iteration: 47013 | Cost/Loss: 0.077612 | Weight: 0.528825 | Bias: 0.070086\n",
            "Iteration: 47014 | Cost/Loss: 0.077612 | Weight: 0.528826 | Bias: 0.070086\n",
            "Iteration: 47015 | Cost/Loss: 0.077612 | Weight: 0.528826 | Bias: 0.070086\n",
            "Iteration: 47016 | Cost/Loss: 0.077612 | Weight: 0.528826 | Bias: 0.070087\n",
            "Iteration: 47017 | Cost/Loss: 0.077612 | Weight: 0.528827 | Bias: 0.070087\n",
            "Iteration: 47018 | Cost/Loss: 0.077612 | Weight: 0.528827 | Bias: 0.070087\n",
            "Iteration: 47019 | Cost/Loss: 0.077611 | Weight: 0.528827 | Bias: 0.070088\n",
            "Iteration: 47020 | Cost/Loss: 0.077611 | Weight: 0.528827 | Bias: 0.070088\n",
            "Iteration: 47021 | Cost/Loss: 0.077611 | Weight: 0.528828 | Bias: 0.070088\n",
            "Iteration: 47022 | Cost/Loss: 0.077611 | Weight: 0.528828 | Bias: 0.070089\n",
            "Iteration: 47023 | Cost/Loss: 0.077611 | Weight: 0.528828 | Bias: 0.070089\n",
            "Iteration: 47024 | Cost/Loss: 0.077611 | Weight: 0.528829 | Bias: 0.070089\n",
            "Iteration: 47025 | Cost/Loss: 0.077611 | Weight: 0.528829 | Bias: 0.070090\n",
            "Iteration: 47026 | Cost/Loss: 0.077611 | Weight: 0.528829 | Bias: 0.070090\n",
            "Iteration: 47027 | Cost/Loss: 0.077611 | Weight: 0.528830 | Bias: 0.070090\n",
            "Iteration: 47028 | Cost/Loss: 0.077611 | Weight: 0.528830 | Bias: 0.070091\n",
            "Iteration: 47029 | Cost/Loss: 0.077611 | Weight: 0.528830 | Bias: 0.070091\n",
            "Iteration: 47030 | Cost/Loss: 0.077611 | Weight: 0.528830 | Bias: 0.070091\n",
            "Iteration: 47031 | Cost/Loss: 0.077611 | Weight: 0.528831 | Bias: 0.070092\n",
            "Iteration: 47032 | Cost/Loss: 0.077611 | Weight: 0.528831 | Bias: 0.070092\n",
            "Iteration: 47033 | Cost/Loss: 0.077611 | Weight: 0.528831 | Bias: 0.070092\n",
            "Iteration: 47034 | Cost/Loss: 0.077611 | Weight: 0.528832 | Bias: 0.070093\n",
            "Iteration: 47035 | Cost/Loss: 0.077611 | Weight: 0.528832 | Bias: 0.070093\n",
            "Iteration: 47036 | Cost/Loss: 0.077611 | Weight: 0.528832 | Bias: 0.070093\n",
            "Iteration: 47037 | Cost/Loss: 0.077611 | Weight: 0.528832 | Bias: 0.070094\n",
            "Iteration: 47038 | Cost/Loss: 0.077611 | Weight: 0.528833 | Bias: 0.070094\n",
            "Iteration: 47039 | Cost/Loss: 0.077611 | Weight: 0.528833 | Bias: 0.070094\n",
            "Iteration: 47040 | Cost/Loss: 0.077611 | Weight: 0.528833 | Bias: 0.070094\n",
            "Iteration: 47041 | Cost/Loss: 0.077611 | Weight: 0.528834 | Bias: 0.070095\n",
            "Iteration: 47042 | Cost/Loss: 0.077611 | Weight: 0.528834 | Bias: 0.070095\n",
            "Iteration: 47043 | Cost/Loss: 0.077611 | Weight: 0.528834 | Bias: 0.070095\n",
            "Iteration: 47044 | Cost/Loss: 0.077611 | Weight: 0.528835 | Bias: 0.070096\n",
            "Iteration: 47045 | Cost/Loss: 0.077611 | Weight: 0.528835 | Bias: 0.070096\n",
            "Iteration: 47046 | Cost/Loss: 0.077611 | Weight: 0.528835 | Bias: 0.070096\n",
            "Iteration: 47047 | Cost/Loss: 0.077611 | Weight: 0.528835 | Bias: 0.070097\n",
            "Iteration: 47048 | Cost/Loss: 0.077611 | Weight: 0.528836 | Bias: 0.070097\n",
            "Iteration: 47049 | Cost/Loss: 0.077611 | Weight: 0.528836 | Bias: 0.070097\n",
            "Iteration: 47050 | Cost/Loss: 0.077611 | Weight: 0.528836 | Bias: 0.070098\n",
            "Iteration: 47051 | Cost/Loss: 0.077611 | Weight: 0.528837 | Bias: 0.070098\n",
            "Iteration: 47052 | Cost/Loss: 0.077611 | Weight: 0.528837 | Bias: 0.070098\n",
            "Iteration: 47053 | Cost/Loss: 0.077611 | Weight: 0.528837 | Bias: 0.070099\n",
            "Iteration: 47054 | Cost/Loss: 0.077611 | Weight: 0.528838 | Bias: 0.070099\n",
            "Iteration: 47055 | Cost/Loss: 0.077611 | Weight: 0.528838 | Bias: 0.070099\n",
            "Iteration: 47056 | Cost/Loss: 0.077611 | Weight: 0.528838 | Bias: 0.070100\n",
            "Iteration: 47057 | Cost/Loss: 0.077611 | Weight: 0.528838 | Bias: 0.070100\n",
            "Iteration: 47058 | Cost/Loss: 0.077611 | Weight: 0.528839 | Bias: 0.070100\n",
            "Iteration: 47059 | Cost/Loss: 0.077610 | Weight: 0.528839 | Bias: 0.070101\n",
            "Iteration: 47060 | Cost/Loss: 0.077610 | Weight: 0.528839 | Bias: 0.070101\n",
            "Iteration: 47061 | Cost/Loss: 0.077610 | Weight: 0.528840 | Bias: 0.070101\n",
            "Iteration: 47062 | Cost/Loss: 0.077610 | Weight: 0.528840 | Bias: 0.070102\n",
            "Iteration: 47063 | Cost/Loss: 0.077610 | Weight: 0.528840 | Bias: 0.070102\n",
            "Iteration: 47064 | Cost/Loss: 0.077610 | Weight: 0.528841 | Bias: 0.070102\n",
            "Iteration: 47065 | Cost/Loss: 0.077610 | Weight: 0.528841 | Bias: 0.070102\n",
            "Iteration: 47066 | Cost/Loss: 0.077610 | Weight: 0.528841 | Bias: 0.070103\n",
            "Iteration: 47067 | Cost/Loss: 0.077610 | Weight: 0.528841 | Bias: 0.070103\n",
            "Iteration: 47068 | Cost/Loss: 0.077610 | Weight: 0.528842 | Bias: 0.070103\n",
            "Iteration: 47069 | Cost/Loss: 0.077610 | Weight: 0.528842 | Bias: 0.070104\n",
            "Iteration: 47070 | Cost/Loss: 0.077610 | Weight: 0.528842 | Bias: 0.070104\n",
            "Iteration: 47071 | Cost/Loss: 0.077610 | Weight: 0.528843 | Bias: 0.070104\n",
            "Iteration: 47072 | Cost/Loss: 0.077610 | Weight: 0.528843 | Bias: 0.070105\n",
            "Iteration: 47073 | Cost/Loss: 0.077610 | Weight: 0.528843 | Bias: 0.070105\n",
            "Iteration: 47074 | Cost/Loss: 0.077610 | Weight: 0.528844 | Bias: 0.070105\n",
            "Iteration: 47075 | Cost/Loss: 0.077610 | Weight: 0.528844 | Bias: 0.070106\n",
            "Iteration: 47076 | Cost/Loss: 0.077610 | Weight: 0.528844 | Bias: 0.070106\n",
            "Iteration: 47077 | Cost/Loss: 0.077610 | Weight: 0.528844 | Bias: 0.070106\n",
            "Iteration: 47078 | Cost/Loss: 0.077610 | Weight: 0.528845 | Bias: 0.070107\n",
            "Iteration: 47079 | Cost/Loss: 0.077610 | Weight: 0.528845 | Bias: 0.070107\n",
            "Iteration: 47080 | Cost/Loss: 0.077610 | Weight: 0.528845 | Bias: 0.070107\n",
            "Iteration: 47081 | Cost/Loss: 0.077610 | Weight: 0.528846 | Bias: 0.070108\n",
            "Iteration: 47082 | Cost/Loss: 0.077610 | Weight: 0.528846 | Bias: 0.070108\n",
            "Iteration: 47083 | Cost/Loss: 0.077610 | Weight: 0.528846 | Bias: 0.070108\n",
            "Iteration: 47084 | Cost/Loss: 0.077610 | Weight: 0.528847 | Bias: 0.070109\n",
            "Iteration: 47085 | Cost/Loss: 0.077610 | Weight: 0.528847 | Bias: 0.070109\n",
            "Iteration: 47086 | Cost/Loss: 0.077610 | Weight: 0.528847 | Bias: 0.070109\n",
            "Iteration: 47087 | Cost/Loss: 0.077610 | Weight: 0.528847 | Bias: 0.070110\n",
            "Iteration: 47088 | Cost/Loss: 0.077610 | Weight: 0.528848 | Bias: 0.070110\n",
            "Iteration: 47089 | Cost/Loss: 0.077610 | Weight: 0.528848 | Bias: 0.070110\n",
            "Iteration: 47090 | Cost/Loss: 0.077610 | Weight: 0.528848 | Bias: 0.070111\n",
            "Iteration: 47091 | Cost/Loss: 0.077610 | Weight: 0.528849 | Bias: 0.070111\n",
            "Iteration: 47092 | Cost/Loss: 0.077610 | Weight: 0.528849 | Bias: 0.070111\n",
            "Iteration: 47093 | Cost/Loss: 0.077610 | Weight: 0.528849 | Bias: 0.070111\n",
            "Iteration: 47094 | Cost/Loss: 0.077610 | Weight: 0.528849 | Bias: 0.070112\n",
            "Iteration: 47095 | Cost/Loss: 0.077610 | Weight: 0.528850 | Bias: 0.070112\n",
            "Iteration: 47096 | Cost/Loss: 0.077610 | Weight: 0.528850 | Bias: 0.070112\n",
            "Iteration: 47097 | Cost/Loss: 0.077610 | Weight: 0.528850 | Bias: 0.070113\n",
            "Iteration: 47098 | Cost/Loss: 0.077610 | Weight: 0.528851 | Bias: 0.070113\n",
            "Iteration: 47099 | Cost/Loss: 0.077609 | Weight: 0.528851 | Bias: 0.070113\n",
            "Iteration: 47100 | Cost/Loss: 0.077609 | Weight: 0.528851 | Bias: 0.070114\n",
            "Iteration: 47101 | Cost/Loss: 0.077609 | Weight: 0.528852 | Bias: 0.070114\n",
            "Iteration: 47102 | Cost/Loss: 0.077609 | Weight: 0.528852 | Bias: 0.070114\n",
            "Iteration: 47103 | Cost/Loss: 0.077609 | Weight: 0.528852 | Bias: 0.070115\n",
            "Iteration: 47104 | Cost/Loss: 0.077609 | Weight: 0.528852 | Bias: 0.070115\n",
            "Iteration: 47105 | Cost/Loss: 0.077609 | Weight: 0.528853 | Bias: 0.070115\n",
            "Iteration: 47106 | Cost/Loss: 0.077609 | Weight: 0.528853 | Bias: 0.070116\n",
            "Iteration: 47107 | Cost/Loss: 0.077609 | Weight: 0.528853 | Bias: 0.070116\n",
            "Iteration: 47108 | Cost/Loss: 0.077609 | Weight: 0.528854 | Bias: 0.070116\n",
            "Iteration: 47109 | Cost/Loss: 0.077609 | Weight: 0.528854 | Bias: 0.070117\n",
            "Iteration: 47110 | Cost/Loss: 0.077609 | Weight: 0.528854 | Bias: 0.070117\n",
            "Iteration: 47111 | Cost/Loss: 0.077609 | Weight: 0.528855 | Bias: 0.070117\n",
            "Iteration: 47112 | Cost/Loss: 0.077609 | Weight: 0.528855 | Bias: 0.070118\n",
            "Iteration: 47113 | Cost/Loss: 0.077609 | Weight: 0.528855 | Bias: 0.070118\n",
            "Iteration: 47114 | Cost/Loss: 0.077609 | Weight: 0.528855 | Bias: 0.070118\n",
            "Iteration: 47115 | Cost/Loss: 0.077609 | Weight: 0.528856 | Bias: 0.070119\n",
            "Iteration: 47116 | Cost/Loss: 0.077609 | Weight: 0.528856 | Bias: 0.070119\n",
            "Iteration: 47117 | Cost/Loss: 0.077609 | Weight: 0.528856 | Bias: 0.070119\n",
            "Iteration: 47118 | Cost/Loss: 0.077609 | Weight: 0.528857 | Bias: 0.070119\n",
            "Iteration: 47119 | Cost/Loss: 0.077609 | Weight: 0.528857 | Bias: 0.070120\n",
            "Iteration: 47120 | Cost/Loss: 0.077609 | Weight: 0.528857 | Bias: 0.070120\n",
            "Iteration: 47121 | Cost/Loss: 0.077609 | Weight: 0.528858 | Bias: 0.070120\n",
            "Iteration: 47122 | Cost/Loss: 0.077609 | Weight: 0.528858 | Bias: 0.070121\n",
            "Iteration: 47123 | Cost/Loss: 0.077609 | Weight: 0.528858 | Bias: 0.070121\n",
            "Iteration: 47124 | Cost/Loss: 0.077609 | Weight: 0.528858 | Bias: 0.070121\n",
            "Iteration: 47125 | Cost/Loss: 0.077609 | Weight: 0.528859 | Bias: 0.070122\n",
            "Iteration: 47126 | Cost/Loss: 0.077609 | Weight: 0.528859 | Bias: 0.070122\n",
            "Iteration: 47127 | Cost/Loss: 0.077609 | Weight: 0.528859 | Bias: 0.070122\n",
            "Iteration: 47128 | Cost/Loss: 0.077609 | Weight: 0.528860 | Bias: 0.070123\n",
            "Iteration: 47129 | Cost/Loss: 0.077609 | Weight: 0.528860 | Bias: 0.070123\n",
            "Iteration: 47130 | Cost/Loss: 0.077609 | Weight: 0.528860 | Bias: 0.070123\n",
            "Iteration: 47131 | Cost/Loss: 0.077609 | Weight: 0.528861 | Bias: 0.070124\n",
            "Iteration: 47132 | Cost/Loss: 0.077609 | Weight: 0.528861 | Bias: 0.070124\n",
            "Iteration: 47133 | Cost/Loss: 0.077609 | Weight: 0.528861 | Bias: 0.070124\n",
            "Iteration: 47134 | Cost/Loss: 0.077609 | Weight: 0.528861 | Bias: 0.070125\n",
            "Iteration: 47135 | Cost/Loss: 0.077609 | Weight: 0.528862 | Bias: 0.070125\n",
            "Iteration: 47136 | Cost/Loss: 0.077609 | Weight: 0.528862 | Bias: 0.070125\n",
            "Iteration: 47137 | Cost/Loss: 0.077609 | Weight: 0.528862 | Bias: 0.070126\n",
            "Iteration: 47138 | Cost/Loss: 0.077608 | Weight: 0.528863 | Bias: 0.070126\n",
            "Iteration: 47139 | Cost/Loss: 0.077608 | Weight: 0.528863 | Bias: 0.070126\n",
            "Iteration: 47140 | Cost/Loss: 0.077608 | Weight: 0.528863 | Bias: 0.070127\n",
            "Iteration: 47141 | Cost/Loss: 0.077608 | Weight: 0.528863 | Bias: 0.070127\n",
            "Iteration: 47142 | Cost/Loss: 0.077608 | Weight: 0.528864 | Bias: 0.070127\n",
            "Iteration: 47143 | Cost/Loss: 0.077608 | Weight: 0.528864 | Bias: 0.070127\n",
            "Iteration: 47144 | Cost/Loss: 0.077608 | Weight: 0.528864 | Bias: 0.070128\n",
            "Iteration: 47145 | Cost/Loss: 0.077608 | Weight: 0.528865 | Bias: 0.070128\n",
            "Iteration: 47146 | Cost/Loss: 0.077608 | Weight: 0.528865 | Bias: 0.070128\n",
            "Iteration: 47147 | Cost/Loss: 0.077608 | Weight: 0.528865 | Bias: 0.070129\n",
            "Iteration: 47148 | Cost/Loss: 0.077608 | Weight: 0.528866 | Bias: 0.070129\n",
            "Iteration: 47149 | Cost/Loss: 0.077608 | Weight: 0.528866 | Bias: 0.070129\n",
            "Iteration: 47150 | Cost/Loss: 0.077608 | Weight: 0.528866 | Bias: 0.070130\n",
            "Iteration: 47151 | Cost/Loss: 0.077608 | Weight: 0.528866 | Bias: 0.070130\n",
            "Iteration: 47152 | Cost/Loss: 0.077608 | Weight: 0.528867 | Bias: 0.070130\n",
            "Iteration: 47153 | Cost/Loss: 0.077608 | Weight: 0.528867 | Bias: 0.070131\n",
            "Iteration: 47154 | Cost/Loss: 0.077608 | Weight: 0.528867 | Bias: 0.070131\n",
            "Iteration: 47155 | Cost/Loss: 0.077608 | Weight: 0.528868 | Bias: 0.070131\n",
            "Iteration: 47156 | Cost/Loss: 0.077608 | Weight: 0.528868 | Bias: 0.070132\n",
            "Iteration: 47157 | Cost/Loss: 0.077608 | Weight: 0.528868 | Bias: 0.070132\n",
            "Iteration: 47158 | Cost/Loss: 0.077608 | Weight: 0.528869 | Bias: 0.070132\n",
            "Iteration: 47159 | Cost/Loss: 0.077608 | Weight: 0.528869 | Bias: 0.070133\n",
            "Iteration: 47160 | Cost/Loss: 0.077608 | Weight: 0.528869 | Bias: 0.070133\n",
            "Iteration: 47161 | Cost/Loss: 0.077608 | Weight: 0.528869 | Bias: 0.070133\n",
            "Iteration: 47162 | Cost/Loss: 0.077608 | Weight: 0.528870 | Bias: 0.070134\n",
            "Iteration: 47163 | Cost/Loss: 0.077608 | Weight: 0.528870 | Bias: 0.070134\n",
            "Iteration: 47164 | Cost/Loss: 0.077608 | Weight: 0.528870 | Bias: 0.070134\n",
            "Iteration: 47165 | Cost/Loss: 0.077608 | Weight: 0.528871 | Bias: 0.070135\n",
            "Iteration: 47166 | Cost/Loss: 0.077608 | Weight: 0.528871 | Bias: 0.070135\n",
            "Iteration: 47167 | Cost/Loss: 0.077608 | Weight: 0.528871 | Bias: 0.070135\n",
            "Iteration: 47168 | Cost/Loss: 0.077608 | Weight: 0.528872 | Bias: 0.070135\n",
            "Iteration: 47169 | Cost/Loss: 0.077608 | Weight: 0.528872 | Bias: 0.070136\n",
            "Iteration: 47170 | Cost/Loss: 0.077608 | Weight: 0.528872 | Bias: 0.070136\n",
            "Iteration: 47171 | Cost/Loss: 0.077608 | Weight: 0.528872 | Bias: 0.070136\n",
            "Iteration: 47172 | Cost/Loss: 0.077608 | Weight: 0.528873 | Bias: 0.070137\n",
            "Iteration: 47173 | Cost/Loss: 0.077608 | Weight: 0.528873 | Bias: 0.070137\n",
            "Iteration: 47174 | Cost/Loss: 0.077608 | Weight: 0.528873 | Bias: 0.070137\n",
            "Iteration: 47175 | Cost/Loss: 0.077608 | Weight: 0.528874 | Bias: 0.070138\n",
            "Iteration: 47176 | Cost/Loss: 0.077608 | Weight: 0.528874 | Bias: 0.070138\n",
            "Iteration: 47177 | Cost/Loss: 0.077608 | Weight: 0.528874 | Bias: 0.070138\n",
            "Iteration: 47178 | Cost/Loss: 0.077607 | Weight: 0.528875 | Bias: 0.070139\n",
            "Iteration: 47179 | Cost/Loss: 0.077607 | Weight: 0.528875 | Bias: 0.070139\n",
            "Iteration: 47180 | Cost/Loss: 0.077607 | Weight: 0.528875 | Bias: 0.070139\n",
            "Iteration: 47181 | Cost/Loss: 0.077607 | Weight: 0.528875 | Bias: 0.070140\n",
            "Iteration: 47182 | Cost/Loss: 0.077607 | Weight: 0.528876 | Bias: 0.070140\n",
            "Iteration: 47183 | Cost/Loss: 0.077607 | Weight: 0.528876 | Bias: 0.070140\n",
            "Iteration: 47184 | Cost/Loss: 0.077607 | Weight: 0.528876 | Bias: 0.070141\n",
            "Iteration: 47185 | Cost/Loss: 0.077607 | Weight: 0.528877 | Bias: 0.070141\n",
            "Iteration: 47186 | Cost/Loss: 0.077607 | Weight: 0.528877 | Bias: 0.070141\n",
            "Iteration: 47187 | Cost/Loss: 0.077607 | Weight: 0.528877 | Bias: 0.070142\n",
            "Iteration: 47188 | Cost/Loss: 0.077607 | Weight: 0.528877 | Bias: 0.070142\n",
            "Iteration: 47189 | Cost/Loss: 0.077607 | Weight: 0.528878 | Bias: 0.070142\n",
            "Iteration: 47190 | Cost/Loss: 0.077607 | Weight: 0.528878 | Bias: 0.070143\n",
            "Iteration: 47191 | Cost/Loss: 0.077607 | Weight: 0.528878 | Bias: 0.070143\n",
            "Iteration: 47192 | Cost/Loss: 0.077607 | Weight: 0.528879 | Bias: 0.070143\n",
            "Iteration: 47193 | Cost/Loss: 0.077607 | Weight: 0.528879 | Bias: 0.070144\n",
            "Iteration: 47194 | Cost/Loss: 0.077607 | Weight: 0.528879 | Bias: 0.070144\n",
            "Iteration: 47195 | Cost/Loss: 0.077607 | Weight: 0.528880 | Bias: 0.070144\n",
            "Iteration: 47196 | Cost/Loss: 0.077607 | Weight: 0.528880 | Bias: 0.070144\n",
            "Iteration: 47197 | Cost/Loss: 0.077607 | Weight: 0.528880 | Bias: 0.070145\n",
            "Iteration: 47198 | Cost/Loss: 0.077607 | Weight: 0.528880 | Bias: 0.070145\n",
            "Iteration: 47199 | Cost/Loss: 0.077607 | Weight: 0.528881 | Bias: 0.070145\n",
            "Iteration: 47200 | Cost/Loss: 0.077607 | Weight: 0.528881 | Bias: 0.070146\n",
            "Iteration: 47201 | Cost/Loss: 0.077607 | Weight: 0.528881 | Bias: 0.070146\n",
            "Iteration: 47202 | Cost/Loss: 0.077607 | Weight: 0.528882 | Bias: 0.070146\n",
            "Iteration: 47203 | Cost/Loss: 0.077607 | Weight: 0.528882 | Bias: 0.070147\n",
            "Iteration: 47204 | Cost/Loss: 0.077607 | Weight: 0.528882 | Bias: 0.070147\n",
            "Iteration: 47205 | Cost/Loss: 0.077607 | Weight: 0.528883 | Bias: 0.070147\n",
            "Iteration: 47206 | Cost/Loss: 0.077607 | Weight: 0.528883 | Bias: 0.070148\n",
            "Iteration: 47207 | Cost/Loss: 0.077607 | Weight: 0.528883 | Bias: 0.070148\n",
            "Iteration: 47208 | Cost/Loss: 0.077607 | Weight: 0.528883 | Bias: 0.070148\n",
            "Iteration: 47209 | Cost/Loss: 0.077607 | Weight: 0.528884 | Bias: 0.070149\n",
            "Iteration: 47210 | Cost/Loss: 0.077607 | Weight: 0.528884 | Bias: 0.070149\n",
            "Iteration: 47211 | Cost/Loss: 0.077607 | Weight: 0.528884 | Bias: 0.070149\n",
            "Iteration: 47212 | Cost/Loss: 0.077607 | Weight: 0.528885 | Bias: 0.070150\n",
            "Iteration: 47213 | Cost/Loss: 0.077607 | Weight: 0.528885 | Bias: 0.070150\n",
            "Iteration: 47214 | Cost/Loss: 0.077607 | Weight: 0.528885 | Bias: 0.070150\n",
            "Iteration: 47215 | Cost/Loss: 0.077607 | Weight: 0.528886 | Bias: 0.070151\n",
            "Iteration: 47216 | Cost/Loss: 0.077607 | Weight: 0.528886 | Bias: 0.070151\n",
            "Iteration: 47217 | Cost/Loss: 0.077606 | Weight: 0.528886 | Bias: 0.070151\n",
            "Iteration: 47218 | Cost/Loss: 0.077606 | Weight: 0.528886 | Bias: 0.070152\n",
            "Iteration: 47219 | Cost/Loss: 0.077606 | Weight: 0.528887 | Bias: 0.070152\n",
            "Iteration: 47220 | Cost/Loss: 0.077606 | Weight: 0.528887 | Bias: 0.070152\n",
            "Iteration: 47221 | Cost/Loss: 0.077606 | Weight: 0.528887 | Bias: 0.070152\n",
            "Iteration: 47222 | Cost/Loss: 0.077606 | Weight: 0.528888 | Bias: 0.070153\n",
            "Iteration: 47223 | Cost/Loss: 0.077606 | Weight: 0.528888 | Bias: 0.070153\n",
            "Iteration: 47224 | Cost/Loss: 0.077606 | Weight: 0.528888 | Bias: 0.070153\n",
            "Iteration: 47225 | Cost/Loss: 0.077606 | Weight: 0.528889 | Bias: 0.070154\n",
            "Iteration: 47226 | Cost/Loss: 0.077606 | Weight: 0.528889 | Bias: 0.070154\n",
            "Iteration: 47227 | Cost/Loss: 0.077606 | Weight: 0.528889 | Bias: 0.070154\n",
            "Iteration: 47228 | Cost/Loss: 0.077606 | Weight: 0.528889 | Bias: 0.070155\n",
            "Iteration: 47229 | Cost/Loss: 0.077606 | Weight: 0.528890 | Bias: 0.070155\n",
            "Iteration: 47230 | Cost/Loss: 0.077606 | Weight: 0.528890 | Bias: 0.070155\n",
            "Iteration: 47231 | Cost/Loss: 0.077606 | Weight: 0.528890 | Bias: 0.070156\n",
            "Iteration: 47232 | Cost/Loss: 0.077606 | Weight: 0.528891 | Bias: 0.070156\n",
            "Iteration: 47233 | Cost/Loss: 0.077606 | Weight: 0.528891 | Bias: 0.070156\n",
            "Iteration: 47234 | Cost/Loss: 0.077606 | Weight: 0.528891 | Bias: 0.070157\n",
            "Iteration: 47235 | Cost/Loss: 0.077606 | Weight: 0.528892 | Bias: 0.070157\n",
            "Iteration: 47236 | Cost/Loss: 0.077606 | Weight: 0.528892 | Bias: 0.070157\n",
            "Iteration: 47237 | Cost/Loss: 0.077606 | Weight: 0.528892 | Bias: 0.070158\n",
            "Iteration: 47238 | Cost/Loss: 0.077606 | Weight: 0.528892 | Bias: 0.070158\n",
            "Iteration: 47239 | Cost/Loss: 0.077606 | Weight: 0.528893 | Bias: 0.070158\n",
            "Iteration: 47240 | Cost/Loss: 0.077606 | Weight: 0.528893 | Bias: 0.070159\n",
            "Iteration: 47241 | Cost/Loss: 0.077606 | Weight: 0.528893 | Bias: 0.070159\n",
            "Iteration: 47242 | Cost/Loss: 0.077606 | Weight: 0.528894 | Bias: 0.070159\n",
            "Iteration: 47243 | Cost/Loss: 0.077606 | Weight: 0.528894 | Bias: 0.070160\n",
            "Iteration: 47244 | Cost/Loss: 0.077606 | Weight: 0.528894 | Bias: 0.070160\n",
            "Iteration: 47245 | Cost/Loss: 0.077606 | Weight: 0.528894 | Bias: 0.070160\n",
            "Iteration: 47246 | Cost/Loss: 0.077606 | Weight: 0.528895 | Bias: 0.070160\n",
            "Iteration: 47247 | Cost/Loss: 0.077606 | Weight: 0.528895 | Bias: 0.070161\n",
            "Iteration: 47248 | Cost/Loss: 0.077606 | Weight: 0.528895 | Bias: 0.070161\n",
            "Iteration: 47249 | Cost/Loss: 0.077606 | Weight: 0.528896 | Bias: 0.070161\n",
            "Iteration: 47250 | Cost/Loss: 0.077606 | Weight: 0.528896 | Bias: 0.070162\n",
            "Iteration: 47251 | Cost/Loss: 0.077606 | Weight: 0.528896 | Bias: 0.070162\n",
            "Iteration: 47252 | Cost/Loss: 0.077606 | Weight: 0.528897 | Bias: 0.070162\n",
            "Iteration: 47253 | Cost/Loss: 0.077606 | Weight: 0.528897 | Bias: 0.070163\n",
            "Iteration: 47254 | Cost/Loss: 0.077606 | Weight: 0.528897 | Bias: 0.070163\n",
            "Iteration: 47255 | Cost/Loss: 0.077606 | Weight: 0.528897 | Bias: 0.070163\n",
            "Iteration: 47256 | Cost/Loss: 0.077606 | Weight: 0.528898 | Bias: 0.070164\n",
            "Iteration: 47257 | Cost/Loss: 0.077605 | Weight: 0.528898 | Bias: 0.070164\n",
            "Iteration: 47258 | Cost/Loss: 0.077605 | Weight: 0.528898 | Bias: 0.070164\n",
            "Iteration: 47259 | Cost/Loss: 0.077605 | Weight: 0.528899 | Bias: 0.070165\n",
            "Iteration: 47260 | Cost/Loss: 0.077605 | Weight: 0.528899 | Bias: 0.070165\n",
            "Iteration: 47261 | Cost/Loss: 0.077605 | Weight: 0.528899 | Bias: 0.070165\n",
            "Iteration: 47262 | Cost/Loss: 0.077605 | Weight: 0.528900 | Bias: 0.070166\n",
            "Iteration: 47263 | Cost/Loss: 0.077605 | Weight: 0.528900 | Bias: 0.070166\n",
            "Iteration: 47264 | Cost/Loss: 0.077605 | Weight: 0.528900 | Bias: 0.070166\n",
            "Iteration: 47265 | Cost/Loss: 0.077605 | Weight: 0.528900 | Bias: 0.070167\n",
            "Iteration: 47266 | Cost/Loss: 0.077605 | Weight: 0.528901 | Bias: 0.070167\n",
            "Iteration: 47267 | Cost/Loss: 0.077605 | Weight: 0.528901 | Bias: 0.070167\n",
            "Iteration: 47268 | Cost/Loss: 0.077605 | Weight: 0.528901 | Bias: 0.070168\n",
            "Iteration: 47269 | Cost/Loss: 0.077605 | Weight: 0.528902 | Bias: 0.070168\n",
            "Iteration: 47270 | Cost/Loss: 0.077605 | Weight: 0.528902 | Bias: 0.070168\n",
            "Iteration: 47271 | Cost/Loss: 0.077605 | Weight: 0.528902 | Bias: 0.070168\n",
            "Iteration: 47272 | Cost/Loss: 0.077605 | Weight: 0.528903 | Bias: 0.070169\n",
            "Iteration: 47273 | Cost/Loss: 0.077605 | Weight: 0.528903 | Bias: 0.070169\n",
            "Iteration: 47274 | Cost/Loss: 0.077605 | Weight: 0.528903 | Bias: 0.070169\n",
            "Iteration: 47275 | Cost/Loss: 0.077605 | Weight: 0.528903 | Bias: 0.070170\n",
            "Iteration: 47276 | Cost/Loss: 0.077605 | Weight: 0.528904 | Bias: 0.070170\n",
            "Iteration: 47277 | Cost/Loss: 0.077605 | Weight: 0.528904 | Bias: 0.070170\n",
            "Iteration: 47278 | Cost/Loss: 0.077605 | Weight: 0.528904 | Bias: 0.070171\n",
            "Iteration: 47279 | Cost/Loss: 0.077605 | Weight: 0.528905 | Bias: 0.070171\n",
            "Iteration: 47280 | Cost/Loss: 0.077605 | Weight: 0.528905 | Bias: 0.070171\n",
            "Iteration: 47281 | Cost/Loss: 0.077605 | Weight: 0.528905 | Bias: 0.070172\n",
            "Iteration: 47282 | Cost/Loss: 0.077605 | Weight: 0.528906 | Bias: 0.070172\n",
            "Iteration: 47283 | Cost/Loss: 0.077605 | Weight: 0.528906 | Bias: 0.070172\n",
            "Iteration: 47284 | Cost/Loss: 0.077605 | Weight: 0.528906 | Bias: 0.070173\n",
            "Iteration: 47285 | Cost/Loss: 0.077605 | Weight: 0.528906 | Bias: 0.070173\n",
            "Iteration: 47286 | Cost/Loss: 0.077605 | Weight: 0.528907 | Bias: 0.070173\n",
            "Iteration: 47287 | Cost/Loss: 0.077605 | Weight: 0.528907 | Bias: 0.070174\n",
            "Iteration: 47288 | Cost/Loss: 0.077605 | Weight: 0.528907 | Bias: 0.070174\n",
            "Iteration: 47289 | Cost/Loss: 0.077605 | Weight: 0.528908 | Bias: 0.070174\n",
            "Iteration: 47290 | Cost/Loss: 0.077605 | Weight: 0.528908 | Bias: 0.070175\n",
            "Iteration: 47291 | Cost/Loss: 0.077605 | Weight: 0.528908 | Bias: 0.070175\n",
            "Iteration: 47292 | Cost/Loss: 0.077605 | Weight: 0.528908 | Bias: 0.070175\n",
            "Iteration: 47293 | Cost/Loss: 0.077605 | Weight: 0.528909 | Bias: 0.070176\n",
            "Iteration: 47294 | Cost/Loss: 0.077605 | Weight: 0.528909 | Bias: 0.070176\n",
            "Iteration: 47295 | Cost/Loss: 0.077605 | Weight: 0.528909 | Bias: 0.070176\n",
            "Iteration: 47296 | Cost/Loss: 0.077605 | Weight: 0.528910 | Bias: 0.070177\n",
            "Iteration: 47297 | Cost/Loss: 0.077604 | Weight: 0.528910 | Bias: 0.070177\n",
            "Iteration: 47298 | Cost/Loss: 0.077604 | Weight: 0.528910 | Bias: 0.070177\n",
            "Iteration: 47299 | Cost/Loss: 0.077604 | Weight: 0.528911 | Bias: 0.070177\n",
            "Iteration: 47300 | Cost/Loss: 0.077604 | Weight: 0.528911 | Bias: 0.070178\n",
            "Iteration: 47301 | Cost/Loss: 0.077604 | Weight: 0.528911 | Bias: 0.070178\n",
            "Iteration: 47302 | Cost/Loss: 0.077604 | Weight: 0.528911 | Bias: 0.070178\n",
            "Iteration: 47303 | Cost/Loss: 0.077604 | Weight: 0.528912 | Bias: 0.070179\n",
            "Iteration: 47304 | Cost/Loss: 0.077604 | Weight: 0.528912 | Bias: 0.070179\n",
            "Iteration: 47305 | Cost/Loss: 0.077604 | Weight: 0.528912 | Bias: 0.070179\n",
            "Iteration: 47306 | Cost/Loss: 0.077604 | Weight: 0.528913 | Bias: 0.070180\n",
            "Iteration: 47307 | Cost/Loss: 0.077604 | Weight: 0.528913 | Bias: 0.070180\n",
            "Iteration: 47308 | Cost/Loss: 0.077604 | Weight: 0.528913 | Bias: 0.070180\n",
            "Iteration: 47309 | Cost/Loss: 0.077604 | Weight: 0.528914 | Bias: 0.070181\n",
            "Iteration: 47310 | Cost/Loss: 0.077604 | Weight: 0.528914 | Bias: 0.070181\n",
            "Iteration: 47311 | Cost/Loss: 0.077604 | Weight: 0.528914 | Bias: 0.070181\n",
            "Iteration: 47312 | Cost/Loss: 0.077604 | Weight: 0.528914 | Bias: 0.070182\n",
            "Iteration: 47313 | Cost/Loss: 0.077604 | Weight: 0.528915 | Bias: 0.070182\n",
            "Iteration: 47314 | Cost/Loss: 0.077604 | Weight: 0.528915 | Bias: 0.070182\n",
            "Iteration: 47315 | Cost/Loss: 0.077604 | Weight: 0.528915 | Bias: 0.070183\n",
            "Iteration: 47316 | Cost/Loss: 0.077604 | Weight: 0.528916 | Bias: 0.070183\n",
            "Iteration: 47317 | Cost/Loss: 0.077604 | Weight: 0.528916 | Bias: 0.070183\n",
            "Iteration: 47318 | Cost/Loss: 0.077604 | Weight: 0.528916 | Bias: 0.070184\n",
            "Iteration: 47319 | Cost/Loss: 0.077604 | Weight: 0.528917 | Bias: 0.070184\n",
            "Iteration: 47320 | Cost/Loss: 0.077604 | Weight: 0.528917 | Bias: 0.070184\n",
            "Iteration: 47321 | Cost/Loss: 0.077604 | Weight: 0.528917 | Bias: 0.070185\n",
            "Iteration: 47322 | Cost/Loss: 0.077604 | Weight: 0.528917 | Bias: 0.070185\n",
            "Iteration: 47323 | Cost/Loss: 0.077604 | Weight: 0.528918 | Bias: 0.070185\n",
            "Iteration: 47324 | Cost/Loss: 0.077604 | Weight: 0.528918 | Bias: 0.070185\n",
            "Iteration: 47325 | Cost/Loss: 0.077604 | Weight: 0.528918 | Bias: 0.070186\n",
            "Iteration: 47326 | Cost/Loss: 0.077604 | Weight: 0.528919 | Bias: 0.070186\n",
            "Iteration: 47327 | Cost/Loss: 0.077604 | Weight: 0.528919 | Bias: 0.070186\n",
            "Iteration: 47328 | Cost/Loss: 0.077604 | Weight: 0.528919 | Bias: 0.070187\n",
            "Iteration: 47329 | Cost/Loss: 0.077604 | Weight: 0.528920 | Bias: 0.070187\n",
            "Iteration: 47330 | Cost/Loss: 0.077604 | Weight: 0.528920 | Bias: 0.070187\n",
            "Iteration: 47331 | Cost/Loss: 0.077604 | Weight: 0.528920 | Bias: 0.070188\n",
            "Iteration: 47332 | Cost/Loss: 0.077604 | Weight: 0.528920 | Bias: 0.070188\n",
            "Iteration: 47333 | Cost/Loss: 0.077604 | Weight: 0.528921 | Bias: 0.070188\n",
            "Iteration: 47334 | Cost/Loss: 0.077604 | Weight: 0.528921 | Bias: 0.070189\n",
            "Iteration: 47335 | Cost/Loss: 0.077604 | Weight: 0.528921 | Bias: 0.070189\n",
            "Iteration: 47336 | Cost/Loss: 0.077603 | Weight: 0.528922 | Bias: 0.070189\n",
            "Iteration: 47337 | Cost/Loss: 0.077603 | Weight: 0.528922 | Bias: 0.070190\n",
            "Iteration: 47338 | Cost/Loss: 0.077603 | Weight: 0.528922 | Bias: 0.070190\n",
            "Iteration: 47339 | Cost/Loss: 0.077603 | Weight: 0.528922 | Bias: 0.070190\n",
            "Iteration: 47340 | Cost/Loss: 0.077603 | Weight: 0.528923 | Bias: 0.070191\n",
            "Iteration: 47341 | Cost/Loss: 0.077603 | Weight: 0.528923 | Bias: 0.070191\n",
            "Iteration: 47342 | Cost/Loss: 0.077603 | Weight: 0.528923 | Bias: 0.070191\n",
            "Iteration: 47343 | Cost/Loss: 0.077603 | Weight: 0.528924 | Bias: 0.070192\n",
            "Iteration: 47344 | Cost/Loss: 0.077603 | Weight: 0.528924 | Bias: 0.070192\n",
            "Iteration: 47345 | Cost/Loss: 0.077603 | Weight: 0.528924 | Bias: 0.070192\n",
            "Iteration: 47346 | Cost/Loss: 0.077603 | Weight: 0.528925 | Bias: 0.070193\n",
            "Iteration: 47347 | Cost/Loss: 0.077603 | Weight: 0.528925 | Bias: 0.070193\n",
            "Iteration: 47348 | Cost/Loss: 0.077603 | Weight: 0.528925 | Bias: 0.070193\n",
            "Iteration: 47349 | Cost/Loss: 0.077603 | Weight: 0.528925 | Bias: 0.070193\n",
            "Iteration: 47350 | Cost/Loss: 0.077603 | Weight: 0.528926 | Bias: 0.070194\n",
            "Iteration: 47351 | Cost/Loss: 0.077603 | Weight: 0.528926 | Bias: 0.070194\n",
            "Iteration: 47352 | Cost/Loss: 0.077603 | Weight: 0.528926 | Bias: 0.070194\n",
            "Iteration: 47353 | Cost/Loss: 0.077603 | Weight: 0.528927 | Bias: 0.070195\n",
            "Iteration: 47354 | Cost/Loss: 0.077603 | Weight: 0.528927 | Bias: 0.070195\n",
            "Iteration: 47355 | Cost/Loss: 0.077603 | Weight: 0.528927 | Bias: 0.070195\n",
            "Iteration: 47356 | Cost/Loss: 0.077603 | Weight: 0.528928 | Bias: 0.070196\n",
            "Iteration: 47357 | Cost/Loss: 0.077603 | Weight: 0.528928 | Bias: 0.070196\n",
            "Iteration: 47358 | Cost/Loss: 0.077603 | Weight: 0.528928 | Bias: 0.070196\n",
            "Iteration: 47359 | Cost/Loss: 0.077603 | Weight: 0.528928 | Bias: 0.070197\n",
            "Iteration: 47360 | Cost/Loss: 0.077603 | Weight: 0.528929 | Bias: 0.070197\n",
            "Iteration: 47361 | Cost/Loss: 0.077603 | Weight: 0.528929 | Bias: 0.070197\n",
            "Iteration: 47362 | Cost/Loss: 0.077603 | Weight: 0.528929 | Bias: 0.070198\n",
            "Iteration: 47363 | Cost/Loss: 0.077603 | Weight: 0.528930 | Bias: 0.070198\n",
            "Iteration: 47364 | Cost/Loss: 0.077603 | Weight: 0.528930 | Bias: 0.070198\n",
            "Iteration: 47365 | Cost/Loss: 0.077603 | Weight: 0.528930 | Bias: 0.070199\n",
            "Iteration: 47366 | Cost/Loss: 0.077603 | Weight: 0.528931 | Bias: 0.070199\n",
            "Iteration: 47367 | Cost/Loss: 0.077603 | Weight: 0.528931 | Bias: 0.070199\n",
            "Iteration: 47368 | Cost/Loss: 0.077603 | Weight: 0.528931 | Bias: 0.070200\n",
            "Iteration: 47369 | Cost/Loss: 0.077603 | Weight: 0.528931 | Bias: 0.070200\n",
            "Iteration: 47370 | Cost/Loss: 0.077603 | Weight: 0.528932 | Bias: 0.070200\n",
            "Iteration: 47371 | Cost/Loss: 0.077603 | Weight: 0.528932 | Bias: 0.070201\n",
            "Iteration: 47372 | Cost/Loss: 0.077603 | Weight: 0.528932 | Bias: 0.070201\n",
            "Iteration: 47373 | Cost/Loss: 0.077603 | Weight: 0.528933 | Bias: 0.070201\n",
            "Iteration: 47374 | Cost/Loss: 0.077603 | Weight: 0.528933 | Bias: 0.070201\n",
            "Iteration: 47375 | Cost/Loss: 0.077603 | Weight: 0.528933 | Bias: 0.070202\n",
            "Iteration: 47376 | Cost/Loss: 0.077602 | Weight: 0.528934 | Bias: 0.070202\n",
            "Iteration: 47377 | Cost/Loss: 0.077602 | Weight: 0.528934 | Bias: 0.070202\n",
            "Iteration: 47378 | Cost/Loss: 0.077602 | Weight: 0.528934 | Bias: 0.070203\n",
            "Iteration: 47379 | Cost/Loss: 0.077602 | Weight: 0.528934 | Bias: 0.070203\n",
            "Iteration: 47380 | Cost/Loss: 0.077602 | Weight: 0.528935 | Bias: 0.070203\n",
            "Iteration: 47381 | Cost/Loss: 0.077602 | Weight: 0.528935 | Bias: 0.070204\n",
            "Iteration: 47382 | Cost/Loss: 0.077602 | Weight: 0.528935 | Bias: 0.070204\n",
            "Iteration: 47383 | Cost/Loss: 0.077602 | Weight: 0.528936 | Bias: 0.070204\n",
            "Iteration: 47384 | Cost/Loss: 0.077602 | Weight: 0.528936 | Bias: 0.070205\n",
            "Iteration: 47385 | Cost/Loss: 0.077602 | Weight: 0.528936 | Bias: 0.070205\n",
            "Iteration: 47386 | Cost/Loss: 0.077602 | Weight: 0.528937 | Bias: 0.070205\n",
            "Iteration: 47387 | Cost/Loss: 0.077602 | Weight: 0.528937 | Bias: 0.070206\n",
            "Iteration: 47388 | Cost/Loss: 0.077602 | Weight: 0.528937 | Bias: 0.070206\n",
            "Iteration: 47389 | Cost/Loss: 0.077602 | Weight: 0.528937 | Bias: 0.070206\n",
            "Iteration: 47390 | Cost/Loss: 0.077602 | Weight: 0.528938 | Bias: 0.070207\n",
            "Iteration: 47391 | Cost/Loss: 0.077602 | Weight: 0.528938 | Bias: 0.070207\n",
            "Iteration: 47392 | Cost/Loss: 0.077602 | Weight: 0.528938 | Bias: 0.070207\n",
            "Iteration: 47393 | Cost/Loss: 0.077602 | Weight: 0.528939 | Bias: 0.070208\n",
            "Iteration: 47394 | Cost/Loss: 0.077602 | Weight: 0.528939 | Bias: 0.070208\n",
            "Iteration: 47395 | Cost/Loss: 0.077602 | Weight: 0.528939 | Bias: 0.070208\n",
            "Iteration: 47396 | Cost/Loss: 0.077602 | Weight: 0.528939 | Bias: 0.070209\n",
            "Iteration: 47397 | Cost/Loss: 0.077602 | Weight: 0.528940 | Bias: 0.070209\n",
            "Iteration: 47398 | Cost/Loss: 0.077602 | Weight: 0.528940 | Bias: 0.070209\n",
            "Iteration: 47399 | Cost/Loss: 0.077602 | Weight: 0.528940 | Bias: 0.070210\n",
            "Iteration: 47400 | Cost/Loss: 0.077602 | Weight: 0.528941 | Bias: 0.070210\n",
            "Iteration: 47401 | Cost/Loss: 0.077602 | Weight: 0.528941 | Bias: 0.070210\n",
            "Iteration: 47402 | Cost/Loss: 0.077602 | Weight: 0.528941 | Bias: 0.070210\n",
            "Iteration: 47403 | Cost/Loss: 0.077602 | Weight: 0.528942 | Bias: 0.070211\n",
            "Iteration: 47404 | Cost/Loss: 0.077602 | Weight: 0.528942 | Bias: 0.070211\n",
            "Iteration: 47405 | Cost/Loss: 0.077602 | Weight: 0.528942 | Bias: 0.070211\n",
            "Iteration: 47406 | Cost/Loss: 0.077602 | Weight: 0.528942 | Bias: 0.070212\n",
            "Iteration: 47407 | Cost/Loss: 0.077602 | Weight: 0.528943 | Bias: 0.070212\n",
            "Iteration: 47408 | Cost/Loss: 0.077602 | Weight: 0.528943 | Bias: 0.070212\n",
            "Iteration: 47409 | Cost/Loss: 0.077602 | Weight: 0.528943 | Bias: 0.070213\n",
            "Iteration: 47410 | Cost/Loss: 0.077602 | Weight: 0.528944 | Bias: 0.070213\n",
            "Iteration: 47411 | Cost/Loss: 0.077602 | Weight: 0.528944 | Bias: 0.070213\n",
            "Iteration: 47412 | Cost/Loss: 0.077602 | Weight: 0.528944 | Bias: 0.070214\n",
            "Iteration: 47413 | Cost/Loss: 0.077602 | Weight: 0.528945 | Bias: 0.070214\n",
            "Iteration: 47414 | Cost/Loss: 0.077602 | Weight: 0.528945 | Bias: 0.070214\n",
            "Iteration: 47415 | Cost/Loss: 0.077601 | Weight: 0.528945 | Bias: 0.070215\n",
            "Iteration: 47416 | Cost/Loss: 0.077601 | Weight: 0.528945 | Bias: 0.070215\n",
            "Iteration: 47417 | Cost/Loss: 0.077601 | Weight: 0.528946 | Bias: 0.070215\n",
            "Iteration: 47418 | Cost/Loss: 0.077601 | Weight: 0.528946 | Bias: 0.070216\n",
            "Iteration: 47419 | Cost/Loss: 0.077601 | Weight: 0.528946 | Bias: 0.070216\n",
            "Iteration: 47420 | Cost/Loss: 0.077601 | Weight: 0.528947 | Bias: 0.070216\n",
            "Iteration: 47421 | Cost/Loss: 0.077601 | Weight: 0.528947 | Bias: 0.070217\n",
            "Iteration: 47422 | Cost/Loss: 0.077601 | Weight: 0.528947 | Bias: 0.070217\n",
            "Iteration: 47423 | Cost/Loss: 0.077601 | Weight: 0.528948 | Bias: 0.070217\n",
            "Iteration: 47424 | Cost/Loss: 0.077601 | Weight: 0.528948 | Bias: 0.070218\n",
            "Iteration: 47425 | Cost/Loss: 0.077601 | Weight: 0.528948 | Bias: 0.070218\n",
            "Iteration: 47426 | Cost/Loss: 0.077601 | Weight: 0.528948 | Bias: 0.070218\n",
            "Iteration: 47427 | Cost/Loss: 0.077601 | Weight: 0.528949 | Bias: 0.070218\n",
            "Iteration: 47428 | Cost/Loss: 0.077601 | Weight: 0.528949 | Bias: 0.070219\n",
            "Iteration: 47429 | Cost/Loss: 0.077601 | Weight: 0.528949 | Bias: 0.070219\n",
            "Iteration: 47430 | Cost/Loss: 0.077601 | Weight: 0.528950 | Bias: 0.070219\n",
            "Iteration: 47431 | Cost/Loss: 0.077601 | Weight: 0.528950 | Bias: 0.070220\n",
            "Iteration: 47432 | Cost/Loss: 0.077601 | Weight: 0.528950 | Bias: 0.070220\n",
            "Iteration: 47433 | Cost/Loss: 0.077601 | Weight: 0.528951 | Bias: 0.070220\n",
            "Iteration: 47434 | Cost/Loss: 0.077601 | Weight: 0.528951 | Bias: 0.070221\n",
            "Iteration: 47435 | Cost/Loss: 0.077601 | Weight: 0.528951 | Bias: 0.070221\n",
            "Iteration: 47436 | Cost/Loss: 0.077601 | Weight: 0.528951 | Bias: 0.070221\n",
            "Iteration: 47437 | Cost/Loss: 0.077601 | Weight: 0.528952 | Bias: 0.070222\n",
            "Iteration: 47438 | Cost/Loss: 0.077601 | Weight: 0.528952 | Bias: 0.070222\n",
            "Iteration: 47439 | Cost/Loss: 0.077601 | Weight: 0.528952 | Bias: 0.070222\n",
            "Iteration: 47440 | Cost/Loss: 0.077601 | Weight: 0.528953 | Bias: 0.070223\n",
            "Iteration: 47441 | Cost/Loss: 0.077601 | Weight: 0.528953 | Bias: 0.070223\n",
            "Iteration: 47442 | Cost/Loss: 0.077601 | Weight: 0.528953 | Bias: 0.070223\n",
            "Iteration: 47443 | Cost/Loss: 0.077601 | Weight: 0.528953 | Bias: 0.070224\n",
            "Iteration: 47444 | Cost/Loss: 0.077601 | Weight: 0.528954 | Bias: 0.070224\n",
            "Iteration: 47445 | Cost/Loss: 0.077601 | Weight: 0.528954 | Bias: 0.070224\n",
            "Iteration: 47446 | Cost/Loss: 0.077601 | Weight: 0.528954 | Bias: 0.070225\n",
            "Iteration: 47447 | Cost/Loss: 0.077601 | Weight: 0.528955 | Bias: 0.070225\n",
            "Iteration: 47448 | Cost/Loss: 0.077601 | Weight: 0.528955 | Bias: 0.070225\n",
            "Iteration: 47449 | Cost/Loss: 0.077601 | Weight: 0.528955 | Bias: 0.070226\n",
            "Iteration: 47450 | Cost/Loss: 0.077601 | Weight: 0.528956 | Bias: 0.070226\n",
            "Iteration: 47451 | Cost/Loss: 0.077601 | Weight: 0.528956 | Bias: 0.070226\n",
            "Iteration: 47452 | Cost/Loss: 0.077601 | Weight: 0.528956 | Bias: 0.070226\n",
            "Iteration: 47453 | Cost/Loss: 0.077601 | Weight: 0.528956 | Bias: 0.070227\n",
            "Iteration: 47454 | Cost/Loss: 0.077601 | Weight: 0.528957 | Bias: 0.070227\n",
            "Iteration: 47455 | Cost/Loss: 0.077600 | Weight: 0.528957 | Bias: 0.070227\n",
            "Iteration: 47456 | Cost/Loss: 0.077600 | Weight: 0.528957 | Bias: 0.070228\n",
            "Iteration: 47457 | Cost/Loss: 0.077600 | Weight: 0.528958 | Bias: 0.070228\n",
            "Iteration: 47458 | Cost/Loss: 0.077600 | Weight: 0.528958 | Bias: 0.070228\n",
            "Iteration: 47459 | Cost/Loss: 0.077600 | Weight: 0.528958 | Bias: 0.070229\n",
            "Iteration: 47460 | Cost/Loss: 0.077600 | Weight: 0.528959 | Bias: 0.070229\n",
            "Iteration: 47461 | Cost/Loss: 0.077600 | Weight: 0.528959 | Bias: 0.070229\n",
            "Iteration: 47462 | Cost/Loss: 0.077600 | Weight: 0.528959 | Bias: 0.070230\n",
            "Iteration: 47463 | Cost/Loss: 0.077600 | Weight: 0.528959 | Bias: 0.070230\n",
            "Iteration: 47464 | Cost/Loss: 0.077600 | Weight: 0.528960 | Bias: 0.070230\n",
            "Iteration: 47465 | Cost/Loss: 0.077600 | Weight: 0.528960 | Bias: 0.070231\n",
            "Iteration: 47466 | Cost/Loss: 0.077600 | Weight: 0.528960 | Bias: 0.070231\n",
            "Iteration: 47467 | Cost/Loss: 0.077600 | Weight: 0.528961 | Bias: 0.070231\n",
            "Iteration: 47468 | Cost/Loss: 0.077600 | Weight: 0.528961 | Bias: 0.070232\n",
            "Iteration: 47469 | Cost/Loss: 0.077600 | Weight: 0.528961 | Bias: 0.070232\n",
            "Iteration: 47470 | Cost/Loss: 0.077600 | Weight: 0.528962 | Bias: 0.070232\n",
            "Iteration: 47471 | Cost/Loss: 0.077600 | Weight: 0.528962 | Bias: 0.070233\n",
            "Iteration: 47472 | Cost/Loss: 0.077600 | Weight: 0.528962 | Bias: 0.070233\n",
            "Iteration: 47473 | Cost/Loss: 0.077600 | Weight: 0.528962 | Bias: 0.070233\n",
            "Iteration: 47474 | Cost/Loss: 0.077600 | Weight: 0.528963 | Bias: 0.070234\n",
            "Iteration: 47475 | Cost/Loss: 0.077600 | Weight: 0.528963 | Bias: 0.070234\n",
            "Iteration: 47476 | Cost/Loss: 0.077600 | Weight: 0.528963 | Bias: 0.070234\n",
            "Iteration: 47477 | Cost/Loss: 0.077600 | Weight: 0.528964 | Bias: 0.070234\n",
            "Iteration: 47478 | Cost/Loss: 0.077600 | Weight: 0.528964 | Bias: 0.070235\n",
            "Iteration: 47479 | Cost/Loss: 0.077600 | Weight: 0.528964 | Bias: 0.070235\n",
            "Iteration: 47480 | Cost/Loss: 0.077600 | Weight: 0.528965 | Bias: 0.070235\n",
            "Iteration: 47481 | Cost/Loss: 0.077600 | Weight: 0.528965 | Bias: 0.070236\n",
            "Iteration: 47482 | Cost/Loss: 0.077600 | Weight: 0.528965 | Bias: 0.070236\n",
            "Iteration: 47483 | Cost/Loss: 0.077600 | Weight: 0.528965 | Bias: 0.070236\n",
            "Iteration: 47484 | Cost/Loss: 0.077600 | Weight: 0.528966 | Bias: 0.070237\n",
            "Iteration: 47485 | Cost/Loss: 0.077600 | Weight: 0.528966 | Bias: 0.070237\n",
            "Iteration: 47486 | Cost/Loss: 0.077600 | Weight: 0.528966 | Bias: 0.070237\n",
            "Iteration: 47487 | Cost/Loss: 0.077600 | Weight: 0.528967 | Bias: 0.070238\n",
            "Iteration: 47488 | Cost/Loss: 0.077600 | Weight: 0.528967 | Bias: 0.070238\n",
            "Iteration: 47489 | Cost/Loss: 0.077600 | Weight: 0.528967 | Bias: 0.070238\n",
            "Iteration: 47490 | Cost/Loss: 0.077600 | Weight: 0.528967 | Bias: 0.070239\n",
            "Iteration: 47491 | Cost/Loss: 0.077600 | Weight: 0.528968 | Bias: 0.070239\n",
            "Iteration: 47492 | Cost/Loss: 0.077600 | Weight: 0.528968 | Bias: 0.070239\n",
            "Iteration: 47493 | Cost/Loss: 0.077600 | Weight: 0.528968 | Bias: 0.070240\n",
            "Iteration: 47494 | Cost/Loss: 0.077600 | Weight: 0.528969 | Bias: 0.070240\n",
            "Iteration: 47495 | Cost/Loss: 0.077599 | Weight: 0.528969 | Bias: 0.070240\n",
            "Iteration: 47496 | Cost/Loss: 0.077599 | Weight: 0.528969 | Bias: 0.070241\n",
            "Iteration: 47497 | Cost/Loss: 0.077599 | Weight: 0.528970 | Bias: 0.070241\n",
            "Iteration: 47498 | Cost/Loss: 0.077599 | Weight: 0.528970 | Bias: 0.070241\n",
            "Iteration: 47499 | Cost/Loss: 0.077599 | Weight: 0.528970 | Bias: 0.070242\n",
            "Iteration: 47500 | Cost/Loss: 0.077599 | Weight: 0.528970 | Bias: 0.070242\n",
            "Iteration: 47501 | Cost/Loss: 0.077599 | Weight: 0.528971 | Bias: 0.070242\n",
            "Iteration: 47502 | Cost/Loss: 0.077599 | Weight: 0.528971 | Bias: 0.070243\n",
            "Iteration: 47503 | Cost/Loss: 0.077599 | Weight: 0.528971 | Bias: 0.070243\n",
            "Iteration: 47504 | Cost/Loss: 0.077599 | Weight: 0.528972 | Bias: 0.070243\n",
            "Iteration: 47505 | Cost/Loss: 0.077599 | Weight: 0.528972 | Bias: 0.070243\n",
            "Iteration: 47506 | Cost/Loss: 0.077599 | Weight: 0.528972 | Bias: 0.070244\n",
            "Iteration: 47507 | Cost/Loss: 0.077599 | Weight: 0.528973 | Bias: 0.070244\n",
            "Iteration: 47508 | Cost/Loss: 0.077599 | Weight: 0.528973 | Bias: 0.070244\n",
            "Iteration: 47509 | Cost/Loss: 0.077599 | Weight: 0.528973 | Bias: 0.070245\n",
            "Iteration: 47510 | Cost/Loss: 0.077599 | Weight: 0.528973 | Bias: 0.070245\n",
            "Iteration: 47511 | Cost/Loss: 0.077599 | Weight: 0.528974 | Bias: 0.070245\n",
            "Iteration: 47512 | Cost/Loss: 0.077599 | Weight: 0.528974 | Bias: 0.070246\n",
            "Iteration: 47513 | Cost/Loss: 0.077599 | Weight: 0.528974 | Bias: 0.070246\n",
            "Iteration: 47514 | Cost/Loss: 0.077599 | Weight: 0.528975 | Bias: 0.070246\n",
            "Iteration: 47515 | Cost/Loss: 0.077599 | Weight: 0.528975 | Bias: 0.070247\n",
            "Iteration: 47516 | Cost/Loss: 0.077599 | Weight: 0.528975 | Bias: 0.070247\n",
            "Iteration: 47517 | Cost/Loss: 0.077599 | Weight: 0.528976 | Bias: 0.070247\n",
            "Iteration: 47518 | Cost/Loss: 0.077599 | Weight: 0.528976 | Bias: 0.070248\n",
            "Iteration: 47519 | Cost/Loss: 0.077599 | Weight: 0.528976 | Bias: 0.070248\n",
            "Iteration: 47520 | Cost/Loss: 0.077599 | Weight: 0.528976 | Bias: 0.070248\n",
            "Iteration: 47521 | Cost/Loss: 0.077599 | Weight: 0.528977 | Bias: 0.070249\n",
            "Iteration: 47522 | Cost/Loss: 0.077599 | Weight: 0.528977 | Bias: 0.070249\n",
            "Iteration: 47523 | Cost/Loss: 0.077599 | Weight: 0.528977 | Bias: 0.070249\n",
            "Iteration: 47524 | Cost/Loss: 0.077599 | Weight: 0.528978 | Bias: 0.070250\n",
            "Iteration: 47525 | Cost/Loss: 0.077599 | Weight: 0.528978 | Bias: 0.070250\n",
            "Iteration: 47526 | Cost/Loss: 0.077599 | Weight: 0.528978 | Bias: 0.070250\n",
            "Iteration: 47527 | Cost/Loss: 0.077599 | Weight: 0.528979 | Bias: 0.070251\n",
            "Iteration: 47528 | Cost/Loss: 0.077599 | Weight: 0.528979 | Bias: 0.070251\n",
            "Iteration: 47529 | Cost/Loss: 0.077599 | Weight: 0.528979 | Bias: 0.070251\n",
            "Iteration: 47530 | Cost/Loss: 0.077599 | Weight: 0.528979 | Bias: 0.070251\n",
            "Iteration: 47531 | Cost/Loss: 0.077599 | Weight: 0.528980 | Bias: 0.070252\n",
            "Iteration: 47532 | Cost/Loss: 0.077599 | Weight: 0.528980 | Bias: 0.070252\n",
            "Iteration: 47533 | Cost/Loss: 0.077599 | Weight: 0.528980 | Bias: 0.070252\n",
            "Iteration: 47534 | Cost/Loss: 0.077599 | Weight: 0.528981 | Bias: 0.070253\n",
            "Iteration: 47535 | Cost/Loss: 0.077598 | Weight: 0.528981 | Bias: 0.070253\n",
            "Iteration: 47536 | Cost/Loss: 0.077598 | Weight: 0.528981 | Bias: 0.070253\n",
            "Iteration: 47537 | Cost/Loss: 0.077598 | Weight: 0.528982 | Bias: 0.070254\n",
            "Iteration: 47538 | Cost/Loss: 0.077598 | Weight: 0.528982 | Bias: 0.070254\n",
            "Iteration: 47539 | Cost/Loss: 0.077598 | Weight: 0.528982 | Bias: 0.070254\n",
            "Iteration: 47540 | Cost/Loss: 0.077598 | Weight: 0.528982 | Bias: 0.070255\n",
            "Iteration: 47541 | Cost/Loss: 0.077598 | Weight: 0.528983 | Bias: 0.070255\n",
            "Iteration: 47542 | Cost/Loss: 0.077598 | Weight: 0.528983 | Bias: 0.070255\n",
            "Iteration: 47543 | Cost/Loss: 0.077598 | Weight: 0.528983 | Bias: 0.070256\n",
            "Iteration: 47544 | Cost/Loss: 0.077598 | Weight: 0.528984 | Bias: 0.070256\n",
            "Iteration: 47545 | Cost/Loss: 0.077598 | Weight: 0.528984 | Bias: 0.070256\n",
            "Iteration: 47546 | Cost/Loss: 0.077598 | Weight: 0.528984 | Bias: 0.070257\n",
            "Iteration: 47547 | Cost/Loss: 0.077598 | Weight: 0.528984 | Bias: 0.070257\n",
            "Iteration: 47548 | Cost/Loss: 0.077598 | Weight: 0.528985 | Bias: 0.070257\n",
            "Iteration: 47549 | Cost/Loss: 0.077598 | Weight: 0.528985 | Bias: 0.070258\n",
            "Iteration: 47550 | Cost/Loss: 0.077598 | Weight: 0.528985 | Bias: 0.070258\n",
            "Iteration: 47551 | Cost/Loss: 0.077598 | Weight: 0.528986 | Bias: 0.070258\n",
            "Iteration: 47552 | Cost/Loss: 0.077598 | Weight: 0.528986 | Bias: 0.070259\n",
            "Iteration: 47553 | Cost/Loss: 0.077598 | Weight: 0.528986 | Bias: 0.070259\n",
            "Iteration: 47554 | Cost/Loss: 0.077598 | Weight: 0.528987 | Bias: 0.070259\n",
            "Iteration: 47555 | Cost/Loss: 0.077598 | Weight: 0.528987 | Bias: 0.070259\n",
            "Iteration: 47556 | Cost/Loss: 0.077598 | Weight: 0.528987 | Bias: 0.070260\n",
            "Iteration: 47557 | Cost/Loss: 0.077598 | Weight: 0.528987 | Bias: 0.070260\n",
            "Iteration: 47558 | Cost/Loss: 0.077598 | Weight: 0.528988 | Bias: 0.070260\n",
            "Iteration: 47559 | Cost/Loss: 0.077598 | Weight: 0.528988 | Bias: 0.070261\n",
            "Iteration: 47560 | Cost/Loss: 0.077598 | Weight: 0.528988 | Bias: 0.070261\n",
            "Iteration: 47561 | Cost/Loss: 0.077598 | Weight: 0.528989 | Bias: 0.070261\n",
            "Iteration: 47562 | Cost/Loss: 0.077598 | Weight: 0.528989 | Bias: 0.070262\n",
            "Iteration: 47563 | Cost/Loss: 0.077598 | Weight: 0.528989 | Bias: 0.070262\n",
            "Iteration: 47564 | Cost/Loss: 0.077598 | Weight: 0.528990 | Bias: 0.070262\n",
            "Iteration: 47565 | Cost/Loss: 0.077598 | Weight: 0.528990 | Bias: 0.070263\n",
            "Iteration: 47566 | Cost/Loss: 0.077598 | Weight: 0.528990 | Bias: 0.070263\n",
            "Iteration: 47567 | Cost/Loss: 0.077598 | Weight: 0.528990 | Bias: 0.070263\n",
            "Iteration: 47568 | Cost/Loss: 0.077598 | Weight: 0.528991 | Bias: 0.070264\n",
            "Iteration: 47569 | Cost/Loss: 0.077598 | Weight: 0.528991 | Bias: 0.070264\n",
            "Iteration: 47570 | Cost/Loss: 0.077598 | Weight: 0.528991 | Bias: 0.070264\n",
            "Iteration: 47571 | Cost/Loss: 0.077598 | Weight: 0.528992 | Bias: 0.070265\n",
            "Iteration: 47572 | Cost/Loss: 0.077598 | Weight: 0.528992 | Bias: 0.070265\n",
            "Iteration: 47573 | Cost/Loss: 0.077598 | Weight: 0.528992 | Bias: 0.070265\n",
            "Iteration: 47574 | Cost/Loss: 0.077597 | Weight: 0.528993 | Bias: 0.070266\n",
            "Iteration: 47575 | Cost/Loss: 0.077597 | Weight: 0.528993 | Bias: 0.070266\n",
            "Iteration: 47576 | Cost/Loss: 0.077597 | Weight: 0.528993 | Bias: 0.070266\n",
            "Iteration: 47577 | Cost/Loss: 0.077597 | Weight: 0.528993 | Bias: 0.070267\n",
            "Iteration: 47578 | Cost/Loss: 0.077597 | Weight: 0.528994 | Bias: 0.070267\n",
            "Iteration: 47579 | Cost/Loss: 0.077597 | Weight: 0.528994 | Bias: 0.070267\n",
            "Iteration: 47580 | Cost/Loss: 0.077597 | Weight: 0.528994 | Bias: 0.070267\n",
            "Iteration: 47581 | Cost/Loss: 0.077597 | Weight: 0.528995 | Bias: 0.070268\n",
            "Iteration: 47582 | Cost/Loss: 0.077597 | Weight: 0.528995 | Bias: 0.070268\n",
            "Iteration: 47583 | Cost/Loss: 0.077597 | Weight: 0.528995 | Bias: 0.070268\n",
            "Iteration: 47584 | Cost/Loss: 0.077597 | Weight: 0.528996 | Bias: 0.070269\n",
            "Iteration: 47585 | Cost/Loss: 0.077597 | Weight: 0.528996 | Bias: 0.070269\n",
            "Iteration: 47586 | Cost/Loss: 0.077597 | Weight: 0.528996 | Bias: 0.070269\n",
            "Iteration: 47587 | Cost/Loss: 0.077597 | Weight: 0.528996 | Bias: 0.070270\n",
            "Iteration: 47588 | Cost/Loss: 0.077597 | Weight: 0.528997 | Bias: 0.070270\n",
            "Iteration: 47589 | Cost/Loss: 0.077597 | Weight: 0.528997 | Bias: 0.070270\n",
            "Iteration: 47590 | Cost/Loss: 0.077597 | Weight: 0.528997 | Bias: 0.070271\n",
            "Iteration: 47591 | Cost/Loss: 0.077597 | Weight: 0.528998 | Bias: 0.070271\n",
            "Iteration: 47592 | Cost/Loss: 0.077597 | Weight: 0.528998 | Bias: 0.070271\n",
            "Iteration: 47593 | Cost/Loss: 0.077597 | Weight: 0.528998 | Bias: 0.070272\n",
            "Iteration: 47594 | Cost/Loss: 0.077597 | Weight: 0.528998 | Bias: 0.070272\n",
            "Iteration: 47595 | Cost/Loss: 0.077597 | Weight: 0.528999 | Bias: 0.070272\n",
            "Iteration: 47596 | Cost/Loss: 0.077597 | Weight: 0.528999 | Bias: 0.070273\n",
            "Iteration: 47597 | Cost/Loss: 0.077597 | Weight: 0.528999 | Bias: 0.070273\n",
            "Iteration: 47598 | Cost/Loss: 0.077597 | Weight: 0.529000 | Bias: 0.070273\n",
            "Iteration: 47599 | Cost/Loss: 0.077597 | Weight: 0.529000 | Bias: 0.070274\n",
            "Iteration: 47600 | Cost/Loss: 0.077597 | Weight: 0.529000 | Bias: 0.070274\n",
            "Iteration: 47601 | Cost/Loss: 0.077597 | Weight: 0.529001 | Bias: 0.070274\n",
            "Iteration: 47602 | Cost/Loss: 0.077597 | Weight: 0.529001 | Bias: 0.070275\n",
            "Iteration: 47603 | Cost/Loss: 0.077597 | Weight: 0.529001 | Bias: 0.070275\n",
            "Iteration: 47604 | Cost/Loss: 0.077597 | Weight: 0.529001 | Bias: 0.070275\n",
            "Iteration: 47605 | Cost/Loss: 0.077597 | Weight: 0.529002 | Bias: 0.070276\n",
            "Iteration: 47606 | Cost/Loss: 0.077597 | Weight: 0.529002 | Bias: 0.070276\n",
            "Iteration: 47607 | Cost/Loss: 0.077597 | Weight: 0.529002 | Bias: 0.070276\n",
            "Iteration: 47608 | Cost/Loss: 0.077597 | Weight: 0.529003 | Bias: 0.070276\n",
            "Iteration: 47609 | Cost/Loss: 0.077597 | Weight: 0.529003 | Bias: 0.070277\n",
            "Iteration: 47610 | Cost/Loss: 0.077597 | Weight: 0.529003 | Bias: 0.070277\n",
            "Iteration: 47611 | Cost/Loss: 0.077597 | Weight: 0.529004 | Bias: 0.070277\n",
            "Iteration: 47612 | Cost/Loss: 0.077597 | Weight: 0.529004 | Bias: 0.070278\n",
            "Iteration: 47613 | Cost/Loss: 0.077597 | Weight: 0.529004 | Bias: 0.070278\n",
            "Iteration: 47614 | Cost/Loss: 0.077596 | Weight: 0.529004 | Bias: 0.070278\n",
            "Iteration: 47615 | Cost/Loss: 0.077596 | Weight: 0.529005 | Bias: 0.070279\n",
            "Iteration: 47616 | Cost/Loss: 0.077596 | Weight: 0.529005 | Bias: 0.070279\n",
            "Iteration: 47617 | Cost/Loss: 0.077596 | Weight: 0.529005 | Bias: 0.070279\n",
            "Iteration: 47618 | Cost/Loss: 0.077596 | Weight: 0.529006 | Bias: 0.070280\n",
            "Iteration: 47619 | Cost/Loss: 0.077596 | Weight: 0.529006 | Bias: 0.070280\n",
            "Iteration: 47620 | Cost/Loss: 0.077596 | Weight: 0.529006 | Bias: 0.070280\n",
            "Iteration: 47621 | Cost/Loss: 0.077596 | Weight: 0.529007 | Bias: 0.070281\n",
            "Iteration: 47622 | Cost/Loss: 0.077596 | Weight: 0.529007 | Bias: 0.070281\n",
            "Iteration: 47623 | Cost/Loss: 0.077596 | Weight: 0.529007 | Bias: 0.070281\n",
            "Iteration: 47624 | Cost/Loss: 0.077596 | Weight: 0.529007 | Bias: 0.070282\n",
            "Iteration: 47625 | Cost/Loss: 0.077596 | Weight: 0.529008 | Bias: 0.070282\n",
            "Iteration: 47626 | Cost/Loss: 0.077596 | Weight: 0.529008 | Bias: 0.070282\n",
            "Iteration: 47627 | Cost/Loss: 0.077596 | Weight: 0.529008 | Bias: 0.070283\n",
            "Iteration: 47628 | Cost/Loss: 0.077596 | Weight: 0.529009 | Bias: 0.070283\n",
            "Iteration: 47629 | Cost/Loss: 0.077596 | Weight: 0.529009 | Bias: 0.070283\n",
            "Iteration: 47630 | Cost/Loss: 0.077596 | Weight: 0.529009 | Bias: 0.070284\n",
            "Iteration: 47631 | Cost/Loss: 0.077596 | Weight: 0.529010 | Bias: 0.070284\n",
            "Iteration: 47632 | Cost/Loss: 0.077596 | Weight: 0.529010 | Bias: 0.070284\n",
            "Iteration: 47633 | Cost/Loss: 0.077596 | Weight: 0.529010 | Bias: 0.070284\n",
            "Iteration: 47634 | Cost/Loss: 0.077596 | Weight: 0.529010 | Bias: 0.070285\n",
            "Iteration: 47635 | Cost/Loss: 0.077596 | Weight: 0.529011 | Bias: 0.070285\n",
            "Iteration: 47636 | Cost/Loss: 0.077596 | Weight: 0.529011 | Bias: 0.070285\n",
            "Iteration: 47637 | Cost/Loss: 0.077596 | Weight: 0.529011 | Bias: 0.070286\n",
            "Iteration: 47638 | Cost/Loss: 0.077596 | Weight: 0.529012 | Bias: 0.070286\n",
            "Iteration: 47639 | Cost/Loss: 0.077596 | Weight: 0.529012 | Bias: 0.070286\n",
            "Iteration: 47640 | Cost/Loss: 0.077596 | Weight: 0.529012 | Bias: 0.070287\n",
            "Iteration: 47641 | Cost/Loss: 0.077596 | Weight: 0.529013 | Bias: 0.070287\n",
            "Iteration: 47642 | Cost/Loss: 0.077596 | Weight: 0.529013 | Bias: 0.070287\n",
            "Iteration: 47643 | Cost/Loss: 0.077596 | Weight: 0.529013 | Bias: 0.070288\n",
            "Iteration: 47644 | Cost/Loss: 0.077596 | Weight: 0.529013 | Bias: 0.070288\n",
            "Iteration: 47645 | Cost/Loss: 0.077596 | Weight: 0.529014 | Bias: 0.070288\n",
            "Iteration: 47646 | Cost/Loss: 0.077596 | Weight: 0.529014 | Bias: 0.070289\n",
            "Iteration: 47647 | Cost/Loss: 0.077596 | Weight: 0.529014 | Bias: 0.070289\n",
            "Iteration: 47648 | Cost/Loss: 0.077596 | Weight: 0.529015 | Bias: 0.070289\n",
            "Iteration: 47649 | Cost/Loss: 0.077596 | Weight: 0.529015 | Bias: 0.070290\n",
            "Iteration: 47650 | Cost/Loss: 0.077596 | Weight: 0.529015 | Bias: 0.070290\n",
            "Iteration: 47651 | Cost/Loss: 0.077596 | Weight: 0.529015 | Bias: 0.070290\n",
            "Iteration: 47652 | Cost/Loss: 0.077596 | Weight: 0.529016 | Bias: 0.070291\n",
            "Iteration: 47653 | Cost/Loss: 0.077595 | Weight: 0.529016 | Bias: 0.070291\n",
            "Iteration: 47654 | Cost/Loss: 0.077595 | Weight: 0.529016 | Bias: 0.070291\n",
            "Iteration: 47655 | Cost/Loss: 0.077595 | Weight: 0.529017 | Bias: 0.070292\n",
            "Iteration: 47656 | Cost/Loss: 0.077595 | Weight: 0.529017 | Bias: 0.070292\n",
            "Iteration: 47657 | Cost/Loss: 0.077595 | Weight: 0.529017 | Bias: 0.070292\n",
            "Iteration: 47658 | Cost/Loss: 0.077595 | Weight: 0.529018 | Bias: 0.070292\n",
            "Iteration: 47659 | Cost/Loss: 0.077595 | Weight: 0.529018 | Bias: 0.070293\n",
            "Iteration: 47660 | Cost/Loss: 0.077595 | Weight: 0.529018 | Bias: 0.070293\n",
            "Iteration: 47661 | Cost/Loss: 0.077595 | Weight: 0.529018 | Bias: 0.070293\n",
            "Iteration: 47662 | Cost/Loss: 0.077595 | Weight: 0.529019 | Bias: 0.070294\n",
            "Iteration: 47663 | Cost/Loss: 0.077595 | Weight: 0.529019 | Bias: 0.070294\n",
            "Iteration: 47664 | Cost/Loss: 0.077595 | Weight: 0.529019 | Bias: 0.070294\n",
            "Iteration: 47665 | Cost/Loss: 0.077595 | Weight: 0.529020 | Bias: 0.070295\n",
            "Iteration: 47666 | Cost/Loss: 0.077595 | Weight: 0.529020 | Bias: 0.070295\n",
            "Iteration: 47667 | Cost/Loss: 0.077595 | Weight: 0.529020 | Bias: 0.070295\n",
            "Iteration: 47668 | Cost/Loss: 0.077595 | Weight: 0.529021 | Bias: 0.070296\n",
            "Iteration: 47669 | Cost/Loss: 0.077595 | Weight: 0.529021 | Bias: 0.070296\n",
            "Iteration: 47670 | Cost/Loss: 0.077595 | Weight: 0.529021 | Bias: 0.070296\n",
            "Iteration: 47671 | Cost/Loss: 0.077595 | Weight: 0.529021 | Bias: 0.070297\n",
            "Iteration: 47672 | Cost/Loss: 0.077595 | Weight: 0.529022 | Bias: 0.070297\n",
            "Iteration: 47673 | Cost/Loss: 0.077595 | Weight: 0.529022 | Bias: 0.070297\n",
            "Iteration: 47674 | Cost/Loss: 0.077595 | Weight: 0.529022 | Bias: 0.070298\n",
            "Iteration: 47675 | Cost/Loss: 0.077595 | Weight: 0.529023 | Bias: 0.070298\n",
            "Iteration: 47676 | Cost/Loss: 0.077595 | Weight: 0.529023 | Bias: 0.070298\n",
            "Iteration: 47677 | Cost/Loss: 0.077595 | Weight: 0.529023 | Bias: 0.070299\n",
            "Iteration: 47678 | Cost/Loss: 0.077595 | Weight: 0.529024 | Bias: 0.070299\n",
            "Iteration: 47679 | Cost/Loss: 0.077595 | Weight: 0.529024 | Bias: 0.070299\n",
            "Iteration: 47680 | Cost/Loss: 0.077595 | Weight: 0.529024 | Bias: 0.070300\n",
            "Iteration: 47681 | Cost/Loss: 0.077595 | Weight: 0.529024 | Bias: 0.070300\n",
            "Iteration: 47682 | Cost/Loss: 0.077595 | Weight: 0.529025 | Bias: 0.070300\n",
            "Iteration: 47683 | Cost/Loss: 0.077595 | Weight: 0.529025 | Bias: 0.070300\n",
            "Iteration: 47684 | Cost/Loss: 0.077595 | Weight: 0.529025 | Bias: 0.070301\n",
            "Iteration: 47685 | Cost/Loss: 0.077595 | Weight: 0.529026 | Bias: 0.070301\n",
            "Iteration: 47686 | Cost/Loss: 0.077595 | Weight: 0.529026 | Bias: 0.070301\n",
            "Iteration: 47687 | Cost/Loss: 0.077595 | Weight: 0.529026 | Bias: 0.070302\n",
            "Iteration: 47688 | Cost/Loss: 0.077595 | Weight: 0.529027 | Bias: 0.070302\n",
            "Iteration: 47689 | Cost/Loss: 0.077595 | Weight: 0.529027 | Bias: 0.070302\n",
            "Iteration: 47690 | Cost/Loss: 0.077595 | Weight: 0.529027 | Bias: 0.070303\n",
            "Iteration: 47691 | Cost/Loss: 0.077595 | Weight: 0.529027 | Bias: 0.070303\n",
            "Iteration: 47692 | Cost/Loss: 0.077595 | Weight: 0.529028 | Bias: 0.070303\n",
            "Iteration: 47693 | Cost/Loss: 0.077594 | Weight: 0.529028 | Bias: 0.070304\n",
            "Iteration: 47694 | Cost/Loss: 0.077594 | Weight: 0.529028 | Bias: 0.070304\n",
            "Iteration: 47695 | Cost/Loss: 0.077594 | Weight: 0.529029 | Bias: 0.070304\n",
            "Iteration: 47696 | Cost/Loss: 0.077594 | Weight: 0.529029 | Bias: 0.070305\n",
            "Iteration: 47697 | Cost/Loss: 0.077594 | Weight: 0.529029 | Bias: 0.070305\n",
            "Iteration: 47698 | Cost/Loss: 0.077594 | Weight: 0.529029 | Bias: 0.070305\n",
            "Iteration: 47699 | Cost/Loss: 0.077594 | Weight: 0.529030 | Bias: 0.070306\n",
            "Iteration: 47700 | Cost/Loss: 0.077594 | Weight: 0.529030 | Bias: 0.070306\n",
            "Iteration: 47701 | Cost/Loss: 0.077594 | Weight: 0.529030 | Bias: 0.070306\n",
            "Iteration: 47702 | Cost/Loss: 0.077594 | Weight: 0.529031 | Bias: 0.070307\n",
            "Iteration: 47703 | Cost/Loss: 0.077594 | Weight: 0.529031 | Bias: 0.070307\n",
            "Iteration: 47704 | Cost/Loss: 0.077594 | Weight: 0.529031 | Bias: 0.070307\n",
            "Iteration: 47705 | Cost/Loss: 0.077594 | Weight: 0.529032 | Bias: 0.070308\n",
            "Iteration: 47706 | Cost/Loss: 0.077594 | Weight: 0.529032 | Bias: 0.070308\n",
            "Iteration: 47707 | Cost/Loss: 0.077594 | Weight: 0.529032 | Bias: 0.070308\n",
            "Iteration: 47708 | Cost/Loss: 0.077594 | Weight: 0.529032 | Bias: 0.070308\n",
            "Iteration: 47709 | Cost/Loss: 0.077594 | Weight: 0.529033 | Bias: 0.070309\n",
            "Iteration: 47710 | Cost/Loss: 0.077594 | Weight: 0.529033 | Bias: 0.070309\n",
            "Iteration: 47711 | Cost/Loss: 0.077594 | Weight: 0.529033 | Bias: 0.070309\n",
            "Iteration: 47712 | Cost/Loss: 0.077594 | Weight: 0.529034 | Bias: 0.070310\n",
            "Iteration: 47713 | Cost/Loss: 0.077594 | Weight: 0.529034 | Bias: 0.070310\n",
            "Iteration: 47714 | Cost/Loss: 0.077594 | Weight: 0.529034 | Bias: 0.070310\n",
            "Iteration: 47715 | Cost/Loss: 0.077594 | Weight: 0.529035 | Bias: 0.070311\n",
            "Iteration: 47716 | Cost/Loss: 0.077594 | Weight: 0.529035 | Bias: 0.070311\n",
            "Iteration: 47717 | Cost/Loss: 0.077594 | Weight: 0.529035 | Bias: 0.070311\n",
            "Iteration: 47718 | Cost/Loss: 0.077594 | Weight: 0.529035 | Bias: 0.070312\n",
            "Iteration: 47719 | Cost/Loss: 0.077594 | Weight: 0.529036 | Bias: 0.070312\n",
            "Iteration: 47720 | Cost/Loss: 0.077594 | Weight: 0.529036 | Bias: 0.070312\n",
            "Iteration: 47721 | Cost/Loss: 0.077594 | Weight: 0.529036 | Bias: 0.070313\n",
            "Iteration: 47722 | Cost/Loss: 0.077594 | Weight: 0.529037 | Bias: 0.070313\n",
            "Iteration: 47723 | Cost/Loss: 0.077594 | Weight: 0.529037 | Bias: 0.070313\n",
            "Iteration: 47724 | Cost/Loss: 0.077594 | Weight: 0.529037 | Bias: 0.070314\n",
            "Iteration: 47725 | Cost/Loss: 0.077594 | Weight: 0.529038 | Bias: 0.070314\n",
            "Iteration: 47726 | Cost/Loss: 0.077594 | Weight: 0.529038 | Bias: 0.070314\n",
            "Iteration: 47727 | Cost/Loss: 0.077594 | Weight: 0.529038 | Bias: 0.070315\n",
            "Iteration: 47728 | Cost/Loss: 0.077594 | Weight: 0.529038 | Bias: 0.070315\n",
            "Iteration: 47729 | Cost/Loss: 0.077594 | Weight: 0.529039 | Bias: 0.070315\n",
            "Iteration: 47730 | Cost/Loss: 0.077594 | Weight: 0.529039 | Bias: 0.070316\n",
            "Iteration: 47731 | Cost/Loss: 0.077594 | Weight: 0.529039 | Bias: 0.070316\n",
            "Iteration: 47732 | Cost/Loss: 0.077593 | Weight: 0.529040 | Bias: 0.070316\n",
            "Iteration: 47733 | Cost/Loss: 0.077593 | Weight: 0.529040 | Bias: 0.070317\n",
            "Iteration: 47734 | Cost/Loss: 0.077593 | Weight: 0.529040 | Bias: 0.070317\n",
            "Iteration: 47735 | Cost/Loss: 0.077593 | Weight: 0.529041 | Bias: 0.070317\n",
            "Iteration: 47736 | Cost/Loss: 0.077593 | Weight: 0.529041 | Bias: 0.070317\n",
            "Iteration: 47737 | Cost/Loss: 0.077593 | Weight: 0.529041 | Bias: 0.070318\n",
            "Iteration: 47738 | Cost/Loss: 0.077593 | Weight: 0.529041 | Bias: 0.070318\n",
            "Iteration: 47739 | Cost/Loss: 0.077593 | Weight: 0.529042 | Bias: 0.070318\n",
            "Iteration: 47740 | Cost/Loss: 0.077593 | Weight: 0.529042 | Bias: 0.070319\n",
            "Iteration: 47741 | Cost/Loss: 0.077593 | Weight: 0.529042 | Bias: 0.070319\n",
            "Iteration: 47742 | Cost/Loss: 0.077593 | Weight: 0.529043 | Bias: 0.070319\n",
            "Iteration: 47743 | Cost/Loss: 0.077593 | Weight: 0.529043 | Bias: 0.070320\n",
            "Iteration: 47744 | Cost/Loss: 0.077593 | Weight: 0.529043 | Bias: 0.070320\n",
            "Iteration: 47745 | Cost/Loss: 0.077593 | Weight: 0.529043 | Bias: 0.070320\n",
            "Iteration: 47746 | Cost/Loss: 0.077593 | Weight: 0.529044 | Bias: 0.070321\n",
            "Iteration: 47747 | Cost/Loss: 0.077593 | Weight: 0.529044 | Bias: 0.070321\n",
            "Iteration: 47748 | Cost/Loss: 0.077593 | Weight: 0.529044 | Bias: 0.070321\n",
            "Iteration: 47749 | Cost/Loss: 0.077593 | Weight: 0.529045 | Bias: 0.070322\n",
            "Iteration: 47750 | Cost/Loss: 0.077593 | Weight: 0.529045 | Bias: 0.070322\n",
            "Iteration: 47751 | Cost/Loss: 0.077593 | Weight: 0.529045 | Bias: 0.070322\n",
            "Iteration: 47752 | Cost/Loss: 0.077593 | Weight: 0.529046 | Bias: 0.070323\n",
            "Iteration: 47753 | Cost/Loss: 0.077593 | Weight: 0.529046 | Bias: 0.070323\n",
            "Iteration: 47754 | Cost/Loss: 0.077593 | Weight: 0.529046 | Bias: 0.070323\n",
            "Iteration: 47755 | Cost/Loss: 0.077593 | Weight: 0.529046 | Bias: 0.070324\n",
            "Iteration: 47756 | Cost/Loss: 0.077593 | Weight: 0.529047 | Bias: 0.070324\n",
            "Iteration: 47757 | Cost/Loss: 0.077593 | Weight: 0.529047 | Bias: 0.070324\n",
            "Iteration: 47758 | Cost/Loss: 0.077593 | Weight: 0.529047 | Bias: 0.070325\n",
            "Iteration: 47759 | Cost/Loss: 0.077593 | Weight: 0.529048 | Bias: 0.070325\n",
            "Iteration: 47760 | Cost/Loss: 0.077593 | Weight: 0.529048 | Bias: 0.070325\n",
            "Iteration: 47761 | Cost/Loss: 0.077593 | Weight: 0.529048 | Bias: 0.070325\n",
            "Iteration: 47762 | Cost/Loss: 0.077593 | Weight: 0.529049 | Bias: 0.070326\n",
            "Iteration: 47763 | Cost/Loss: 0.077593 | Weight: 0.529049 | Bias: 0.070326\n",
            "Iteration: 47764 | Cost/Loss: 0.077593 | Weight: 0.529049 | Bias: 0.070326\n",
            "Iteration: 47765 | Cost/Loss: 0.077593 | Weight: 0.529049 | Bias: 0.070327\n",
            "Iteration: 47766 | Cost/Loss: 0.077593 | Weight: 0.529050 | Bias: 0.070327\n",
            "Iteration: 47767 | Cost/Loss: 0.077593 | Weight: 0.529050 | Bias: 0.070327\n",
            "Iteration: 47768 | Cost/Loss: 0.077593 | Weight: 0.529050 | Bias: 0.070328\n",
            "Iteration: 47769 | Cost/Loss: 0.077593 | Weight: 0.529051 | Bias: 0.070328\n",
            "Iteration: 47770 | Cost/Loss: 0.077593 | Weight: 0.529051 | Bias: 0.070328\n",
            "Iteration: 47771 | Cost/Loss: 0.077593 | Weight: 0.529051 | Bias: 0.070329\n",
            "Iteration: 47772 | Cost/Loss: 0.077592 | Weight: 0.529052 | Bias: 0.070329\n",
            "Iteration: 47773 | Cost/Loss: 0.077592 | Weight: 0.529052 | Bias: 0.070329\n",
            "Iteration: 47774 | Cost/Loss: 0.077592 | Weight: 0.529052 | Bias: 0.070330\n",
            "Iteration: 47775 | Cost/Loss: 0.077592 | Weight: 0.529052 | Bias: 0.070330\n",
            "Iteration: 47776 | Cost/Loss: 0.077592 | Weight: 0.529053 | Bias: 0.070330\n",
            "Iteration: 47777 | Cost/Loss: 0.077592 | Weight: 0.529053 | Bias: 0.070331\n",
            "Iteration: 47778 | Cost/Loss: 0.077592 | Weight: 0.529053 | Bias: 0.070331\n",
            "Iteration: 47779 | Cost/Loss: 0.077592 | Weight: 0.529054 | Bias: 0.070331\n",
            "Iteration: 47780 | Cost/Loss: 0.077592 | Weight: 0.529054 | Bias: 0.070332\n",
            "Iteration: 47781 | Cost/Loss: 0.077592 | Weight: 0.529054 | Bias: 0.070332\n",
            "Iteration: 47782 | Cost/Loss: 0.077592 | Weight: 0.529055 | Bias: 0.070332\n",
            "Iteration: 47783 | Cost/Loss: 0.077592 | Weight: 0.529055 | Bias: 0.070333\n",
            "Iteration: 47784 | Cost/Loss: 0.077592 | Weight: 0.529055 | Bias: 0.070333\n",
            "Iteration: 47785 | Cost/Loss: 0.077592 | Weight: 0.529055 | Bias: 0.070333\n",
            "Iteration: 47786 | Cost/Loss: 0.077592 | Weight: 0.529056 | Bias: 0.070333\n",
            "Iteration: 47787 | Cost/Loss: 0.077592 | Weight: 0.529056 | Bias: 0.070334\n",
            "Iteration: 47788 | Cost/Loss: 0.077592 | Weight: 0.529056 | Bias: 0.070334\n",
            "Iteration: 47789 | Cost/Loss: 0.077592 | Weight: 0.529057 | Bias: 0.070334\n",
            "Iteration: 47790 | Cost/Loss: 0.077592 | Weight: 0.529057 | Bias: 0.070335\n",
            "Iteration: 47791 | Cost/Loss: 0.077592 | Weight: 0.529057 | Bias: 0.070335\n",
            "Iteration: 47792 | Cost/Loss: 0.077592 | Weight: 0.529058 | Bias: 0.070335\n",
            "Iteration: 47793 | Cost/Loss: 0.077592 | Weight: 0.529058 | Bias: 0.070336\n",
            "Iteration: 47794 | Cost/Loss: 0.077592 | Weight: 0.529058 | Bias: 0.070336\n",
            "Iteration: 47795 | Cost/Loss: 0.077592 | Weight: 0.529058 | Bias: 0.070336\n",
            "Iteration: 47796 | Cost/Loss: 0.077592 | Weight: 0.529059 | Bias: 0.070337\n",
            "Iteration: 47797 | Cost/Loss: 0.077592 | Weight: 0.529059 | Bias: 0.070337\n",
            "Iteration: 47798 | Cost/Loss: 0.077592 | Weight: 0.529059 | Bias: 0.070337\n",
            "Iteration: 47799 | Cost/Loss: 0.077592 | Weight: 0.529060 | Bias: 0.070338\n",
            "Iteration: 47800 | Cost/Loss: 0.077592 | Weight: 0.529060 | Bias: 0.070338\n",
            "Iteration: 47801 | Cost/Loss: 0.077592 | Weight: 0.529060 | Bias: 0.070338\n",
            "Iteration: 47802 | Cost/Loss: 0.077592 | Weight: 0.529060 | Bias: 0.070339\n",
            "Iteration: 47803 | Cost/Loss: 0.077592 | Weight: 0.529061 | Bias: 0.070339\n",
            "Iteration: 47804 | Cost/Loss: 0.077592 | Weight: 0.529061 | Bias: 0.070339\n",
            "Iteration: 47805 | Cost/Loss: 0.077592 | Weight: 0.529061 | Bias: 0.070340\n",
            "Iteration: 47806 | Cost/Loss: 0.077592 | Weight: 0.529062 | Bias: 0.070340\n",
            "Iteration: 47807 | Cost/Loss: 0.077592 | Weight: 0.529062 | Bias: 0.070340\n",
            "Iteration: 47808 | Cost/Loss: 0.077592 | Weight: 0.529062 | Bias: 0.070341\n",
            "Iteration: 47809 | Cost/Loss: 0.077592 | Weight: 0.529063 | Bias: 0.070341\n",
            "Iteration: 47810 | Cost/Loss: 0.077592 | Weight: 0.529063 | Bias: 0.070341\n",
            "Iteration: 47811 | Cost/Loss: 0.077592 | Weight: 0.529063 | Bias: 0.070341\n",
            "Iteration: 47812 | Cost/Loss: 0.077591 | Weight: 0.529063 | Bias: 0.070342\n",
            "Iteration: 47813 | Cost/Loss: 0.077591 | Weight: 0.529064 | Bias: 0.070342\n",
            "Iteration: 47814 | Cost/Loss: 0.077591 | Weight: 0.529064 | Bias: 0.070342\n",
            "Iteration: 47815 | Cost/Loss: 0.077591 | Weight: 0.529064 | Bias: 0.070343\n",
            "Iteration: 47816 | Cost/Loss: 0.077591 | Weight: 0.529065 | Bias: 0.070343\n",
            "Iteration: 47817 | Cost/Loss: 0.077591 | Weight: 0.529065 | Bias: 0.070343\n",
            "Iteration: 47818 | Cost/Loss: 0.077591 | Weight: 0.529065 | Bias: 0.070344\n",
            "Iteration: 47819 | Cost/Loss: 0.077591 | Weight: 0.529066 | Bias: 0.070344\n",
            "Iteration: 47820 | Cost/Loss: 0.077591 | Weight: 0.529066 | Bias: 0.070344\n",
            "Iteration: 47821 | Cost/Loss: 0.077591 | Weight: 0.529066 | Bias: 0.070345\n",
            "Iteration: 47822 | Cost/Loss: 0.077591 | Weight: 0.529066 | Bias: 0.070345\n",
            "Iteration: 47823 | Cost/Loss: 0.077591 | Weight: 0.529067 | Bias: 0.070345\n",
            "Iteration: 47824 | Cost/Loss: 0.077591 | Weight: 0.529067 | Bias: 0.070346\n",
            "Iteration: 47825 | Cost/Loss: 0.077591 | Weight: 0.529067 | Bias: 0.070346\n",
            "Iteration: 47826 | Cost/Loss: 0.077591 | Weight: 0.529068 | Bias: 0.070346\n",
            "Iteration: 47827 | Cost/Loss: 0.077591 | Weight: 0.529068 | Bias: 0.070347\n",
            "Iteration: 47828 | Cost/Loss: 0.077591 | Weight: 0.529068 | Bias: 0.070347\n",
            "Iteration: 47829 | Cost/Loss: 0.077591 | Weight: 0.529069 | Bias: 0.070347\n",
            "Iteration: 47830 | Cost/Loss: 0.077591 | Weight: 0.529069 | Bias: 0.070348\n",
            "Iteration: 47831 | Cost/Loss: 0.077591 | Weight: 0.529069 | Bias: 0.070348\n",
            "Iteration: 47832 | Cost/Loss: 0.077591 | Weight: 0.529069 | Bias: 0.070348\n",
            "Iteration: 47833 | Cost/Loss: 0.077591 | Weight: 0.529070 | Bias: 0.070349\n",
            "Iteration: 47834 | Cost/Loss: 0.077591 | Weight: 0.529070 | Bias: 0.070349\n",
            "Iteration: 47835 | Cost/Loss: 0.077591 | Weight: 0.529070 | Bias: 0.070349\n",
            "Iteration: 47836 | Cost/Loss: 0.077591 | Weight: 0.529071 | Bias: 0.070350\n",
            "Iteration: 47837 | Cost/Loss: 0.077591 | Weight: 0.529071 | Bias: 0.070350\n",
            "Iteration: 47838 | Cost/Loss: 0.077591 | Weight: 0.529071 | Bias: 0.070350\n",
            "Iteration: 47839 | Cost/Loss: 0.077591 | Weight: 0.529072 | Bias: 0.070350\n",
            "Iteration: 47840 | Cost/Loss: 0.077591 | Weight: 0.529072 | Bias: 0.070351\n",
            "Iteration: 47841 | Cost/Loss: 0.077591 | Weight: 0.529072 | Bias: 0.070351\n",
            "Iteration: 47842 | Cost/Loss: 0.077591 | Weight: 0.529072 | Bias: 0.070351\n",
            "Iteration: 47843 | Cost/Loss: 0.077591 | Weight: 0.529073 | Bias: 0.070352\n",
            "Iteration: 47844 | Cost/Loss: 0.077591 | Weight: 0.529073 | Bias: 0.070352\n",
            "Iteration: 47845 | Cost/Loss: 0.077591 | Weight: 0.529073 | Bias: 0.070352\n",
            "Iteration: 47846 | Cost/Loss: 0.077591 | Weight: 0.529074 | Bias: 0.070353\n",
            "Iteration: 47847 | Cost/Loss: 0.077591 | Weight: 0.529074 | Bias: 0.070353\n",
            "Iteration: 47848 | Cost/Loss: 0.077591 | Weight: 0.529074 | Bias: 0.070353\n",
            "Iteration: 47849 | Cost/Loss: 0.077591 | Weight: 0.529074 | Bias: 0.070354\n",
            "Iteration: 47850 | Cost/Loss: 0.077591 | Weight: 0.529075 | Bias: 0.070354\n",
            "Iteration: 47851 | Cost/Loss: 0.077590 | Weight: 0.529075 | Bias: 0.070354\n",
            "Iteration: 47852 | Cost/Loss: 0.077590 | Weight: 0.529075 | Bias: 0.070355\n",
            "Iteration: 47853 | Cost/Loss: 0.077590 | Weight: 0.529076 | Bias: 0.070355\n",
            "Iteration: 47854 | Cost/Loss: 0.077590 | Weight: 0.529076 | Bias: 0.070355\n",
            "Iteration: 47855 | Cost/Loss: 0.077590 | Weight: 0.529076 | Bias: 0.070356\n",
            "Iteration: 47856 | Cost/Loss: 0.077590 | Weight: 0.529077 | Bias: 0.070356\n",
            "Iteration: 47857 | Cost/Loss: 0.077590 | Weight: 0.529077 | Bias: 0.070356\n",
            "Iteration: 47858 | Cost/Loss: 0.077590 | Weight: 0.529077 | Bias: 0.070357\n",
            "Iteration: 47859 | Cost/Loss: 0.077590 | Weight: 0.529077 | Bias: 0.070357\n",
            "Iteration: 47860 | Cost/Loss: 0.077590 | Weight: 0.529078 | Bias: 0.070357\n",
            "Iteration: 47861 | Cost/Loss: 0.077590 | Weight: 0.529078 | Bias: 0.070358\n",
            "Iteration: 47862 | Cost/Loss: 0.077590 | Weight: 0.529078 | Bias: 0.070358\n",
            "Iteration: 47863 | Cost/Loss: 0.077590 | Weight: 0.529079 | Bias: 0.070358\n",
            "Iteration: 47864 | Cost/Loss: 0.077590 | Weight: 0.529079 | Bias: 0.070358\n",
            "Iteration: 47865 | Cost/Loss: 0.077590 | Weight: 0.529079 | Bias: 0.070359\n",
            "Iteration: 47866 | Cost/Loss: 0.077590 | Weight: 0.529080 | Bias: 0.070359\n",
            "Iteration: 47867 | Cost/Loss: 0.077590 | Weight: 0.529080 | Bias: 0.070359\n",
            "Iteration: 47868 | Cost/Loss: 0.077590 | Weight: 0.529080 | Bias: 0.070360\n",
            "Iteration: 47869 | Cost/Loss: 0.077590 | Weight: 0.529080 | Bias: 0.070360\n",
            "Iteration: 47870 | Cost/Loss: 0.077590 | Weight: 0.529081 | Bias: 0.070360\n",
            "Iteration: 47871 | Cost/Loss: 0.077590 | Weight: 0.529081 | Bias: 0.070361\n",
            "Iteration: 47872 | Cost/Loss: 0.077590 | Weight: 0.529081 | Bias: 0.070361\n",
            "Iteration: 47873 | Cost/Loss: 0.077590 | Weight: 0.529082 | Bias: 0.070361\n",
            "Iteration: 47874 | Cost/Loss: 0.077590 | Weight: 0.529082 | Bias: 0.070362\n",
            "Iteration: 47875 | Cost/Loss: 0.077590 | Weight: 0.529082 | Bias: 0.070362\n",
            "Iteration: 47876 | Cost/Loss: 0.077590 | Weight: 0.529083 | Bias: 0.070362\n",
            "Iteration: 47877 | Cost/Loss: 0.077590 | Weight: 0.529083 | Bias: 0.070363\n",
            "Iteration: 47878 | Cost/Loss: 0.077590 | Weight: 0.529083 | Bias: 0.070363\n",
            "Iteration: 47879 | Cost/Loss: 0.077590 | Weight: 0.529083 | Bias: 0.070363\n",
            "Iteration: 47880 | Cost/Loss: 0.077590 | Weight: 0.529084 | Bias: 0.070364\n",
            "Iteration: 47881 | Cost/Loss: 0.077590 | Weight: 0.529084 | Bias: 0.070364\n",
            "Iteration: 47882 | Cost/Loss: 0.077590 | Weight: 0.529084 | Bias: 0.070364\n",
            "Iteration: 47883 | Cost/Loss: 0.077590 | Weight: 0.529085 | Bias: 0.070365\n",
            "Iteration: 47884 | Cost/Loss: 0.077590 | Weight: 0.529085 | Bias: 0.070365\n",
            "Iteration: 47885 | Cost/Loss: 0.077590 | Weight: 0.529085 | Bias: 0.070365\n",
            "Iteration: 47886 | Cost/Loss: 0.077590 | Weight: 0.529086 | Bias: 0.070366\n",
            "Iteration: 47887 | Cost/Loss: 0.077590 | Weight: 0.529086 | Bias: 0.070366\n",
            "Iteration: 47888 | Cost/Loss: 0.077590 | Weight: 0.529086 | Bias: 0.070366\n",
            "Iteration: 47889 | Cost/Loss: 0.077590 | Weight: 0.529086 | Bias: 0.070366\n",
            "Iteration: 47890 | Cost/Loss: 0.077590 | Weight: 0.529087 | Bias: 0.070367\n",
            "Iteration: 47891 | Cost/Loss: 0.077589 | Weight: 0.529087 | Bias: 0.070367\n",
            "Iteration: 47892 | Cost/Loss: 0.077589 | Weight: 0.529087 | Bias: 0.070367\n",
            "Iteration: 47893 | Cost/Loss: 0.077589 | Weight: 0.529088 | Bias: 0.070368\n",
            "Iteration: 47894 | Cost/Loss: 0.077589 | Weight: 0.529088 | Bias: 0.070368\n",
            "Iteration: 47895 | Cost/Loss: 0.077589 | Weight: 0.529088 | Bias: 0.070368\n",
            "Iteration: 47896 | Cost/Loss: 0.077589 | Weight: 0.529088 | Bias: 0.070369\n",
            "Iteration: 47897 | Cost/Loss: 0.077589 | Weight: 0.529089 | Bias: 0.070369\n",
            "Iteration: 47898 | Cost/Loss: 0.077589 | Weight: 0.529089 | Bias: 0.070369\n",
            "Iteration: 47899 | Cost/Loss: 0.077589 | Weight: 0.529089 | Bias: 0.070370\n",
            "Iteration: 47900 | Cost/Loss: 0.077589 | Weight: 0.529090 | Bias: 0.070370\n",
            "Iteration: 47901 | Cost/Loss: 0.077589 | Weight: 0.529090 | Bias: 0.070370\n",
            "Iteration: 47902 | Cost/Loss: 0.077589 | Weight: 0.529090 | Bias: 0.070371\n",
            "Iteration: 47903 | Cost/Loss: 0.077589 | Weight: 0.529091 | Bias: 0.070371\n",
            "Iteration: 47904 | Cost/Loss: 0.077589 | Weight: 0.529091 | Bias: 0.070371\n",
            "Iteration: 47905 | Cost/Loss: 0.077589 | Weight: 0.529091 | Bias: 0.070372\n",
            "Iteration: 47906 | Cost/Loss: 0.077589 | Weight: 0.529091 | Bias: 0.070372\n",
            "Iteration: 47907 | Cost/Loss: 0.077589 | Weight: 0.529092 | Bias: 0.070372\n",
            "Iteration: 47908 | Cost/Loss: 0.077589 | Weight: 0.529092 | Bias: 0.070373\n",
            "Iteration: 47909 | Cost/Loss: 0.077589 | Weight: 0.529092 | Bias: 0.070373\n",
            "Iteration: 47910 | Cost/Loss: 0.077589 | Weight: 0.529093 | Bias: 0.070373\n",
            "Iteration: 47911 | Cost/Loss: 0.077589 | Weight: 0.529093 | Bias: 0.070374\n",
            "Iteration: 47912 | Cost/Loss: 0.077589 | Weight: 0.529093 | Bias: 0.070374\n",
            "Iteration: 47913 | Cost/Loss: 0.077589 | Weight: 0.529094 | Bias: 0.070374\n",
            "Iteration: 47914 | Cost/Loss: 0.077589 | Weight: 0.529094 | Bias: 0.070374\n",
            "Iteration: 47915 | Cost/Loss: 0.077589 | Weight: 0.529094 | Bias: 0.070375\n",
            "Iteration: 47916 | Cost/Loss: 0.077589 | Weight: 0.529094 | Bias: 0.070375\n",
            "Iteration: 47917 | Cost/Loss: 0.077589 | Weight: 0.529095 | Bias: 0.070375\n",
            "Iteration: 47918 | Cost/Loss: 0.077589 | Weight: 0.529095 | Bias: 0.070376\n",
            "Iteration: 47919 | Cost/Loss: 0.077589 | Weight: 0.529095 | Bias: 0.070376\n",
            "Iteration: 47920 | Cost/Loss: 0.077589 | Weight: 0.529096 | Bias: 0.070376\n",
            "Iteration: 47921 | Cost/Loss: 0.077589 | Weight: 0.529096 | Bias: 0.070377\n",
            "Iteration: 47922 | Cost/Loss: 0.077589 | Weight: 0.529096 | Bias: 0.070377\n",
            "Iteration: 47923 | Cost/Loss: 0.077589 | Weight: 0.529097 | Bias: 0.070377\n",
            "Iteration: 47924 | Cost/Loss: 0.077589 | Weight: 0.529097 | Bias: 0.070378\n",
            "Iteration: 47925 | Cost/Loss: 0.077589 | Weight: 0.529097 | Bias: 0.070378\n",
            "Iteration: 47926 | Cost/Loss: 0.077589 | Weight: 0.529097 | Bias: 0.070378\n",
            "Iteration: 47927 | Cost/Loss: 0.077589 | Weight: 0.529098 | Bias: 0.070379\n",
            "Iteration: 47928 | Cost/Loss: 0.077589 | Weight: 0.529098 | Bias: 0.070379\n",
            "Iteration: 47929 | Cost/Loss: 0.077589 | Weight: 0.529098 | Bias: 0.070379\n",
            "Iteration: 47930 | Cost/Loss: 0.077588 | Weight: 0.529099 | Bias: 0.070380\n",
            "Iteration: 47931 | Cost/Loss: 0.077588 | Weight: 0.529099 | Bias: 0.070380\n",
            "Iteration: 47932 | Cost/Loss: 0.077588 | Weight: 0.529099 | Bias: 0.070380\n",
            "Iteration: 47933 | Cost/Loss: 0.077588 | Weight: 0.529100 | Bias: 0.070381\n",
            "Iteration: 47934 | Cost/Loss: 0.077588 | Weight: 0.529100 | Bias: 0.070381\n",
            "Iteration: 47935 | Cost/Loss: 0.077588 | Weight: 0.529100 | Bias: 0.070381\n",
            "Iteration: 47936 | Cost/Loss: 0.077588 | Weight: 0.529100 | Bias: 0.070382\n",
            "Iteration: 47937 | Cost/Loss: 0.077588 | Weight: 0.529101 | Bias: 0.070382\n",
            "Iteration: 47938 | Cost/Loss: 0.077588 | Weight: 0.529101 | Bias: 0.070382\n",
            "Iteration: 47939 | Cost/Loss: 0.077588 | Weight: 0.529101 | Bias: 0.070383\n",
            "Iteration: 47940 | Cost/Loss: 0.077588 | Weight: 0.529102 | Bias: 0.070383\n",
            "Iteration: 47941 | Cost/Loss: 0.077588 | Weight: 0.529102 | Bias: 0.070383\n",
            "Iteration: 47942 | Cost/Loss: 0.077588 | Weight: 0.529102 | Bias: 0.070383\n",
            "Iteration: 47943 | Cost/Loss: 0.077588 | Weight: 0.529103 | Bias: 0.070384\n",
            "Iteration: 47944 | Cost/Loss: 0.077588 | Weight: 0.529103 | Bias: 0.070384\n",
            "Iteration: 47945 | Cost/Loss: 0.077588 | Weight: 0.529103 | Bias: 0.070384\n",
            "Iteration: 47946 | Cost/Loss: 0.077588 | Weight: 0.529103 | Bias: 0.070385\n",
            "Iteration: 47947 | Cost/Loss: 0.077588 | Weight: 0.529104 | Bias: 0.070385\n",
            "Iteration: 47948 | Cost/Loss: 0.077588 | Weight: 0.529104 | Bias: 0.070385\n",
            "Iteration: 47949 | Cost/Loss: 0.077588 | Weight: 0.529104 | Bias: 0.070386\n",
            "Iteration: 47950 | Cost/Loss: 0.077588 | Weight: 0.529105 | Bias: 0.070386\n",
            "Iteration: 47951 | Cost/Loss: 0.077588 | Weight: 0.529105 | Bias: 0.070386\n",
            "Iteration: 47952 | Cost/Loss: 0.077588 | Weight: 0.529105 | Bias: 0.070387\n",
            "Iteration: 47953 | Cost/Loss: 0.077588 | Weight: 0.529105 | Bias: 0.070387\n",
            "Iteration: 47954 | Cost/Loss: 0.077588 | Weight: 0.529106 | Bias: 0.070387\n",
            "Iteration: 47955 | Cost/Loss: 0.077588 | Weight: 0.529106 | Bias: 0.070388\n",
            "Iteration: 47956 | Cost/Loss: 0.077588 | Weight: 0.529106 | Bias: 0.070388\n",
            "Iteration: 47957 | Cost/Loss: 0.077588 | Weight: 0.529107 | Bias: 0.070388\n",
            "Iteration: 47958 | Cost/Loss: 0.077588 | Weight: 0.529107 | Bias: 0.070389\n",
            "Iteration: 47959 | Cost/Loss: 0.077588 | Weight: 0.529107 | Bias: 0.070389\n",
            "Iteration: 47960 | Cost/Loss: 0.077588 | Weight: 0.529108 | Bias: 0.070389\n",
            "Iteration: 47961 | Cost/Loss: 0.077588 | Weight: 0.529108 | Bias: 0.070390\n",
            "Iteration: 47962 | Cost/Loss: 0.077588 | Weight: 0.529108 | Bias: 0.070390\n",
            "Iteration: 47963 | Cost/Loss: 0.077588 | Weight: 0.529108 | Bias: 0.070390\n",
            "Iteration: 47964 | Cost/Loss: 0.077588 | Weight: 0.529109 | Bias: 0.070391\n",
            "Iteration: 47965 | Cost/Loss: 0.077588 | Weight: 0.529109 | Bias: 0.070391\n",
            "Iteration: 47966 | Cost/Loss: 0.077588 | Weight: 0.529109 | Bias: 0.070391\n",
            "Iteration: 47967 | Cost/Loss: 0.077588 | Weight: 0.529110 | Bias: 0.070391\n",
            "Iteration: 47968 | Cost/Loss: 0.077588 | Weight: 0.529110 | Bias: 0.070392\n",
            "Iteration: 47969 | Cost/Loss: 0.077588 | Weight: 0.529110 | Bias: 0.070392\n",
            "Iteration: 47970 | Cost/Loss: 0.077587 | Weight: 0.529111 | Bias: 0.070392\n",
            "Iteration: 47971 | Cost/Loss: 0.077587 | Weight: 0.529111 | Bias: 0.070393\n",
            "Iteration: 47972 | Cost/Loss: 0.077587 | Weight: 0.529111 | Bias: 0.070393\n",
            "Iteration: 47973 | Cost/Loss: 0.077587 | Weight: 0.529111 | Bias: 0.070393\n",
            "Iteration: 47974 | Cost/Loss: 0.077587 | Weight: 0.529112 | Bias: 0.070394\n",
            "Iteration: 47975 | Cost/Loss: 0.077587 | Weight: 0.529112 | Bias: 0.070394\n",
            "Iteration: 47976 | Cost/Loss: 0.077587 | Weight: 0.529112 | Bias: 0.070394\n",
            "Iteration: 47977 | Cost/Loss: 0.077587 | Weight: 0.529113 | Bias: 0.070395\n",
            "Iteration: 47978 | Cost/Loss: 0.077587 | Weight: 0.529113 | Bias: 0.070395\n",
            "Iteration: 47979 | Cost/Loss: 0.077587 | Weight: 0.529113 | Bias: 0.070395\n",
            "Iteration: 47980 | Cost/Loss: 0.077587 | Weight: 0.529114 | Bias: 0.070396\n",
            "Iteration: 47981 | Cost/Loss: 0.077587 | Weight: 0.529114 | Bias: 0.070396\n",
            "Iteration: 47982 | Cost/Loss: 0.077587 | Weight: 0.529114 | Bias: 0.070396\n",
            "Iteration: 47983 | Cost/Loss: 0.077587 | Weight: 0.529114 | Bias: 0.070397\n",
            "Iteration: 47984 | Cost/Loss: 0.077587 | Weight: 0.529115 | Bias: 0.070397\n",
            "Iteration: 47985 | Cost/Loss: 0.077587 | Weight: 0.529115 | Bias: 0.070397\n",
            "Iteration: 47986 | Cost/Loss: 0.077587 | Weight: 0.529115 | Bias: 0.070398\n",
            "Iteration: 47987 | Cost/Loss: 0.077587 | Weight: 0.529116 | Bias: 0.070398\n",
            "Iteration: 47988 | Cost/Loss: 0.077587 | Weight: 0.529116 | Bias: 0.070398\n",
            "Iteration: 47989 | Cost/Loss: 0.077587 | Weight: 0.529116 | Bias: 0.070399\n",
            "Iteration: 47990 | Cost/Loss: 0.077587 | Weight: 0.529117 | Bias: 0.070399\n",
            "Iteration: 47991 | Cost/Loss: 0.077587 | Weight: 0.529117 | Bias: 0.070399\n",
            "Iteration: 47992 | Cost/Loss: 0.077587 | Weight: 0.529117 | Bias: 0.070399\n",
            "Iteration: 47993 | Cost/Loss: 0.077587 | Weight: 0.529117 | Bias: 0.070400\n",
            "Iteration: 47994 | Cost/Loss: 0.077587 | Weight: 0.529118 | Bias: 0.070400\n",
            "Iteration: 47995 | Cost/Loss: 0.077587 | Weight: 0.529118 | Bias: 0.070400\n",
            "Iteration: 47996 | Cost/Loss: 0.077587 | Weight: 0.529118 | Bias: 0.070401\n",
            "Iteration: 47997 | Cost/Loss: 0.077587 | Weight: 0.529119 | Bias: 0.070401\n",
            "Iteration: 47998 | Cost/Loss: 0.077587 | Weight: 0.529119 | Bias: 0.070401\n",
            "Iteration: 47999 | Cost/Loss: 0.077587 | Weight: 0.529119 | Bias: 0.070402\n",
            "Iteration: 48000 | Cost/Loss: 0.077587 | Weight: 0.529119 | Bias: 0.070402\n",
            "Iteration: 48001 | Cost/Loss: 0.077587 | Weight: 0.529120 | Bias: 0.070402\n",
            "Iteration: 48002 | Cost/Loss: 0.077587 | Weight: 0.529120 | Bias: 0.070403\n",
            "Iteration: 48003 | Cost/Loss: 0.077587 | Weight: 0.529120 | Bias: 0.070403\n",
            "Iteration: 48004 | Cost/Loss: 0.077587 | Weight: 0.529121 | Bias: 0.070403\n",
            "Iteration: 48005 | Cost/Loss: 0.077587 | Weight: 0.529121 | Bias: 0.070404\n",
            "Iteration: 48006 | Cost/Loss: 0.077587 | Weight: 0.529121 | Bias: 0.070404\n",
            "Iteration: 48007 | Cost/Loss: 0.077587 | Weight: 0.529122 | Bias: 0.070404\n",
            "Iteration: 48008 | Cost/Loss: 0.077587 | Weight: 0.529122 | Bias: 0.070405\n",
            "Iteration: 48009 | Cost/Loss: 0.077587 | Weight: 0.529122 | Bias: 0.070405\n",
            "Iteration: 48010 | Cost/Loss: 0.077586 | Weight: 0.529122 | Bias: 0.070405\n",
            "Iteration: 48011 | Cost/Loss: 0.077586 | Weight: 0.529123 | Bias: 0.070406\n",
            "Iteration: 48012 | Cost/Loss: 0.077586 | Weight: 0.529123 | Bias: 0.070406\n",
            "Iteration: 48013 | Cost/Loss: 0.077586 | Weight: 0.529123 | Bias: 0.070406\n",
            "Iteration: 48014 | Cost/Loss: 0.077586 | Weight: 0.529124 | Bias: 0.070407\n",
            "Iteration: 48015 | Cost/Loss: 0.077586 | Weight: 0.529124 | Bias: 0.070407\n",
            "Iteration: 48016 | Cost/Loss: 0.077586 | Weight: 0.529124 | Bias: 0.070407\n",
            "Iteration: 48017 | Cost/Loss: 0.077586 | Weight: 0.529125 | Bias: 0.070407\n",
            "Iteration: 48018 | Cost/Loss: 0.077586 | Weight: 0.529125 | Bias: 0.070408\n",
            "Iteration: 48019 | Cost/Loss: 0.077586 | Weight: 0.529125 | Bias: 0.070408\n",
            "Iteration: 48020 | Cost/Loss: 0.077586 | Weight: 0.529125 | Bias: 0.070408\n",
            "Iteration: 48021 | Cost/Loss: 0.077586 | Weight: 0.529126 | Bias: 0.070409\n",
            "Iteration: 48022 | Cost/Loss: 0.077586 | Weight: 0.529126 | Bias: 0.070409\n",
            "Iteration: 48023 | Cost/Loss: 0.077586 | Weight: 0.529126 | Bias: 0.070409\n",
            "Iteration: 48024 | Cost/Loss: 0.077586 | Weight: 0.529127 | Bias: 0.070410\n",
            "Iteration: 48025 | Cost/Loss: 0.077586 | Weight: 0.529127 | Bias: 0.070410\n",
            "Iteration: 48026 | Cost/Loss: 0.077586 | Weight: 0.529127 | Bias: 0.070410\n",
            "Iteration: 48027 | Cost/Loss: 0.077586 | Weight: 0.529128 | Bias: 0.070411\n",
            "Iteration: 48028 | Cost/Loss: 0.077586 | Weight: 0.529128 | Bias: 0.070411\n",
            "Iteration: 48029 | Cost/Loss: 0.077586 | Weight: 0.529128 | Bias: 0.070411\n",
            "Iteration: 48030 | Cost/Loss: 0.077586 | Weight: 0.529128 | Bias: 0.070412\n",
            "Iteration: 48031 | Cost/Loss: 0.077586 | Weight: 0.529129 | Bias: 0.070412\n",
            "Iteration: 48032 | Cost/Loss: 0.077586 | Weight: 0.529129 | Bias: 0.070412\n",
            "Iteration: 48033 | Cost/Loss: 0.077586 | Weight: 0.529129 | Bias: 0.070413\n",
            "Iteration: 48034 | Cost/Loss: 0.077586 | Weight: 0.529130 | Bias: 0.070413\n",
            "Iteration: 48035 | Cost/Loss: 0.077586 | Weight: 0.529130 | Bias: 0.070413\n",
            "Iteration: 48036 | Cost/Loss: 0.077586 | Weight: 0.529130 | Bias: 0.070414\n",
            "Iteration: 48037 | Cost/Loss: 0.077586 | Weight: 0.529131 | Bias: 0.070414\n",
            "Iteration: 48038 | Cost/Loss: 0.077586 | Weight: 0.529131 | Bias: 0.070414\n",
            "Iteration: 48039 | Cost/Loss: 0.077586 | Weight: 0.529131 | Bias: 0.070415\n",
            "Iteration: 48040 | Cost/Loss: 0.077586 | Weight: 0.529131 | Bias: 0.070415\n",
            "Iteration: 48041 | Cost/Loss: 0.077586 | Weight: 0.529132 | Bias: 0.070415\n",
            "Iteration: 48042 | Cost/Loss: 0.077586 | Weight: 0.529132 | Bias: 0.070416\n",
            "Iteration: 48043 | Cost/Loss: 0.077586 | Weight: 0.529132 | Bias: 0.070416\n",
            "Iteration: 48044 | Cost/Loss: 0.077586 | Weight: 0.529133 | Bias: 0.070416\n",
            "Iteration: 48045 | Cost/Loss: 0.077586 | Weight: 0.529133 | Bias: 0.070416\n",
            "Iteration: 48046 | Cost/Loss: 0.077586 | Weight: 0.529133 | Bias: 0.070417\n",
            "Iteration: 48047 | Cost/Loss: 0.077586 | Weight: 0.529133 | Bias: 0.070417\n",
            "Iteration: 48048 | Cost/Loss: 0.077586 | Weight: 0.529134 | Bias: 0.070417\n",
            "Iteration: 48049 | Cost/Loss: 0.077585 | Weight: 0.529134 | Bias: 0.070418\n",
            "Iteration: 48050 | Cost/Loss: 0.077585 | Weight: 0.529134 | Bias: 0.070418\n",
            "Iteration: 48051 | Cost/Loss: 0.077585 | Weight: 0.529135 | Bias: 0.070418\n",
            "Iteration: 48052 | Cost/Loss: 0.077585 | Weight: 0.529135 | Bias: 0.070419\n",
            "Iteration: 48053 | Cost/Loss: 0.077585 | Weight: 0.529135 | Bias: 0.070419\n",
            "Iteration: 48054 | Cost/Loss: 0.077585 | Weight: 0.529136 | Bias: 0.070419\n",
            "Iteration: 48055 | Cost/Loss: 0.077585 | Weight: 0.529136 | Bias: 0.070420\n",
            "Iteration: 48056 | Cost/Loss: 0.077585 | Weight: 0.529136 | Bias: 0.070420\n",
            "Iteration: 48057 | Cost/Loss: 0.077585 | Weight: 0.529136 | Bias: 0.070420\n",
            "Iteration: 48058 | Cost/Loss: 0.077585 | Weight: 0.529137 | Bias: 0.070421\n",
            "Iteration: 48059 | Cost/Loss: 0.077585 | Weight: 0.529137 | Bias: 0.070421\n",
            "Iteration: 48060 | Cost/Loss: 0.077585 | Weight: 0.529137 | Bias: 0.070421\n",
            "Iteration: 48061 | Cost/Loss: 0.077585 | Weight: 0.529138 | Bias: 0.070422\n",
            "Iteration: 48062 | Cost/Loss: 0.077585 | Weight: 0.529138 | Bias: 0.070422\n",
            "Iteration: 48063 | Cost/Loss: 0.077585 | Weight: 0.529138 | Bias: 0.070422\n",
            "Iteration: 48064 | Cost/Loss: 0.077585 | Weight: 0.529139 | Bias: 0.070423\n",
            "Iteration: 48065 | Cost/Loss: 0.077585 | Weight: 0.529139 | Bias: 0.070423\n",
            "Iteration: 48066 | Cost/Loss: 0.077585 | Weight: 0.529139 | Bias: 0.070423\n",
            "Iteration: 48067 | Cost/Loss: 0.077585 | Weight: 0.529139 | Bias: 0.070424\n",
            "Iteration: 48068 | Cost/Loss: 0.077585 | Weight: 0.529140 | Bias: 0.070424\n",
            "Iteration: 48069 | Cost/Loss: 0.077585 | Weight: 0.529140 | Bias: 0.070424\n",
            "Iteration: 48070 | Cost/Loss: 0.077585 | Weight: 0.529140 | Bias: 0.070424\n",
            "Iteration: 48071 | Cost/Loss: 0.077585 | Weight: 0.529141 | Bias: 0.070425\n",
            "Iteration: 48072 | Cost/Loss: 0.077585 | Weight: 0.529141 | Bias: 0.070425\n",
            "Iteration: 48073 | Cost/Loss: 0.077585 | Weight: 0.529141 | Bias: 0.070425\n",
            "Iteration: 48074 | Cost/Loss: 0.077585 | Weight: 0.529142 | Bias: 0.070426\n",
            "Iteration: 48075 | Cost/Loss: 0.077585 | Weight: 0.529142 | Bias: 0.070426\n",
            "Iteration: 48076 | Cost/Loss: 0.077585 | Weight: 0.529142 | Bias: 0.070426\n",
            "Iteration: 48077 | Cost/Loss: 0.077585 | Weight: 0.529142 | Bias: 0.070427\n",
            "Iteration: 48078 | Cost/Loss: 0.077585 | Weight: 0.529143 | Bias: 0.070427\n",
            "Iteration: 48079 | Cost/Loss: 0.077585 | Weight: 0.529143 | Bias: 0.070427\n",
            "Iteration: 48080 | Cost/Loss: 0.077585 | Weight: 0.529143 | Bias: 0.070428\n",
            "Iteration: 48081 | Cost/Loss: 0.077585 | Weight: 0.529144 | Bias: 0.070428\n",
            "Iteration: 48082 | Cost/Loss: 0.077585 | Weight: 0.529144 | Bias: 0.070428\n",
            "Iteration: 48083 | Cost/Loss: 0.077585 | Weight: 0.529144 | Bias: 0.070429\n",
            "Iteration: 48084 | Cost/Loss: 0.077585 | Weight: 0.529145 | Bias: 0.070429\n",
            "Iteration: 48085 | Cost/Loss: 0.077585 | Weight: 0.529145 | Bias: 0.070429\n",
            "Iteration: 48086 | Cost/Loss: 0.077585 | Weight: 0.529145 | Bias: 0.070430\n",
            "Iteration: 48087 | Cost/Loss: 0.077585 | Weight: 0.529145 | Bias: 0.070430\n",
            "Iteration: 48088 | Cost/Loss: 0.077585 | Weight: 0.529146 | Bias: 0.070430\n",
            "Iteration: 48089 | Cost/Loss: 0.077584 | Weight: 0.529146 | Bias: 0.070431\n",
            "Iteration: 48090 | Cost/Loss: 0.077584 | Weight: 0.529146 | Bias: 0.070431\n",
            "Iteration: 48091 | Cost/Loss: 0.077584 | Weight: 0.529147 | Bias: 0.070431\n",
            "Iteration: 48092 | Cost/Loss: 0.077584 | Weight: 0.529147 | Bias: 0.070432\n",
            "Iteration: 48093 | Cost/Loss: 0.077584 | Weight: 0.529147 | Bias: 0.070432\n",
            "Iteration: 48094 | Cost/Loss: 0.077584 | Weight: 0.529148 | Bias: 0.070432\n",
            "Iteration: 48095 | Cost/Loss: 0.077584 | Weight: 0.529148 | Bias: 0.070432\n",
            "Iteration: 48096 | Cost/Loss: 0.077584 | Weight: 0.529148 | Bias: 0.070433\n",
            "Iteration: 48097 | Cost/Loss: 0.077584 | Weight: 0.529148 | Bias: 0.070433\n",
            "Iteration: 48098 | Cost/Loss: 0.077584 | Weight: 0.529149 | Bias: 0.070433\n",
            "Iteration: 48099 | Cost/Loss: 0.077584 | Weight: 0.529149 | Bias: 0.070434\n",
            "Iteration: 48100 | Cost/Loss: 0.077584 | Weight: 0.529149 | Bias: 0.070434\n",
            "Iteration: 48101 | Cost/Loss: 0.077584 | Weight: 0.529150 | Bias: 0.070434\n",
            "Iteration: 48102 | Cost/Loss: 0.077584 | Weight: 0.529150 | Bias: 0.070435\n",
            "Iteration: 48103 | Cost/Loss: 0.077584 | Weight: 0.529150 | Bias: 0.070435\n",
            "Iteration: 48104 | Cost/Loss: 0.077584 | Weight: 0.529150 | Bias: 0.070435\n",
            "Iteration: 48105 | Cost/Loss: 0.077584 | Weight: 0.529151 | Bias: 0.070436\n",
            "Iteration: 48106 | Cost/Loss: 0.077584 | Weight: 0.529151 | Bias: 0.070436\n",
            "Iteration: 48107 | Cost/Loss: 0.077584 | Weight: 0.529151 | Bias: 0.070436\n",
            "Iteration: 48108 | Cost/Loss: 0.077584 | Weight: 0.529152 | Bias: 0.070437\n",
            "Iteration: 48109 | Cost/Loss: 0.077584 | Weight: 0.529152 | Bias: 0.070437\n",
            "Iteration: 48110 | Cost/Loss: 0.077584 | Weight: 0.529152 | Bias: 0.070437\n",
            "Iteration: 48111 | Cost/Loss: 0.077584 | Weight: 0.529153 | Bias: 0.070438\n",
            "Iteration: 48112 | Cost/Loss: 0.077584 | Weight: 0.529153 | Bias: 0.070438\n",
            "Iteration: 48113 | Cost/Loss: 0.077584 | Weight: 0.529153 | Bias: 0.070438\n",
            "Iteration: 48114 | Cost/Loss: 0.077584 | Weight: 0.529153 | Bias: 0.070439\n",
            "Iteration: 48115 | Cost/Loss: 0.077584 | Weight: 0.529154 | Bias: 0.070439\n",
            "Iteration: 48116 | Cost/Loss: 0.077584 | Weight: 0.529154 | Bias: 0.070439\n",
            "Iteration: 48117 | Cost/Loss: 0.077584 | Weight: 0.529154 | Bias: 0.070440\n",
            "Iteration: 48118 | Cost/Loss: 0.077584 | Weight: 0.529155 | Bias: 0.070440\n",
            "Iteration: 48119 | Cost/Loss: 0.077584 | Weight: 0.529155 | Bias: 0.070440\n",
            "Iteration: 48120 | Cost/Loss: 0.077584 | Weight: 0.529155 | Bias: 0.070440\n",
            "Iteration: 48121 | Cost/Loss: 0.077584 | Weight: 0.529156 | Bias: 0.070441\n",
            "Iteration: 48122 | Cost/Loss: 0.077584 | Weight: 0.529156 | Bias: 0.070441\n",
            "Iteration: 48123 | Cost/Loss: 0.077584 | Weight: 0.529156 | Bias: 0.070441\n",
            "Iteration: 48124 | Cost/Loss: 0.077584 | Weight: 0.529156 | Bias: 0.070442\n",
            "Iteration: 48125 | Cost/Loss: 0.077584 | Weight: 0.529157 | Bias: 0.070442\n",
            "Iteration: 48126 | Cost/Loss: 0.077584 | Weight: 0.529157 | Bias: 0.070442\n",
            "Iteration: 48127 | Cost/Loss: 0.077584 | Weight: 0.529157 | Bias: 0.070443\n",
            "Iteration: 48128 | Cost/Loss: 0.077583 | Weight: 0.529158 | Bias: 0.070443\n",
            "Iteration: 48129 | Cost/Loss: 0.077583 | Weight: 0.529158 | Bias: 0.070443\n",
            "Iteration: 48130 | Cost/Loss: 0.077583 | Weight: 0.529158 | Bias: 0.070444\n",
            "Iteration: 48131 | Cost/Loss: 0.077583 | Weight: 0.529159 | Bias: 0.070444\n",
            "Iteration: 48132 | Cost/Loss: 0.077583 | Weight: 0.529159 | Bias: 0.070444\n",
            "Iteration: 48133 | Cost/Loss: 0.077583 | Weight: 0.529159 | Bias: 0.070445\n",
            "Iteration: 48134 | Cost/Loss: 0.077583 | Weight: 0.529159 | Bias: 0.070445\n",
            "Iteration: 48135 | Cost/Loss: 0.077583 | Weight: 0.529160 | Bias: 0.070445\n",
            "Iteration: 48136 | Cost/Loss: 0.077583 | Weight: 0.529160 | Bias: 0.070446\n",
            "Iteration: 48137 | Cost/Loss: 0.077583 | Weight: 0.529160 | Bias: 0.070446\n",
            "Iteration: 48138 | Cost/Loss: 0.077583 | Weight: 0.529161 | Bias: 0.070446\n",
            "Iteration: 48139 | Cost/Loss: 0.077583 | Weight: 0.529161 | Bias: 0.070447\n",
            "Iteration: 48140 | Cost/Loss: 0.077583 | Weight: 0.529161 | Bias: 0.070447\n",
            "Iteration: 48141 | Cost/Loss: 0.077583 | Weight: 0.529162 | Bias: 0.070447\n",
            "Iteration: 48142 | Cost/Loss: 0.077583 | Weight: 0.529162 | Bias: 0.070448\n",
            "Iteration: 48143 | Cost/Loss: 0.077583 | Weight: 0.529162 | Bias: 0.070448\n",
            "Iteration: 48144 | Cost/Loss: 0.077583 | Weight: 0.529162 | Bias: 0.070448\n",
            "Iteration: 48145 | Cost/Loss: 0.077583 | Weight: 0.529163 | Bias: 0.070449\n",
            "Iteration: 48146 | Cost/Loss: 0.077583 | Weight: 0.529163 | Bias: 0.070449\n",
            "Iteration: 48147 | Cost/Loss: 0.077583 | Weight: 0.529163 | Bias: 0.070449\n",
            "Iteration: 48148 | Cost/Loss: 0.077583 | Weight: 0.529164 | Bias: 0.070449\n",
            "Iteration: 48149 | Cost/Loss: 0.077583 | Weight: 0.529164 | Bias: 0.070450\n",
            "Iteration: 48150 | Cost/Loss: 0.077583 | Weight: 0.529164 | Bias: 0.070450\n",
            "Iteration: 48151 | Cost/Loss: 0.077583 | Weight: 0.529164 | Bias: 0.070450\n",
            "Iteration: 48152 | Cost/Loss: 0.077583 | Weight: 0.529165 | Bias: 0.070451\n",
            "Iteration: 48153 | Cost/Loss: 0.077583 | Weight: 0.529165 | Bias: 0.070451\n",
            "Iteration: 48154 | Cost/Loss: 0.077583 | Weight: 0.529165 | Bias: 0.070451\n",
            "Iteration: 48155 | Cost/Loss: 0.077583 | Weight: 0.529166 | Bias: 0.070452\n",
            "Iteration: 48156 | Cost/Loss: 0.077583 | Weight: 0.529166 | Bias: 0.070452\n",
            "Iteration: 48157 | Cost/Loss: 0.077583 | Weight: 0.529166 | Bias: 0.070452\n",
            "Iteration: 48158 | Cost/Loss: 0.077583 | Weight: 0.529167 | Bias: 0.070453\n",
            "Iteration: 48159 | Cost/Loss: 0.077583 | Weight: 0.529167 | Bias: 0.070453\n",
            "Iteration: 48160 | Cost/Loss: 0.077583 | Weight: 0.529167 | Bias: 0.070453\n",
            "Iteration: 48161 | Cost/Loss: 0.077583 | Weight: 0.529167 | Bias: 0.070454\n",
            "Iteration: 48162 | Cost/Loss: 0.077583 | Weight: 0.529168 | Bias: 0.070454\n",
            "Iteration: 48163 | Cost/Loss: 0.077583 | Weight: 0.529168 | Bias: 0.070454\n",
            "Iteration: 48164 | Cost/Loss: 0.077583 | Weight: 0.529168 | Bias: 0.070455\n",
            "Iteration: 48165 | Cost/Loss: 0.077583 | Weight: 0.529169 | Bias: 0.070455\n",
            "Iteration: 48166 | Cost/Loss: 0.077583 | Weight: 0.529169 | Bias: 0.070455\n",
            "Iteration: 48167 | Cost/Loss: 0.077583 | Weight: 0.529169 | Bias: 0.070456\n",
            "Iteration: 48168 | Cost/Loss: 0.077582 | Weight: 0.529170 | Bias: 0.070456\n",
            "Iteration: 48169 | Cost/Loss: 0.077582 | Weight: 0.529170 | Bias: 0.070456\n",
            "Iteration: 48170 | Cost/Loss: 0.077582 | Weight: 0.529170 | Bias: 0.070457\n",
            "Iteration: 48171 | Cost/Loss: 0.077582 | Weight: 0.529170 | Bias: 0.070457\n",
            "Iteration: 48172 | Cost/Loss: 0.077582 | Weight: 0.529171 | Bias: 0.070457\n",
            "Iteration: 48173 | Cost/Loss: 0.077582 | Weight: 0.529171 | Bias: 0.070457\n",
            "Iteration: 48174 | Cost/Loss: 0.077582 | Weight: 0.529171 | Bias: 0.070458\n",
            "Iteration: 48175 | Cost/Loss: 0.077582 | Weight: 0.529172 | Bias: 0.070458\n",
            "Iteration: 48176 | Cost/Loss: 0.077582 | Weight: 0.529172 | Bias: 0.070458\n",
            "Iteration: 48177 | Cost/Loss: 0.077582 | Weight: 0.529172 | Bias: 0.070459\n",
            "Iteration: 48178 | Cost/Loss: 0.077582 | Weight: 0.529173 | Bias: 0.070459\n",
            "Iteration: 48179 | Cost/Loss: 0.077582 | Weight: 0.529173 | Bias: 0.070459\n",
            "Iteration: 48180 | Cost/Loss: 0.077582 | Weight: 0.529173 | Bias: 0.070460\n",
            "Iteration: 48181 | Cost/Loss: 0.077582 | Weight: 0.529173 | Bias: 0.070460\n",
            "Iteration: 48182 | Cost/Loss: 0.077582 | Weight: 0.529174 | Bias: 0.070460\n",
            "Iteration: 48183 | Cost/Loss: 0.077582 | Weight: 0.529174 | Bias: 0.070461\n",
            "Iteration: 48184 | Cost/Loss: 0.077582 | Weight: 0.529174 | Bias: 0.070461\n",
            "Iteration: 48185 | Cost/Loss: 0.077582 | Weight: 0.529175 | Bias: 0.070461\n",
            "Iteration: 48186 | Cost/Loss: 0.077582 | Weight: 0.529175 | Bias: 0.070462\n",
            "Iteration: 48187 | Cost/Loss: 0.077582 | Weight: 0.529175 | Bias: 0.070462\n",
            "Iteration: 48188 | Cost/Loss: 0.077582 | Weight: 0.529176 | Bias: 0.070462\n",
            "Iteration: 48189 | Cost/Loss: 0.077582 | Weight: 0.529176 | Bias: 0.070463\n",
            "Iteration: 48190 | Cost/Loss: 0.077582 | Weight: 0.529176 | Bias: 0.070463\n",
            "Iteration: 48191 | Cost/Loss: 0.077582 | Weight: 0.529176 | Bias: 0.070463\n",
            "Iteration: 48192 | Cost/Loss: 0.077582 | Weight: 0.529177 | Bias: 0.070464\n",
            "Iteration: 48193 | Cost/Loss: 0.077582 | Weight: 0.529177 | Bias: 0.070464\n",
            "Iteration: 48194 | Cost/Loss: 0.077582 | Weight: 0.529177 | Bias: 0.070464\n",
            "Iteration: 48195 | Cost/Loss: 0.077582 | Weight: 0.529178 | Bias: 0.070465\n",
            "Iteration: 48196 | Cost/Loss: 0.077582 | Weight: 0.529178 | Bias: 0.070465\n",
            "Iteration: 48197 | Cost/Loss: 0.077582 | Weight: 0.529178 | Bias: 0.070465\n",
            "Iteration: 48198 | Cost/Loss: 0.077582 | Weight: 0.529179 | Bias: 0.070465\n",
            "Iteration: 48199 | Cost/Loss: 0.077582 | Weight: 0.529179 | Bias: 0.070466\n",
            "Iteration: 48200 | Cost/Loss: 0.077582 | Weight: 0.529179 | Bias: 0.070466\n",
            "Iteration: 48201 | Cost/Loss: 0.077582 | Weight: 0.529179 | Bias: 0.070466\n",
            "Iteration: 48202 | Cost/Loss: 0.077582 | Weight: 0.529180 | Bias: 0.070467\n",
            "Iteration: 48203 | Cost/Loss: 0.077582 | Weight: 0.529180 | Bias: 0.070467\n",
            "Iteration: 48204 | Cost/Loss: 0.077582 | Weight: 0.529180 | Bias: 0.070467\n",
            "Iteration: 48205 | Cost/Loss: 0.077582 | Weight: 0.529181 | Bias: 0.070468\n",
            "Iteration: 48206 | Cost/Loss: 0.077582 | Weight: 0.529181 | Bias: 0.070468\n",
            "Iteration: 48207 | Cost/Loss: 0.077582 | Weight: 0.529181 | Bias: 0.070468\n",
            "Iteration: 48208 | Cost/Loss: 0.077581 | Weight: 0.529181 | Bias: 0.070469\n",
            "Iteration: 48209 | Cost/Loss: 0.077581 | Weight: 0.529182 | Bias: 0.070469\n",
            "Iteration: 48210 | Cost/Loss: 0.077581 | Weight: 0.529182 | Bias: 0.070469\n",
            "Iteration: 48211 | Cost/Loss: 0.077581 | Weight: 0.529182 | Bias: 0.070470\n",
            "Iteration: 48212 | Cost/Loss: 0.077581 | Weight: 0.529183 | Bias: 0.070470\n",
            "Iteration: 48213 | Cost/Loss: 0.077581 | Weight: 0.529183 | Bias: 0.070470\n",
            "Iteration: 48214 | Cost/Loss: 0.077581 | Weight: 0.529183 | Bias: 0.070471\n",
            "Iteration: 48215 | Cost/Loss: 0.077581 | Weight: 0.529184 | Bias: 0.070471\n",
            "Iteration: 48216 | Cost/Loss: 0.077581 | Weight: 0.529184 | Bias: 0.070471\n",
            "Iteration: 48217 | Cost/Loss: 0.077581 | Weight: 0.529184 | Bias: 0.070472\n",
            "Iteration: 48218 | Cost/Loss: 0.077581 | Weight: 0.529184 | Bias: 0.070472\n",
            "Iteration: 48219 | Cost/Loss: 0.077581 | Weight: 0.529185 | Bias: 0.070472\n",
            "Iteration: 48220 | Cost/Loss: 0.077581 | Weight: 0.529185 | Bias: 0.070473\n",
            "Iteration: 48221 | Cost/Loss: 0.077581 | Weight: 0.529185 | Bias: 0.070473\n",
            "Iteration: 48222 | Cost/Loss: 0.077581 | Weight: 0.529186 | Bias: 0.070473\n",
            "Iteration: 48223 | Cost/Loss: 0.077581 | Weight: 0.529186 | Bias: 0.070473\n",
            "Iteration: 48224 | Cost/Loss: 0.077581 | Weight: 0.529186 | Bias: 0.070474\n",
            "Iteration: 48225 | Cost/Loss: 0.077581 | Weight: 0.529187 | Bias: 0.070474\n",
            "Iteration: 48226 | Cost/Loss: 0.077581 | Weight: 0.529187 | Bias: 0.070474\n",
            "Iteration: 48227 | Cost/Loss: 0.077581 | Weight: 0.529187 | Bias: 0.070475\n",
            "Iteration: 48228 | Cost/Loss: 0.077581 | Weight: 0.529187 | Bias: 0.070475\n",
            "Iteration: 48229 | Cost/Loss: 0.077581 | Weight: 0.529188 | Bias: 0.070475\n",
            "Iteration: 48230 | Cost/Loss: 0.077581 | Weight: 0.529188 | Bias: 0.070476\n",
            "Iteration: 48231 | Cost/Loss: 0.077581 | Weight: 0.529188 | Bias: 0.070476\n",
            "Iteration: 48232 | Cost/Loss: 0.077581 | Weight: 0.529189 | Bias: 0.070476\n",
            "Iteration: 48233 | Cost/Loss: 0.077581 | Weight: 0.529189 | Bias: 0.070477\n",
            "Iteration: 48234 | Cost/Loss: 0.077581 | Weight: 0.529189 | Bias: 0.070477\n",
            "Iteration: 48235 | Cost/Loss: 0.077581 | Weight: 0.529190 | Bias: 0.070477\n",
            "Iteration: 48236 | Cost/Loss: 0.077581 | Weight: 0.529190 | Bias: 0.070478\n",
            "Iteration: 48237 | Cost/Loss: 0.077581 | Weight: 0.529190 | Bias: 0.070478\n",
            "Iteration: 48238 | Cost/Loss: 0.077581 | Weight: 0.529190 | Bias: 0.070478\n",
            "Iteration: 48239 | Cost/Loss: 0.077581 | Weight: 0.529191 | Bias: 0.070479\n",
            "Iteration: 48240 | Cost/Loss: 0.077581 | Weight: 0.529191 | Bias: 0.070479\n",
            "Iteration: 48241 | Cost/Loss: 0.077581 | Weight: 0.529191 | Bias: 0.070479\n",
            "Iteration: 48242 | Cost/Loss: 0.077581 | Weight: 0.529192 | Bias: 0.070480\n",
            "Iteration: 48243 | Cost/Loss: 0.077581 | Weight: 0.529192 | Bias: 0.070480\n",
            "Iteration: 48244 | Cost/Loss: 0.077581 | Weight: 0.529192 | Bias: 0.070480\n",
            "Iteration: 48245 | Cost/Loss: 0.077581 | Weight: 0.529193 | Bias: 0.070481\n",
            "Iteration: 48246 | Cost/Loss: 0.077581 | Weight: 0.529193 | Bias: 0.070481\n",
            "Iteration: 48247 | Cost/Loss: 0.077580 | Weight: 0.529193 | Bias: 0.070481\n",
            "Iteration: 48248 | Cost/Loss: 0.077580 | Weight: 0.529193 | Bias: 0.070482\n",
            "Iteration: 48249 | Cost/Loss: 0.077580 | Weight: 0.529194 | Bias: 0.070482\n",
            "Iteration: 48250 | Cost/Loss: 0.077580 | Weight: 0.529194 | Bias: 0.070482\n",
            "Iteration: 48251 | Cost/Loss: 0.077580 | Weight: 0.529194 | Bias: 0.070482\n",
            "Iteration: 48252 | Cost/Loss: 0.077580 | Weight: 0.529195 | Bias: 0.070483\n",
            "Iteration: 48253 | Cost/Loss: 0.077580 | Weight: 0.529195 | Bias: 0.070483\n",
            "Iteration: 48254 | Cost/Loss: 0.077580 | Weight: 0.529195 | Bias: 0.070483\n",
            "Iteration: 48255 | Cost/Loss: 0.077580 | Weight: 0.529195 | Bias: 0.070484\n",
            "Iteration: 48256 | Cost/Loss: 0.077580 | Weight: 0.529196 | Bias: 0.070484\n",
            "Iteration: 48257 | Cost/Loss: 0.077580 | Weight: 0.529196 | Bias: 0.070484\n",
            "Iteration: 48258 | Cost/Loss: 0.077580 | Weight: 0.529196 | Bias: 0.070485\n",
            "Iteration: 48259 | Cost/Loss: 0.077580 | Weight: 0.529197 | Bias: 0.070485\n",
            "Iteration: 48260 | Cost/Loss: 0.077580 | Weight: 0.529197 | Bias: 0.070485\n",
            "Iteration: 48261 | Cost/Loss: 0.077580 | Weight: 0.529197 | Bias: 0.070486\n",
            "Iteration: 48262 | Cost/Loss: 0.077580 | Weight: 0.529198 | Bias: 0.070486\n",
            "Iteration: 48263 | Cost/Loss: 0.077580 | Weight: 0.529198 | Bias: 0.070486\n",
            "Iteration: 48264 | Cost/Loss: 0.077580 | Weight: 0.529198 | Bias: 0.070487\n",
            "Iteration: 48265 | Cost/Loss: 0.077580 | Weight: 0.529198 | Bias: 0.070487\n",
            "Iteration: 48266 | Cost/Loss: 0.077580 | Weight: 0.529199 | Bias: 0.070487\n",
            "Iteration: 48267 | Cost/Loss: 0.077580 | Weight: 0.529199 | Bias: 0.070488\n",
            "Iteration: 48268 | Cost/Loss: 0.077580 | Weight: 0.529199 | Bias: 0.070488\n",
            "Iteration: 48269 | Cost/Loss: 0.077580 | Weight: 0.529200 | Bias: 0.070488\n",
            "Iteration: 48270 | Cost/Loss: 0.077580 | Weight: 0.529200 | Bias: 0.070489\n",
            "Iteration: 48271 | Cost/Loss: 0.077580 | Weight: 0.529200 | Bias: 0.070489\n",
            "Iteration: 48272 | Cost/Loss: 0.077580 | Weight: 0.529201 | Bias: 0.070489\n",
            "Iteration: 48273 | Cost/Loss: 0.077580 | Weight: 0.529201 | Bias: 0.070490\n",
            "Iteration: 48274 | Cost/Loss: 0.077580 | Weight: 0.529201 | Bias: 0.070490\n",
            "Iteration: 48275 | Cost/Loss: 0.077580 | Weight: 0.529201 | Bias: 0.070490\n",
            "Iteration: 48276 | Cost/Loss: 0.077580 | Weight: 0.529202 | Bias: 0.070490\n",
            "Iteration: 48277 | Cost/Loss: 0.077580 | Weight: 0.529202 | Bias: 0.070491\n",
            "Iteration: 48278 | Cost/Loss: 0.077580 | Weight: 0.529202 | Bias: 0.070491\n",
            "Iteration: 48279 | Cost/Loss: 0.077580 | Weight: 0.529203 | Bias: 0.070491\n",
            "Iteration: 48280 | Cost/Loss: 0.077580 | Weight: 0.529203 | Bias: 0.070492\n",
            "Iteration: 48281 | Cost/Loss: 0.077580 | Weight: 0.529203 | Bias: 0.070492\n",
            "Iteration: 48282 | Cost/Loss: 0.077580 | Weight: 0.529204 | Bias: 0.070492\n",
            "Iteration: 48283 | Cost/Loss: 0.077580 | Weight: 0.529204 | Bias: 0.070493\n",
            "Iteration: 48284 | Cost/Loss: 0.077580 | Weight: 0.529204 | Bias: 0.070493\n",
            "Iteration: 48285 | Cost/Loss: 0.077580 | Weight: 0.529204 | Bias: 0.070493\n",
            "Iteration: 48286 | Cost/Loss: 0.077580 | Weight: 0.529205 | Bias: 0.070494\n",
            "Iteration: 48287 | Cost/Loss: 0.077579 | Weight: 0.529205 | Bias: 0.070494\n",
            "Iteration: 48288 | Cost/Loss: 0.077579 | Weight: 0.529205 | Bias: 0.070494\n",
            "Iteration: 48289 | Cost/Loss: 0.077579 | Weight: 0.529206 | Bias: 0.070495\n",
            "Iteration: 48290 | Cost/Loss: 0.077579 | Weight: 0.529206 | Bias: 0.070495\n",
            "Iteration: 48291 | Cost/Loss: 0.077579 | Weight: 0.529206 | Bias: 0.070495\n",
            "Iteration: 48292 | Cost/Loss: 0.077579 | Weight: 0.529207 | Bias: 0.070496\n",
            "Iteration: 48293 | Cost/Loss: 0.077579 | Weight: 0.529207 | Bias: 0.070496\n",
            "Iteration: 48294 | Cost/Loss: 0.077579 | Weight: 0.529207 | Bias: 0.070496\n",
            "Iteration: 48295 | Cost/Loss: 0.077579 | Weight: 0.529207 | Bias: 0.070497\n",
            "Iteration: 48296 | Cost/Loss: 0.077579 | Weight: 0.529208 | Bias: 0.070497\n",
            "Iteration: 48297 | Cost/Loss: 0.077579 | Weight: 0.529208 | Bias: 0.070497\n",
            "Iteration: 48298 | Cost/Loss: 0.077579 | Weight: 0.529208 | Bias: 0.070498\n",
            "Iteration: 48299 | Cost/Loss: 0.077579 | Weight: 0.529209 | Bias: 0.070498\n",
            "Iteration: 48300 | Cost/Loss: 0.077579 | Weight: 0.529209 | Bias: 0.070498\n",
            "Iteration: 48301 | Cost/Loss: 0.077579 | Weight: 0.529209 | Bias: 0.070498\n",
            "Iteration: 48302 | Cost/Loss: 0.077579 | Weight: 0.529209 | Bias: 0.070499\n",
            "Iteration: 48303 | Cost/Loss: 0.077579 | Weight: 0.529210 | Bias: 0.070499\n",
            "Iteration: 48304 | Cost/Loss: 0.077579 | Weight: 0.529210 | Bias: 0.070499\n",
            "Iteration: 48305 | Cost/Loss: 0.077579 | Weight: 0.529210 | Bias: 0.070500\n",
            "Iteration: 48306 | Cost/Loss: 0.077579 | Weight: 0.529211 | Bias: 0.070500\n",
            "Iteration: 48307 | Cost/Loss: 0.077579 | Weight: 0.529211 | Bias: 0.070500\n",
            "Iteration: 48308 | Cost/Loss: 0.077579 | Weight: 0.529211 | Bias: 0.070501\n",
            "Iteration: 48309 | Cost/Loss: 0.077579 | Weight: 0.529212 | Bias: 0.070501\n",
            "Iteration: 48310 | Cost/Loss: 0.077579 | Weight: 0.529212 | Bias: 0.070501\n",
            "Iteration: 48311 | Cost/Loss: 0.077579 | Weight: 0.529212 | Bias: 0.070502\n",
            "Iteration: 48312 | Cost/Loss: 0.077579 | Weight: 0.529212 | Bias: 0.070502\n",
            "Iteration: 48313 | Cost/Loss: 0.077579 | Weight: 0.529213 | Bias: 0.070502\n",
            "Iteration: 48314 | Cost/Loss: 0.077579 | Weight: 0.529213 | Bias: 0.070503\n",
            "Iteration: 48315 | Cost/Loss: 0.077579 | Weight: 0.529213 | Bias: 0.070503\n",
            "Iteration: 48316 | Cost/Loss: 0.077579 | Weight: 0.529214 | Bias: 0.070503\n",
            "Iteration: 48317 | Cost/Loss: 0.077579 | Weight: 0.529214 | Bias: 0.070504\n",
            "Iteration: 48318 | Cost/Loss: 0.077579 | Weight: 0.529214 | Bias: 0.070504\n",
            "Iteration: 48319 | Cost/Loss: 0.077579 | Weight: 0.529215 | Bias: 0.070504\n",
            "Iteration: 48320 | Cost/Loss: 0.077579 | Weight: 0.529215 | Bias: 0.070505\n",
            "Iteration: 48321 | Cost/Loss: 0.077579 | Weight: 0.529215 | Bias: 0.070505\n",
            "Iteration: 48322 | Cost/Loss: 0.077579 | Weight: 0.529215 | Bias: 0.070505\n",
            "Iteration: 48323 | Cost/Loss: 0.077579 | Weight: 0.529216 | Bias: 0.070506\n",
            "Iteration: 48324 | Cost/Loss: 0.077579 | Weight: 0.529216 | Bias: 0.070506\n",
            "Iteration: 48325 | Cost/Loss: 0.077579 | Weight: 0.529216 | Bias: 0.070506\n",
            "Iteration: 48326 | Cost/Loss: 0.077578 | Weight: 0.529217 | Bias: 0.070506\n",
            "Iteration: 48327 | Cost/Loss: 0.077578 | Weight: 0.529217 | Bias: 0.070507\n",
            "Iteration: 48328 | Cost/Loss: 0.077578 | Weight: 0.529217 | Bias: 0.070507\n",
            "Iteration: 48329 | Cost/Loss: 0.077578 | Weight: 0.529218 | Bias: 0.070507\n",
            "Iteration: 48330 | Cost/Loss: 0.077578 | Weight: 0.529218 | Bias: 0.070508\n",
            "Iteration: 48331 | Cost/Loss: 0.077578 | Weight: 0.529218 | Bias: 0.070508\n",
            "Iteration: 48332 | Cost/Loss: 0.077578 | Weight: 0.529218 | Bias: 0.070508\n",
            "Iteration: 48333 | Cost/Loss: 0.077578 | Weight: 0.529219 | Bias: 0.070509\n",
            "Iteration: 48334 | Cost/Loss: 0.077578 | Weight: 0.529219 | Bias: 0.070509\n",
            "Iteration: 48335 | Cost/Loss: 0.077578 | Weight: 0.529219 | Bias: 0.070509\n",
            "Iteration: 48336 | Cost/Loss: 0.077578 | Weight: 0.529220 | Bias: 0.070510\n",
            "Iteration: 48337 | Cost/Loss: 0.077578 | Weight: 0.529220 | Bias: 0.070510\n",
            "Iteration: 48338 | Cost/Loss: 0.077578 | Weight: 0.529220 | Bias: 0.070510\n",
            "Iteration: 48339 | Cost/Loss: 0.077578 | Weight: 0.529221 | Bias: 0.070511\n",
            "Iteration: 48340 | Cost/Loss: 0.077578 | Weight: 0.529221 | Bias: 0.070511\n",
            "Iteration: 48341 | Cost/Loss: 0.077578 | Weight: 0.529221 | Bias: 0.070511\n",
            "Iteration: 48342 | Cost/Loss: 0.077578 | Weight: 0.529221 | Bias: 0.070512\n",
            "Iteration: 48343 | Cost/Loss: 0.077578 | Weight: 0.529222 | Bias: 0.070512\n",
            "Iteration: 48344 | Cost/Loss: 0.077578 | Weight: 0.529222 | Bias: 0.070512\n",
            "Iteration: 48345 | Cost/Loss: 0.077578 | Weight: 0.529222 | Bias: 0.070513\n",
            "Iteration: 48346 | Cost/Loss: 0.077578 | Weight: 0.529223 | Bias: 0.070513\n",
            "Iteration: 48347 | Cost/Loss: 0.077578 | Weight: 0.529223 | Bias: 0.070513\n",
            "Iteration: 48348 | Cost/Loss: 0.077578 | Weight: 0.529223 | Bias: 0.070514\n",
            "Iteration: 48349 | Cost/Loss: 0.077578 | Weight: 0.529224 | Bias: 0.070514\n",
            "Iteration: 48350 | Cost/Loss: 0.077578 | Weight: 0.529224 | Bias: 0.070514\n",
            "Iteration: 48351 | Cost/Loss: 0.077578 | Weight: 0.529224 | Bias: 0.070515\n",
            "Iteration: 48352 | Cost/Loss: 0.077578 | Weight: 0.529224 | Bias: 0.070515\n",
            "Iteration: 48353 | Cost/Loss: 0.077578 | Weight: 0.529225 | Bias: 0.070515\n",
            "Iteration: 48354 | Cost/Loss: 0.077578 | Weight: 0.529225 | Bias: 0.070515\n",
            "Iteration: 48355 | Cost/Loss: 0.077578 | Weight: 0.529225 | Bias: 0.070516\n",
            "Iteration: 48356 | Cost/Loss: 0.077578 | Weight: 0.529226 | Bias: 0.070516\n",
            "Iteration: 48357 | Cost/Loss: 0.077578 | Weight: 0.529226 | Bias: 0.070516\n",
            "Iteration: 48358 | Cost/Loss: 0.077578 | Weight: 0.529226 | Bias: 0.070517\n",
            "Iteration: 48359 | Cost/Loss: 0.077578 | Weight: 0.529226 | Bias: 0.070517\n",
            "Iteration: 48360 | Cost/Loss: 0.077578 | Weight: 0.529227 | Bias: 0.070517\n",
            "Iteration: 48361 | Cost/Loss: 0.077578 | Weight: 0.529227 | Bias: 0.070518\n",
            "Iteration: 48362 | Cost/Loss: 0.077578 | Weight: 0.529227 | Bias: 0.070518\n",
            "Iteration: 48363 | Cost/Loss: 0.077578 | Weight: 0.529228 | Bias: 0.070518\n",
            "Iteration: 48364 | Cost/Loss: 0.077578 | Weight: 0.529228 | Bias: 0.070519\n",
            "Iteration: 48365 | Cost/Loss: 0.077578 | Weight: 0.529228 | Bias: 0.070519\n",
            "Iteration: 48366 | Cost/Loss: 0.077577 | Weight: 0.529229 | Bias: 0.070519\n",
            "Iteration: 48367 | Cost/Loss: 0.077577 | Weight: 0.529229 | Bias: 0.070520\n",
            "Iteration: 48368 | Cost/Loss: 0.077577 | Weight: 0.529229 | Bias: 0.070520\n",
            "Iteration: 48369 | Cost/Loss: 0.077577 | Weight: 0.529229 | Bias: 0.070520\n",
            "Iteration: 48370 | Cost/Loss: 0.077577 | Weight: 0.529230 | Bias: 0.070521\n",
            "Iteration: 48371 | Cost/Loss: 0.077577 | Weight: 0.529230 | Bias: 0.070521\n",
            "Iteration: 48372 | Cost/Loss: 0.077577 | Weight: 0.529230 | Bias: 0.070521\n",
            "Iteration: 48373 | Cost/Loss: 0.077577 | Weight: 0.529231 | Bias: 0.070522\n",
            "Iteration: 48374 | Cost/Loss: 0.077577 | Weight: 0.529231 | Bias: 0.070522\n",
            "Iteration: 48375 | Cost/Loss: 0.077577 | Weight: 0.529231 | Bias: 0.070522\n",
            "Iteration: 48376 | Cost/Loss: 0.077577 | Weight: 0.529232 | Bias: 0.070523\n",
            "Iteration: 48377 | Cost/Loss: 0.077577 | Weight: 0.529232 | Bias: 0.070523\n",
            "Iteration: 48378 | Cost/Loss: 0.077577 | Weight: 0.529232 | Bias: 0.070523\n",
            "Iteration: 48379 | Cost/Loss: 0.077577 | Weight: 0.529232 | Bias: 0.070523\n",
            "Iteration: 48380 | Cost/Loss: 0.077577 | Weight: 0.529233 | Bias: 0.070524\n",
            "Iteration: 48381 | Cost/Loss: 0.077577 | Weight: 0.529233 | Bias: 0.070524\n",
            "Iteration: 48382 | Cost/Loss: 0.077577 | Weight: 0.529233 | Bias: 0.070524\n",
            "Iteration: 48383 | Cost/Loss: 0.077577 | Weight: 0.529234 | Bias: 0.070525\n",
            "Iteration: 48384 | Cost/Loss: 0.077577 | Weight: 0.529234 | Bias: 0.070525\n",
            "Iteration: 48385 | Cost/Loss: 0.077577 | Weight: 0.529234 | Bias: 0.070525\n",
            "Iteration: 48386 | Cost/Loss: 0.077577 | Weight: 0.529235 | Bias: 0.070526\n",
            "Iteration: 48387 | Cost/Loss: 0.077577 | Weight: 0.529235 | Bias: 0.070526\n",
            "Iteration: 48388 | Cost/Loss: 0.077577 | Weight: 0.529235 | Bias: 0.070526\n",
            "Iteration: 48389 | Cost/Loss: 0.077577 | Weight: 0.529235 | Bias: 0.070527\n",
            "Iteration: 48390 | Cost/Loss: 0.077577 | Weight: 0.529236 | Bias: 0.070527\n",
            "Iteration: 48391 | Cost/Loss: 0.077577 | Weight: 0.529236 | Bias: 0.070527\n",
            "Iteration: 48392 | Cost/Loss: 0.077577 | Weight: 0.529236 | Bias: 0.070528\n",
            "Iteration: 48393 | Cost/Loss: 0.077577 | Weight: 0.529237 | Bias: 0.070528\n",
            "Iteration: 48394 | Cost/Loss: 0.077577 | Weight: 0.529237 | Bias: 0.070528\n",
            "Iteration: 48395 | Cost/Loss: 0.077577 | Weight: 0.529237 | Bias: 0.070529\n",
            "Iteration: 48396 | Cost/Loss: 0.077577 | Weight: 0.529238 | Bias: 0.070529\n",
            "Iteration: 48397 | Cost/Loss: 0.077577 | Weight: 0.529238 | Bias: 0.070529\n",
            "Iteration: 48398 | Cost/Loss: 0.077577 | Weight: 0.529238 | Bias: 0.070530\n",
            "Iteration: 48399 | Cost/Loss: 0.077577 | Weight: 0.529238 | Bias: 0.070530\n",
            "Iteration: 48400 | Cost/Loss: 0.077577 | Weight: 0.529239 | Bias: 0.070530\n",
            "Iteration: 48401 | Cost/Loss: 0.077577 | Weight: 0.529239 | Bias: 0.070531\n",
            "Iteration: 48402 | Cost/Loss: 0.077577 | Weight: 0.529239 | Bias: 0.070531\n",
            "Iteration: 48403 | Cost/Loss: 0.077577 | Weight: 0.529240 | Bias: 0.070531\n",
            "Iteration: 48404 | Cost/Loss: 0.077577 | Weight: 0.529240 | Bias: 0.070531\n",
            "Iteration: 48405 | Cost/Loss: 0.077577 | Weight: 0.529240 | Bias: 0.070532\n",
            "Iteration: 48406 | Cost/Loss: 0.077576 | Weight: 0.529240 | Bias: 0.070532\n",
            "Iteration: 48407 | Cost/Loss: 0.077576 | Weight: 0.529241 | Bias: 0.070532\n",
            "Iteration: 48408 | Cost/Loss: 0.077576 | Weight: 0.529241 | Bias: 0.070533\n",
            "Iteration: 48409 | Cost/Loss: 0.077576 | Weight: 0.529241 | Bias: 0.070533\n",
            "Iteration: 48410 | Cost/Loss: 0.077576 | Weight: 0.529242 | Bias: 0.070533\n",
            "Iteration: 48411 | Cost/Loss: 0.077576 | Weight: 0.529242 | Bias: 0.070534\n",
            "Iteration: 48412 | Cost/Loss: 0.077576 | Weight: 0.529242 | Bias: 0.070534\n",
            "Iteration: 48413 | Cost/Loss: 0.077576 | Weight: 0.529243 | Bias: 0.070534\n",
            "Iteration: 48414 | Cost/Loss: 0.077576 | Weight: 0.529243 | Bias: 0.070535\n",
            "Iteration: 48415 | Cost/Loss: 0.077576 | Weight: 0.529243 | Bias: 0.070535\n",
            "Iteration: 48416 | Cost/Loss: 0.077576 | Weight: 0.529243 | Bias: 0.070535\n",
            "Iteration: 48417 | Cost/Loss: 0.077576 | Weight: 0.529244 | Bias: 0.070536\n",
            "Iteration: 48418 | Cost/Loss: 0.077576 | Weight: 0.529244 | Bias: 0.070536\n",
            "Iteration: 48419 | Cost/Loss: 0.077576 | Weight: 0.529244 | Bias: 0.070536\n",
            "Iteration: 48420 | Cost/Loss: 0.077576 | Weight: 0.529245 | Bias: 0.070537\n",
            "Iteration: 48421 | Cost/Loss: 0.077576 | Weight: 0.529245 | Bias: 0.070537\n",
            "Iteration: 48422 | Cost/Loss: 0.077576 | Weight: 0.529245 | Bias: 0.070537\n",
            "Iteration: 48423 | Cost/Loss: 0.077576 | Weight: 0.529246 | Bias: 0.070538\n",
            "Iteration: 48424 | Cost/Loss: 0.077576 | Weight: 0.529246 | Bias: 0.070538\n",
            "Iteration: 48425 | Cost/Loss: 0.077576 | Weight: 0.529246 | Bias: 0.070538\n",
            "Iteration: 48426 | Cost/Loss: 0.077576 | Weight: 0.529246 | Bias: 0.070539\n",
            "Iteration: 48427 | Cost/Loss: 0.077576 | Weight: 0.529247 | Bias: 0.070539\n",
            "Iteration: 48428 | Cost/Loss: 0.077576 | Weight: 0.529247 | Bias: 0.070539\n",
            "Iteration: 48429 | Cost/Loss: 0.077576 | Weight: 0.529247 | Bias: 0.070539\n",
            "Iteration: 48430 | Cost/Loss: 0.077576 | Weight: 0.529248 | Bias: 0.070540\n",
            "Iteration: 48431 | Cost/Loss: 0.077576 | Weight: 0.529248 | Bias: 0.070540\n",
            "Iteration: 48432 | Cost/Loss: 0.077576 | Weight: 0.529248 | Bias: 0.070540\n",
            "Iteration: 48433 | Cost/Loss: 0.077576 | Weight: 0.529249 | Bias: 0.070541\n",
            "Iteration: 48434 | Cost/Loss: 0.077576 | Weight: 0.529249 | Bias: 0.070541\n",
            "Iteration: 48435 | Cost/Loss: 0.077576 | Weight: 0.529249 | Bias: 0.070541\n",
            "Iteration: 48436 | Cost/Loss: 0.077576 | Weight: 0.529249 | Bias: 0.070542\n",
            "Iteration: 48437 | Cost/Loss: 0.077576 | Weight: 0.529250 | Bias: 0.070542\n",
            "Iteration: 48438 | Cost/Loss: 0.077576 | Weight: 0.529250 | Bias: 0.070542\n",
            "Iteration: 48439 | Cost/Loss: 0.077576 | Weight: 0.529250 | Bias: 0.070543\n",
            "Iteration: 48440 | Cost/Loss: 0.077576 | Weight: 0.529251 | Bias: 0.070543\n",
            "Iteration: 48441 | Cost/Loss: 0.077576 | Weight: 0.529251 | Bias: 0.070543\n",
            "Iteration: 48442 | Cost/Loss: 0.077576 | Weight: 0.529251 | Bias: 0.070544\n",
            "Iteration: 48443 | Cost/Loss: 0.077576 | Weight: 0.529252 | Bias: 0.070544\n",
            "Iteration: 48444 | Cost/Loss: 0.077576 | Weight: 0.529252 | Bias: 0.070544\n",
            "Iteration: 48445 | Cost/Loss: 0.077575 | Weight: 0.529252 | Bias: 0.070545\n",
            "Iteration: 48446 | Cost/Loss: 0.077575 | Weight: 0.529252 | Bias: 0.070545\n",
            "Iteration: 48447 | Cost/Loss: 0.077575 | Weight: 0.529253 | Bias: 0.070545\n",
            "Iteration: 48448 | Cost/Loss: 0.077575 | Weight: 0.529253 | Bias: 0.070546\n",
            "Iteration: 48449 | Cost/Loss: 0.077575 | Weight: 0.529253 | Bias: 0.070546\n",
            "Iteration: 48450 | Cost/Loss: 0.077575 | Weight: 0.529254 | Bias: 0.070546\n",
            "Iteration: 48451 | Cost/Loss: 0.077575 | Weight: 0.529254 | Bias: 0.070547\n",
            "Iteration: 48452 | Cost/Loss: 0.077575 | Weight: 0.529254 | Bias: 0.070547\n",
            "Iteration: 48453 | Cost/Loss: 0.077575 | Weight: 0.529254 | Bias: 0.070547\n",
            "Iteration: 48454 | Cost/Loss: 0.077575 | Weight: 0.529255 | Bias: 0.070547\n",
            "Iteration: 48455 | Cost/Loss: 0.077575 | Weight: 0.529255 | Bias: 0.070548\n",
            "Iteration: 48456 | Cost/Loss: 0.077575 | Weight: 0.529255 | Bias: 0.070548\n",
            "Iteration: 48457 | Cost/Loss: 0.077575 | Weight: 0.529256 | Bias: 0.070548\n",
            "Iteration: 48458 | Cost/Loss: 0.077575 | Weight: 0.529256 | Bias: 0.070549\n",
            "Iteration: 48459 | Cost/Loss: 0.077575 | Weight: 0.529256 | Bias: 0.070549\n",
            "Iteration: 48460 | Cost/Loss: 0.077575 | Weight: 0.529257 | Bias: 0.070549\n",
            "Iteration: 48461 | Cost/Loss: 0.077575 | Weight: 0.529257 | Bias: 0.070550\n",
            "Iteration: 48462 | Cost/Loss: 0.077575 | Weight: 0.529257 | Bias: 0.070550\n",
            "Iteration: 48463 | Cost/Loss: 0.077575 | Weight: 0.529257 | Bias: 0.070550\n",
            "Iteration: 48464 | Cost/Loss: 0.077575 | Weight: 0.529258 | Bias: 0.070551\n",
            "Iteration: 48465 | Cost/Loss: 0.077575 | Weight: 0.529258 | Bias: 0.070551\n",
            "Iteration: 48466 | Cost/Loss: 0.077575 | Weight: 0.529258 | Bias: 0.070551\n",
            "Iteration: 48467 | Cost/Loss: 0.077575 | Weight: 0.529259 | Bias: 0.070552\n",
            "Iteration: 48468 | Cost/Loss: 0.077575 | Weight: 0.529259 | Bias: 0.070552\n",
            "Iteration: 48469 | Cost/Loss: 0.077575 | Weight: 0.529259 | Bias: 0.070552\n",
            "Iteration: 48470 | Cost/Loss: 0.077575 | Weight: 0.529260 | Bias: 0.070553\n",
            "Iteration: 48471 | Cost/Loss: 0.077575 | Weight: 0.529260 | Bias: 0.070553\n",
            "Iteration: 48472 | Cost/Loss: 0.077575 | Weight: 0.529260 | Bias: 0.070553\n",
            "Iteration: 48473 | Cost/Loss: 0.077575 | Weight: 0.529260 | Bias: 0.070554\n",
            "Iteration: 48474 | Cost/Loss: 0.077575 | Weight: 0.529261 | Bias: 0.070554\n",
            "Iteration: 48475 | Cost/Loss: 0.077575 | Weight: 0.529261 | Bias: 0.070554\n",
            "Iteration: 48476 | Cost/Loss: 0.077575 | Weight: 0.529261 | Bias: 0.070555\n",
            "Iteration: 48477 | Cost/Loss: 0.077575 | Weight: 0.529262 | Bias: 0.070555\n",
            "Iteration: 48478 | Cost/Loss: 0.077575 | Weight: 0.529262 | Bias: 0.070555\n",
            "Iteration: 48479 | Cost/Loss: 0.077575 | Weight: 0.529262 | Bias: 0.070556\n",
            "Iteration: 48480 | Cost/Loss: 0.077575 | Weight: 0.529263 | Bias: 0.070556\n",
            "Iteration: 48481 | Cost/Loss: 0.077575 | Weight: 0.529263 | Bias: 0.070556\n",
            "Iteration: 48482 | Cost/Loss: 0.077575 | Weight: 0.529263 | Bias: 0.070556\n",
            "Iteration: 48483 | Cost/Loss: 0.077575 | Weight: 0.529263 | Bias: 0.070557\n",
            "Iteration: 48484 | Cost/Loss: 0.077575 | Weight: 0.529264 | Bias: 0.070557\n",
            "Iteration: 48485 | Cost/Loss: 0.077574 | Weight: 0.529264 | Bias: 0.070557\n",
            "Iteration: 48486 | Cost/Loss: 0.077574 | Weight: 0.529264 | Bias: 0.070558\n",
            "Iteration: 48487 | Cost/Loss: 0.077574 | Weight: 0.529265 | Bias: 0.070558\n",
            "Iteration: 48488 | Cost/Loss: 0.077574 | Weight: 0.529265 | Bias: 0.070558\n",
            "Iteration: 48489 | Cost/Loss: 0.077574 | Weight: 0.529265 | Bias: 0.070559\n",
            "Iteration: 48490 | Cost/Loss: 0.077574 | Weight: 0.529266 | Bias: 0.070559\n",
            "Iteration: 48491 | Cost/Loss: 0.077574 | Weight: 0.529266 | Bias: 0.070559\n",
            "Iteration: 48492 | Cost/Loss: 0.077574 | Weight: 0.529266 | Bias: 0.070560\n",
            "Iteration: 48493 | Cost/Loss: 0.077574 | Weight: 0.529266 | Bias: 0.070560\n",
            "Iteration: 48494 | Cost/Loss: 0.077574 | Weight: 0.529267 | Bias: 0.070560\n",
            "Iteration: 48495 | Cost/Loss: 0.077574 | Weight: 0.529267 | Bias: 0.070561\n",
            "Iteration: 48496 | Cost/Loss: 0.077574 | Weight: 0.529267 | Bias: 0.070561\n",
            "Iteration: 48497 | Cost/Loss: 0.077574 | Weight: 0.529268 | Bias: 0.070561\n",
            "Iteration: 48498 | Cost/Loss: 0.077574 | Weight: 0.529268 | Bias: 0.070562\n",
            "Iteration: 48499 | Cost/Loss: 0.077574 | Weight: 0.529268 | Bias: 0.070562\n",
            "Iteration: 48500 | Cost/Loss: 0.077574 | Weight: 0.529269 | Bias: 0.070562\n",
            "Iteration: 48501 | Cost/Loss: 0.077574 | Weight: 0.529269 | Bias: 0.070563\n",
            "Iteration: 48502 | Cost/Loss: 0.077574 | Weight: 0.529269 | Bias: 0.070563\n",
            "Iteration: 48503 | Cost/Loss: 0.077574 | Weight: 0.529269 | Bias: 0.070563\n",
            "Iteration: 48504 | Cost/Loss: 0.077574 | Weight: 0.529270 | Bias: 0.070564\n",
            "Iteration: 48505 | Cost/Loss: 0.077574 | Weight: 0.529270 | Bias: 0.070564\n",
            "Iteration: 48506 | Cost/Loss: 0.077574 | Weight: 0.529270 | Bias: 0.070564\n",
            "Iteration: 48507 | Cost/Loss: 0.077574 | Weight: 0.529271 | Bias: 0.070564\n",
            "Iteration: 48508 | Cost/Loss: 0.077574 | Weight: 0.529271 | Bias: 0.070565\n",
            "Iteration: 48509 | Cost/Loss: 0.077574 | Weight: 0.529271 | Bias: 0.070565\n",
            "Iteration: 48510 | Cost/Loss: 0.077574 | Weight: 0.529271 | Bias: 0.070565\n",
            "Iteration: 48511 | Cost/Loss: 0.077574 | Weight: 0.529272 | Bias: 0.070566\n",
            "Iteration: 48512 | Cost/Loss: 0.077574 | Weight: 0.529272 | Bias: 0.070566\n",
            "Iteration: 48513 | Cost/Loss: 0.077574 | Weight: 0.529272 | Bias: 0.070566\n",
            "Iteration: 48514 | Cost/Loss: 0.077574 | Weight: 0.529273 | Bias: 0.070567\n",
            "Iteration: 48515 | Cost/Loss: 0.077574 | Weight: 0.529273 | Bias: 0.070567\n",
            "Iteration: 48516 | Cost/Loss: 0.077574 | Weight: 0.529273 | Bias: 0.070567\n",
            "Iteration: 48517 | Cost/Loss: 0.077574 | Weight: 0.529274 | Bias: 0.070568\n",
            "Iteration: 48518 | Cost/Loss: 0.077574 | Weight: 0.529274 | Bias: 0.070568\n",
            "Iteration: 48519 | Cost/Loss: 0.077574 | Weight: 0.529274 | Bias: 0.070568\n",
            "Iteration: 48520 | Cost/Loss: 0.077574 | Weight: 0.529274 | Bias: 0.070569\n",
            "Iteration: 48521 | Cost/Loss: 0.077574 | Weight: 0.529275 | Bias: 0.070569\n",
            "Iteration: 48522 | Cost/Loss: 0.077574 | Weight: 0.529275 | Bias: 0.070569\n",
            "Iteration: 48523 | Cost/Loss: 0.077574 | Weight: 0.529275 | Bias: 0.070570\n",
            "Iteration: 48524 | Cost/Loss: 0.077574 | Weight: 0.529276 | Bias: 0.070570\n",
            "Iteration: 48525 | Cost/Loss: 0.077573 | Weight: 0.529276 | Bias: 0.070570\n",
            "Iteration: 48526 | Cost/Loss: 0.077573 | Weight: 0.529276 | Bias: 0.070571\n",
            "Iteration: 48527 | Cost/Loss: 0.077573 | Weight: 0.529277 | Bias: 0.070571\n",
            "Iteration: 48528 | Cost/Loss: 0.077573 | Weight: 0.529277 | Bias: 0.070571\n",
            "Iteration: 48529 | Cost/Loss: 0.077573 | Weight: 0.529277 | Bias: 0.070572\n",
            "Iteration: 48530 | Cost/Loss: 0.077573 | Weight: 0.529277 | Bias: 0.070572\n",
            "Iteration: 48531 | Cost/Loss: 0.077573 | Weight: 0.529278 | Bias: 0.070572\n",
            "Iteration: 48532 | Cost/Loss: 0.077573 | Weight: 0.529278 | Bias: 0.070572\n",
            "Iteration: 48533 | Cost/Loss: 0.077573 | Weight: 0.529278 | Bias: 0.070573\n",
            "Iteration: 48534 | Cost/Loss: 0.077573 | Weight: 0.529279 | Bias: 0.070573\n",
            "Iteration: 48535 | Cost/Loss: 0.077573 | Weight: 0.529279 | Bias: 0.070573\n",
            "Iteration: 48536 | Cost/Loss: 0.077573 | Weight: 0.529279 | Bias: 0.070574\n",
            "Iteration: 48537 | Cost/Loss: 0.077573 | Weight: 0.529280 | Bias: 0.070574\n",
            "Iteration: 48538 | Cost/Loss: 0.077573 | Weight: 0.529280 | Bias: 0.070574\n",
            "Iteration: 48539 | Cost/Loss: 0.077573 | Weight: 0.529280 | Bias: 0.070575\n",
            "Iteration: 48540 | Cost/Loss: 0.077573 | Weight: 0.529280 | Bias: 0.070575\n",
            "Iteration: 48541 | Cost/Loss: 0.077573 | Weight: 0.529281 | Bias: 0.070575\n",
            "Iteration: 48542 | Cost/Loss: 0.077573 | Weight: 0.529281 | Bias: 0.070576\n",
            "Iteration: 48543 | Cost/Loss: 0.077573 | Weight: 0.529281 | Bias: 0.070576\n",
            "Iteration: 48544 | Cost/Loss: 0.077573 | Weight: 0.529282 | Bias: 0.070576\n",
            "Iteration: 48545 | Cost/Loss: 0.077573 | Weight: 0.529282 | Bias: 0.070577\n",
            "Iteration: 48546 | Cost/Loss: 0.077573 | Weight: 0.529282 | Bias: 0.070577\n",
            "Iteration: 48547 | Cost/Loss: 0.077573 | Weight: 0.529283 | Bias: 0.070577\n",
            "Iteration: 48548 | Cost/Loss: 0.077573 | Weight: 0.529283 | Bias: 0.070578\n",
            "Iteration: 48549 | Cost/Loss: 0.077573 | Weight: 0.529283 | Bias: 0.070578\n",
            "Iteration: 48550 | Cost/Loss: 0.077573 | Weight: 0.529283 | Bias: 0.070578\n",
            "Iteration: 48551 | Cost/Loss: 0.077573 | Weight: 0.529284 | Bias: 0.070579\n",
            "Iteration: 48552 | Cost/Loss: 0.077573 | Weight: 0.529284 | Bias: 0.070579\n",
            "Iteration: 48553 | Cost/Loss: 0.077573 | Weight: 0.529284 | Bias: 0.070579\n",
            "Iteration: 48554 | Cost/Loss: 0.077573 | Weight: 0.529285 | Bias: 0.070580\n",
            "Iteration: 48555 | Cost/Loss: 0.077573 | Weight: 0.529285 | Bias: 0.070580\n",
            "Iteration: 48556 | Cost/Loss: 0.077573 | Weight: 0.529285 | Bias: 0.070580\n",
            "Iteration: 48557 | Cost/Loss: 0.077573 | Weight: 0.529285 | Bias: 0.070580\n",
            "Iteration: 48558 | Cost/Loss: 0.077573 | Weight: 0.529286 | Bias: 0.070581\n",
            "Iteration: 48559 | Cost/Loss: 0.077573 | Weight: 0.529286 | Bias: 0.070581\n",
            "Iteration: 48560 | Cost/Loss: 0.077573 | Weight: 0.529286 | Bias: 0.070581\n",
            "Iteration: 48561 | Cost/Loss: 0.077573 | Weight: 0.529287 | Bias: 0.070582\n",
            "Iteration: 48562 | Cost/Loss: 0.077573 | Weight: 0.529287 | Bias: 0.070582\n",
            "Iteration: 48563 | Cost/Loss: 0.077573 | Weight: 0.529287 | Bias: 0.070582\n",
            "Iteration: 48564 | Cost/Loss: 0.077572 | Weight: 0.529288 | Bias: 0.070583\n",
            "Iteration: 48565 | Cost/Loss: 0.077572 | Weight: 0.529288 | Bias: 0.070583\n",
            "Iteration: 48566 | Cost/Loss: 0.077572 | Weight: 0.529288 | Bias: 0.070583\n",
            "Iteration: 48567 | Cost/Loss: 0.077572 | Weight: 0.529288 | Bias: 0.070584\n",
            "Iteration: 48568 | Cost/Loss: 0.077572 | Weight: 0.529289 | Bias: 0.070584\n",
            "Iteration: 48569 | Cost/Loss: 0.077572 | Weight: 0.529289 | Bias: 0.070584\n",
            "Iteration: 48570 | Cost/Loss: 0.077572 | Weight: 0.529289 | Bias: 0.070585\n",
            "Iteration: 48571 | Cost/Loss: 0.077572 | Weight: 0.529290 | Bias: 0.070585\n",
            "Iteration: 48572 | Cost/Loss: 0.077572 | Weight: 0.529290 | Bias: 0.070585\n",
            "Iteration: 48573 | Cost/Loss: 0.077572 | Weight: 0.529290 | Bias: 0.070586\n",
            "Iteration: 48574 | Cost/Loss: 0.077572 | Weight: 0.529291 | Bias: 0.070586\n",
            "Iteration: 48575 | Cost/Loss: 0.077572 | Weight: 0.529291 | Bias: 0.070586\n",
            "Iteration: 48576 | Cost/Loss: 0.077572 | Weight: 0.529291 | Bias: 0.070587\n",
            "Iteration: 48577 | Cost/Loss: 0.077572 | Weight: 0.529291 | Bias: 0.070587\n",
            "Iteration: 48578 | Cost/Loss: 0.077572 | Weight: 0.529292 | Bias: 0.070587\n",
            "Iteration: 48579 | Cost/Loss: 0.077572 | Weight: 0.529292 | Bias: 0.070588\n",
            "Iteration: 48580 | Cost/Loss: 0.077572 | Weight: 0.529292 | Bias: 0.070588\n",
            "Iteration: 48581 | Cost/Loss: 0.077572 | Weight: 0.529293 | Bias: 0.070588\n",
            "Iteration: 48582 | Cost/Loss: 0.077572 | Weight: 0.529293 | Bias: 0.070589\n",
            "Iteration: 48583 | Cost/Loss: 0.077572 | Weight: 0.529293 | Bias: 0.070589\n",
            "Iteration: 48584 | Cost/Loss: 0.077572 | Weight: 0.529294 | Bias: 0.070589\n",
            "Iteration: 48585 | Cost/Loss: 0.077572 | Weight: 0.529294 | Bias: 0.070589\n",
            "Iteration: 48586 | Cost/Loss: 0.077572 | Weight: 0.529294 | Bias: 0.070590\n",
            "Iteration: 48587 | Cost/Loss: 0.077572 | Weight: 0.529294 | Bias: 0.070590\n",
            "Iteration: 48588 | Cost/Loss: 0.077572 | Weight: 0.529295 | Bias: 0.070590\n",
            "Iteration: 48589 | Cost/Loss: 0.077572 | Weight: 0.529295 | Bias: 0.070591\n",
            "Iteration: 48590 | Cost/Loss: 0.077572 | Weight: 0.529295 | Bias: 0.070591\n",
            "Iteration: 48591 | Cost/Loss: 0.077572 | Weight: 0.529296 | Bias: 0.070591\n",
            "Iteration: 48592 | Cost/Loss: 0.077572 | Weight: 0.529296 | Bias: 0.070592\n",
            "Iteration: 48593 | Cost/Loss: 0.077572 | Weight: 0.529296 | Bias: 0.070592\n",
            "Iteration: 48594 | Cost/Loss: 0.077572 | Weight: 0.529297 | Bias: 0.070592\n",
            "Iteration: 48595 | Cost/Loss: 0.077572 | Weight: 0.529297 | Bias: 0.070593\n",
            "Iteration: 48596 | Cost/Loss: 0.077572 | Weight: 0.529297 | Bias: 0.070593\n",
            "Iteration: 48597 | Cost/Loss: 0.077572 | Weight: 0.529297 | Bias: 0.070593\n",
            "Iteration: 48598 | Cost/Loss: 0.077572 | Weight: 0.529298 | Bias: 0.070594\n",
            "Iteration: 48599 | Cost/Loss: 0.077572 | Weight: 0.529298 | Bias: 0.070594\n",
            "Iteration: 48600 | Cost/Loss: 0.077572 | Weight: 0.529298 | Bias: 0.070594\n",
            "Iteration: 48601 | Cost/Loss: 0.077572 | Weight: 0.529299 | Bias: 0.070595\n",
            "Iteration: 48602 | Cost/Loss: 0.077572 | Weight: 0.529299 | Bias: 0.070595\n",
            "Iteration: 48603 | Cost/Loss: 0.077572 | Weight: 0.529299 | Bias: 0.070595\n",
            "Iteration: 48604 | Cost/Loss: 0.077571 | Weight: 0.529299 | Bias: 0.070596\n",
            "Iteration: 48605 | Cost/Loss: 0.077571 | Weight: 0.529300 | Bias: 0.070596\n",
            "Iteration: 48606 | Cost/Loss: 0.077571 | Weight: 0.529300 | Bias: 0.070596\n",
            "Iteration: 48607 | Cost/Loss: 0.077571 | Weight: 0.529300 | Bias: 0.070597\n",
            "Iteration: 48608 | Cost/Loss: 0.077571 | Weight: 0.529301 | Bias: 0.070597\n",
            "Iteration: 48609 | Cost/Loss: 0.077571 | Weight: 0.529301 | Bias: 0.070597\n",
            "Iteration: 48610 | Cost/Loss: 0.077571 | Weight: 0.529301 | Bias: 0.070597\n",
            "Iteration: 48611 | Cost/Loss: 0.077571 | Weight: 0.529302 | Bias: 0.070598\n",
            "Iteration: 48612 | Cost/Loss: 0.077571 | Weight: 0.529302 | Bias: 0.070598\n",
            "Iteration: 48613 | Cost/Loss: 0.077571 | Weight: 0.529302 | Bias: 0.070598\n",
            "Iteration: 48614 | Cost/Loss: 0.077571 | Weight: 0.529302 | Bias: 0.070599\n",
            "Iteration: 48615 | Cost/Loss: 0.077571 | Weight: 0.529303 | Bias: 0.070599\n",
            "Iteration: 48616 | Cost/Loss: 0.077571 | Weight: 0.529303 | Bias: 0.070599\n",
            "Iteration: 48617 | Cost/Loss: 0.077571 | Weight: 0.529303 | Bias: 0.070600\n",
            "Iteration: 48618 | Cost/Loss: 0.077571 | Weight: 0.529304 | Bias: 0.070600\n",
            "Iteration: 48619 | Cost/Loss: 0.077571 | Weight: 0.529304 | Bias: 0.070600\n",
            "Iteration: 48620 | Cost/Loss: 0.077571 | Weight: 0.529304 | Bias: 0.070601\n",
            "Iteration: 48621 | Cost/Loss: 0.077571 | Weight: 0.529305 | Bias: 0.070601\n",
            "Iteration: 48622 | Cost/Loss: 0.077571 | Weight: 0.529305 | Bias: 0.070601\n",
            "Iteration: 48623 | Cost/Loss: 0.077571 | Weight: 0.529305 | Bias: 0.070602\n",
            "Iteration: 48624 | Cost/Loss: 0.077571 | Weight: 0.529305 | Bias: 0.070602\n",
            "Iteration: 48625 | Cost/Loss: 0.077571 | Weight: 0.529306 | Bias: 0.070602\n",
            "Iteration: 48626 | Cost/Loss: 0.077571 | Weight: 0.529306 | Bias: 0.070603\n",
            "Iteration: 48627 | Cost/Loss: 0.077571 | Weight: 0.529306 | Bias: 0.070603\n",
            "Iteration: 48628 | Cost/Loss: 0.077571 | Weight: 0.529307 | Bias: 0.070603\n",
            "Iteration: 48629 | Cost/Loss: 0.077571 | Weight: 0.529307 | Bias: 0.070604\n",
            "Iteration: 48630 | Cost/Loss: 0.077571 | Weight: 0.529307 | Bias: 0.070604\n",
            "Iteration: 48631 | Cost/Loss: 0.077571 | Weight: 0.529308 | Bias: 0.070604\n",
            "Iteration: 48632 | Cost/Loss: 0.077571 | Weight: 0.529308 | Bias: 0.070605\n",
            "Iteration: 48633 | Cost/Loss: 0.077571 | Weight: 0.529308 | Bias: 0.070605\n",
            "Iteration: 48634 | Cost/Loss: 0.077571 | Weight: 0.529308 | Bias: 0.070605\n",
            "Iteration: 48635 | Cost/Loss: 0.077571 | Weight: 0.529309 | Bias: 0.070605\n",
            "Iteration: 48636 | Cost/Loss: 0.077571 | Weight: 0.529309 | Bias: 0.070606\n",
            "Iteration: 48637 | Cost/Loss: 0.077571 | Weight: 0.529309 | Bias: 0.070606\n",
            "Iteration: 48638 | Cost/Loss: 0.077571 | Weight: 0.529310 | Bias: 0.070606\n",
            "Iteration: 48639 | Cost/Loss: 0.077571 | Weight: 0.529310 | Bias: 0.070607\n",
            "Iteration: 48640 | Cost/Loss: 0.077571 | Weight: 0.529310 | Bias: 0.070607\n",
            "Iteration: 48641 | Cost/Loss: 0.077571 | Weight: 0.529311 | Bias: 0.070607\n",
            "Iteration: 48642 | Cost/Loss: 0.077571 | Weight: 0.529311 | Bias: 0.070608\n",
            "Iteration: 48643 | Cost/Loss: 0.077570 | Weight: 0.529311 | Bias: 0.070608\n",
            "Iteration: 48644 | Cost/Loss: 0.077570 | Weight: 0.529311 | Bias: 0.070608\n",
            "Iteration: 48645 | Cost/Loss: 0.077570 | Weight: 0.529312 | Bias: 0.070609\n",
            "Iteration: 48646 | Cost/Loss: 0.077570 | Weight: 0.529312 | Bias: 0.070609\n",
            "Iteration: 48647 | Cost/Loss: 0.077570 | Weight: 0.529312 | Bias: 0.070609\n",
            "Iteration: 48648 | Cost/Loss: 0.077570 | Weight: 0.529313 | Bias: 0.070610\n",
            "Iteration: 48649 | Cost/Loss: 0.077570 | Weight: 0.529313 | Bias: 0.070610\n",
            "Iteration: 48650 | Cost/Loss: 0.077570 | Weight: 0.529313 | Bias: 0.070610\n",
            "Iteration: 48651 | Cost/Loss: 0.077570 | Weight: 0.529314 | Bias: 0.070611\n",
            "Iteration: 48652 | Cost/Loss: 0.077570 | Weight: 0.529314 | Bias: 0.070611\n",
            "Iteration: 48653 | Cost/Loss: 0.077570 | Weight: 0.529314 | Bias: 0.070611\n",
            "Iteration: 48654 | Cost/Loss: 0.077570 | Weight: 0.529314 | Bias: 0.070612\n",
            "Iteration: 48655 | Cost/Loss: 0.077570 | Weight: 0.529315 | Bias: 0.070612\n",
            "Iteration: 48656 | Cost/Loss: 0.077570 | Weight: 0.529315 | Bias: 0.070612\n",
            "Iteration: 48657 | Cost/Loss: 0.077570 | Weight: 0.529315 | Bias: 0.070613\n",
            "Iteration: 48658 | Cost/Loss: 0.077570 | Weight: 0.529316 | Bias: 0.070613\n",
            "Iteration: 48659 | Cost/Loss: 0.077570 | Weight: 0.529316 | Bias: 0.070613\n",
            "Iteration: 48660 | Cost/Loss: 0.077570 | Weight: 0.529316 | Bias: 0.070613\n",
            "Iteration: 48661 | Cost/Loss: 0.077570 | Weight: 0.529316 | Bias: 0.070614\n",
            "Iteration: 48662 | Cost/Loss: 0.077570 | Weight: 0.529317 | Bias: 0.070614\n",
            "Iteration: 48663 | Cost/Loss: 0.077570 | Weight: 0.529317 | Bias: 0.070614\n",
            "Iteration: 48664 | Cost/Loss: 0.077570 | Weight: 0.529317 | Bias: 0.070615\n",
            "Iteration: 48665 | Cost/Loss: 0.077570 | Weight: 0.529318 | Bias: 0.070615\n",
            "Iteration: 48666 | Cost/Loss: 0.077570 | Weight: 0.529318 | Bias: 0.070615\n",
            "Iteration: 48667 | Cost/Loss: 0.077570 | Weight: 0.529318 | Bias: 0.070616\n",
            "Iteration: 48668 | Cost/Loss: 0.077570 | Weight: 0.529319 | Bias: 0.070616\n",
            "Iteration: 48669 | Cost/Loss: 0.077570 | Weight: 0.529319 | Bias: 0.070616\n",
            "Iteration: 48670 | Cost/Loss: 0.077570 | Weight: 0.529319 | Bias: 0.070617\n",
            "Iteration: 48671 | Cost/Loss: 0.077570 | Weight: 0.529319 | Bias: 0.070617\n",
            "Iteration: 48672 | Cost/Loss: 0.077570 | Weight: 0.529320 | Bias: 0.070617\n",
            "Iteration: 48673 | Cost/Loss: 0.077570 | Weight: 0.529320 | Bias: 0.070618\n",
            "Iteration: 48674 | Cost/Loss: 0.077570 | Weight: 0.529320 | Bias: 0.070618\n",
            "Iteration: 48675 | Cost/Loss: 0.077570 | Weight: 0.529321 | Bias: 0.070618\n",
            "Iteration: 48676 | Cost/Loss: 0.077570 | Weight: 0.529321 | Bias: 0.070619\n",
            "Iteration: 48677 | Cost/Loss: 0.077570 | Weight: 0.529321 | Bias: 0.070619\n",
            "Iteration: 48678 | Cost/Loss: 0.077570 | Weight: 0.529322 | Bias: 0.070619\n",
            "Iteration: 48679 | Cost/Loss: 0.077570 | Weight: 0.529322 | Bias: 0.070620\n",
            "Iteration: 48680 | Cost/Loss: 0.077570 | Weight: 0.529322 | Bias: 0.070620\n",
            "Iteration: 48681 | Cost/Loss: 0.077570 | Weight: 0.529322 | Bias: 0.070620\n",
            "Iteration: 48682 | Cost/Loss: 0.077570 | Weight: 0.529323 | Bias: 0.070621\n",
            "Iteration: 48683 | Cost/Loss: 0.077569 | Weight: 0.529323 | Bias: 0.070621\n",
            "Iteration: 48684 | Cost/Loss: 0.077569 | Weight: 0.529323 | Bias: 0.070621\n",
            "Iteration: 48685 | Cost/Loss: 0.077569 | Weight: 0.529324 | Bias: 0.070622\n",
            "Iteration: 48686 | Cost/Loss: 0.077569 | Weight: 0.529324 | Bias: 0.070622\n",
            "Iteration: 48687 | Cost/Loss: 0.077569 | Weight: 0.529324 | Bias: 0.070622\n",
            "Iteration: 48688 | Cost/Loss: 0.077569 | Weight: 0.529325 | Bias: 0.070622\n",
            "Iteration: 48689 | Cost/Loss: 0.077569 | Weight: 0.529325 | Bias: 0.070623\n",
            "Iteration: 48690 | Cost/Loss: 0.077569 | Weight: 0.529325 | Bias: 0.070623\n",
            "Iteration: 48691 | Cost/Loss: 0.077569 | Weight: 0.529325 | Bias: 0.070623\n",
            "Iteration: 48692 | Cost/Loss: 0.077569 | Weight: 0.529326 | Bias: 0.070624\n",
            "Iteration: 48693 | Cost/Loss: 0.077569 | Weight: 0.529326 | Bias: 0.070624\n",
            "Iteration: 48694 | Cost/Loss: 0.077569 | Weight: 0.529326 | Bias: 0.070624\n",
            "Iteration: 48695 | Cost/Loss: 0.077569 | Weight: 0.529327 | Bias: 0.070625\n",
            "Iteration: 48696 | Cost/Loss: 0.077569 | Weight: 0.529327 | Bias: 0.070625\n",
            "Iteration: 48697 | Cost/Loss: 0.077569 | Weight: 0.529327 | Bias: 0.070625\n",
            "Iteration: 48698 | Cost/Loss: 0.077569 | Weight: 0.529328 | Bias: 0.070626\n",
            "Iteration: 48699 | Cost/Loss: 0.077569 | Weight: 0.529328 | Bias: 0.070626\n",
            "Iteration: 48700 | Cost/Loss: 0.077569 | Weight: 0.529328 | Bias: 0.070626\n",
            "Iteration: 48701 | Cost/Loss: 0.077569 | Weight: 0.529328 | Bias: 0.070627\n",
            "Iteration: 48702 | Cost/Loss: 0.077569 | Weight: 0.529329 | Bias: 0.070627\n",
            "Iteration: 48703 | Cost/Loss: 0.077569 | Weight: 0.529329 | Bias: 0.070627\n",
            "Iteration: 48704 | Cost/Loss: 0.077569 | Weight: 0.529329 | Bias: 0.070628\n",
            "Iteration: 48705 | Cost/Loss: 0.077569 | Weight: 0.529330 | Bias: 0.070628\n",
            "Iteration: 48706 | Cost/Loss: 0.077569 | Weight: 0.529330 | Bias: 0.070628\n",
            "Iteration: 48707 | Cost/Loss: 0.077569 | Weight: 0.529330 | Bias: 0.070629\n",
            "Iteration: 48708 | Cost/Loss: 0.077569 | Weight: 0.529330 | Bias: 0.070629\n",
            "Iteration: 48709 | Cost/Loss: 0.077569 | Weight: 0.529331 | Bias: 0.070629\n",
            "Iteration: 48710 | Cost/Loss: 0.077569 | Weight: 0.529331 | Bias: 0.070630\n",
            "Iteration: 48711 | Cost/Loss: 0.077569 | Weight: 0.529331 | Bias: 0.070630\n",
            "Iteration: 48712 | Cost/Loss: 0.077569 | Weight: 0.529332 | Bias: 0.070630\n",
            "Iteration: 48713 | Cost/Loss: 0.077569 | Weight: 0.529332 | Bias: 0.070630\n",
            "Iteration: 48714 | Cost/Loss: 0.077569 | Weight: 0.529332 | Bias: 0.070631\n",
            "Iteration: 48715 | Cost/Loss: 0.077569 | Weight: 0.529333 | Bias: 0.070631\n",
            "Iteration: 48716 | Cost/Loss: 0.077569 | Weight: 0.529333 | Bias: 0.070631\n",
            "Iteration: 48717 | Cost/Loss: 0.077569 | Weight: 0.529333 | Bias: 0.070632\n",
            "Iteration: 48718 | Cost/Loss: 0.077569 | Weight: 0.529333 | Bias: 0.070632\n",
            "Iteration: 48719 | Cost/Loss: 0.077569 | Weight: 0.529334 | Bias: 0.070632\n",
            "Iteration: 48720 | Cost/Loss: 0.077569 | Weight: 0.529334 | Bias: 0.070633\n",
            "Iteration: 48721 | Cost/Loss: 0.077569 | Weight: 0.529334 | Bias: 0.070633\n",
            "Iteration: 48722 | Cost/Loss: 0.077569 | Weight: 0.529335 | Bias: 0.070633\n",
            "Iteration: 48723 | Cost/Loss: 0.077568 | Weight: 0.529335 | Bias: 0.070634\n",
            "Iteration: 48724 | Cost/Loss: 0.077568 | Weight: 0.529335 | Bias: 0.070634\n",
            "Iteration: 48725 | Cost/Loss: 0.077568 | Weight: 0.529336 | Bias: 0.070634\n",
            "Iteration: 48726 | Cost/Loss: 0.077568 | Weight: 0.529336 | Bias: 0.070635\n",
            "Iteration: 48727 | Cost/Loss: 0.077568 | Weight: 0.529336 | Bias: 0.070635\n",
            "Iteration: 48728 | Cost/Loss: 0.077568 | Weight: 0.529336 | Bias: 0.070635\n",
            "Iteration: 48729 | Cost/Loss: 0.077568 | Weight: 0.529337 | Bias: 0.070636\n",
            "Iteration: 48730 | Cost/Loss: 0.077568 | Weight: 0.529337 | Bias: 0.070636\n",
            "Iteration: 48731 | Cost/Loss: 0.077568 | Weight: 0.529337 | Bias: 0.070636\n",
            "Iteration: 48732 | Cost/Loss: 0.077568 | Weight: 0.529338 | Bias: 0.070637\n",
            "Iteration: 48733 | Cost/Loss: 0.077568 | Weight: 0.529338 | Bias: 0.070637\n",
            "Iteration: 48734 | Cost/Loss: 0.077568 | Weight: 0.529338 | Bias: 0.070637\n",
            "Iteration: 48735 | Cost/Loss: 0.077568 | Weight: 0.529339 | Bias: 0.070638\n",
            "Iteration: 48736 | Cost/Loss: 0.077568 | Weight: 0.529339 | Bias: 0.070638\n",
            "Iteration: 48737 | Cost/Loss: 0.077568 | Weight: 0.529339 | Bias: 0.070638\n",
            "Iteration: 48738 | Cost/Loss: 0.077568 | Weight: 0.529339 | Bias: 0.070638\n",
            "Iteration: 48739 | Cost/Loss: 0.077568 | Weight: 0.529340 | Bias: 0.070639\n",
            "Iteration: 48740 | Cost/Loss: 0.077568 | Weight: 0.529340 | Bias: 0.070639\n",
            "Iteration: 48741 | Cost/Loss: 0.077568 | Weight: 0.529340 | Bias: 0.070639\n",
            "Iteration: 48742 | Cost/Loss: 0.077568 | Weight: 0.529341 | Bias: 0.070640\n",
            "Iteration: 48743 | Cost/Loss: 0.077568 | Weight: 0.529341 | Bias: 0.070640\n",
            "Iteration: 48744 | Cost/Loss: 0.077568 | Weight: 0.529341 | Bias: 0.070640\n",
            "Iteration: 48745 | Cost/Loss: 0.077568 | Weight: 0.529342 | Bias: 0.070641\n",
            "Iteration: 48746 | Cost/Loss: 0.077568 | Weight: 0.529342 | Bias: 0.070641\n",
            "Iteration: 48747 | Cost/Loss: 0.077568 | Weight: 0.529342 | Bias: 0.070641\n",
            "Iteration: 48748 | Cost/Loss: 0.077568 | Weight: 0.529342 | Bias: 0.070642\n",
            "Iteration: 48749 | Cost/Loss: 0.077568 | Weight: 0.529343 | Bias: 0.070642\n",
            "Iteration: 48750 | Cost/Loss: 0.077568 | Weight: 0.529343 | Bias: 0.070642\n",
            "Iteration: 48751 | Cost/Loss: 0.077568 | Weight: 0.529343 | Bias: 0.070643\n",
            "Iteration: 48752 | Cost/Loss: 0.077568 | Weight: 0.529344 | Bias: 0.070643\n",
            "Iteration: 48753 | Cost/Loss: 0.077568 | Weight: 0.529344 | Bias: 0.070643\n",
            "Iteration: 48754 | Cost/Loss: 0.077568 | Weight: 0.529344 | Bias: 0.070644\n",
            "Iteration: 48755 | Cost/Loss: 0.077568 | Weight: 0.529344 | Bias: 0.070644\n",
            "Iteration: 48756 | Cost/Loss: 0.077568 | Weight: 0.529345 | Bias: 0.070644\n",
            "Iteration: 48757 | Cost/Loss: 0.077568 | Weight: 0.529345 | Bias: 0.070645\n",
            "Iteration: 48758 | Cost/Loss: 0.077568 | Weight: 0.529345 | Bias: 0.070645\n",
            "Iteration: 48759 | Cost/Loss: 0.077568 | Weight: 0.529346 | Bias: 0.070645\n",
            "Iteration: 48760 | Cost/Loss: 0.077568 | Weight: 0.529346 | Bias: 0.070646\n",
            "Iteration: 48761 | Cost/Loss: 0.077568 | Weight: 0.529346 | Bias: 0.070646\n",
            "Iteration: 48762 | Cost/Loss: 0.077567 | Weight: 0.529347 | Bias: 0.070646\n",
            "Iteration: 48763 | Cost/Loss: 0.077567 | Weight: 0.529347 | Bias: 0.070646\n",
            "Iteration: 48764 | Cost/Loss: 0.077567 | Weight: 0.529347 | Bias: 0.070647\n",
            "Iteration: 48765 | Cost/Loss: 0.077567 | Weight: 0.529347 | Bias: 0.070647\n",
            "Iteration: 48766 | Cost/Loss: 0.077567 | Weight: 0.529348 | Bias: 0.070647\n",
            "Iteration: 48767 | Cost/Loss: 0.077567 | Weight: 0.529348 | Bias: 0.070648\n",
            "Iteration: 48768 | Cost/Loss: 0.077567 | Weight: 0.529348 | Bias: 0.070648\n",
            "Iteration: 48769 | Cost/Loss: 0.077567 | Weight: 0.529349 | Bias: 0.070648\n",
            "Iteration: 48770 | Cost/Loss: 0.077567 | Weight: 0.529349 | Bias: 0.070649\n",
            "Iteration: 48771 | Cost/Loss: 0.077567 | Weight: 0.529349 | Bias: 0.070649\n",
            "Iteration: 48772 | Cost/Loss: 0.077567 | Weight: 0.529350 | Bias: 0.070649\n",
            "Iteration: 48773 | Cost/Loss: 0.077567 | Weight: 0.529350 | Bias: 0.070650\n",
            "Iteration: 48774 | Cost/Loss: 0.077567 | Weight: 0.529350 | Bias: 0.070650\n",
            "Iteration: 48775 | Cost/Loss: 0.077567 | Weight: 0.529350 | Bias: 0.070650\n",
            "Iteration: 48776 | Cost/Loss: 0.077567 | Weight: 0.529351 | Bias: 0.070651\n",
            "Iteration: 48777 | Cost/Loss: 0.077567 | Weight: 0.529351 | Bias: 0.070651\n",
            "Iteration: 48778 | Cost/Loss: 0.077567 | Weight: 0.529351 | Bias: 0.070651\n",
            "Iteration: 48779 | Cost/Loss: 0.077567 | Weight: 0.529352 | Bias: 0.070652\n",
            "Iteration: 48780 | Cost/Loss: 0.077567 | Weight: 0.529352 | Bias: 0.070652\n",
            "Iteration: 48781 | Cost/Loss: 0.077567 | Weight: 0.529352 | Bias: 0.070652\n",
            "Iteration: 48782 | Cost/Loss: 0.077567 | Weight: 0.529353 | Bias: 0.070653\n",
            "Iteration: 48783 | Cost/Loss: 0.077567 | Weight: 0.529353 | Bias: 0.070653\n",
            "Iteration: 48784 | Cost/Loss: 0.077567 | Weight: 0.529353 | Bias: 0.070653\n",
            "Iteration: 48785 | Cost/Loss: 0.077567 | Weight: 0.529353 | Bias: 0.070654\n",
            "Iteration: 48786 | Cost/Loss: 0.077567 | Weight: 0.529354 | Bias: 0.070654\n",
            "Iteration: 48787 | Cost/Loss: 0.077567 | Weight: 0.529354 | Bias: 0.070654\n",
            "Iteration: 48788 | Cost/Loss: 0.077567 | Weight: 0.529354 | Bias: 0.070655\n",
            "Iteration: 48789 | Cost/Loss: 0.077567 | Weight: 0.529355 | Bias: 0.070655\n",
            "Iteration: 48790 | Cost/Loss: 0.077567 | Weight: 0.529355 | Bias: 0.070655\n",
            "Iteration: 48791 | Cost/Loss: 0.077567 | Weight: 0.529355 | Bias: 0.070655\n",
            "Iteration: 48792 | Cost/Loss: 0.077567 | Weight: 0.529356 | Bias: 0.070656\n",
            "Iteration: 48793 | Cost/Loss: 0.077567 | Weight: 0.529356 | Bias: 0.070656\n",
            "Iteration: 48794 | Cost/Loss: 0.077567 | Weight: 0.529356 | Bias: 0.070656\n",
            "Iteration: 48795 | Cost/Loss: 0.077567 | Weight: 0.529356 | Bias: 0.070657\n",
            "Iteration: 48796 | Cost/Loss: 0.077567 | Weight: 0.529357 | Bias: 0.070657\n",
            "Iteration: 48797 | Cost/Loss: 0.077567 | Weight: 0.529357 | Bias: 0.070657\n",
            "Iteration: 48798 | Cost/Loss: 0.077567 | Weight: 0.529357 | Bias: 0.070658\n",
            "Iteration: 48799 | Cost/Loss: 0.077567 | Weight: 0.529358 | Bias: 0.070658\n",
            "Iteration: 48800 | Cost/Loss: 0.077567 | Weight: 0.529358 | Bias: 0.070658\n",
            "Iteration: 48801 | Cost/Loss: 0.077567 | Weight: 0.529358 | Bias: 0.070659\n",
            "Iteration: 48802 | Cost/Loss: 0.077566 | Weight: 0.529359 | Bias: 0.070659\n",
            "Iteration: 48803 | Cost/Loss: 0.077566 | Weight: 0.529359 | Bias: 0.070659\n",
            "Iteration: 48804 | Cost/Loss: 0.077566 | Weight: 0.529359 | Bias: 0.070660\n",
            "Iteration: 48805 | Cost/Loss: 0.077566 | Weight: 0.529359 | Bias: 0.070660\n",
            "Iteration: 48806 | Cost/Loss: 0.077566 | Weight: 0.529360 | Bias: 0.070660\n",
            "Iteration: 48807 | Cost/Loss: 0.077566 | Weight: 0.529360 | Bias: 0.070661\n",
            "Iteration: 48808 | Cost/Loss: 0.077566 | Weight: 0.529360 | Bias: 0.070661\n",
            "Iteration: 48809 | Cost/Loss: 0.077566 | Weight: 0.529361 | Bias: 0.070661\n",
            "Iteration: 48810 | Cost/Loss: 0.077566 | Weight: 0.529361 | Bias: 0.070662\n",
            "Iteration: 48811 | Cost/Loss: 0.077566 | Weight: 0.529361 | Bias: 0.070662\n",
            "Iteration: 48812 | Cost/Loss: 0.077566 | Weight: 0.529361 | Bias: 0.070662\n",
            "Iteration: 48813 | Cost/Loss: 0.077566 | Weight: 0.529362 | Bias: 0.070663\n",
            "Iteration: 48814 | Cost/Loss: 0.077566 | Weight: 0.529362 | Bias: 0.070663\n",
            "Iteration: 48815 | Cost/Loss: 0.077566 | Weight: 0.529362 | Bias: 0.070663\n",
            "Iteration: 48816 | Cost/Loss: 0.077566 | Weight: 0.529363 | Bias: 0.070663\n",
            "Iteration: 48817 | Cost/Loss: 0.077566 | Weight: 0.529363 | Bias: 0.070664\n",
            "Iteration: 48818 | Cost/Loss: 0.077566 | Weight: 0.529363 | Bias: 0.070664\n",
            "Iteration: 48819 | Cost/Loss: 0.077566 | Weight: 0.529364 | Bias: 0.070664\n",
            "Iteration: 48820 | Cost/Loss: 0.077566 | Weight: 0.529364 | Bias: 0.070665\n",
            "Iteration: 48821 | Cost/Loss: 0.077566 | Weight: 0.529364 | Bias: 0.070665\n",
            "Iteration: 48822 | Cost/Loss: 0.077566 | Weight: 0.529364 | Bias: 0.070665\n",
            "Iteration: 48823 | Cost/Loss: 0.077566 | Weight: 0.529365 | Bias: 0.070666\n",
            "Iteration: 48824 | Cost/Loss: 0.077566 | Weight: 0.529365 | Bias: 0.070666\n",
            "Iteration: 48825 | Cost/Loss: 0.077566 | Weight: 0.529365 | Bias: 0.070666\n",
            "Iteration: 48826 | Cost/Loss: 0.077566 | Weight: 0.529366 | Bias: 0.070667\n",
            "Iteration: 48827 | Cost/Loss: 0.077566 | Weight: 0.529366 | Bias: 0.070667\n",
            "Iteration: 48828 | Cost/Loss: 0.077566 | Weight: 0.529366 | Bias: 0.070667\n",
            "Iteration: 48829 | Cost/Loss: 0.077566 | Weight: 0.529367 | Bias: 0.070668\n",
            "Iteration: 48830 | Cost/Loss: 0.077566 | Weight: 0.529367 | Bias: 0.070668\n",
            "Iteration: 48831 | Cost/Loss: 0.077566 | Weight: 0.529367 | Bias: 0.070668\n",
            "Iteration: 48832 | Cost/Loss: 0.077566 | Weight: 0.529367 | Bias: 0.070669\n",
            "Iteration: 48833 | Cost/Loss: 0.077566 | Weight: 0.529368 | Bias: 0.070669\n",
            "Iteration: 48834 | Cost/Loss: 0.077566 | Weight: 0.529368 | Bias: 0.070669\n",
            "Iteration: 48835 | Cost/Loss: 0.077566 | Weight: 0.529368 | Bias: 0.070670\n",
            "Iteration: 48836 | Cost/Loss: 0.077566 | Weight: 0.529369 | Bias: 0.070670\n",
            "Iteration: 48837 | Cost/Loss: 0.077566 | Weight: 0.529369 | Bias: 0.070670\n",
            "Iteration: 48838 | Cost/Loss: 0.077566 | Weight: 0.529369 | Bias: 0.070671\n",
            "Iteration: 48839 | Cost/Loss: 0.077566 | Weight: 0.529370 | Bias: 0.070671\n",
            "Iteration: 48840 | Cost/Loss: 0.077566 | Weight: 0.529370 | Bias: 0.070671\n",
            "Iteration: 48841 | Cost/Loss: 0.077566 | Weight: 0.529370 | Bias: 0.070671\n",
            "Iteration: 48842 | Cost/Loss: 0.077565 | Weight: 0.529370 | Bias: 0.070672\n",
            "Iteration: 48843 | Cost/Loss: 0.077565 | Weight: 0.529371 | Bias: 0.070672\n",
            "Iteration: 48844 | Cost/Loss: 0.077565 | Weight: 0.529371 | Bias: 0.070672\n",
            "Iteration: 48845 | Cost/Loss: 0.077565 | Weight: 0.529371 | Bias: 0.070673\n",
            "Iteration: 48846 | Cost/Loss: 0.077565 | Weight: 0.529372 | Bias: 0.070673\n",
            "Iteration: 48847 | Cost/Loss: 0.077565 | Weight: 0.529372 | Bias: 0.070673\n",
            "Iteration: 48848 | Cost/Loss: 0.077565 | Weight: 0.529372 | Bias: 0.070674\n",
            "Iteration: 48849 | Cost/Loss: 0.077565 | Weight: 0.529373 | Bias: 0.070674\n",
            "Iteration: 48850 | Cost/Loss: 0.077565 | Weight: 0.529373 | Bias: 0.070674\n",
            "Iteration: 48851 | Cost/Loss: 0.077565 | Weight: 0.529373 | Bias: 0.070675\n",
            "Iteration: 48852 | Cost/Loss: 0.077565 | Weight: 0.529373 | Bias: 0.070675\n",
            "Iteration: 48853 | Cost/Loss: 0.077565 | Weight: 0.529374 | Bias: 0.070675\n",
            "Iteration: 48854 | Cost/Loss: 0.077565 | Weight: 0.529374 | Bias: 0.070676\n",
            "Iteration: 48855 | Cost/Loss: 0.077565 | Weight: 0.529374 | Bias: 0.070676\n",
            "Iteration: 48856 | Cost/Loss: 0.077565 | Weight: 0.529375 | Bias: 0.070676\n",
            "Iteration: 48857 | Cost/Loss: 0.077565 | Weight: 0.529375 | Bias: 0.070677\n",
            "Iteration: 48858 | Cost/Loss: 0.077565 | Weight: 0.529375 | Bias: 0.070677\n",
            "Iteration: 48859 | Cost/Loss: 0.077565 | Weight: 0.529375 | Bias: 0.070677\n",
            "Iteration: 48860 | Cost/Loss: 0.077565 | Weight: 0.529376 | Bias: 0.070678\n",
            "Iteration: 48861 | Cost/Loss: 0.077565 | Weight: 0.529376 | Bias: 0.070678\n",
            "Iteration: 48862 | Cost/Loss: 0.077565 | Weight: 0.529376 | Bias: 0.070678\n",
            "Iteration: 48863 | Cost/Loss: 0.077565 | Weight: 0.529377 | Bias: 0.070679\n",
            "Iteration: 48864 | Cost/Loss: 0.077565 | Weight: 0.529377 | Bias: 0.070679\n",
            "Iteration: 48865 | Cost/Loss: 0.077565 | Weight: 0.529377 | Bias: 0.070679\n",
            "Iteration: 48866 | Cost/Loss: 0.077565 | Weight: 0.529378 | Bias: 0.070679\n",
            "Iteration: 48867 | Cost/Loss: 0.077565 | Weight: 0.529378 | Bias: 0.070680\n",
            "Iteration: 48868 | Cost/Loss: 0.077565 | Weight: 0.529378 | Bias: 0.070680\n",
            "Iteration: 48869 | Cost/Loss: 0.077565 | Weight: 0.529378 | Bias: 0.070680\n",
            "Iteration: 48870 | Cost/Loss: 0.077565 | Weight: 0.529379 | Bias: 0.070681\n",
            "Iteration: 48871 | Cost/Loss: 0.077565 | Weight: 0.529379 | Bias: 0.070681\n",
            "Iteration: 48872 | Cost/Loss: 0.077565 | Weight: 0.529379 | Bias: 0.070681\n",
            "Iteration: 48873 | Cost/Loss: 0.077565 | Weight: 0.529380 | Bias: 0.070682\n",
            "Iteration: 48874 | Cost/Loss: 0.077565 | Weight: 0.529380 | Bias: 0.070682\n",
            "Iteration: 48875 | Cost/Loss: 0.077565 | Weight: 0.529380 | Bias: 0.070682\n",
            "Iteration: 48876 | Cost/Loss: 0.077565 | Weight: 0.529381 | Bias: 0.070683\n",
            "Iteration: 48877 | Cost/Loss: 0.077565 | Weight: 0.529381 | Bias: 0.070683\n",
            "Iteration: 48878 | Cost/Loss: 0.077565 | Weight: 0.529381 | Bias: 0.070683\n",
            "Iteration: 48879 | Cost/Loss: 0.077565 | Weight: 0.529381 | Bias: 0.070684\n",
            "Iteration: 48880 | Cost/Loss: 0.077565 | Weight: 0.529382 | Bias: 0.070684\n",
            "Iteration: 48881 | Cost/Loss: 0.077564 | Weight: 0.529382 | Bias: 0.070684\n",
            "Iteration: 48882 | Cost/Loss: 0.077564 | Weight: 0.529382 | Bias: 0.070685\n",
            "Iteration: 48883 | Cost/Loss: 0.077564 | Weight: 0.529383 | Bias: 0.070685\n",
            "Iteration: 48884 | Cost/Loss: 0.077564 | Weight: 0.529383 | Bias: 0.070685\n",
            "Iteration: 48885 | Cost/Loss: 0.077564 | Weight: 0.529383 | Bias: 0.070686\n",
            "Iteration: 48886 | Cost/Loss: 0.077564 | Weight: 0.529384 | Bias: 0.070686\n",
            "Iteration: 48887 | Cost/Loss: 0.077564 | Weight: 0.529384 | Bias: 0.070686\n",
            "Iteration: 48888 | Cost/Loss: 0.077564 | Weight: 0.529384 | Bias: 0.070687\n",
            "Iteration: 48889 | Cost/Loss: 0.077564 | Weight: 0.529384 | Bias: 0.070687\n",
            "Iteration: 48890 | Cost/Loss: 0.077564 | Weight: 0.529385 | Bias: 0.070687\n",
            "Iteration: 48891 | Cost/Loss: 0.077564 | Weight: 0.529385 | Bias: 0.070688\n",
            "Iteration: 48892 | Cost/Loss: 0.077564 | Weight: 0.529385 | Bias: 0.070688\n",
            "Iteration: 48893 | Cost/Loss: 0.077564 | Weight: 0.529386 | Bias: 0.070688\n",
            "Iteration: 48894 | Cost/Loss: 0.077564 | Weight: 0.529386 | Bias: 0.070688\n",
            "Iteration: 48895 | Cost/Loss: 0.077564 | Weight: 0.529386 | Bias: 0.070689\n",
            "Iteration: 48896 | Cost/Loss: 0.077564 | Weight: 0.529387 | Bias: 0.070689\n",
            "Iteration: 48897 | Cost/Loss: 0.077564 | Weight: 0.529387 | Bias: 0.070689\n",
            "Iteration: 48898 | Cost/Loss: 0.077564 | Weight: 0.529387 | Bias: 0.070690\n",
            "Iteration: 48899 | Cost/Loss: 0.077564 | Weight: 0.529387 | Bias: 0.070690\n",
            "Iteration: 48900 | Cost/Loss: 0.077564 | Weight: 0.529388 | Bias: 0.070690\n",
            "Iteration: 48901 | Cost/Loss: 0.077564 | Weight: 0.529388 | Bias: 0.070691\n",
            "Iteration: 48902 | Cost/Loss: 0.077564 | Weight: 0.529388 | Bias: 0.070691\n",
            "Iteration: 48903 | Cost/Loss: 0.077564 | Weight: 0.529389 | Bias: 0.070691\n",
            "Iteration: 48904 | Cost/Loss: 0.077564 | Weight: 0.529389 | Bias: 0.070692\n",
            "Iteration: 48905 | Cost/Loss: 0.077564 | Weight: 0.529389 | Bias: 0.070692\n",
            "Iteration: 48906 | Cost/Loss: 0.077564 | Weight: 0.529390 | Bias: 0.070692\n",
            "Iteration: 48907 | Cost/Loss: 0.077564 | Weight: 0.529390 | Bias: 0.070693\n",
            "Iteration: 48908 | Cost/Loss: 0.077564 | Weight: 0.529390 | Bias: 0.070693\n",
            "Iteration: 48909 | Cost/Loss: 0.077564 | Weight: 0.529390 | Bias: 0.070693\n",
            "Iteration: 48910 | Cost/Loss: 0.077564 | Weight: 0.529391 | Bias: 0.070694\n",
            "Iteration: 48911 | Cost/Loss: 0.077564 | Weight: 0.529391 | Bias: 0.070694\n",
            "Iteration: 48912 | Cost/Loss: 0.077564 | Weight: 0.529391 | Bias: 0.070694\n",
            "Iteration: 48913 | Cost/Loss: 0.077564 | Weight: 0.529392 | Bias: 0.070695\n",
            "Iteration: 48914 | Cost/Loss: 0.077564 | Weight: 0.529392 | Bias: 0.070695\n",
            "Iteration: 48915 | Cost/Loss: 0.077564 | Weight: 0.529392 | Bias: 0.070695\n",
            "Iteration: 48916 | Cost/Loss: 0.077564 | Weight: 0.529392 | Bias: 0.070696\n",
            "Iteration: 48917 | Cost/Loss: 0.077564 | Weight: 0.529393 | Bias: 0.070696\n",
            "Iteration: 48918 | Cost/Loss: 0.077564 | Weight: 0.529393 | Bias: 0.070696\n",
            "Iteration: 48919 | Cost/Loss: 0.077564 | Weight: 0.529393 | Bias: 0.070696\n",
            "Iteration: 48920 | Cost/Loss: 0.077564 | Weight: 0.529394 | Bias: 0.070697\n",
            "Iteration: 48921 | Cost/Loss: 0.077563 | Weight: 0.529394 | Bias: 0.070697\n",
            "Iteration: 48922 | Cost/Loss: 0.077563 | Weight: 0.529394 | Bias: 0.070697\n",
            "Iteration: 48923 | Cost/Loss: 0.077563 | Weight: 0.529395 | Bias: 0.070698\n",
            "Iteration: 48924 | Cost/Loss: 0.077563 | Weight: 0.529395 | Bias: 0.070698\n",
            "Iteration: 48925 | Cost/Loss: 0.077563 | Weight: 0.529395 | Bias: 0.070698\n",
            "Iteration: 48926 | Cost/Loss: 0.077563 | Weight: 0.529395 | Bias: 0.070699\n",
            "Iteration: 48927 | Cost/Loss: 0.077563 | Weight: 0.529396 | Bias: 0.070699\n",
            "Iteration: 48928 | Cost/Loss: 0.077563 | Weight: 0.529396 | Bias: 0.070699\n",
            "Iteration: 48929 | Cost/Loss: 0.077563 | Weight: 0.529396 | Bias: 0.070700\n",
            "Iteration: 48930 | Cost/Loss: 0.077563 | Weight: 0.529397 | Bias: 0.070700\n",
            "Iteration: 48931 | Cost/Loss: 0.077563 | Weight: 0.529397 | Bias: 0.070700\n",
            "Iteration: 48932 | Cost/Loss: 0.077563 | Weight: 0.529397 | Bias: 0.070701\n",
            "Iteration: 48933 | Cost/Loss: 0.077563 | Weight: 0.529398 | Bias: 0.070701\n",
            "Iteration: 48934 | Cost/Loss: 0.077563 | Weight: 0.529398 | Bias: 0.070701\n",
            "Iteration: 48935 | Cost/Loss: 0.077563 | Weight: 0.529398 | Bias: 0.070702\n",
            "Iteration: 48936 | Cost/Loss: 0.077563 | Weight: 0.529398 | Bias: 0.070702\n",
            "Iteration: 48937 | Cost/Loss: 0.077563 | Weight: 0.529399 | Bias: 0.070702\n",
            "Iteration: 48938 | Cost/Loss: 0.077563 | Weight: 0.529399 | Bias: 0.070703\n",
            "Iteration: 48939 | Cost/Loss: 0.077563 | Weight: 0.529399 | Bias: 0.070703\n",
            "Iteration: 48940 | Cost/Loss: 0.077563 | Weight: 0.529400 | Bias: 0.070703\n",
            "Iteration: 48941 | Cost/Loss: 0.077563 | Weight: 0.529400 | Bias: 0.070704\n",
            "Iteration: 48942 | Cost/Loss: 0.077563 | Weight: 0.529400 | Bias: 0.070704\n",
            "Iteration: 48943 | Cost/Loss: 0.077563 | Weight: 0.529401 | Bias: 0.070704\n",
            "Iteration: 48944 | Cost/Loss: 0.077563 | Weight: 0.529401 | Bias: 0.070704\n",
            "Iteration: 48945 | Cost/Loss: 0.077563 | Weight: 0.529401 | Bias: 0.070705\n",
            "Iteration: 48946 | Cost/Loss: 0.077563 | Weight: 0.529401 | Bias: 0.070705\n",
            "Iteration: 48947 | Cost/Loss: 0.077563 | Weight: 0.529402 | Bias: 0.070705\n",
            "Iteration: 48948 | Cost/Loss: 0.077563 | Weight: 0.529402 | Bias: 0.070706\n",
            "Iteration: 48949 | Cost/Loss: 0.077563 | Weight: 0.529402 | Bias: 0.070706\n",
            "Iteration: 48950 | Cost/Loss: 0.077563 | Weight: 0.529403 | Bias: 0.070706\n",
            "Iteration: 48951 | Cost/Loss: 0.077563 | Weight: 0.529403 | Bias: 0.070707\n",
            "Iteration: 48952 | Cost/Loss: 0.077563 | Weight: 0.529403 | Bias: 0.070707\n",
            "Iteration: 48953 | Cost/Loss: 0.077563 | Weight: 0.529404 | Bias: 0.070707\n",
            "Iteration: 48954 | Cost/Loss: 0.077563 | Weight: 0.529404 | Bias: 0.070708\n",
            "Iteration: 48955 | Cost/Loss: 0.077563 | Weight: 0.529404 | Bias: 0.070708\n",
            "Iteration: 48956 | Cost/Loss: 0.077563 | Weight: 0.529404 | Bias: 0.070708\n",
            "Iteration: 48957 | Cost/Loss: 0.077563 | Weight: 0.529405 | Bias: 0.070709\n",
            "Iteration: 48958 | Cost/Loss: 0.077563 | Weight: 0.529405 | Bias: 0.070709\n",
            "Iteration: 48959 | Cost/Loss: 0.077563 | Weight: 0.529405 | Bias: 0.070709\n",
            "Iteration: 48960 | Cost/Loss: 0.077563 | Weight: 0.529406 | Bias: 0.070709\n",
            "Iteration: 48961 | Cost/Loss: 0.077562 | Weight: 0.529406 | Bias: 0.070710\n",
            "Iteration: 48962 | Cost/Loss: 0.077562 | Weight: 0.529406 | Bias: 0.070710\n",
            "Iteration: 48963 | Cost/Loss: 0.077562 | Weight: 0.529406 | Bias: 0.070710\n",
            "Iteration: 48964 | Cost/Loss: 0.077562 | Weight: 0.529407 | Bias: 0.070711\n",
            "Iteration: 48965 | Cost/Loss: 0.077562 | Weight: 0.529407 | Bias: 0.070711\n",
            "Iteration: 48966 | Cost/Loss: 0.077562 | Weight: 0.529407 | Bias: 0.070711\n",
            "Iteration: 48967 | Cost/Loss: 0.077562 | Weight: 0.529408 | Bias: 0.070712\n",
            "Iteration: 48968 | Cost/Loss: 0.077562 | Weight: 0.529408 | Bias: 0.070712\n",
            "Iteration: 48969 | Cost/Loss: 0.077562 | Weight: 0.529408 | Bias: 0.070712\n",
            "Iteration: 48970 | Cost/Loss: 0.077562 | Weight: 0.529409 | Bias: 0.070713\n",
            "Iteration: 48971 | Cost/Loss: 0.077562 | Weight: 0.529409 | Bias: 0.070713\n",
            "Iteration: 48972 | Cost/Loss: 0.077562 | Weight: 0.529409 | Bias: 0.070713\n",
            "Iteration: 48973 | Cost/Loss: 0.077562 | Weight: 0.529409 | Bias: 0.070714\n",
            "Iteration: 48974 | Cost/Loss: 0.077562 | Weight: 0.529410 | Bias: 0.070714\n",
            "Iteration: 48975 | Cost/Loss: 0.077562 | Weight: 0.529410 | Bias: 0.070714\n",
            "Iteration: 48976 | Cost/Loss: 0.077562 | Weight: 0.529410 | Bias: 0.070714\n",
            "Iteration: 48977 | Cost/Loss: 0.077562 | Weight: 0.529411 | Bias: 0.070715\n",
            "Iteration: 48978 | Cost/Loss: 0.077562 | Weight: 0.529411 | Bias: 0.070715\n",
            "Iteration: 48979 | Cost/Loss: 0.077562 | Weight: 0.529411 | Bias: 0.070715\n",
            "Iteration: 48980 | Cost/Loss: 0.077562 | Weight: 0.529412 | Bias: 0.070716\n",
            "Iteration: 48981 | Cost/Loss: 0.077562 | Weight: 0.529412 | Bias: 0.070716\n",
            "Iteration: 48982 | Cost/Loss: 0.077562 | Weight: 0.529412 | Bias: 0.070716\n",
            "Iteration: 48983 | Cost/Loss: 0.077562 | Weight: 0.529412 | Bias: 0.070717\n",
            "Iteration: 48984 | Cost/Loss: 0.077562 | Weight: 0.529413 | Bias: 0.070717\n",
            "Iteration: 48985 | Cost/Loss: 0.077562 | Weight: 0.529413 | Bias: 0.070717\n",
            "Iteration: 48986 | Cost/Loss: 0.077562 | Weight: 0.529413 | Bias: 0.070718\n",
            "Iteration: 48987 | Cost/Loss: 0.077562 | Weight: 0.529414 | Bias: 0.070718\n",
            "Iteration: 48988 | Cost/Loss: 0.077562 | Weight: 0.529414 | Bias: 0.070718\n",
            "Iteration: 48989 | Cost/Loss: 0.077562 | Weight: 0.529414 | Bias: 0.070719\n",
            "Iteration: 48990 | Cost/Loss: 0.077562 | Weight: 0.529415 | Bias: 0.070719\n",
            "Iteration: 48991 | Cost/Loss: 0.077562 | Weight: 0.529415 | Bias: 0.070719\n",
            "Iteration: 48992 | Cost/Loss: 0.077562 | Weight: 0.529415 | Bias: 0.070719\n",
            "Iteration: 48993 | Cost/Loss: 0.077562 | Weight: 0.529415 | Bias: 0.070720\n",
            "Iteration: 48994 | Cost/Loss: 0.077562 | Weight: 0.529416 | Bias: 0.070720\n",
            "Iteration: 48995 | Cost/Loss: 0.077562 | Weight: 0.529416 | Bias: 0.070720\n",
            "Iteration: 48996 | Cost/Loss: 0.077562 | Weight: 0.529416 | Bias: 0.070721\n",
            "Iteration: 48997 | Cost/Loss: 0.077562 | Weight: 0.529417 | Bias: 0.070721\n",
            "Iteration: 48998 | Cost/Loss: 0.077562 | Weight: 0.529417 | Bias: 0.070721\n",
            "Iteration: 48999 | Cost/Loss: 0.077562 | Weight: 0.529417 | Bias: 0.070722\n",
            "Iteration: 49000 | Cost/Loss: 0.077562 | Weight: 0.529418 | Bias: 0.070722\n",
            "Iteration: 49001 | Cost/Loss: 0.077561 | Weight: 0.529418 | Bias: 0.070722\n",
            "Iteration: 49002 | Cost/Loss: 0.077561 | Weight: 0.529418 | Bias: 0.070723\n",
            "Iteration: 49003 | Cost/Loss: 0.077561 | Weight: 0.529418 | Bias: 0.070723\n",
            "Iteration: 49004 | Cost/Loss: 0.077561 | Weight: 0.529419 | Bias: 0.070723\n",
            "Iteration: 49005 | Cost/Loss: 0.077561 | Weight: 0.529419 | Bias: 0.070724\n",
            "Iteration: 49006 | Cost/Loss: 0.077561 | Weight: 0.529419 | Bias: 0.070724\n",
            "Iteration: 49007 | Cost/Loss: 0.077561 | Weight: 0.529420 | Bias: 0.070724\n",
            "Iteration: 49008 | Cost/Loss: 0.077561 | Weight: 0.529420 | Bias: 0.070724\n",
            "Iteration: 49009 | Cost/Loss: 0.077561 | Weight: 0.529420 | Bias: 0.070725\n",
            "Iteration: 49010 | Cost/Loss: 0.077561 | Weight: 0.529420 | Bias: 0.070725\n",
            "Iteration: 49011 | Cost/Loss: 0.077561 | Weight: 0.529421 | Bias: 0.070725\n",
            "Iteration: 49012 | Cost/Loss: 0.077561 | Weight: 0.529421 | Bias: 0.070726\n",
            "Iteration: 49013 | Cost/Loss: 0.077561 | Weight: 0.529421 | Bias: 0.070726\n",
            "Iteration: 49014 | Cost/Loss: 0.077561 | Weight: 0.529422 | Bias: 0.070726\n",
            "Iteration: 49015 | Cost/Loss: 0.077561 | Weight: 0.529422 | Bias: 0.070727\n",
            "Iteration: 49016 | Cost/Loss: 0.077561 | Weight: 0.529422 | Bias: 0.070727\n",
            "Iteration: 49017 | Cost/Loss: 0.077561 | Weight: 0.529423 | Bias: 0.070727\n",
            "Iteration: 49018 | Cost/Loss: 0.077561 | Weight: 0.529423 | Bias: 0.070728\n",
            "Iteration: 49019 | Cost/Loss: 0.077561 | Weight: 0.529423 | Bias: 0.070728\n",
            "Iteration: 49020 | Cost/Loss: 0.077561 | Weight: 0.529423 | Bias: 0.070728\n",
            "Iteration: 49021 | Cost/Loss: 0.077561 | Weight: 0.529424 | Bias: 0.070729\n",
            "Iteration: 49022 | Cost/Loss: 0.077561 | Weight: 0.529424 | Bias: 0.070729\n",
            "Iteration: 49023 | Cost/Loss: 0.077561 | Weight: 0.529424 | Bias: 0.070729\n",
            "Iteration: 49024 | Cost/Loss: 0.077561 | Weight: 0.529425 | Bias: 0.070729\n",
            "Iteration: 49025 | Cost/Loss: 0.077561 | Weight: 0.529425 | Bias: 0.070730\n",
            "Iteration: 49026 | Cost/Loss: 0.077561 | Weight: 0.529425 | Bias: 0.070730\n",
            "Iteration: 49027 | Cost/Loss: 0.077561 | Weight: 0.529426 | Bias: 0.070730\n",
            "Iteration: 49028 | Cost/Loss: 0.077561 | Weight: 0.529426 | Bias: 0.070731\n",
            "Iteration: 49029 | Cost/Loss: 0.077561 | Weight: 0.529426 | Bias: 0.070731\n",
            "Iteration: 49030 | Cost/Loss: 0.077561 | Weight: 0.529426 | Bias: 0.070731\n",
            "Iteration: 49031 | Cost/Loss: 0.077561 | Weight: 0.529427 | Bias: 0.070732\n",
            "Iteration: 49032 | Cost/Loss: 0.077561 | Weight: 0.529427 | Bias: 0.070732\n",
            "Iteration: 49033 | Cost/Loss: 0.077561 | Weight: 0.529427 | Bias: 0.070732\n",
            "Iteration: 49034 | Cost/Loss: 0.077561 | Weight: 0.529428 | Bias: 0.070733\n",
            "Iteration: 49035 | Cost/Loss: 0.077561 | Weight: 0.529428 | Bias: 0.070733\n",
            "Iteration: 49036 | Cost/Loss: 0.077561 | Weight: 0.529428 | Bias: 0.070733\n",
            "Iteration: 49037 | Cost/Loss: 0.077561 | Weight: 0.529429 | Bias: 0.070734\n",
            "Iteration: 49038 | Cost/Loss: 0.077561 | Weight: 0.529429 | Bias: 0.070734\n",
            "Iteration: 49039 | Cost/Loss: 0.077561 | Weight: 0.529429 | Bias: 0.070734\n",
            "Iteration: 49040 | Cost/Loss: 0.077561 | Weight: 0.529429 | Bias: 0.070734\n",
            "Iteration: 49041 | Cost/Loss: 0.077560 | Weight: 0.529430 | Bias: 0.070735\n",
            "Iteration: 49042 | Cost/Loss: 0.077560 | Weight: 0.529430 | Bias: 0.070735\n",
            "Iteration: 49043 | Cost/Loss: 0.077560 | Weight: 0.529430 | Bias: 0.070735\n",
            "Iteration: 49044 | Cost/Loss: 0.077560 | Weight: 0.529431 | Bias: 0.070736\n",
            "Iteration: 49045 | Cost/Loss: 0.077560 | Weight: 0.529431 | Bias: 0.070736\n",
            "Iteration: 49046 | Cost/Loss: 0.077560 | Weight: 0.529431 | Bias: 0.070736\n",
            "Iteration: 49047 | Cost/Loss: 0.077560 | Weight: 0.529432 | Bias: 0.070737\n",
            "Iteration: 49048 | Cost/Loss: 0.077560 | Weight: 0.529432 | Bias: 0.070737\n",
            "Iteration: 49049 | Cost/Loss: 0.077560 | Weight: 0.529432 | Bias: 0.070737\n",
            "Iteration: 49050 | Cost/Loss: 0.077560 | Weight: 0.529432 | Bias: 0.070738\n",
            "Iteration: 49051 | Cost/Loss: 0.077560 | Weight: 0.529433 | Bias: 0.070738\n",
            "Iteration: 49052 | Cost/Loss: 0.077560 | Weight: 0.529433 | Bias: 0.070738\n",
            "Iteration: 49053 | Cost/Loss: 0.077560 | Weight: 0.529433 | Bias: 0.070739\n",
            "Iteration: 49054 | Cost/Loss: 0.077560 | Weight: 0.529434 | Bias: 0.070739\n",
            "Iteration: 49055 | Cost/Loss: 0.077560 | Weight: 0.529434 | Bias: 0.070739\n",
            "Iteration: 49056 | Cost/Loss: 0.077560 | Weight: 0.529434 | Bias: 0.070739\n",
            "Iteration: 49057 | Cost/Loss: 0.077560 | Weight: 0.529435 | Bias: 0.070740\n",
            "Iteration: 49058 | Cost/Loss: 0.077560 | Weight: 0.529435 | Bias: 0.070740\n",
            "Iteration: 49059 | Cost/Loss: 0.077560 | Weight: 0.529435 | Bias: 0.070740\n",
            "Iteration: 49060 | Cost/Loss: 0.077560 | Weight: 0.529435 | Bias: 0.070741\n",
            "Iteration: 49061 | Cost/Loss: 0.077560 | Weight: 0.529436 | Bias: 0.070741\n",
            "Iteration: 49062 | Cost/Loss: 0.077560 | Weight: 0.529436 | Bias: 0.070741\n",
            "Iteration: 49063 | Cost/Loss: 0.077560 | Weight: 0.529436 | Bias: 0.070742\n",
            "Iteration: 49064 | Cost/Loss: 0.077560 | Weight: 0.529437 | Bias: 0.070742\n",
            "Iteration: 49065 | Cost/Loss: 0.077560 | Weight: 0.529437 | Bias: 0.070742\n",
            "Iteration: 49066 | Cost/Loss: 0.077560 | Weight: 0.529437 | Bias: 0.070743\n",
            "Iteration: 49067 | Cost/Loss: 0.077560 | Weight: 0.529437 | Bias: 0.070743\n",
            "Iteration: 49068 | Cost/Loss: 0.077560 | Weight: 0.529438 | Bias: 0.070743\n",
            "Iteration: 49069 | Cost/Loss: 0.077560 | Weight: 0.529438 | Bias: 0.070744\n",
            "Iteration: 49070 | Cost/Loss: 0.077560 | Weight: 0.529438 | Bias: 0.070744\n",
            "Iteration: 49071 | Cost/Loss: 0.077560 | Weight: 0.529439 | Bias: 0.070744\n",
            "Iteration: 49072 | Cost/Loss: 0.077560 | Weight: 0.529439 | Bias: 0.070744\n",
            "Iteration: 49073 | Cost/Loss: 0.077560 | Weight: 0.529439 | Bias: 0.070745\n",
            "Iteration: 49074 | Cost/Loss: 0.077560 | Weight: 0.529440 | Bias: 0.070745\n",
            "Iteration: 49075 | Cost/Loss: 0.077560 | Weight: 0.529440 | Bias: 0.070745\n",
            "Iteration: 49076 | Cost/Loss: 0.077560 | Weight: 0.529440 | Bias: 0.070746\n",
            "Iteration: 49077 | Cost/Loss: 0.077560 | Weight: 0.529440 | Bias: 0.070746\n",
            "Iteration: 49078 | Cost/Loss: 0.077560 | Weight: 0.529441 | Bias: 0.070746\n",
            "Iteration: 49079 | Cost/Loss: 0.077560 | Weight: 0.529441 | Bias: 0.070747\n",
            "Iteration: 49080 | Cost/Loss: 0.077560 | Weight: 0.529441 | Bias: 0.070747\n",
            "Iteration: 49081 | Cost/Loss: 0.077559 | Weight: 0.529442 | Bias: 0.070747\n",
            "Iteration: 49082 | Cost/Loss: 0.077559 | Weight: 0.529442 | Bias: 0.070748\n",
            "Iteration: 49083 | Cost/Loss: 0.077559 | Weight: 0.529442 | Bias: 0.070748\n",
            "Iteration: 49084 | Cost/Loss: 0.077559 | Weight: 0.529443 | Bias: 0.070748\n",
            "Iteration: 49085 | Cost/Loss: 0.077559 | Weight: 0.529443 | Bias: 0.070749\n",
            "Iteration: 49086 | Cost/Loss: 0.077559 | Weight: 0.529443 | Bias: 0.070749\n",
            "Iteration: 49087 | Cost/Loss: 0.077559 | Weight: 0.529443 | Bias: 0.070749\n",
            "Iteration: 49088 | Cost/Loss: 0.077559 | Weight: 0.529444 | Bias: 0.070750\n",
            "Iteration: 49089 | Cost/Loss: 0.077559 | Weight: 0.529444 | Bias: 0.070750\n",
            "Iteration: 49090 | Cost/Loss: 0.077559 | Weight: 0.529444 | Bias: 0.070750\n",
            "Iteration: 49091 | Cost/Loss: 0.077559 | Weight: 0.529445 | Bias: 0.070750\n",
            "Iteration: 49092 | Cost/Loss: 0.077559 | Weight: 0.529445 | Bias: 0.070751\n",
            "Iteration: 49093 | Cost/Loss: 0.077559 | Weight: 0.529445 | Bias: 0.070751\n",
            "Iteration: 49094 | Cost/Loss: 0.077559 | Weight: 0.529446 | Bias: 0.070751\n",
            "Iteration: 49095 | Cost/Loss: 0.077559 | Weight: 0.529446 | Bias: 0.070752\n",
            "Iteration: 49096 | Cost/Loss: 0.077559 | Weight: 0.529446 | Bias: 0.070752\n",
            "Iteration: 49097 | Cost/Loss: 0.077559 | Weight: 0.529446 | Bias: 0.070752\n",
            "Iteration: 49098 | Cost/Loss: 0.077559 | Weight: 0.529447 | Bias: 0.070753\n",
            "Iteration: 49099 | Cost/Loss: 0.077559 | Weight: 0.529447 | Bias: 0.070753\n",
            "Iteration: 49100 | Cost/Loss: 0.077559 | Weight: 0.529447 | Bias: 0.070753\n",
            "Iteration: 49101 | Cost/Loss: 0.077559 | Weight: 0.529448 | Bias: 0.070754\n",
            "Iteration: 49102 | Cost/Loss: 0.077559 | Weight: 0.529448 | Bias: 0.070754\n",
            "Iteration: 49103 | Cost/Loss: 0.077559 | Weight: 0.529448 | Bias: 0.070754\n",
            "Iteration: 49104 | Cost/Loss: 0.077559 | Weight: 0.529449 | Bias: 0.070755\n",
            "Iteration: 49105 | Cost/Loss: 0.077559 | Weight: 0.529449 | Bias: 0.070755\n",
            "Iteration: 49106 | Cost/Loss: 0.077559 | Weight: 0.529449 | Bias: 0.070755\n",
            "Iteration: 49107 | Cost/Loss: 0.077559 | Weight: 0.529449 | Bias: 0.070755\n",
            "Iteration: 49108 | Cost/Loss: 0.077559 | Weight: 0.529450 | Bias: 0.070756\n",
            "Iteration: 49109 | Cost/Loss: 0.077559 | Weight: 0.529450 | Bias: 0.070756\n",
            "Iteration: 49110 | Cost/Loss: 0.077559 | Weight: 0.529450 | Bias: 0.070756\n",
            "Iteration: 49111 | Cost/Loss: 0.077559 | Weight: 0.529451 | Bias: 0.070757\n",
            "Iteration: 49112 | Cost/Loss: 0.077559 | Weight: 0.529451 | Bias: 0.070757\n",
            "Iteration: 49113 | Cost/Loss: 0.077559 | Weight: 0.529451 | Bias: 0.070757\n",
            "Iteration: 49114 | Cost/Loss: 0.077559 | Weight: 0.529451 | Bias: 0.070758\n",
            "Iteration: 49115 | Cost/Loss: 0.077559 | Weight: 0.529452 | Bias: 0.070758\n",
            "Iteration: 49116 | Cost/Loss: 0.077559 | Weight: 0.529452 | Bias: 0.070758\n",
            "Iteration: 49117 | Cost/Loss: 0.077559 | Weight: 0.529452 | Bias: 0.070759\n",
            "Iteration: 49118 | Cost/Loss: 0.077559 | Weight: 0.529453 | Bias: 0.070759\n",
            "Iteration: 49119 | Cost/Loss: 0.077559 | Weight: 0.529453 | Bias: 0.070759\n",
            "Iteration: 49120 | Cost/Loss: 0.077559 | Weight: 0.529453 | Bias: 0.070760\n",
            "Iteration: 49121 | Cost/Loss: 0.077558 | Weight: 0.529454 | Bias: 0.070760\n",
            "Iteration: 49122 | Cost/Loss: 0.077558 | Weight: 0.529454 | Bias: 0.070760\n",
            "Iteration: 49123 | Cost/Loss: 0.077558 | Weight: 0.529454 | Bias: 0.070760\n",
            "Iteration: 49124 | Cost/Loss: 0.077558 | Weight: 0.529454 | Bias: 0.070761\n",
            "Iteration: 49125 | Cost/Loss: 0.077558 | Weight: 0.529455 | Bias: 0.070761\n",
            "Iteration: 49126 | Cost/Loss: 0.077558 | Weight: 0.529455 | Bias: 0.070761\n",
            "Iteration: 49127 | Cost/Loss: 0.077558 | Weight: 0.529455 | Bias: 0.070762\n",
            "Iteration: 49128 | Cost/Loss: 0.077558 | Weight: 0.529456 | Bias: 0.070762\n",
            "Iteration: 49129 | Cost/Loss: 0.077558 | Weight: 0.529456 | Bias: 0.070762\n",
            "Iteration: 49130 | Cost/Loss: 0.077558 | Weight: 0.529456 | Bias: 0.070763\n",
            "Iteration: 49131 | Cost/Loss: 0.077558 | Weight: 0.529457 | Bias: 0.070763\n",
            "Iteration: 49132 | Cost/Loss: 0.077558 | Weight: 0.529457 | Bias: 0.070763\n",
            "Iteration: 49133 | Cost/Loss: 0.077558 | Weight: 0.529457 | Bias: 0.070764\n",
            "Iteration: 49134 | Cost/Loss: 0.077558 | Weight: 0.529457 | Bias: 0.070764\n",
            "Iteration: 49135 | Cost/Loss: 0.077558 | Weight: 0.529458 | Bias: 0.070764\n",
            "Iteration: 49136 | Cost/Loss: 0.077558 | Weight: 0.529458 | Bias: 0.070765\n",
            "Iteration: 49137 | Cost/Loss: 0.077558 | Weight: 0.529458 | Bias: 0.070765\n",
            "Iteration: 49138 | Cost/Loss: 0.077558 | Weight: 0.529459 | Bias: 0.070765\n",
            "Iteration: 49139 | Cost/Loss: 0.077558 | Weight: 0.529459 | Bias: 0.070765\n",
            "Iteration: 49140 | Cost/Loss: 0.077558 | Weight: 0.529459 | Bias: 0.070766\n",
            "Iteration: 49141 | Cost/Loss: 0.077558 | Weight: 0.529460 | Bias: 0.070766\n",
            "Iteration: 49142 | Cost/Loss: 0.077558 | Weight: 0.529460 | Bias: 0.070766\n",
            "Iteration: 49143 | Cost/Loss: 0.077558 | Weight: 0.529460 | Bias: 0.070767\n",
            "Iteration: 49144 | Cost/Loss: 0.077558 | Weight: 0.529460 | Bias: 0.070767\n",
            "Iteration: 49145 | Cost/Loss: 0.077558 | Weight: 0.529461 | Bias: 0.070767\n",
            "Iteration: 49146 | Cost/Loss: 0.077558 | Weight: 0.529461 | Bias: 0.070768\n",
            "Iteration: 49147 | Cost/Loss: 0.077558 | Weight: 0.529461 | Bias: 0.070768\n",
            "Iteration: 49148 | Cost/Loss: 0.077558 | Weight: 0.529462 | Bias: 0.070768\n",
            "Iteration: 49149 | Cost/Loss: 0.077558 | Weight: 0.529462 | Bias: 0.070769\n",
            "Iteration: 49150 | Cost/Loss: 0.077558 | Weight: 0.529462 | Bias: 0.070769\n",
            "Iteration: 49151 | Cost/Loss: 0.077558 | Weight: 0.529463 | Bias: 0.070769\n",
            "Iteration: 49152 | Cost/Loss: 0.077558 | Weight: 0.529463 | Bias: 0.070770\n",
            "Iteration: 49153 | Cost/Loss: 0.077558 | Weight: 0.529463 | Bias: 0.070770\n",
            "Iteration: 49154 | Cost/Loss: 0.077558 | Weight: 0.529463 | Bias: 0.070770\n",
            "Iteration: 49155 | Cost/Loss: 0.077558 | Weight: 0.529464 | Bias: 0.070770\n",
            "Iteration: 49156 | Cost/Loss: 0.077558 | Weight: 0.529464 | Bias: 0.070771\n",
            "Iteration: 49157 | Cost/Loss: 0.077558 | Weight: 0.529464 | Bias: 0.070771\n",
            "Iteration: 49158 | Cost/Loss: 0.077558 | Weight: 0.529465 | Bias: 0.070771\n",
            "Iteration: 49159 | Cost/Loss: 0.077558 | Weight: 0.529465 | Bias: 0.070772\n",
            "Iteration: 49160 | Cost/Loss: 0.077558 | Weight: 0.529465 | Bias: 0.070772\n",
            "Iteration: 49161 | Cost/Loss: 0.077557 | Weight: 0.529465 | Bias: 0.070772\n",
            "Iteration: 49162 | Cost/Loss: 0.077557 | Weight: 0.529466 | Bias: 0.070773\n",
            "Iteration: 49163 | Cost/Loss: 0.077557 | Weight: 0.529466 | Bias: 0.070773\n",
            "Iteration: 49164 | Cost/Loss: 0.077557 | Weight: 0.529466 | Bias: 0.070773\n",
            "Iteration: 49165 | Cost/Loss: 0.077557 | Weight: 0.529467 | Bias: 0.070774\n",
            "Iteration: 49166 | Cost/Loss: 0.077557 | Weight: 0.529467 | Bias: 0.070774\n",
            "Iteration: 49167 | Cost/Loss: 0.077557 | Weight: 0.529467 | Bias: 0.070774\n",
            "Iteration: 49168 | Cost/Loss: 0.077557 | Weight: 0.529468 | Bias: 0.070775\n",
            "Iteration: 49169 | Cost/Loss: 0.077557 | Weight: 0.529468 | Bias: 0.070775\n",
            "Iteration: 49170 | Cost/Loss: 0.077557 | Weight: 0.529468 | Bias: 0.070775\n",
            "Iteration: 49171 | Cost/Loss: 0.077557 | Weight: 0.529468 | Bias: 0.070775\n",
            "Iteration: 49172 | Cost/Loss: 0.077557 | Weight: 0.529469 | Bias: 0.070776\n",
            "Iteration: 49173 | Cost/Loss: 0.077557 | Weight: 0.529469 | Bias: 0.070776\n",
            "Iteration: 49174 | Cost/Loss: 0.077557 | Weight: 0.529469 | Bias: 0.070776\n",
            "Iteration: 49175 | Cost/Loss: 0.077557 | Weight: 0.529470 | Bias: 0.070777\n",
            "Iteration: 49176 | Cost/Loss: 0.077557 | Weight: 0.529470 | Bias: 0.070777\n",
            "Iteration: 49177 | Cost/Loss: 0.077557 | Weight: 0.529470 | Bias: 0.070777\n",
            "Iteration: 49178 | Cost/Loss: 0.077557 | Weight: 0.529471 | Bias: 0.070778\n",
            "Iteration: 49179 | Cost/Loss: 0.077557 | Weight: 0.529471 | Bias: 0.070778\n",
            "Iteration: 49180 | Cost/Loss: 0.077557 | Weight: 0.529471 | Bias: 0.070778\n",
            "Iteration: 49181 | Cost/Loss: 0.077557 | Weight: 0.529471 | Bias: 0.070779\n",
            "Iteration: 49182 | Cost/Loss: 0.077557 | Weight: 0.529472 | Bias: 0.070779\n",
            "Iteration: 49183 | Cost/Loss: 0.077557 | Weight: 0.529472 | Bias: 0.070779\n",
            "Iteration: 49184 | Cost/Loss: 0.077557 | Weight: 0.529472 | Bias: 0.070780\n",
            "Iteration: 49185 | Cost/Loss: 0.077557 | Weight: 0.529473 | Bias: 0.070780\n",
            "Iteration: 49186 | Cost/Loss: 0.077557 | Weight: 0.529473 | Bias: 0.070780\n",
            "Iteration: 49187 | Cost/Loss: 0.077557 | Weight: 0.529473 | Bias: 0.070780\n",
            "Iteration: 49188 | Cost/Loss: 0.077557 | Weight: 0.529474 | Bias: 0.070781\n",
            "Iteration: 49189 | Cost/Loss: 0.077557 | Weight: 0.529474 | Bias: 0.070781\n",
            "Iteration: 49190 | Cost/Loss: 0.077557 | Weight: 0.529474 | Bias: 0.070781\n",
            "Iteration: 49191 | Cost/Loss: 0.077557 | Weight: 0.529474 | Bias: 0.070782\n",
            "Iteration: 49192 | Cost/Loss: 0.077557 | Weight: 0.529475 | Bias: 0.070782\n",
            "Iteration: 49193 | Cost/Loss: 0.077557 | Weight: 0.529475 | Bias: 0.070782\n",
            "Iteration: 49194 | Cost/Loss: 0.077557 | Weight: 0.529475 | Bias: 0.070783\n",
            "Iteration: 49195 | Cost/Loss: 0.077557 | Weight: 0.529476 | Bias: 0.070783\n",
            "Iteration: 49196 | Cost/Loss: 0.077557 | Weight: 0.529476 | Bias: 0.070783\n",
            "Iteration: 49197 | Cost/Loss: 0.077557 | Weight: 0.529476 | Bias: 0.070784\n",
            "Iteration: 49198 | Cost/Loss: 0.077557 | Weight: 0.529477 | Bias: 0.070784\n",
            "Iteration: 49199 | Cost/Loss: 0.077557 | Weight: 0.529477 | Bias: 0.070784\n",
            "Iteration: 49200 | Cost/Loss: 0.077557 | Weight: 0.529477 | Bias: 0.070785\n",
            "Iteration: 49201 | Cost/Loss: 0.077556 | Weight: 0.529477 | Bias: 0.070785\n",
            "Iteration: 49202 | Cost/Loss: 0.077556 | Weight: 0.529478 | Bias: 0.070785\n",
            "Iteration: 49203 | Cost/Loss: 0.077556 | Weight: 0.529478 | Bias: 0.070785\n",
            "Iteration: 49204 | Cost/Loss: 0.077556 | Weight: 0.529478 | Bias: 0.070786\n",
            "Iteration: 49205 | Cost/Loss: 0.077556 | Weight: 0.529479 | Bias: 0.070786\n",
            "Iteration: 49206 | Cost/Loss: 0.077556 | Weight: 0.529479 | Bias: 0.070786\n",
            "Iteration: 49207 | Cost/Loss: 0.077556 | Weight: 0.529479 | Bias: 0.070787\n",
            "Iteration: 49208 | Cost/Loss: 0.077556 | Weight: 0.529480 | Bias: 0.070787\n",
            "Iteration: 49209 | Cost/Loss: 0.077556 | Weight: 0.529480 | Bias: 0.070787\n",
            "Iteration: 49210 | Cost/Loss: 0.077556 | Weight: 0.529480 | Bias: 0.070788\n",
            "Iteration: 49211 | Cost/Loss: 0.077556 | Weight: 0.529480 | Bias: 0.070788\n",
            "Iteration: 49212 | Cost/Loss: 0.077556 | Weight: 0.529481 | Bias: 0.070788\n",
            "Iteration: 49213 | Cost/Loss: 0.077556 | Weight: 0.529481 | Bias: 0.070789\n",
            "Iteration: 49214 | Cost/Loss: 0.077556 | Weight: 0.529481 | Bias: 0.070789\n",
            "Iteration: 49215 | Cost/Loss: 0.077556 | Weight: 0.529482 | Bias: 0.070789\n",
            "Iteration: 49216 | Cost/Loss: 0.077556 | Weight: 0.529482 | Bias: 0.070790\n",
            "Iteration: 49217 | Cost/Loss: 0.077556 | Weight: 0.529482 | Bias: 0.070790\n",
            "Iteration: 49218 | Cost/Loss: 0.077556 | Weight: 0.529482 | Bias: 0.070790\n",
            "Iteration: 49219 | Cost/Loss: 0.077556 | Weight: 0.529483 | Bias: 0.070790\n",
            "Iteration: 49220 | Cost/Loss: 0.077556 | Weight: 0.529483 | Bias: 0.070791\n",
            "Iteration: 49221 | Cost/Loss: 0.077556 | Weight: 0.529483 | Bias: 0.070791\n",
            "Iteration: 49222 | Cost/Loss: 0.077556 | Weight: 0.529484 | Bias: 0.070791\n",
            "Iteration: 49223 | Cost/Loss: 0.077556 | Weight: 0.529484 | Bias: 0.070792\n",
            "Iteration: 49224 | Cost/Loss: 0.077556 | Weight: 0.529484 | Bias: 0.070792\n",
            "Iteration: 49225 | Cost/Loss: 0.077556 | Weight: 0.529485 | Bias: 0.070792\n",
            "Iteration: 49226 | Cost/Loss: 0.077556 | Weight: 0.529485 | Bias: 0.070793\n",
            "Iteration: 49227 | Cost/Loss: 0.077556 | Weight: 0.529485 | Bias: 0.070793\n",
            "Iteration: 49228 | Cost/Loss: 0.077556 | Weight: 0.529485 | Bias: 0.070793\n",
            "Iteration: 49229 | Cost/Loss: 0.077556 | Weight: 0.529486 | Bias: 0.070794\n",
            "Iteration: 49230 | Cost/Loss: 0.077556 | Weight: 0.529486 | Bias: 0.070794\n",
            "Iteration: 49231 | Cost/Loss: 0.077556 | Weight: 0.529486 | Bias: 0.070794\n",
            "Iteration: 49232 | Cost/Loss: 0.077556 | Weight: 0.529487 | Bias: 0.070795\n",
            "Iteration: 49233 | Cost/Loss: 0.077556 | Weight: 0.529487 | Bias: 0.070795\n",
            "Iteration: 49234 | Cost/Loss: 0.077556 | Weight: 0.529487 | Bias: 0.070795\n",
            "Iteration: 49235 | Cost/Loss: 0.077556 | Weight: 0.529488 | Bias: 0.070796\n",
            "Iteration: 49236 | Cost/Loss: 0.077556 | Weight: 0.529488 | Bias: 0.070796\n",
            "Iteration: 49237 | Cost/Loss: 0.077556 | Weight: 0.529488 | Bias: 0.070796\n",
            "Iteration: 49238 | Cost/Loss: 0.077556 | Weight: 0.529488 | Bias: 0.070796\n",
            "Iteration: 49239 | Cost/Loss: 0.077556 | Weight: 0.529489 | Bias: 0.070797\n",
            "Iteration: 49240 | Cost/Loss: 0.077556 | Weight: 0.529489 | Bias: 0.070797\n",
            "Iteration: 49241 | Cost/Loss: 0.077555 | Weight: 0.529489 | Bias: 0.070797\n",
            "Iteration: 49242 | Cost/Loss: 0.077555 | Weight: 0.529490 | Bias: 0.070798\n",
            "Iteration: 49243 | Cost/Loss: 0.077555 | Weight: 0.529490 | Bias: 0.070798\n",
            "Iteration: 49244 | Cost/Loss: 0.077555 | Weight: 0.529490 | Bias: 0.070798\n",
            "Iteration: 49245 | Cost/Loss: 0.077555 | Weight: 0.529491 | Bias: 0.070799\n",
            "Iteration: 49246 | Cost/Loss: 0.077555 | Weight: 0.529491 | Bias: 0.070799\n",
            "Iteration: 49247 | Cost/Loss: 0.077555 | Weight: 0.529491 | Bias: 0.070799\n",
            "Iteration: 49248 | Cost/Loss: 0.077555 | Weight: 0.529491 | Bias: 0.070800\n",
            "Iteration: 49249 | Cost/Loss: 0.077555 | Weight: 0.529492 | Bias: 0.070800\n",
            "Iteration: 49250 | Cost/Loss: 0.077555 | Weight: 0.529492 | Bias: 0.070800\n",
            "Iteration: 49251 | Cost/Loss: 0.077555 | Weight: 0.529492 | Bias: 0.070801\n",
            "Iteration: 49252 | Cost/Loss: 0.077555 | Weight: 0.529493 | Bias: 0.070801\n",
            "Iteration: 49253 | Cost/Loss: 0.077555 | Weight: 0.529493 | Bias: 0.070801\n",
            "Iteration: 49254 | Cost/Loss: 0.077555 | Weight: 0.529493 | Bias: 0.070801\n",
            "Iteration: 49255 | Cost/Loss: 0.077555 | Weight: 0.529494 | Bias: 0.070802\n",
            "Iteration: 49256 | Cost/Loss: 0.077555 | Weight: 0.529494 | Bias: 0.070802\n",
            "Iteration: 49257 | Cost/Loss: 0.077555 | Weight: 0.529494 | Bias: 0.070802\n",
            "Iteration: 49258 | Cost/Loss: 0.077555 | Weight: 0.529494 | Bias: 0.070803\n",
            "Iteration: 49259 | Cost/Loss: 0.077555 | Weight: 0.529495 | Bias: 0.070803\n",
            "Iteration: 49260 | Cost/Loss: 0.077555 | Weight: 0.529495 | Bias: 0.070803\n",
            "Iteration: 49261 | Cost/Loss: 0.077555 | Weight: 0.529495 | Bias: 0.070804\n",
            "Iteration: 49262 | Cost/Loss: 0.077555 | Weight: 0.529496 | Bias: 0.070804\n",
            "Iteration: 49263 | Cost/Loss: 0.077555 | Weight: 0.529496 | Bias: 0.070804\n",
            "Iteration: 49264 | Cost/Loss: 0.077555 | Weight: 0.529496 | Bias: 0.070805\n",
            "Iteration: 49265 | Cost/Loss: 0.077555 | Weight: 0.529496 | Bias: 0.070805\n",
            "Iteration: 49266 | Cost/Loss: 0.077555 | Weight: 0.529497 | Bias: 0.070805\n",
            "Iteration: 49267 | Cost/Loss: 0.077555 | Weight: 0.529497 | Bias: 0.070806\n",
            "Iteration: 49268 | Cost/Loss: 0.077555 | Weight: 0.529497 | Bias: 0.070806\n",
            "Iteration: 49269 | Cost/Loss: 0.077555 | Weight: 0.529498 | Bias: 0.070806\n",
            "Iteration: 49270 | Cost/Loss: 0.077555 | Weight: 0.529498 | Bias: 0.070806\n",
            "Iteration: 49271 | Cost/Loss: 0.077555 | Weight: 0.529498 | Bias: 0.070807\n",
            "Iteration: 49272 | Cost/Loss: 0.077555 | Weight: 0.529499 | Bias: 0.070807\n",
            "Iteration: 49273 | Cost/Loss: 0.077555 | Weight: 0.529499 | Bias: 0.070807\n",
            "Iteration: 49274 | Cost/Loss: 0.077555 | Weight: 0.529499 | Bias: 0.070808\n",
            "Iteration: 49275 | Cost/Loss: 0.077555 | Weight: 0.529499 | Bias: 0.070808\n",
            "Iteration: 49276 | Cost/Loss: 0.077555 | Weight: 0.529500 | Bias: 0.070808\n",
            "Iteration: 49277 | Cost/Loss: 0.077555 | Weight: 0.529500 | Bias: 0.070809\n",
            "Iteration: 49278 | Cost/Loss: 0.077555 | Weight: 0.529500 | Bias: 0.070809\n",
            "Iteration: 49279 | Cost/Loss: 0.077555 | Weight: 0.529501 | Bias: 0.070809\n",
            "Iteration: 49280 | Cost/Loss: 0.077555 | Weight: 0.529501 | Bias: 0.070810\n",
            "Iteration: 49281 | Cost/Loss: 0.077554 | Weight: 0.529501 | Bias: 0.070810\n",
            "Iteration: 49282 | Cost/Loss: 0.077554 | Weight: 0.529502 | Bias: 0.070810\n",
            "Iteration: 49283 | Cost/Loss: 0.077554 | Weight: 0.529502 | Bias: 0.070811\n",
            "Iteration: 49284 | Cost/Loss: 0.077554 | Weight: 0.529502 | Bias: 0.070811\n",
            "Iteration: 49285 | Cost/Loss: 0.077554 | Weight: 0.529502 | Bias: 0.070811\n",
            "Iteration: 49286 | Cost/Loss: 0.077554 | Weight: 0.529503 | Bias: 0.070811\n",
            "Iteration: 49287 | Cost/Loss: 0.077554 | Weight: 0.529503 | Bias: 0.070812\n",
            "Iteration: 49288 | Cost/Loss: 0.077554 | Weight: 0.529503 | Bias: 0.070812\n",
            "Iteration: 49289 | Cost/Loss: 0.077554 | Weight: 0.529504 | Bias: 0.070812\n",
            "Iteration: 49290 | Cost/Loss: 0.077554 | Weight: 0.529504 | Bias: 0.070813\n",
            "Iteration: 49291 | Cost/Loss: 0.077554 | Weight: 0.529504 | Bias: 0.070813\n",
            "Iteration: 49292 | Cost/Loss: 0.077554 | Weight: 0.529505 | Bias: 0.070813\n",
            "Iteration: 49293 | Cost/Loss: 0.077554 | Weight: 0.529505 | Bias: 0.070814\n",
            "Iteration: 49294 | Cost/Loss: 0.077554 | Weight: 0.529505 | Bias: 0.070814\n",
            "Iteration: 49295 | Cost/Loss: 0.077554 | Weight: 0.529505 | Bias: 0.070814\n",
            "Iteration: 49296 | Cost/Loss: 0.077554 | Weight: 0.529506 | Bias: 0.070815\n",
            "Iteration: 49297 | Cost/Loss: 0.077554 | Weight: 0.529506 | Bias: 0.070815\n",
            "Iteration: 49298 | Cost/Loss: 0.077554 | Weight: 0.529506 | Bias: 0.070815\n",
            "Iteration: 49299 | Cost/Loss: 0.077554 | Weight: 0.529507 | Bias: 0.070816\n",
            "Iteration: 49300 | Cost/Loss: 0.077554 | Weight: 0.529507 | Bias: 0.070816\n",
            "Iteration: 49301 | Cost/Loss: 0.077554 | Weight: 0.529507 | Bias: 0.070816\n",
            "Iteration: 49302 | Cost/Loss: 0.077554 | Weight: 0.529508 | Bias: 0.070816\n",
            "Iteration: 49303 | Cost/Loss: 0.077554 | Weight: 0.529508 | Bias: 0.070817\n",
            "Iteration: 49304 | Cost/Loss: 0.077554 | Weight: 0.529508 | Bias: 0.070817\n",
            "Iteration: 49305 | Cost/Loss: 0.077554 | Weight: 0.529508 | Bias: 0.070817\n",
            "Iteration: 49306 | Cost/Loss: 0.077554 | Weight: 0.529509 | Bias: 0.070818\n",
            "Iteration: 49307 | Cost/Loss: 0.077554 | Weight: 0.529509 | Bias: 0.070818\n",
            "Iteration: 49308 | Cost/Loss: 0.077554 | Weight: 0.529509 | Bias: 0.070818\n",
            "Iteration: 49309 | Cost/Loss: 0.077554 | Weight: 0.529510 | Bias: 0.070819\n",
            "Iteration: 49310 | Cost/Loss: 0.077554 | Weight: 0.529510 | Bias: 0.070819\n",
            "Iteration: 49311 | Cost/Loss: 0.077554 | Weight: 0.529510 | Bias: 0.070819\n",
            "Iteration: 49312 | Cost/Loss: 0.077554 | Weight: 0.529510 | Bias: 0.070820\n",
            "Iteration: 49313 | Cost/Loss: 0.077554 | Weight: 0.529511 | Bias: 0.070820\n",
            "Iteration: 49314 | Cost/Loss: 0.077554 | Weight: 0.529511 | Bias: 0.070820\n",
            "Iteration: 49315 | Cost/Loss: 0.077554 | Weight: 0.529511 | Bias: 0.070821\n",
            "Iteration: 49316 | Cost/Loss: 0.077554 | Weight: 0.529512 | Bias: 0.070821\n",
            "Iteration: 49317 | Cost/Loss: 0.077554 | Weight: 0.529512 | Bias: 0.070821\n",
            "Iteration: 49318 | Cost/Loss: 0.077554 | Weight: 0.529512 | Bias: 0.070821\n",
            "Iteration: 49319 | Cost/Loss: 0.077554 | Weight: 0.529513 | Bias: 0.070822\n",
            "Iteration: 49320 | Cost/Loss: 0.077554 | Weight: 0.529513 | Bias: 0.070822\n",
            "Iteration: 49321 | Cost/Loss: 0.077553 | Weight: 0.529513 | Bias: 0.070822\n",
            "Iteration: 49322 | Cost/Loss: 0.077553 | Weight: 0.529513 | Bias: 0.070823\n",
            "Iteration: 49323 | Cost/Loss: 0.077553 | Weight: 0.529514 | Bias: 0.070823\n",
            "Iteration: 49324 | Cost/Loss: 0.077553 | Weight: 0.529514 | Bias: 0.070823\n",
            "Iteration: 49325 | Cost/Loss: 0.077553 | Weight: 0.529514 | Bias: 0.070824\n",
            "Iteration: 49326 | Cost/Loss: 0.077553 | Weight: 0.529515 | Bias: 0.070824\n",
            "Iteration: 49327 | Cost/Loss: 0.077553 | Weight: 0.529515 | Bias: 0.070824\n",
            "Iteration: 49328 | Cost/Loss: 0.077553 | Weight: 0.529515 | Bias: 0.070825\n",
            "Iteration: 49329 | Cost/Loss: 0.077553 | Weight: 0.529516 | Bias: 0.070825\n",
            "Iteration: 49330 | Cost/Loss: 0.077553 | Weight: 0.529516 | Bias: 0.070825\n",
            "Iteration: 49331 | Cost/Loss: 0.077553 | Weight: 0.529516 | Bias: 0.070826\n",
            "Iteration: 49332 | Cost/Loss: 0.077553 | Weight: 0.529516 | Bias: 0.070826\n",
            "Iteration: 49333 | Cost/Loss: 0.077553 | Weight: 0.529517 | Bias: 0.070826\n",
            "Iteration: 49334 | Cost/Loss: 0.077553 | Weight: 0.529517 | Bias: 0.070826\n",
            "Iteration: 49335 | Cost/Loss: 0.077553 | Weight: 0.529517 | Bias: 0.070827\n",
            "Iteration: 49336 | Cost/Loss: 0.077553 | Weight: 0.529518 | Bias: 0.070827\n",
            "Iteration: 49337 | Cost/Loss: 0.077553 | Weight: 0.529518 | Bias: 0.070827\n",
            "Iteration: 49338 | Cost/Loss: 0.077553 | Weight: 0.529518 | Bias: 0.070828\n",
            "Iteration: 49339 | Cost/Loss: 0.077553 | Weight: 0.529519 | Bias: 0.070828\n",
            "Iteration: 49340 | Cost/Loss: 0.077553 | Weight: 0.529519 | Bias: 0.070828\n",
            "Iteration: 49341 | Cost/Loss: 0.077553 | Weight: 0.529519 | Bias: 0.070829\n",
            "Iteration: 49342 | Cost/Loss: 0.077553 | Weight: 0.529519 | Bias: 0.070829\n",
            "Iteration: 49343 | Cost/Loss: 0.077553 | Weight: 0.529520 | Bias: 0.070829\n",
            "Iteration: 49344 | Cost/Loss: 0.077553 | Weight: 0.529520 | Bias: 0.070830\n",
            "Iteration: 49345 | Cost/Loss: 0.077553 | Weight: 0.529520 | Bias: 0.070830\n",
            "Iteration: 49346 | Cost/Loss: 0.077553 | Weight: 0.529521 | Bias: 0.070830\n",
            "Iteration: 49347 | Cost/Loss: 0.077553 | Weight: 0.529521 | Bias: 0.070831\n",
            "Iteration: 49348 | Cost/Loss: 0.077553 | Weight: 0.529521 | Bias: 0.070831\n",
            "Iteration: 49349 | Cost/Loss: 0.077553 | Weight: 0.529522 | Bias: 0.070831\n",
            "Iteration: 49350 | Cost/Loss: 0.077553 | Weight: 0.529522 | Bias: 0.070831\n",
            "Iteration: 49351 | Cost/Loss: 0.077553 | Weight: 0.529522 | Bias: 0.070832\n",
            "Iteration: 49352 | Cost/Loss: 0.077553 | Weight: 0.529522 | Bias: 0.070832\n",
            "Iteration: 49353 | Cost/Loss: 0.077553 | Weight: 0.529523 | Bias: 0.070832\n",
            "Iteration: 49354 | Cost/Loss: 0.077553 | Weight: 0.529523 | Bias: 0.070833\n",
            "Iteration: 49355 | Cost/Loss: 0.077553 | Weight: 0.529523 | Bias: 0.070833\n",
            "Iteration: 49356 | Cost/Loss: 0.077553 | Weight: 0.529524 | Bias: 0.070833\n",
            "Iteration: 49357 | Cost/Loss: 0.077553 | Weight: 0.529524 | Bias: 0.070834\n",
            "Iteration: 49358 | Cost/Loss: 0.077553 | Weight: 0.529524 | Bias: 0.070834\n",
            "Iteration: 49359 | Cost/Loss: 0.077553 | Weight: 0.529525 | Bias: 0.070834\n",
            "Iteration: 49360 | Cost/Loss: 0.077553 | Weight: 0.529525 | Bias: 0.070835\n",
            "Iteration: 49361 | Cost/Loss: 0.077552 | Weight: 0.529525 | Bias: 0.070835\n",
            "Iteration: 49362 | Cost/Loss: 0.077552 | Weight: 0.529525 | Bias: 0.070835\n",
            "Iteration: 49363 | Cost/Loss: 0.077552 | Weight: 0.529526 | Bias: 0.070836\n",
            "Iteration: 49364 | Cost/Loss: 0.077552 | Weight: 0.529526 | Bias: 0.070836\n",
            "Iteration: 49365 | Cost/Loss: 0.077552 | Weight: 0.529526 | Bias: 0.070836\n",
            "Iteration: 49366 | Cost/Loss: 0.077552 | Weight: 0.529527 | Bias: 0.070836\n",
            "Iteration: 49367 | Cost/Loss: 0.077552 | Weight: 0.529527 | Bias: 0.070837\n",
            "Iteration: 49368 | Cost/Loss: 0.077552 | Weight: 0.529527 | Bias: 0.070837\n",
            "Iteration: 49369 | Cost/Loss: 0.077552 | Weight: 0.529527 | Bias: 0.070837\n",
            "Iteration: 49370 | Cost/Loss: 0.077552 | Weight: 0.529528 | Bias: 0.070838\n",
            "Iteration: 49371 | Cost/Loss: 0.077552 | Weight: 0.529528 | Bias: 0.070838\n",
            "Iteration: 49372 | Cost/Loss: 0.077552 | Weight: 0.529528 | Bias: 0.070838\n",
            "Iteration: 49373 | Cost/Loss: 0.077552 | Weight: 0.529529 | Bias: 0.070839\n",
            "Iteration: 49374 | Cost/Loss: 0.077552 | Weight: 0.529529 | Bias: 0.070839\n",
            "Iteration: 49375 | Cost/Loss: 0.077552 | Weight: 0.529529 | Bias: 0.070839\n",
            "Iteration: 49376 | Cost/Loss: 0.077552 | Weight: 0.529530 | Bias: 0.070840\n",
            "Iteration: 49377 | Cost/Loss: 0.077552 | Weight: 0.529530 | Bias: 0.070840\n",
            "Iteration: 49378 | Cost/Loss: 0.077552 | Weight: 0.529530 | Bias: 0.070840\n",
            "Iteration: 49379 | Cost/Loss: 0.077552 | Weight: 0.529530 | Bias: 0.070841\n",
            "Iteration: 49380 | Cost/Loss: 0.077552 | Weight: 0.529531 | Bias: 0.070841\n",
            "Iteration: 49381 | Cost/Loss: 0.077552 | Weight: 0.529531 | Bias: 0.070841\n",
            "Iteration: 49382 | Cost/Loss: 0.077552 | Weight: 0.529531 | Bias: 0.070842\n",
            "Iteration: 49383 | Cost/Loss: 0.077552 | Weight: 0.529532 | Bias: 0.070842\n",
            "Iteration: 49384 | Cost/Loss: 0.077552 | Weight: 0.529532 | Bias: 0.070842\n",
            "Iteration: 49385 | Cost/Loss: 0.077552 | Weight: 0.529532 | Bias: 0.070842\n",
            "Iteration: 49386 | Cost/Loss: 0.077552 | Weight: 0.529533 | Bias: 0.070843\n",
            "Iteration: 49387 | Cost/Loss: 0.077552 | Weight: 0.529533 | Bias: 0.070843\n",
            "Iteration: 49388 | Cost/Loss: 0.077552 | Weight: 0.529533 | Bias: 0.070843\n",
            "Iteration: 49389 | Cost/Loss: 0.077552 | Weight: 0.529533 | Bias: 0.070844\n",
            "Iteration: 49390 | Cost/Loss: 0.077552 | Weight: 0.529534 | Bias: 0.070844\n",
            "Iteration: 49391 | Cost/Loss: 0.077552 | Weight: 0.529534 | Bias: 0.070844\n",
            "Iteration: 49392 | Cost/Loss: 0.077552 | Weight: 0.529534 | Bias: 0.070845\n",
            "Iteration: 49393 | Cost/Loss: 0.077552 | Weight: 0.529535 | Bias: 0.070845\n",
            "Iteration: 49394 | Cost/Loss: 0.077552 | Weight: 0.529535 | Bias: 0.070845\n",
            "Iteration: 49395 | Cost/Loss: 0.077552 | Weight: 0.529535 | Bias: 0.070846\n",
            "Iteration: 49396 | Cost/Loss: 0.077552 | Weight: 0.529536 | Bias: 0.070846\n",
            "Iteration: 49397 | Cost/Loss: 0.077552 | Weight: 0.529536 | Bias: 0.070846\n",
            "Iteration: 49398 | Cost/Loss: 0.077552 | Weight: 0.529536 | Bias: 0.070847\n",
            "Iteration: 49399 | Cost/Loss: 0.077552 | Weight: 0.529536 | Bias: 0.070847\n",
            "Iteration: 49400 | Cost/Loss: 0.077552 | Weight: 0.529537 | Bias: 0.070847\n",
            "Iteration: 49401 | Cost/Loss: 0.077552 | Weight: 0.529537 | Bias: 0.070847\n",
            "Iteration: 49402 | Cost/Loss: 0.077551 | Weight: 0.529537 | Bias: 0.070848\n",
            "Iteration: 49403 | Cost/Loss: 0.077551 | Weight: 0.529538 | Bias: 0.070848\n",
            "Iteration: 49404 | Cost/Loss: 0.077551 | Weight: 0.529538 | Bias: 0.070848\n",
            "Iteration: 49405 | Cost/Loss: 0.077551 | Weight: 0.529538 | Bias: 0.070849\n",
            "Iteration: 49406 | Cost/Loss: 0.077551 | Weight: 0.529539 | Bias: 0.070849\n",
            "Iteration: 49407 | Cost/Loss: 0.077551 | Weight: 0.529539 | Bias: 0.070849\n",
            "Iteration: 49408 | Cost/Loss: 0.077551 | Weight: 0.529539 | Bias: 0.070850\n",
            "Iteration: 49409 | Cost/Loss: 0.077551 | Weight: 0.529539 | Bias: 0.070850\n",
            "Iteration: 49410 | Cost/Loss: 0.077551 | Weight: 0.529540 | Bias: 0.070850\n",
            "Iteration: 49411 | Cost/Loss: 0.077551 | Weight: 0.529540 | Bias: 0.070851\n",
            "Iteration: 49412 | Cost/Loss: 0.077551 | Weight: 0.529540 | Bias: 0.070851\n",
            "Iteration: 49413 | Cost/Loss: 0.077551 | Weight: 0.529541 | Bias: 0.070851\n",
            "Iteration: 49414 | Cost/Loss: 0.077551 | Weight: 0.529541 | Bias: 0.070852\n",
            "Iteration: 49415 | Cost/Loss: 0.077551 | Weight: 0.529541 | Bias: 0.070852\n",
            "Iteration: 49416 | Cost/Loss: 0.077551 | Weight: 0.529541 | Bias: 0.070852\n",
            "Iteration: 49417 | Cost/Loss: 0.077551 | Weight: 0.529542 | Bias: 0.070852\n",
            "Iteration: 49418 | Cost/Loss: 0.077551 | Weight: 0.529542 | Bias: 0.070853\n",
            "Iteration: 49419 | Cost/Loss: 0.077551 | Weight: 0.529542 | Bias: 0.070853\n",
            "Iteration: 49420 | Cost/Loss: 0.077551 | Weight: 0.529543 | Bias: 0.070853\n",
            "Iteration: 49421 | Cost/Loss: 0.077551 | Weight: 0.529543 | Bias: 0.070854\n",
            "Iteration: 49422 | Cost/Loss: 0.077551 | Weight: 0.529543 | Bias: 0.070854\n",
            "Iteration: 49423 | Cost/Loss: 0.077551 | Weight: 0.529544 | Bias: 0.070854\n",
            "Iteration: 49424 | Cost/Loss: 0.077551 | Weight: 0.529544 | Bias: 0.070855\n",
            "Iteration: 49425 | Cost/Loss: 0.077551 | Weight: 0.529544 | Bias: 0.070855\n",
            "Iteration: 49426 | Cost/Loss: 0.077551 | Weight: 0.529544 | Bias: 0.070855\n",
            "Iteration: 49427 | Cost/Loss: 0.077551 | Weight: 0.529545 | Bias: 0.070856\n",
            "Iteration: 49428 | Cost/Loss: 0.077551 | Weight: 0.529545 | Bias: 0.070856\n",
            "Iteration: 49429 | Cost/Loss: 0.077551 | Weight: 0.529545 | Bias: 0.070856\n",
            "Iteration: 49430 | Cost/Loss: 0.077551 | Weight: 0.529546 | Bias: 0.070857\n",
            "Iteration: 49431 | Cost/Loss: 0.077551 | Weight: 0.529546 | Bias: 0.070857\n",
            "Iteration: 49432 | Cost/Loss: 0.077551 | Weight: 0.529546 | Bias: 0.070857\n",
            "Iteration: 49433 | Cost/Loss: 0.077551 | Weight: 0.529547 | Bias: 0.070857\n",
            "Iteration: 49434 | Cost/Loss: 0.077551 | Weight: 0.529547 | Bias: 0.070858\n",
            "Iteration: 49435 | Cost/Loss: 0.077551 | Weight: 0.529547 | Bias: 0.070858\n",
            "Iteration: 49436 | Cost/Loss: 0.077551 | Weight: 0.529547 | Bias: 0.070858\n",
            "Iteration: 49437 | Cost/Loss: 0.077551 | Weight: 0.529548 | Bias: 0.070859\n",
            "Iteration: 49438 | Cost/Loss: 0.077551 | Weight: 0.529548 | Bias: 0.070859\n",
            "Iteration: 49439 | Cost/Loss: 0.077551 | Weight: 0.529548 | Bias: 0.070859\n",
            "Iteration: 49440 | Cost/Loss: 0.077551 | Weight: 0.529549 | Bias: 0.070860\n",
            "Iteration: 49441 | Cost/Loss: 0.077551 | Weight: 0.529549 | Bias: 0.070860\n",
            "Iteration: 49442 | Cost/Loss: 0.077550 | Weight: 0.529549 | Bias: 0.070860\n",
            "Iteration: 49443 | Cost/Loss: 0.077550 | Weight: 0.529550 | Bias: 0.070861\n",
            "Iteration: 49444 | Cost/Loss: 0.077550 | Weight: 0.529550 | Bias: 0.070861\n",
            "Iteration: 49445 | Cost/Loss: 0.077550 | Weight: 0.529550 | Bias: 0.070861\n",
            "Iteration: 49446 | Cost/Loss: 0.077550 | Weight: 0.529550 | Bias: 0.070862\n",
            "Iteration: 49447 | Cost/Loss: 0.077550 | Weight: 0.529551 | Bias: 0.070862\n",
            "Iteration: 49448 | Cost/Loss: 0.077550 | Weight: 0.529551 | Bias: 0.070862\n",
            "Iteration: 49449 | Cost/Loss: 0.077550 | Weight: 0.529551 | Bias: 0.070862\n",
            "Iteration: 49450 | Cost/Loss: 0.077550 | Weight: 0.529552 | Bias: 0.070863\n",
            "Iteration: 49451 | Cost/Loss: 0.077550 | Weight: 0.529552 | Bias: 0.070863\n",
            "Iteration: 49452 | Cost/Loss: 0.077550 | Weight: 0.529552 | Bias: 0.070863\n",
            "Iteration: 49453 | Cost/Loss: 0.077550 | Weight: 0.529553 | Bias: 0.070864\n",
            "Iteration: 49454 | Cost/Loss: 0.077550 | Weight: 0.529553 | Bias: 0.070864\n",
            "Iteration: 49455 | Cost/Loss: 0.077550 | Weight: 0.529553 | Bias: 0.070864\n",
            "Iteration: 49456 | Cost/Loss: 0.077550 | Weight: 0.529553 | Bias: 0.070865\n",
            "Iteration: 49457 | Cost/Loss: 0.077550 | Weight: 0.529554 | Bias: 0.070865\n",
            "Iteration: 49458 | Cost/Loss: 0.077550 | Weight: 0.529554 | Bias: 0.070865\n",
            "Iteration: 49459 | Cost/Loss: 0.077550 | Weight: 0.529554 | Bias: 0.070866\n",
            "Iteration: 49460 | Cost/Loss: 0.077550 | Weight: 0.529555 | Bias: 0.070866\n",
            "Iteration: 49461 | Cost/Loss: 0.077550 | Weight: 0.529555 | Bias: 0.070866\n",
            "Iteration: 49462 | Cost/Loss: 0.077550 | Weight: 0.529555 | Bias: 0.070867\n",
            "Iteration: 49463 | Cost/Loss: 0.077550 | Weight: 0.529555 | Bias: 0.070867\n",
            "Iteration: 49464 | Cost/Loss: 0.077550 | Weight: 0.529556 | Bias: 0.070867\n",
            "Iteration: 49465 | Cost/Loss: 0.077550 | Weight: 0.529556 | Bias: 0.070867\n",
            "Iteration: 49466 | Cost/Loss: 0.077550 | Weight: 0.529556 | Bias: 0.070868\n",
            "Iteration: 49467 | Cost/Loss: 0.077550 | Weight: 0.529557 | Bias: 0.070868\n",
            "Iteration: 49468 | Cost/Loss: 0.077550 | Weight: 0.529557 | Bias: 0.070868\n",
            "Iteration: 49469 | Cost/Loss: 0.077550 | Weight: 0.529557 | Bias: 0.070869\n",
            "Iteration: 49470 | Cost/Loss: 0.077550 | Weight: 0.529558 | Bias: 0.070869\n",
            "Iteration: 49471 | Cost/Loss: 0.077550 | Weight: 0.529558 | Bias: 0.070869\n",
            "Iteration: 49472 | Cost/Loss: 0.077550 | Weight: 0.529558 | Bias: 0.070870\n",
            "Iteration: 49473 | Cost/Loss: 0.077550 | Weight: 0.529558 | Bias: 0.070870\n",
            "Iteration: 49474 | Cost/Loss: 0.077550 | Weight: 0.529559 | Bias: 0.070870\n",
            "Iteration: 49475 | Cost/Loss: 0.077550 | Weight: 0.529559 | Bias: 0.070871\n",
            "Iteration: 49476 | Cost/Loss: 0.077550 | Weight: 0.529559 | Bias: 0.070871\n",
            "Iteration: 49477 | Cost/Loss: 0.077550 | Weight: 0.529560 | Bias: 0.070871\n",
            "Iteration: 49478 | Cost/Loss: 0.077550 | Weight: 0.529560 | Bias: 0.070872\n",
            "Iteration: 49479 | Cost/Loss: 0.077550 | Weight: 0.529560 | Bias: 0.070872\n",
            "Iteration: 49480 | Cost/Loss: 0.077550 | Weight: 0.529561 | Bias: 0.070872\n",
            "Iteration: 49481 | Cost/Loss: 0.077550 | Weight: 0.529561 | Bias: 0.070872\n",
            "Iteration: 49482 | Cost/Loss: 0.077549 | Weight: 0.529561 | Bias: 0.070873\n",
            "Iteration: 49483 | Cost/Loss: 0.077549 | Weight: 0.529561 | Bias: 0.070873\n",
            "Iteration: 49484 | Cost/Loss: 0.077549 | Weight: 0.529562 | Bias: 0.070873\n",
            "Iteration: 49485 | Cost/Loss: 0.077549 | Weight: 0.529562 | Bias: 0.070874\n",
            "Iteration: 49486 | Cost/Loss: 0.077549 | Weight: 0.529562 | Bias: 0.070874\n",
            "Iteration: 49487 | Cost/Loss: 0.077549 | Weight: 0.529563 | Bias: 0.070874\n",
            "Iteration: 49488 | Cost/Loss: 0.077549 | Weight: 0.529563 | Bias: 0.070875\n",
            "Iteration: 49489 | Cost/Loss: 0.077549 | Weight: 0.529563 | Bias: 0.070875\n",
            "Iteration: 49490 | Cost/Loss: 0.077549 | Weight: 0.529564 | Bias: 0.070875\n",
            "Iteration: 49491 | Cost/Loss: 0.077549 | Weight: 0.529564 | Bias: 0.070876\n",
            "Iteration: 49492 | Cost/Loss: 0.077549 | Weight: 0.529564 | Bias: 0.070876\n",
            "Iteration: 49493 | Cost/Loss: 0.077549 | Weight: 0.529564 | Bias: 0.070876\n",
            "Iteration: 49494 | Cost/Loss: 0.077549 | Weight: 0.529565 | Bias: 0.070877\n",
            "Iteration: 49495 | Cost/Loss: 0.077549 | Weight: 0.529565 | Bias: 0.070877\n",
            "Iteration: 49496 | Cost/Loss: 0.077549 | Weight: 0.529565 | Bias: 0.070877\n",
            "Iteration: 49497 | Cost/Loss: 0.077549 | Weight: 0.529566 | Bias: 0.070877\n",
            "Iteration: 49498 | Cost/Loss: 0.077549 | Weight: 0.529566 | Bias: 0.070878\n",
            "Iteration: 49499 | Cost/Loss: 0.077549 | Weight: 0.529566 | Bias: 0.070878\n",
            "Iteration: 49500 | Cost/Loss: 0.077549 | Weight: 0.529567 | Bias: 0.070878\n",
            "Iteration: 49501 | Cost/Loss: 0.077549 | Weight: 0.529567 | Bias: 0.070879\n",
            "Iteration: 49502 | Cost/Loss: 0.077549 | Weight: 0.529567 | Bias: 0.070879\n",
            "Iteration: 49503 | Cost/Loss: 0.077549 | Weight: 0.529567 | Bias: 0.070879\n",
            "Iteration: 49504 | Cost/Loss: 0.077549 | Weight: 0.529568 | Bias: 0.070880\n",
            "Iteration: 49505 | Cost/Loss: 0.077549 | Weight: 0.529568 | Bias: 0.070880\n",
            "Iteration: 49506 | Cost/Loss: 0.077549 | Weight: 0.529568 | Bias: 0.070880\n",
            "Iteration: 49507 | Cost/Loss: 0.077549 | Weight: 0.529569 | Bias: 0.070881\n",
            "Iteration: 49508 | Cost/Loss: 0.077549 | Weight: 0.529569 | Bias: 0.070881\n",
            "Iteration: 49509 | Cost/Loss: 0.077549 | Weight: 0.529569 | Bias: 0.070881\n",
            "Iteration: 49510 | Cost/Loss: 0.077549 | Weight: 0.529570 | Bias: 0.070882\n",
            "Iteration: 49511 | Cost/Loss: 0.077549 | Weight: 0.529570 | Bias: 0.070882\n",
            "Iteration: 49512 | Cost/Loss: 0.077549 | Weight: 0.529570 | Bias: 0.070882\n",
            "Iteration: 49513 | Cost/Loss: 0.077549 | Weight: 0.529570 | Bias: 0.070882\n",
            "Iteration: 49514 | Cost/Loss: 0.077549 | Weight: 0.529571 | Bias: 0.070883\n",
            "Iteration: 49515 | Cost/Loss: 0.077549 | Weight: 0.529571 | Bias: 0.070883\n",
            "Iteration: 49516 | Cost/Loss: 0.077549 | Weight: 0.529571 | Bias: 0.070883\n",
            "Iteration: 49517 | Cost/Loss: 0.077549 | Weight: 0.529572 | Bias: 0.070884\n",
            "Iteration: 49518 | Cost/Loss: 0.077549 | Weight: 0.529572 | Bias: 0.070884\n",
            "Iteration: 49519 | Cost/Loss: 0.077549 | Weight: 0.529572 | Bias: 0.070884\n",
            "Iteration: 49520 | Cost/Loss: 0.077549 | Weight: 0.529572 | Bias: 0.070885\n",
            "Iteration: 49521 | Cost/Loss: 0.077549 | Weight: 0.529573 | Bias: 0.070885\n",
            "Iteration: 49522 | Cost/Loss: 0.077548 | Weight: 0.529573 | Bias: 0.070885\n",
            "Iteration: 49523 | Cost/Loss: 0.077548 | Weight: 0.529573 | Bias: 0.070886\n",
            "Iteration: 49524 | Cost/Loss: 0.077548 | Weight: 0.529574 | Bias: 0.070886\n",
            "Iteration: 49525 | Cost/Loss: 0.077548 | Weight: 0.529574 | Bias: 0.070886\n",
            "Iteration: 49526 | Cost/Loss: 0.077548 | Weight: 0.529574 | Bias: 0.070887\n",
            "Iteration: 49527 | Cost/Loss: 0.077548 | Weight: 0.529575 | Bias: 0.070887\n",
            "Iteration: 49528 | Cost/Loss: 0.077548 | Weight: 0.529575 | Bias: 0.070887\n",
            "Iteration: 49529 | Cost/Loss: 0.077548 | Weight: 0.529575 | Bias: 0.070888\n",
            "Iteration: 49530 | Cost/Loss: 0.077548 | Weight: 0.529575 | Bias: 0.070888\n",
            "Iteration: 49531 | Cost/Loss: 0.077548 | Weight: 0.529576 | Bias: 0.070888\n",
            "Iteration: 49532 | Cost/Loss: 0.077548 | Weight: 0.529576 | Bias: 0.070888\n",
            "Iteration: 49533 | Cost/Loss: 0.077548 | Weight: 0.529576 | Bias: 0.070889\n",
            "Iteration: 49534 | Cost/Loss: 0.077548 | Weight: 0.529577 | Bias: 0.070889\n",
            "Iteration: 49535 | Cost/Loss: 0.077548 | Weight: 0.529577 | Bias: 0.070889\n",
            "Iteration: 49536 | Cost/Loss: 0.077548 | Weight: 0.529577 | Bias: 0.070890\n",
            "Iteration: 49537 | Cost/Loss: 0.077548 | Weight: 0.529578 | Bias: 0.070890\n",
            "Iteration: 49538 | Cost/Loss: 0.077548 | Weight: 0.529578 | Bias: 0.070890\n",
            "Iteration: 49539 | Cost/Loss: 0.077548 | Weight: 0.529578 | Bias: 0.070891\n",
            "Iteration: 49540 | Cost/Loss: 0.077548 | Weight: 0.529578 | Bias: 0.070891\n",
            "Iteration: 49541 | Cost/Loss: 0.077548 | Weight: 0.529579 | Bias: 0.070891\n",
            "Iteration: 49542 | Cost/Loss: 0.077548 | Weight: 0.529579 | Bias: 0.070892\n",
            "Iteration: 49543 | Cost/Loss: 0.077548 | Weight: 0.529579 | Bias: 0.070892\n",
            "Iteration: 49544 | Cost/Loss: 0.077548 | Weight: 0.529580 | Bias: 0.070892\n",
            "Iteration: 49545 | Cost/Loss: 0.077548 | Weight: 0.529580 | Bias: 0.070893\n",
            "Iteration: 49546 | Cost/Loss: 0.077548 | Weight: 0.529580 | Bias: 0.070893\n",
            "Iteration: 49547 | Cost/Loss: 0.077548 | Weight: 0.529581 | Bias: 0.070893\n",
            "Iteration: 49548 | Cost/Loss: 0.077548 | Weight: 0.529581 | Bias: 0.070893\n",
            "Iteration: 49549 | Cost/Loss: 0.077548 | Weight: 0.529581 | Bias: 0.070894\n",
            "Iteration: 49550 | Cost/Loss: 0.077548 | Weight: 0.529581 | Bias: 0.070894\n",
            "Iteration: 49551 | Cost/Loss: 0.077548 | Weight: 0.529582 | Bias: 0.070894\n",
            "Iteration: 49552 | Cost/Loss: 0.077548 | Weight: 0.529582 | Bias: 0.070895\n",
            "Iteration: 49553 | Cost/Loss: 0.077548 | Weight: 0.529582 | Bias: 0.070895\n",
            "Iteration: 49554 | Cost/Loss: 0.077548 | Weight: 0.529583 | Bias: 0.070895\n",
            "Iteration: 49555 | Cost/Loss: 0.077548 | Weight: 0.529583 | Bias: 0.070896\n",
            "Iteration: 49556 | Cost/Loss: 0.077548 | Weight: 0.529583 | Bias: 0.070896\n",
            "Iteration: 49557 | Cost/Loss: 0.077548 | Weight: 0.529584 | Bias: 0.070896\n",
            "Iteration: 49558 | Cost/Loss: 0.077548 | Weight: 0.529584 | Bias: 0.070897\n",
            "Iteration: 49559 | Cost/Loss: 0.077548 | Weight: 0.529584 | Bias: 0.070897\n",
            "Iteration: 49560 | Cost/Loss: 0.077548 | Weight: 0.529584 | Bias: 0.070897\n",
            "Iteration: 49561 | Cost/Loss: 0.077548 | Weight: 0.529585 | Bias: 0.070898\n",
            "Iteration: 49562 | Cost/Loss: 0.077547 | Weight: 0.529585 | Bias: 0.070898\n",
            "Iteration: 49563 | Cost/Loss: 0.077547 | Weight: 0.529585 | Bias: 0.070898\n",
            "Iteration: 49564 | Cost/Loss: 0.077547 | Weight: 0.529586 | Bias: 0.070898\n",
            "Iteration: 49565 | Cost/Loss: 0.077547 | Weight: 0.529586 | Bias: 0.070899\n",
            "Iteration: 49566 | Cost/Loss: 0.077547 | Weight: 0.529586 | Bias: 0.070899\n",
            "Iteration: 49567 | Cost/Loss: 0.077547 | Weight: 0.529586 | Bias: 0.070899\n",
            "Iteration: 49568 | Cost/Loss: 0.077547 | Weight: 0.529587 | Bias: 0.070900\n",
            "Iteration: 49569 | Cost/Loss: 0.077547 | Weight: 0.529587 | Bias: 0.070900\n",
            "Iteration: 49570 | Cost/Loss: 0.077547 | Weight: 0.529587 | Bias: 0.070900\n",
            "Iteration: 49571 | Cost/Loss: 0.077547 | Weight: 0.529588 | Bias: 0.070901\n",
            "Iteration: 49572 | Cost/Loss: 0.077547 | Weight: 0.529588 | Bias: 0.070901\n",
            "Iteration: 49573 | Cost/Loss: 0.077547 | Weight: 0.529588 | Bias: 0.070901\n",
            "Iteration: 49574 | Cost/Loss: 0.077547 | Weight: 0.529589 | Bias: 0.070902\n",
            "Iteration: 49575 | Cost/Loss: 0.077547 | Weight: 0.529589 | Bias: 0.070902\n",
            "Iteration: 49576 | Cost/Loss: 0.077547 | Weight: 0.529589 | Bias: 0.070902\n",
            "Iteration: 49577 | Cost/Loss: 0.077547 | Weight: 0.529589 | Bias: 0.070903\n",
            "Iteration: 49578 | Cost/Loss: 0.077547 | Weight: 0.529590 | Bias: 0.070903\n",
            "Iteration: 49579 | Cost/Loss: 0.077547 | Weight: 0.529590 | Bias: 0.070903\n",
            "Iteration: 49580 | Cost/Loss: 0.077547 | Weight: 0.529590 | Bias: 0.070903\n",
            "Iteration: 49581 | Cost/Loss: 0.077547 | Weight: 0.529591 | Bias: 0.070904\n",
            "Iteration: 49582 | Cost/Loss: 0.077547 | Weight: 0.529591 | Bias: 0.070904\n",
            "Iteration: 49583 | Cost/Loss: 0.077547 | Weight: 0.529591 | Bias: 0.070904\n",
            "Iteration: 49584 | Cost/Loss: 0.077547 | Weight: 0.529592 | Bias: 0.070905\n",
            "Iteration: 49585 | Cost/Loss: 0.077547 | Weight: 0.529592 | Bias: 0.070905\n",
            "Iteration: 49586 | Cost/Loss: 0.077547 | Weight: 0.529592 | Bias: 0.070905\n",
            "Iteration: 49587 | Cost/Loss: 0.077547 | Weight: 0.529592 | Bias: 0.070906\n",
            "Iteration: 49588 | Cost/Loss: 0.077547 | Weight: 0.529593 | Bias: 0.070906\n",
            "Iteration: 49589 | Cost/Loss: 0.077547 | Weight: 0.529593 | Bias: 0.070906\n",
            "Iteration: 49590 | Cost/Loss: 0.077547 | Weight: 0.529593 | Bias: 0.070907\n",
            "Iteration: 49591 | Cost/Loss: 0.077547 | Weight: 0.529594 | Bias: 0.070907\n",
            "Iteration: 49592 | Cost/Loss: 0.077547 | Weight: 0.529594 | Bias: 0.070907\n",
            "Iteration: 49593 | Cost/Loss: 0.077547 | Weight: 0.529594 | Bias: 0.070908\n",
            "Iteration: 49594 | Cost/Loss: 0.077547 | Weight: 0.529595 | Bias: 0.070908\n",
            "Iteration: 49595 | Cost/Loss: 0.077547 | Weight: 0.529595 | Bias: 0.070908\n",
            "Iteration: 49596 | Cost/Loss: 0.077547 | Weight: 0.529595 | Bias: 0.070908\n",
            "Iteration: 49597 | Cost/Loss: 0.077547 | Weight: 0.529595 | Bias: 0.070909\n",
            "Iteration: 49598 | Cost/Loss: 0.077547 | Weight: 0.529596 | Bias: 0.070909\n",
            "Iteration: 49599 | Cost/Loss: 0.077547 | Weight: 0.529596 | Bias: 0.070909\n",
            "Iteration: 49600 | Cost/Loss: 0.077547 | Weight: 0.529596 | Bias: 0.070910\n",
            "Iteration: 49601 | Cost/Loss: 0.077547 | Weight: 0.529597 | Bias: 0.070910\n",
            "Iteration: 49602 | Cost/Loss: 0.077546 | Weight: 0.529597 | Bias: 0.070910\n",
            "Iteration: 49603 | Cost/Loss: 0.077546 | Weight: 0.529597 | Bias: 0.070911\n",
            "Iteration: 49604 | Cost/Loss: 0.077546 | Weight: 0.529598 | Bias: 0.070911\n",
            "Iteration: 49605 | Cost/Loss: 0.077546 | Weight: 0.529598 | Bias: 0.070911\n",
            "Iteration: 49606 | Cost/Loss: 0.077546 | Weight: 0.529598 | Bias: 0.070912\n",
            "Iteration: 49607 | Cost/Loss: 0.077546 | Weight: 0.529598 | Bias: 0.070912\n",
            "Iteration: 49608 | Cost/Loss: 0.077546 | Weight: 0.529599 | Bias: 0.070912\n",
            "Iteration: 49609 | Cost/Loss: 0.077546 | Weight: 0.529599 | Bias: 0.070913\n",
            "Iteration: 49610 | Cost/Loss: 0.077546 | Weight: 0.529599 | Bias: 0.070913\n",
            "Iteration: 49611 | Cost/Loss: 0.077546 | Weight: 0.529600 | Bias: 0.070913\n",
            "Iteration: 49612 | Cost/Loss: 0.077546 | Weight: 0.529600 | Bias: 0.070913\n",
            "Iteration: 49613 | Cost/Loss: 0.077546 | Weight: 0.529600 | Bias: 0.070914\n",
            "Iteration: 49614 | Cost/Loss: 0.077546 | Weight: 0.529601 | Bias: 0.070914\n",
            "Iteration: 49615 | Cost/Loss: 0.077546 | Weight: 0.529601 | Bias: 0.070914\n",
            "Iteration: 49616 | Cost/Loss: 0.077546 | Weight: 0.529601 | Bias: 0.070915\n",
            "Iteration: 49617 | Cost/Loss: 0.077546 | Weight: 0.529601 | Bias: 0.070915\n",
            "Iteration: 49618 | Cost/Loss: 0.077546 | Weight: 0.529602 | Bias: 0.070915\n",
            "Iteration: 49619 | Cost/Loss: 0.077546 | Weight: 0.529602 | Bias: 0.070916\n",
            "Iteration: 49620 | Cost/Loss: 0.077546 | Weight: 0.529602 | Bias: 0.070916\n",
            "Iteration: 49621 | Cost/Loss: 0.077546 | Weight: 0.529603 | Bias: 0.070916\n",
            "Iteration: 49622 | Cost/Loss: 0.077546 | Weight: 0.529603 | Bias: 0.070917\n",
            "Iteration: 49623 | Cost/Loss: 0.077546 | Weight: 0.529603 | Bias: 0.070917\n",
            "Iteration: 49624 | Cost/Loss: 0.077546 | Weight: 0.529603 | Bias: 0.070917\n",
            "Iteration: 49625 | Cost/Loss: 0.077546 | Weight: 0.529604 | Bias: 0.070918\n",
            "Iteration: 49626 | Cost/Loss: 0.077546 | Weight: 0.529604 | Bias: 0.070918\n",
            "Iteration: 49627 | Cost/Loss: 0.077546 | Weight: 0.529604 | Bias: 0.070918\n",
            "Iteration: 49628 | Cost/Loss: 0.077546 | Weight: 0.529605 | Bias: 0.070918\n",
            "Iteration: 49629 | Cost/Loss: 0.077546 | Weight: 0.529605 | Bias: 0.070919\n",
            "Iteration: 49630 | Cost/Loss: 0.077546 | Weight: 0.529605 | Bias: 0.070919\n",
            "Iteration: 49631 | Cost/Loss: 0.077546 | Weight: 0.529606 | Bias: 0.070919\n",
            "Iteration: 49632 | Cost/Loss: 0.077546 | Weight: 0.529606 | Bias: 0.070920\n",
            "Iteration: 49633 | Cost/Loss: 0.077546 | Weight: 0.529606 | Bias: 0.070920\n",
            "Iteration: 49634 | Cost/Loss: 0.077546 | Weight: 0.529606 | Bias: 0.070920\n",
            "Iteration: 49635 | Cost/Loss: 0.077546 | Weight: 0.529607 | Bias: 0.070921\n",
            "Iteration: 49636 | Cost/Loss: 0.077546 | Weight: 0.529607 | Bias: 0.070921\n",
            "Iteration: 49637 | Cost/Loss: 0.077546 | Weight: 0.529607 | Bias: 0.070921\n",
            "Iteration: 49638 | Cost/Loss: 0.077546 | Weight: 0.529608 | Bias: 0.070922\n",
            "Iteration: 49639 | Cost/Loss: 0.077546 | Weight: 0.529608 | Bias: 0.070922\n",
            "Iteration: 49640 | Cost/Loss: 0.077546 | Weight: 0.529608 | Bias: 0.070922\n",
            "Iteration: 49641 | Cost/Loss: 0.077546 | Weight: 0.529609 | Bias: 0.070923\n",
            "Iteration: 49642 | Cost/Loss: 0.077545 | Weight: 0.529609 | Bias: 0.070923\n",
            "Iteration: 49643 | Cost/Loss: 0.077545 | Weight: 0.529609 | Bias: 0.070923\n",
            "Iteration: 49644 | Cost/Loss: 0.077545 | Weight: 0.529609 | Bias: 0.070923\n",
            "Iteration: 49645 | Cost/Loss: 0.077545 | Weight: 0.529610 | Bias: 0.070924\n",
            "Iteration: 49646 | Cost/Loss: 0.077545 | Weight: 0.529610 | Bias: 0.070924\n",
            "Iteration: 49647 | Cost/Loss: 0.077545 | Weight: 0.529610 | Bias: 0.070924\n",
            "Iteration: 49648 | Cost/Loss: 0.077545 | Weight: 0.529611 | Bias: 0.070925\n",
            "Iteration: 49649 | Cost/Loss: 0.077545 | Weight: 0.529611 | Bias: 0.070925\n",
            "Iteration: 49650 | Cost/Loss: 0.077545 | Weight: 0.529611 | Bias: 0.070925\n",
            "Iteration: 49651 | Cost/Loss: 0.077545 | Weight: 0.529612 | Bias: 0.070926\n",
            "Iteration: 49652 | Cost/Loss: 0.077545 | Weight: 0.529612 | Bias: 0.070926\n",
            "Iteration: 49653 | Cost/Loss: 0.077545 | Weight: 0.529612 | Bias: 0.070926\n",
            "Iteration: 49654 | Cost/Loss: 0.077545 | Weight: 0.529612 | Bias: 0.070927\n",
            "Iteration: 49655 | Cost/Loss: 0.077545 | Weight: 0.529613 | Bias: 0.070927\n",
            "Iteration: 49656 | Cost/Loss: 0.077545 | Weight: 0.529613 | Bias: 0.070927\n",
            "Iteration: 49657 | Cost/Loss: 0.077545 | Weight: 0.529613 | Bias: 0.070928\n",
            "Iteration: 49658 | Cost/Loss: 0.077545 | Weight: 0.529614 | Bias: 0.070928\n",
            "Iteration: 49659 | Cost/Loss: 0.077545 | Weight: 0.529614 | Bias: 0.070928\n",
            "Iteration: 49660 | Cost/Loss: 0.077545 | Weight: 0.529614 | Bias: 0.070928\n",
            "Iteration: 49661 | Cost/Loss: 0.077545 | Weight: 0.529615 | Bias: 0.070929\n",
            "Iteration: 49662 | Cost/Loss: 0.077545 | Weight: 0.529615 | Bias: 0.070929\n",
            "Iteration: 49663 | Cost/Loss: 0.077545 | Weight: 0.529615 | Bias: 0.070929\n",
            "Iteration: 49664 | Cost/Loss: 0.077545 | Weight: 0.529615 | Bias: 0.070930\n",
            "Iteration: 49665 | Cost/Loss: 0.077545 | Weight: 0.529616 | Bias: 0.070930\n",
            "Iteration: 49666 | Cost/Loss: 0.077545 | Weight: 0.529616 | Bias: 0.070930\n",
            "Iteration: 49667 | Cost/Loss: 0.077545 | Weight: 0.529616 | Bias: 0.070931\n",
            "Iteration: 49668 | Cost/Loss: 0.077545 | Weight: 0.529617 | Bias: 0.070931\n",
            "Iteration: 49669 | Cost/Loss: 0.077545 | Weight: 0.529617 | Bias: 0.070931\n",
            "Iteration: 49670 | Cost/Loss: 0.077545 | Weight: 0.529617 | Bias: 0.070932\n",
            "Iteration: 49671 | Cost/Loss: 0.077545 | Weight: 0.529617 | Bias: 0.070932\n",
            "Iteration: 49672 | Cost/Loss: 0.077545 | Weight: 0.529618 | Bias: 0.070932\n",
            "Iteration: 49673 | Cost/Loss: 0.077545 | Weight: 0.529618 | Bias: 0.070933\n",
            "Iteration: 49674 | Cost/Loss: 0.077545 | Weight: 0.529618 | Bias: 0.070933\n",
            "Iteration: 49675 | Cost/Loss: 0.077545 | Weight: 0.529619 | Bias: 0.070933\n",
            "Iteration: 49676 | Cost/Loss: 0.077545 | Weight: 0.529619 | Bias: 0.070934\n",
            "Iteration: 49677 | Cost/Loss: 0.077545 | Weight: 0.529619 | Bias: 0.070934\n",
            "Iteration: 49678 | Cost/Loss: 0.077545 | Weight: 0.529620 | Bias: 0.070934\n",
            "Iteration: 49679 | Cost/Loss: 0.077545 | Weight: 0.529620 | Bias: 0.070934\n",
            "Iteration: 49680 | Cost/Loss: 0.077545 | Weight: 0.529620 | Bias: 0.070935\n",
            "Iteration: 49681 | Cost/Loss: 0.077545 | Weight: 0.529620 | Bias: 0.070935\n",
            "Iteration: 49682 | Cost/Loss: 0.077544 | Weight: 0.529621 | Bias: 0.070935\n",
            "Iteration: 49683 | Cost/Loss: 0.077544 | Weight: 0.529621 | Bias: 0.070936\n",
            "Iteration: 49684 | Cost/Loss: 0.077544 | Weight: 0.529621 | Bias: 0.070936\n",
            "Iteration: 49685 | Cost/Loss: 0.077544 | Weight: 0.529622 | Bias: 0.070936\n",
            "Iteration: 49686 | Cost/Loss: 0.077544 | Weight: 0.529622 | Bias: 0.070937\n",
            "Iteration: 49687 | Cost/Loss: 0.077544 | Weight: 0.529622 | Bias: 0.070937\n",
            "Iteration: 49688 | Cost/Loss: 0.077544 | Weight: 0.529623 | Bias: 0.070937\n",
            "Iteration: 49689 | Cost/Loss: 0.077544 | Weight: 0.529623 | Bias: 0.070938\n",
            "Iteration: 49690 | Cost/Loss: 0.077544 | Weight: 0.529623 | Bias: 0.070938\n",
            "Iteration: 49691 | Cost/Loss: 0.077544 | Weight: 0.529623 | Bias: 0.070938\n",
            "Iteration: 49692 | Cost/Loss: 0.077544 | Weight: 0.529624 | Bias: 0.070939\n",
            "Iteration: 49693 | Cost/Loss: 0.077544 | Weight: 0.529624 | Bias: 0.070939\n",
            "Iteration: 49694 | Cost/Loss: 0.077544 | Weight: 0.529624 | Bias: 0.070939\n",
            "Iteration: 49695 | Cost/Loss: 0.077544 | Weight: 0.529625 | Bias: 0.070939\n",
            "Iteration: 49696 | Cost/Loss: 0.077544 | Weight: 0.529625 | Bias: 0.070940\n",
            "Iteration: 49697 | Cost/Loss: 0.077544 | Weight: 0.529625 | Bias: 0.070940\n",
            "Iteration: 49698 | Cost/Loss: 0.077544 | Weight: 0.529626 | Bias: 0.070940\n",
            "Iteration: 49699 | Cost/Loss: 0.077544 | Weight: 0.529626 | Bias: 0.070941\n",
            "Iteration: 49700 | Cost/Loss: 0.077544 | Weight: 0.529626 | Bias: 0.070941\n",
            "Iteration: 49701 | Cost/Loss: 0.077544 | Weight: 0.529626 | Bias: 0.070941\n",
            "Iteration: 49702 | Cost/Loss: 0.077544 | Weight: 0.529627 | Bias: 0.070942\n",
            "Iteration: 49703 | Cost/Loss: 0.077544 | Weight: 0.529627 | Bias: 0.070942\n",
            "Iteration: 49704 | Cost/Loss: 0.077544 | Weight: 0.529627 | Bias: 0.070942\n",
            "Iteration: 49705 | Cost/Loss: 0.077544 | Weight: 0.529628 | Bias: 0.070943\n",
            "Iteration: 49706 | Cost/Loss: 0.077544 | Weight: 0.529628 | Bias: 0.070943\n",
            "Iteration: 49707 | Cost/Loss: 0.077544 | Weight: 0.529628 | Bias: 0.070943\n",
            "Iteration: 49708 | Cost/Loss: 0.077544 | Weight: 0.529629 | Bias: 0.070944\n",
            "Iteration: 49709 | Cost/Loss: 0.077544 | Weight: 0.529629 | Bias: 0.070944\n",
            "Iteration: 49710 | Cost/Loss: 0.077544 | Weight: 0.529629 | Bias: 0.070944\n",
            "Iteration: 49711 | Cost/Loss: 0.077544 | Weight: 0.529629 | Bias: 0.070944\n",
            "Iteration: 49712 | Cost/Loss: 0.077544 | Weight: 0.529630 | Bias: 0.070945\n",
            "Iteration: 49713 | Cost/Loss: 0.077544 | Weight: 0.529630 | Bias: 0.070945\n",
            "Iteration: 49714 | Cost/Loss: 0.077544 | Weight: 0.529630 | Bias: 0.070945\n",
            "Iteration: 49715 | Cost/Loss: 0.077544 | Weight: 0.529631 | Bias: 0.070946\n",
            "Iteration: 49716 | Cost/Loss: 0.077544 | Weight: 0.529631 | Bias: 0.070946\n",
            "Iteration: 49717 | Cost/Loss: 0.077544 | Weight: 0.529631 | Bias: 0.070946\n",
            "Iteration: 49718 | Cost/Loss: 0.077544 | Weight: 0.529631 | Bias: 0.070947\n",
            "Iteration: 49719 | Cost/Loss: 0.077544 | Weight: 0.529632 | Bias: 0.070947\n",
            "Iteration: 49720 | Cost/Loss: 0.077544 | Weight: 0.529632 | Bias: 0.070947\n",
            "Iteration: 49721 | Cost/Loss: 0.077544 | Weight: 0.529632 | Bias: 0.070948\n",
            "Iteration: 49722 | Cost/Loss: 0.077543 | Weight: 0.529633 | Bias: 0.070948\n",
            "Iteration: 49723 | Cost/Loss: 0.077543 | Weight: 0.529633 | Bias: 0.070948\n",
            "Iteration: 49724 | Cost/Loss: 0.077543 | Weight: 0.529633 | Bias: 0.070949\n",
            "Iteration: 49725 | Cost/Loss: 0.077543 | Weight: 0.529634 | Bias: 0.070949\n",
            "Iteration: 49726 | Cost/Loss: 0.077543 | Weight: 0.529634 | Bias: 0.070949\n",
            "Iteration: 49727 | Cost/Loss: 0.077543 | Weight: 0.529634 | Bias: 0.070949\n",
            "Iteration: 49728 | Cost/Loss: 0.077543 | Weight: 0.529634 | Bias: 0.070950\n",
            "Iteration: 49729 | Cost/Loss: 0.077543 | Weight: 0.529635 | Bias: 0.070950\n",
            "Iteration: 49730 | Cost/Loss: 0.077543 | Weight: 0.529635 | Bias: 0.070950\n",
            "Iteration: 49731 | Cost/Loss: 0.077543 | Weight: 0.529635 | Bias: 0.070951\n",
            "Iteration: 49732 | Cost/Loss: 0.077543 | Weight: 0.529636 | Bias: 0.070951\n",
            "Iteration: 49733 | Cost/Loss: 0.077543 | Weight: 0.529636 | Bias: 0.070951\n",
            "Iteration: 49734 | Cost/Loss: 0.077543 | Weight: 0.529636 | Bias: 0.070952\n",
            "Iteration: 49735 | Cost/Loss: 0.077543 | Weight: 0.529637 | Bias: 0.070952\n",
            "Iteration: 49736 | Cost/Loss: 0.077543 | Weight: 0.529637 | Bias: 0.070952\n",
            "Iteration: 49737 | Cost/Loss: 0.077543 | Weight: 0.529637 | Bias: 0.070953\n",
            "Iteration: 49738 | Cost/Loss: 0.077543 | Weight: 0.529637 | Bias: 0.070953\n",
            "Iteration: 49739 | Cost/Loss: 0.077543 | Weight: 0.529638 | Bias: 0.070953\n",
            "Iteration: 49740 | Cost/Loss: 0.077543 | Weight: 0.529638 | Bias: 0.070954\n",
            "Iteration: 49741 | Cost/Loss: 0.077543 | Weight: 0.529638 | Bias: 0.070954\n",
            "Iteration: 49742 | Cost/Loss: 0.077543 | Weight: 0.529639 | Bias: 0.070954\n",
            "Iteration: 49743 | Cost/Loss: 0.077543 | Weight: 0.529639 | Bias: 0.070954\n",
            "Iteration: 49744 | Cost/Loss: 0.077543 | Weight: 0.529639 | Bias: 0.070955\n",
            "Iteration: 49745 | Cost/Loss: 0.077543 | Weight: 0.529640 | Bias: 0.070955\n",
            "Iteration: 49746 | Cost/Loss: 0.077543 | Weight: 0.529640 | Bias: 0.070955\n",
            "Iteration: 49747 | Cost/Loss: 0.077543 | Weight: 0.529640 | Bias: 0.070956\n",
            "Iteration: 49748 | Cost/Loss: 0.077543 | Weight: 0.529640 | Bias: 0.070956\n",
            "Iteration: 49749 | Cost/Loss: 0.077543 | Weight: 0.529641 | Bias: 0.070956\n",
            "Iteration: 49750 | Cost/Loss: 0.077543 | Weight: 0.529641 | Bias: 0.070957\n",
            "Iteration: 49751 | Cost/Loss: 0.077543 | Weight: 0.529641 | Bias: 0.070957\n",
            "Iteration: 49752 | Cost/Loss: 0.077543 | Weight: 0.529642 | Bias: 0.070957\n",
            "Iteration: 49753 | Cost/Loss: 0.077543 | Weight: 0.529642 | Bias: 0.070958\n",
            "Iteration: 49754 | Cost/Loss: 0.077543 | Weight: 0.529642 | Bias: 0.070958\n",
            "Iteration: 49755 | Cost/Loss: 0.077543 | Weight: 0.529643 | Bias: 0.070958\n",
            "Iteration: 49756 | Cost/Loss: 0.077543 | Weight: 0.529643 | Bias: 0.070959\n",
            "Iteration: 49757 | Cost/Loss: 0.077543 | Weight: 0.529643 | Bias: 0.070959\n",
            "Iteration: 49758 | Cost/Loss: 0.077543 | Weight: 0.529643 | Bias: 0.070959\n",
            "Iteration: 49759 | Cost/Loss: 0.077543 | Weight: 0.529644 | Bias: 0.070959\n",
            "Iteration: 49760 | Cost/Loss: 0.077543 | Weight: 0.529644 | Bias: 0.070960\n",
            "Iteration: 49761 | Cost/Loss: 0.077543 | Weight: 0.529644 | Bias: 0.070960\n",
            "Iteration: 49762 | Cost/Loss: 0.077542 | Weight: 0.529645 | Bias: 0.070960\n",
            "Iteration: 49763 | Cost/Loss: 0.077542 | Weight: 0.529645 | Bias: 0.070961\n",
            "Iteration: 49764 | Cost/Loss: 0.077542 | Weight: 0.529645 | Bias: 0.070961\n",
            "Iteration: 49765 | Cost/Loss: 0.077542 | Weight: 0.529646 | Bias: 0.070961\n",
            "Iteration: 49766 | Cost/Loss: 0.077542 | Weight: 0.529646 | Bias: 0.070962\n",
            "Iteration: 49767 | Cost/Loss: 0.077542 | Weight: 0.529646 | Bias: 0.070962\n",
            "Iteration: 49768 | Cost/Loss: 0.077542 | Weight: 0.529646 | Bias: 0.070962\n",
            "Iteration: 49769 | Cost/Loss: 0.077542 | Weight: 0.529647 | Bias: 0.070963\n",
            "Iteration: 49770 | Cost/Loss: 0.077542 | Weight: 0.529647 | Bias: 0.070963\n",
            "Iteration: 49771 | Cost/Loss: 0.077542 | Weight: 0.529647 | Bias: 0.070963\n",
            "Iteration: 49772 | Cost/Loss: 0.077542 | Weight: 0.529648 | Bias: 0.070964\n",
            "Iteration: 49773 | Cost/Loss: 0.077542 | Weight: 0.529648 | Bias: 0.070964\n",
            "Iteration: 49774 | Cost/Loss: 0.077542 | Weight: 0.529648 | Bias: 0.070964\n",
            "Iteration: 49775 | Cost/Loss: 0.077542 | Weight: 0.529648 | Bias: 0.070964\n",
            "Iteration: 49776 | Cost/Loss: 0.077542 | Weight: 0.529649 | Bias: 0.070965\n",
            "Iteration: 49777 | Cost/Loss: 0.077542 | Weight: 0.529649 | Bias: 0.070965\n",
            "Iteration: 49778 | Cost/Loss: 0.077542 | Weight: 0.529649 | Bias: 0.070965\n",
            "Iteration: 49779 | Cost/Loss: 0.077542 | Weight: 0.529650 | Bias: 0.070966\n",
            "Iteration: 49780 | Cost/Loss: 0.077542 | Weight: 0.529650 | Bias: 0.070966\n",
            "Iteration: 49781 | Cost/Loss: 0.077542 | Weight: 0.529650 | Bias: 0.070966\n",
            "Iteration: 49782 | Cost/Loss: 0.077542 | Weight: 0.529651 | Bias: 0.070967\n",
            "Iteration: 49783 | Cost/Loss: 0.077542 | Weight: 0.529651 | Bias: 0.070967\n",
            "Iteration: 49784 | Cost/Loss: 0.077542 | Weight: 0.529651 | Bias: 0.070967\n",
            "Iteration: 49785 | Cost/Loss: 0.077542 | Weight: 0.529651 | Bias: 0.070968\n",
            "Iteration: 49786 | Cost/Loss: 0.077542 | Weight: 0.529652 | Bias: 0.070968\n",
            "Iteration: 49787 | Cost/Loss: 0.077542 | Weight: 0.529652 | Bias: 0.070968\n",
            "Iteration: 49788 | Cost/Loss: 0.077542 | Weight: 0.529652 | Bias: 0.070969\n",
            "Iteration: 49789 | Cost/Loss: 0.077542 | Weight: 0.529653 | Bias: 0.070969\n",
            "Iteration: 49790 | Cost/Loss: 0.077542 | Weight: 0.529653 | Bias: 0.070969\n",
            "Iteration: 49791 | Cost/Loss: 0.077542 | Weight: 0.529653 | Bias: 0.070969\n",
            "Iteration: 49792 | Cost/Loss: 0.077542 | Weight: 0.529654 | Bias: 0.070970\n",
            "Iteration: 49793 | Cost/Loss: 0.077542 | Weight: 0.529654 | Bias: 0.070970\n",
            "Iteration: 49794 | Cost/Loss: 0.077542 | Weight: 0.529654 | Bias: 0.070970\n",
            "Iteration: 49795 | Cost/Loss: 0.077542 | Weight: 0.529654 | Bias: 0.070971\n",
            "Iteration: 49796 | Cost/Loss: 0.077542 | Weight: 0.529655 | Bias: 0.070971\n",
            "Iteration: 49797 | Cost/Loss: 0.077542 | Weight: 0.529655 | Bias: 0.070971\n",
            "Iteration: 49798 | Cost/Loss: 0.077542 | Weight: 0.529655 | Bias: 0.070972\n",
            "Iteration: 49799 | Cost/Loss: 0.077542 | Weight: 0.529656 | Bias: 0.070972\n",
            "Iteration: 49800 | Cost/Loss: 0.077542 | Weight: 0.529656 | Bias: 0.070972\n",
            "Iteration: 49801 | Cost/Loss: 0.077542 | Weight: 0.529656 | Bias: 0.070973\n",
            "Iteration: 49802 | Cost/Loss: 0.077542 | Weight: 0.529657 | Bias: 0.070973\n",
            "Iteration: 49803 | Cost/Loss: 0.077541 | Weight: 0.529657 | Bias: 0.070973\n",
            "Iteration: 49804 | Cost/Loss: 0.077541 | Weight: 0.529657 | Bias: 0.070974\n",
            "Iteration: 49805 | Cost/Loss: 0.077541 | Weight: 0.529657 | Bias: 0.070974\n",
            "Iteration: 49806 | Cost/Loss: 0.077541 | Weight: 0.529658 | Bias: 0.070974\n",
            "Iteration: 49807 | Cost/Loss: 0.077541 | Weight: 0.529658 | Bias: 0.070974\n",
            "Iteration: 49808 | Cost/Loss: 0.077541 | Weight: 0.529658 | Bias: 0.070975\n",
            "Iteration: 49809 | Cost/Loss: 0.077541 | Weight: 0.529659 | Bias: 0.070975\n",
            "Iteration: 49810 | Cost/Loss: 0.077541 | Weight: 0.529659 | Bias: 0.070975\n",
            "Iteration: 49811 | Cost/Loss: 0.077541 | Weight: 0.529659 | Bias: 0.070976\n",
            "Iteration: 49812 | Cost/Loss: 0.077541 | Weight: 0.529660 | Bias: 0.070976\n",
            "Iteration: 49813 | Cost/Loss: 0.077541 | Weight: 0.529660 | Bias: 0.070976\n",
            "Iteration: 49814 | Cost/Loss: 0.077541 | Weight: 0.529660 | Bias: 0.070977\n",
            "Iteration: 49815 | Cost/Loss: 0.077541 | Weight: 0.529660 | Bias: 0.070977\n",
            "Iteration: 49816 | Cost/Loss: 0.077541 | Weight: 0.529661 | Bias: 0.070977\n",
            "Iteration: 49817 | Cost/Loss: 0.077541 | Weight: 0.529661 | Bias: 0.070978\n",
            "Iteration: 49818 | Cost/Loss: 0.077541 | Weight: 0.529661 | Bias: 0.070978\n",
            "Iteration: 49819 | Cost/Loss: 0.077541 | Weight: 0.529662 | Bias: 0.070978\n",
            "Iteration: 49820 | Cost/Loss: 0.077541 | Weight: 0.529662 | Bias: 0.070979\n",
            "Iteration: 49821 | Cost/Loss: 0.077541 | Weight: 0.529662 | Bias: 0.070979\n",
            "Iteration: 49822 | Cost/Loss: 0.077541 | Weight: 0.529662 | Bias: 0.070979\n",
            "Iteration: 49823 | Cost/Loss: 0.077541 | Weight: 0.529663 | Bias: 0.070980\n",
            "Iteration: 49824 | Cost/Loss: 0.077541 | Weight: 0.529663 | Bias: 0.070980\n",
            "Iteration: 49825 | Cost/Loss: 0.077541 | Weight: 0.529663 | Bias: 0.070980\n",
            "Iteration: 49826 | Cost/Loss: 0.077541 | Weight: 0.529664 | Bias: 0.070980\n",
            "Iteration: 49827 | Cost/Loss: 0.077541 | Weight: 0.529664 | Bias: 0.070981\n",
            "Iteration: 49828 | Cost/Loss: 0.077541 | Weight: 0.529664 | Bias: 0.070981\n",
            "Iteration: 49829 | Cost/Loss: 0.077541 | Weight: 0.529665 | Bias: 0.070981\n",
            "Iteration: 49830 | Cost/Loss: 0.077541 | Weight: 0.529665 | Bias: 0.070982\n",
            "Iteration: 49831 | Cost/Loss: 0.077541 | Weight: 0.529665 | Bias: 0.070982\n",
            "Iteration: 49832 | Cost/Loss: 0.077541 | Weight: 0.529665 | Bias: 0.070982\n",
            "Iteration: 49833 | Cost/Loss: 0.077541 | Weight: 0.529666 | Bias: 0.070983\n",
            "Iteration: 49834 | Cost/Loss: 0.077541 | Weight: 0.529666 | Bias: 0.070983\n",
            "Iteration: 49835 | Cost/Loss: 0.077541 | Weight: 0.529666 | Bias: 0.070983\n",
            "Iteration: 49836 | Cost/Loss: 0.077541 | Weight: 0.529667 | Bias: 0.070984\n",
            "Iteration: 49837 | Cost/Loss: 0.077541 | Weight: 0.529667 | Bias: 0.070984\n",
            "Iteration: 49838 | Cost/Loss: 0.077541 | Weight: 0.529667 | Bias: 0.070984\n",
            "Iteration: 49839 | Cost/Loss: 0.077541 | Weight: 0.529668 | Bias: 0.070985\n",
            "Iteration: 49840 | Cost/Loss: 0.077541 | Weight: 0.529668 | Bias: 0.070985\n",
            "Iteration: 49841 | Cost/Loss: 0.077541 | Weight: 0.529668 | Bias: 0.070985\n",
            "Iteration: 49842 | Cost/Loss: 0.077541 | Weight: 0.529668 | Bias: 0.070985\n",
            "Iteration: 49843 | Cost/Loss: 0.077540 | Weight: 0.529669 | Bias: 0.070986\n",
            "Iteration: 49844 | Cost/Loss: 0.077540 | Weight: 0.529669 | Bias: 0.070986\n",
            "Iteration: 49845 | Cost/Loss: 0.077540 | Weight: 0.529669 | Bias: 0.070986\n",
            "Iteration: 49846 | Cost/Loss: 0.077540 | Weight: 0.529670 | Bias: 0.070987\n",
            "Iteration: 49847 | Cost/Loss: 0.077540 | Weight: 0.529670 | Bias: 0.070987\n",
            "Iteration: 49848 | Cost/Loss: 0.077540 | Weight: 0.529670 | Bias: 0.070987\n",
            "Iteration: 49849 | Cost/Loss: 0.077540 | Weight: 0.529671 | Bias: 0.070988\n",
            "Iteration: 49850 | Cost/Loss: 0.077540 | Weight: 0.529671 | Bias: 0.070988\n",
            "Iteration: 49851 | Cost/Loss: 0.077540 | Weight: 0.529671 | Bias: 0.070988\n",
            "Iteration: 49852 | Cost/Loss: 0.077540 | Weight: 0.529671 | Bias: 0.070989\n",
            "Iteration: 49853 | Cost/Loss: 0.077540 | Weight: 0.529672 | Bias: 0.070989\n",
            "Iteration: 49854 | Cost/Loss: 0.077540 | Weight: 0.529672 | Bias: 0.070989\n",
            "Iteration: 49855 | Cost/Loss: 0.077540 | Weight: 0.529672 | Bias: 0.070990\n",
            "Iteration: 49856 | Cost/Loss: 0.077540 | Weight: 0.529673 | Bias: 0.070990\n",
            "Iteration: 49857 | Cost/Loss: 0.077540 | Weight: 0.529673 | Bias: 0.070990\n",
            "Iteration: 49858 | Cost/Loss: 0.077540 | Weight: 0.529673 | Bias: 0.070990\n",
            "Iteration: 49859 | Cost/Loss: 0.077540 | Weight: 0.529674 | Bias: 0.070991\n",
            "Iteration: 49860 | Cost/Loss: 0.077540 | Weight: 0.529674 | Bias: 0.070991\n",
            "Iteration: 49861 | Cost/Loss: 0.077540 | Weight: 0.529674 | Bias: 0.070991\n",
            "Iteration: 49862 | Cost/Loss: 0.077540 | Weight: 0.529674 | Bias: 0.070992\n",
            "Iteration: 49863 | Cost/Loss: 0.077540 | Weight: 0.529675 | Bias: 0.070992\n",
            "Iteration: 49864 | Cost/Loss: 0.077540 | Weight: 0.529675 | Bias: 0.070992\n",
            "Iteration: 49865 | Cost/Loss: 0.077540 | Weight: 0.529675 | Bias: 0.070993\n",
            "Iteration: 49866 | Cost/Loss: 0.077540 | Weight: 0.529676 | Bias: 0.070993\n",
            "Iteration: 49867 | Cost/Loss: 0.077540 | Weight: 0.529676 | Bias: 0.070993\n",
            "Iteration: 49868 | Cost/Loss: 0.077540 | Weight: 0.529676 | Bias: 0.070994\n",
            "Iteration: 49869 | Cost/Loss: 0.077540 | Weight: 0.529676 | Bias: 0.070994\n",
            "Iteration: 49870 | Cost/Loss: 0.077540 | Weight: 0.529677 | Bias: 0.070994\n",
            "Iteration: 49871 | Cost/Loss: 0.077540 | Weight: 0.529677 | Bias: 0.070995\n",
            "Iteration: 49872 | Cost/Loss: 0.077540 | Weight: 0.529677 | Bias: 0.070995\n",
            "Iteration: 49873 | Cost/Loss: 0.077540 | Weight: 0.529678 | Bias: 0.070995\n",
            "Iteration: 49874 | Cost/Loss: 0.077540 | Weight: 0.529678 | Bias: 0.070995\n",
            "Iteration: 49875 | Cost/Loss: 0.077540 | Weight: 0.529678 | Bias: 0.070996\n",
            "Iteration: 49876 | Cost/Loss: 0.077540 | Weight: 0.529679 | Bias: 0.070996\n",
            "Iteration: 49877 | Cost/Loss: 0.077540 | Weight: 0.529679 | Bias: 0.070996\n",
            "Iteration: 49878 | Cost/Loss: 0.077540 | Weight: 0.529679 | Bias: 0.070997\n",
            "Iteration: 49879 | Cost/Loss: 0.077540 | Weight: 0.529679 | Bias: 0.070997\n",
            "Iteration: 49880 | Cost/Loss: 0.077540 | Weight: 0.529680 | Bias: 0.070997\n",
            "Iteration: 49881 | Cost/Loss: 0.077540 | Weight: 0.529680 | Bias: 0.070998\n",
            "Iteration: 49882 | Cost/Loss: 0.077540 | Weight: 0.529680 | Bias: 0.070998\n",
            "Iteration: 49883 | Cost/Loss: 0.077539 | Weight: 0.529681 | Bias: 0.070998\n",
            "Iteration: 49884 | Cost/Loss: 0.077539 | Weight: 0.529681 | Bias: 0.070999\n",
            "Iteration: 49885 | Cost/Loss: 0.077539 | Weight: 0.529681 | Bias: 0.070999\n",
            "Iteration: 49886 | Cost/Loss: 0.077539 | Weight: 0.529682 | Bias: 0.070999\n",
            "Iteration: 49887 | Cost/Loss: 0.077539 | Weight: 0.529682 | Bias: 0.071000\n",
            "Iteration: 49888 | Cost/Loss: 0.077539 | Weight: 0.529682 | Bias: 0.071000\n",
            "Iteration: 49889 | Cost/Loss: 0.077539 | Weight: 0.529682 | Bias: 0.071000\n",
            "Iteration: 49890 | Cost/Loss: 0.077539 | Weight: 0.529683 | Bias: 0.071000\n",
            "Iteration: 49891 | Cost/Loss: 0.077539 | Weight: 0.529683 | Bias: 0.071001\n",
            "Iteration: 49892 | Cost/Loss: 0.077539 | Weight: 0.529683 | Bias: 0.071001\n",
            "Iteration: 49893 | Cost/Loss: 0.077539 | Weight: 0.529684 | Bias: 0.071001\n",
            "Iteration: 49894 | Cost/Loss: 0.077539 | Weight: 0.529684 | Bias: 0.071002\n",
            "Iteration: 49895 | Cost/Loss: 0.077539 | Weight: 0.529684 | Bias: 0.071002\n",
            "Iteration: 49896 | Cost/Loss: 0.077539 | Weight: 0.529685 | Bias: 0.071002\n",
            "Iteration: 49897 | Cost/Loss: 0.077539 | Weight: 0.529685 | Bias: 0.071003\n",
            "Iteration: 49898 | Cost/Loss: 0.077539 | Weight: 0.529685 | Bias: 0.071003\n",
            "Iteration: 49899 | Cost/Loss: 0.077539 | Weight: 0.529685 | Bias: 0.071003\n",
            "Iteration: 49900 | Cost/Loss: 0.077539 | Weight: 0.529686 | Bias: 0.071004\n",
            "Iteration: 49901 | Cost/Loss: 0.077539 | Weight: 0.529686 | Bias: 0.071004\n",
            "Iteration: 49902 | Cost/Loss: 0.077539 | Weight: 0.529686 | Bias: 0.071004\n",
            "Iteration: 49903 | Cost/Loss: 0.077539 | Weight: 0.529687 | Bias: 0.071005\n",
            "Iteration: 49904 | Cost/Loss: 0.077539 | Weight: 0.529687 | Bias: 0.071005\n",
            "Iteration: 49905 | Cost/Loss: 0.077539 | Weight: 0.529687 | Bias: 0.071005\n",
            "Iteration: 49906 | Cost/Loss: 0.077539 | Weight: 0.529688 | Bias: 0.071005\n",
            "Iteration: 49907 | Cost/Loss: 0.077539 | Weight: 0.529688 | Bias: 0.071006\n",
            "Iteration: 49908 | Cost/Loss: 0.077539 | Weight: 0.529688 | Bias: 0.071006\n",
            "Iteration: 49909 | Cost/Loss: 0.077539 | Weight: 0.529688 | Bias: 0.071006\n",
            "Iteration: 49910 | Cost/Loss: 0.077539 | Weight: 0.529689 | Bias: 0.071007\n",
            "Iteration: 49911 | Cost/Loss: 0.077539 | Weight: 0.529689 | Bias: 0.071007\n",
            "Iteration: 49912 | Cost/Loss: 0.077539 | Weight: 0.529689 | Bias: 0.071007\n",
            "Iteration: 49913 | Cost/Loss: 0.077539 | Weight: 0.529690 | Bias: 0.071008\n",
            "Iteration: 49914 | Cost/Loss: 0.077539 | Weight: 0.529690 | Bias: 0.071008\n",
            "Iteration: 49915 | Cost/Loss: 0.077539 | Weight: 0.529690 | Bias: 0.071008\n",
            "Iteration: 49916 | Cost/Loss: 0.077539 | Weight: 0.529691 | Bias: 0.071009\n",
            "Iteration: 49917 | Cost/Loss: 0.077539 | Weight: 0.529691 | Bias: 0.071009\n",
            "Iteration: 49918 | Cost/Loss: 0.077539 | Weight: 0.529691 | Bias: 0.071009\n",
            "Iteration: 49919 | Cost/Loss: 0.077539 | Weight: 0.529691 | Bias: 0.071010\n",
            "Iteration: 49920 | Cost/Loss: 0.077539 | Weight: 0.529692 | Bias: 0.071010\n",
            "Iteration: 49921 | Cost/Loss: 0.077539 | Weight: 0.529692 | Bias: 0.071010\n",
            "Iteration: 49922 | Cost/Loss: 0.077539 | Weight: 0.529692 | Bias: 0.071010\n",
            "Iteration: 49923 | Cost/Loss: 0.077538 | Weight: 0.529693 | Bias: 0.071011\n",
            "Iteration: 49924 | Cost/Loss: 0.077538 | Weight: 0.529693 | Bias: 0.071011\n",
            "Iteration: 49925 | Cost/Loss: 0.077538 | Weight: 0.529693 | Bias: 0.071011\n",
            "Iteration: 49926 | Cost/Loss: 0.077538 | Weight: 0.529693 | Bias: 0.071012\n",
            "Iteration: 49927 | Cost/Loss: 0.077538 | Weight: 0.529694 | Bias: 0.071012\n",
            "Iteration: 49928 | Cost/Loss: 0.077538 | Weight: 0.529694 | Bias: 0.071012\n",
            "Iteration: 49929 | Cost/Loss: 0.077538 | Weight: 0.529694 | Bias: 0.071013\n",
            "Iteration: 49930 | Cost/Loss: 0.077538 | Weight: 0.529695 | Bias: 0.071013\n",
            "Iteration: 49931 | Cost/Loss: 0.077538 | Weight: 0.529695 | Bias: 0.071013\n",
            "Iteration: 49932 | Cost/Loss: 0.077538 | Weight: 0.529695 | Bias: 0.071014\n",
            "Iteration: 49933 | Cost/Loss: 0.077538 | Weight: 0.529696 | Bias: 0.071014\n",
            "Iteration: 49934 | Cost/Loss: 0.077538 | Weight: 0.529696 | Bias: 0.071014\n",
            "Iteration: 49935 | Cost/Loss: 0.077538 | Weight: 0.529696 | Bias: 0.071015\n",
            "Iteration: 49936 | Cost/Loss: 0.077538 | Weight: 0.529696 | Bias: 0.071015\n",
            "Iteration: 49937 | Cost/Loss: 0.077538 | Weight: 0.529697 | Bias: 0.071015\n",
            "Iteration: 49938 | Cost/Loss: 0.077538 | Weight: 0.529697 | Bias: 0.071015\n",
            "Iteration: 49939 | Cost/Loss: 0.077538 | Weight: 0.529697 | Bias: 0.071016\n",
            "Iteration: 49940 | Cost/Loss: 0.077538 | Weight: 0.529698 | Bias: 0.071016\n",
            "Iteration: 49941 | Cost/Loss: 0.077538 | Weight: 0.529698 | Bias: 0.071016\n",
            "Iteration: 49942 | Cost/Loss: 0.077538 | Weight: 0.529698 | Bias: 0.071017\n",
            "Iteration: 49943 | Cost/Loss: 0.077538 | Weight: 0.529699 | Bias: 0.071017\n",
            "Iteration: 49944 | Cost/Loss: 0.077538 | Weight: 0.529699 | Bias: 0.071017\n",
            "Iteration: 49945 | Cost/Loss: 0.077538 | Weight: 0.529699 | Bias: 0.071018\n",
            "Iteration: 49946 | Cost/Loss: 0.077538 | Weight: 0.529699 | Bias: 0.071018\n",
            "Iteration: 49947 | Cost/Loss: 0.077538 | Weight: 0.529700 | Bias: 0.071018\n",
            "Iteration: 49948 | Cost/Loss: 0.077538 | Weight: 0.529700 | Bias: 0.071019\n",
            "Iteration: 49949 | Cost/Loss: 0.077538 | Weight: 0.529700 | Bias: 0.071019\n",
            "Iteration: 49950 | Cost/Loss: 0.077538 | Weight: 0.529701 | Bias: 0.071019\n",
            "Iteration: 49951 | Cost/Loss: 0.077538 | Weight: 0.529701 | Bias: 0.071020\n",
            "Iteration: 49952 | Cost/Loss: 0.077538 | Weight: 0.529701 | Bias: 0.071020\n",
            "Iteration: 49953 | Cost/Loss: 0.077538 | Weight: 0.529702 | Bias: 0.071020\n",
            "Iteration: 49954 | Cost/Loss: 0.077538 | Weight: 0.529702 | Bias: 0.071020\n",
            "Iteration: 49955 | Cost/Loss: 0.077538 | Weight: 0.529702 | Bias: 0.071021\n",
            "Iteration: 49956 | Cost/Loss: 0.077538 | Weight: 0.529702 | Bias: 0.071021\n",
            "Iteration: 49957 | Cost/Loss: 0.077538 | Weight: 0.529703 | Bias: 0.071021\n",
            "Iteration: 49958 | Cost/Loss: 0.077538 | Weight: 0.529703 | Bias: 0.071022\n",
            "Iteration: 49959 | Cost/Loss: 0.077538 | Weight: 0.529703 | Bias: 0.071022\n",
            "Iteration: 49960 | Cost/Loss: 0.077538 | Weight: 0.529704 | Bias: 0.071022\n",
            "Iteration: 49961 | Cost/Loss: 0.077538 | Weight: 0.529704 | Bias: 0.071023\n",
            "Iteration: 49962 | Cost/Loss: 0.077538 | Weight: 0.529704 | Bias: 0.071023\n",
            "Iteration: 49963 | Cost/Loss: 0.077537 | Weight: 0.529705 | Bias: 0.071023\n",
            "Iteration: 49964 | Cost/Loss: 0.077537 | Weight: 0.529705 | Bias: 0.071024\n",
            "Iteration: 49965 | Cost/Loss: 0.077537 | Weight: 0.529705 | Bias: 0.071024\n",
            "Iteration: 49966 | Cost/Loss: 0.077537 | Weight: 0.529705 | Bias: 0.071024\n",
            "Iteration: 49967 | Cost/Loss: 0.077537 | Weight: 0.529706 | Bias: 0.071025\n",
            "Iteration: 49968 | Cost/Loss: 0.077537 | Weight: 0.529706 | Bias: 0.071025\n",
            "Iteration: 49969 | Cost/Loss: 0.077537 | Weight: 0.529706 | Bias: 0.071025\n",
            "Iteration: 49970 | Cost/Loss: 0.077537 | Weight: 0.529707 | Bias: 0.071026\n",
            "Iteration: 49971 | Cost/Loss: 0.077537 | Weight: 0.529707 | Bias: 0.071026\n",
            "Iteration: 49972 | Cost/Loss: 0.077537 | Weight: 0.529707 | Bias: 0.071026\n",
            "Iteration: 49973 | Cost/Loss: 0.077537 | Weight: 0.529707 | Bias: 0.071026\n",
            "Iteration: 49974 | Cost/Loss: 0.077537 | Weight: 0.529708 | Bias: 0.071027\n",
            "Iteration: 49975 | Cost/Loss: 0.077537 | Weight: 0.529708 | Bias: 0.071027\n",
            "Iteration: 49976 | Cost/Loss: 0.077537 | Weight: 0.529708 | Bias: 0.071027\n",
            "Iteration: 49977 | Cost/Loss: 0.077537 | Weight: 0.529709 | Bias: 0.071028\n",
            "Iteration: 49978 | Cost/Loss: 0.077537 | Weight: 0.529709 | Bias: 0.071028\n",
            "Iteration: 49979 | Cost/Loss: 0.077537 | Weight: 0.529709 | Bias: 0.071028\n",
            "Iteration: 49980 | Cost/Loss: 0.077537 | Weight: 0.529710 | Bias: 0.071029\n",
            "Iteration: 49981 | Cost/Loss: 0.077537 | Weight: 0.529710 | Bias: 0.071029\n",
            "Iteration: 49982 | Cost/Loss: 0.077537 | Weight: 0.529710 | Bias: 0.071029\n",
            "Iteration: 49983 | Cost/Loss: 0.077537 | Weight: 0.529710 | Bias: 0.071030\n",
            "Iteration: 49984 | Cost/Loss: 0.077537 | Weight: 0.529711 | Bias: 0.071030\n",
            "Iteration: 49985 | Cost/Loss: 0.077537 | Weight: 0.529711 | Bias: 0.071030\n",
            "Iteration: 49986 | Cost/Loss: 0.077537 | Weight: 0.529711 | Bias: 0.071031\n",
            "Iteration: 49987 | Cost/Loss: 0.077537 | Weight: 0.529712 | Bias: 0.071031\n",
            "Iteration: 49988 | Cost/Loss: 0.077537 | Weight: 0.529712 | Bias: 0.071031\n",
            "Iteration: 49989 | Cost/Loss: 0.077537 | Weight: 0.529712 | Bias: 0.071031\n",
            "Iteration: 49990 | Cost/Loss: 0.077537 | Weight: 0.529713 | Bias: 0.071032\n",
            "Iteration: 49991 | Cost/Loss: 0.077537 | Weight: 0.529713 | Bias: 0.071032\n",
            "Iteration: 49992 | Cost/Loss: 0.077537 | Weight: 0.529713 | Bias: 0.071032\n",
            "Iteration: 49993 | Cost/Loss: 0.077537 | Weight: 0.529713 | Bias: 0.071033\n",
            "Iteration: 49994 | Cost/Loss: 0.077537 | Weight: 0.529714 | Bias: 0.071033\n",
            "Iteration: 49995 | Cost/Loss: 0.077537 | Weight: 0.529714 | Bias: 0.071033\n",
            "Iteration: 49996 | Cost/Loss: 0.077537 | Weight: 0.529714 | Bias: 0.071034\n",
            "Iteration: 49997 | Cost/Loss: 0.077537 | Weight: 0.529715 | Bias: 0.071034\n",
            "Iteration: 49998 | Cost/Loss: 0.077537 | Weight: 0.529715 | Bias: 0.071034\n",
            "Iteration: 49999 | Cost/Loss: 0.077537 | Weight: 0.529715 | Bias: 0.071035\n",
            "Iteration: 50000 | Cost/Loss: 0.077537 | Weight: 0.529716 | Bias: 0.071035\n",
            "Iteration: 50001 | Cost/Loss: 0.077537 | Weight: 0.529716 | Bias: 0.071035\n",
            "Iteration: 50002 | Cost/Loss: 0.077537 | Weight: 0.529716 | Bias: 0.071036\n",
            "Iteration: 50003 | Cost/Loss: 0.077536 | Weight: 0.529716 | Bias: 0.071036\n",
            "Iteration: 50004 | Cost/Loss: 0.077536 | Weight: 0.529717 | Bias: 0.071036\n",
            "Iteration: 50005 | Cost/Loss: 0.077536 | Weight: 0.529717 | Bias: 0.071036\n",
            "Iteration: 50006 | Cost/Loss: 0.077536 | Weight: 0.529717 | Bias: 0.071037\n",
            "Iteration: 50007 | Cost/Loss: 0.077536 | Weight: 0.529718 | Bias: 0.071037\n",
            "Iteration: 50008 | Cost/Loss: 0.077536 | Weight: 0.529718 | Bias: 0.071037\n",
            "Iteration: 50009 | Cost/Loss: 0.077536 | Weight: 0.529718 | Bias: 0.071038\n",
            "Iteration: 50010 | Cost/Loss: 0.077536 | Weight: 0.529719 | Bias: 0.071038\n",
            "Iteration: 50011 | Cost/Loss: 0.077536 | Weight: 0.529719 | Bias: 0.071038\n",
            "Iteration: 50012 | Cost/Loss: 0.077536 | Weight: 0.529719 | Bias: 0.071039\n",
            "Iteration: 50013 | Cost/Loss: 0.077536 | Weight: 0.529719 | Bias: 0.071039\n",
            "Iteration: 50014 | Cost/Loss: 0.077536 | Weight: 0.529720 | Bias: 0.071039\n",
            "Iteration: 50015 | Cost/Loss: 0.077536 | Weight: 0.529720 | Bias: 0.071040\n",
            "Iteration: 50016 | Cost/Loss: 0.077536 | Weight: 0.529720 | Bias: 0.071040\n",
            "Iteration: 50017 | Cost/Loss: 0.077536 | Weight: 0.529721 | Bias: 0.071040\n",
            "Iteration: 50018 | Cost/Loss: 0.077536 | Weight: 0.529721 | Bias: 0.071041\n",
            "Iteration: 50019 | Cost/Loss: 0.077536 | Weight: 0.529721 | Bias: 0.071041\n",
            "Iteration: 50020 | Cost/Loss: 0.077536 | Weight: 0.529721 | Bias: 0.071041\n",
            "Iteration: 50021 | Cost/Loss: 0.077536 | Weight: 0.529722 | Bias: 0.071041\n",
            "Iteration: 50022 | Cost/Loss: 0.077536 | Weight: 0.529722 | Bias: 0.071042\n",
            "Iteration: 50023 | Cost/Loss: 0.077536 | Weight: 0.529722 | Bias: 0.071042\n",
            "Iteration: 50024 | Cost/Loss: 0.077536 | Weight: 0.529723 | Bias: 0.071042\n",
            "Iteration: 50025 | Cost/Loss: 0.077536 | Weight: 0.529723 | Bias: 0.071043\n",
            "Iteration: 50026 | Cost/Loss: 0.077536 | Weight: 0.529723 | Bias: 0.071043\n",
            "Iteration: 50027 | Cost/Loss: 0.077536 | Weight: 0.529724 | Bias: 0.071043\n",
            "Iteration: 50028 | Cost/Loss: 0.077536 | Weight: 0.529724 | Bias: 0.071044\n",
            "Iteration: 50029 | Cost/Loss: 0.077536 | Weight: 0.529724 | Bias: 0.071044\n",
            "Iteration: 50030 | Cost/Loss: 0.077536 | Weight: 0.529724 | Bias: 0.071044\n",
            "Iteration: 50031 | Cost/Loss: 0.077536 | Weight: 0.529725 | Bias: 0.071045\n",
            "Iteration: 50032 | Cost/Loss: 0.077536 | Weight: 0.529725 | Bias: 0.071045\n",
            "Iteration: 50033 | Cost/Loss: 0.077536 | Weight: 0.529725 | Bias: 0.071045\n",
            "Iteration: 50034 | Cost/Loss: 0.077536 | Weight: 0.529726 | Bias: 0.071046\n",
            "Iteration: 50035 | Cost/Loss: 0.077536 | Weight: 0.529726 | Bias: 0.071046\n",
            "Iteration: 50036 | Cost/Loss: 0.077536 | Weight: 0.529726 | Bias: 0.071046\n",
            "Iteration: 50037 | Cost/Loss: 0.077536 | Weight: 0.529727 | Bias: 0.071046\n",
            "Iteration: 50038 | Cost/Loss: 0.077536 | Weight: 0.529727 | Bias: 0.071047\n",
            "Iteration: 50039 | Cost/Loss: 0.077536 | Weight: 0.529727 | Bias: 0.071047\n",
            "Iteration: 50040 | Cost/Loss: 0.077536 | Weight: 0.529727 | Bias: 0.071047\n",
            "Iteration: 50041 | Cost/Loss: 0.077536 | Weight: 0.529728 | Bias: 0.071048\n",
            "Iteration: 50042 | Cost/Loss: 0.077536 | Weight: 0.529728 | Bias: 0.071048\n",
            "Iteration: 50043 | Cost/Loss: 0.077535 | Weight: 0.529728 | Bias: 0.071048\n",
            "Iteration: 50044 | Cost/Loss: 0.077535 | Weight: 0.529729 | Bias: 0.071049\n",
            "Iteration: 50045 | Cost/Loss: 0.077535 | Weight: 0.529729 | Bias: 0.071049\n",
            "Iteration: 50046 | Cost/Loss: 0.077535 | Weight: 0.529729 | Bias: 0.071049\n",
            "Iteration: 50047 | Cost/Loss: 0.077535 | Weight: 0.529730 | Bias: 0.071050\n",
            "Iteration: 50048 | Cost/Loss: 0.077535 | Weight: 0.529730 | Bias: 0.071050\n",
            "Iteration: 50049 | Cost/Loss: 0.077535 | Weight: 0.529730 | Bias: 0.071050\n",
            "Iteration: 50050 | Cost/Loss: 0.077535 | Weight: 0.529730 | Bias: 0.071051\n",
            "Iteration: 50051 | Cost/Loss: 0.077535 | Weight: 0.529731 | Bias: 0.071051\n",
            "Iteration: 50052 | Cost/Loss: 0.077535 | Weight: 0.529731 | Bias: 0.071051\n",
            "Iteration: 50053 | Cost/Loss: 0.077535 | Weight: 0.529731 | Bias: 0.071051\n",
            "Iteration: 50054 | Cost/Loss: 0.077535 | Weight: 0.529732 | Bias: 0.071052\n",
            "Iteration: 50055 | Cost/Loss: 0.077535 | Weight: 0.529732 | Bias: 0.071052\n",
            "Iteration: 50056 | Cost/Loss: 0.077535 | Weight: 0.529732 | Bias: 0.071052\n",
            "Iteration: 50057 | Cost/Loss: 0.077535 | Weight: 0.529733 | Bias: 0.071053\n",
            "Iteration: 50058 | Cost/Loss: 0.077535 | Weight: 0.529733 | Bias: 0.071053\n",
            "Iteration: 50059 | Cost/Loss: 0.077535 | Weight: 0.529733 | Bias: 0.071053\n",
            "Iteration: 50060 | Cost/Loss: 0.077535 | Weight: 0.529733 | Bias: 0.071054\n",
            "Iteration: 50061 | Cost/Loss: 0.077535 | Weight: 0.529734 | Bias: 0.071054\n",
            "Iteration: 50062 | Cost/Loss: 0.077535 | Weight: 0.529734 | Bias: 0.071054\n",
            "Iteration: 50063 | Cost/Loss: 0.077535 | Weight: 0.529734 | Bias: 0.071055\n",
            "Iteration: 50064 | Cost/Loss: 0.077535 | Weight: 0.529735 | Bias: 0.071055\n",
            "Iteration: 50065 | Cost/Loss: 0.077535 | Weight: 0.529735 | Bias: 0.071055\n",
            "Iteration: 50066 | Cost/Loss: 0.077535 | Weight: 0.529735 | Bias: 0.071056\n",
            "Iteration: 50067 | Cost/Loss: 0.077535 | Weight: 0.529736 | Bias: 0.071056\n",
            "Iteration: 50068 | Cost/Loss: 0.077535 | Weight: 0.529736 | Bias: 0.071056\n",
            "Iteration: 50069 | Cost/Loss: 0.077535 | Weight: 0.529736 | Bias: 0.071056\n",
            "Iteration: 50070 | Cost/Loss: 0.077535 | Weight: 0.529736 | Bias: 0.071057\n",
            "Iteration: 50071 | Cost/Loss: 0.077535 | Weight: 0.529737 | Bias: 0.071057\n",
            "Iteration: 50072 | Cost/Loss: 0.077535 | Weight: 0.529737 | Bias: 0.071057\n",
            "Iteration: 50073 | Cost/Loss: 0.077535 | Weight: 0.529737 | Bias: 0.071058\n",
            "Iteration: 50074 | Cost/Loss: 0.077535 | Weight: 0.529738 | Bias: 0.071058\n",
            "Iteration: 50075 | Cost/Loss: 0.077535 | Weight: 0.529738 | Bias: 0.071058\n",
            "Iteration: 50076 | Cost/Loss: 0.077535 | Weight: 0.529738 | Bias: 0.071059\n",
            "Iteration: 50077 | Cost/Loss: 0.077535 | Weight: 0.529738 | Bias: 0.071059\n",
            "Iteration: 50078 | Cost/Loss: 0.077535 | Weight: 0.529739 | Bias: 0.071059\n",
            "Iteration: 50079 | Cost/Loss: 0.077535 | Weight: 0.529739 | Bias: 0.071060\n",
            "Iteration: 50080 | Cost/Loss: 0.077535 | Weight: 0.529739 | Bias: 0.071060\n",
            "Iteration: 50081 | Cost/Loss: 0.077535 | Weight: 0.529740 | Bias: 0.071060\n",
            "Iteration: 50082 | Cost/Loss: 0.077535 | Weight: 0.529740 | Bias: 0.071061\n",
            "Iteration: 50083 | Cost/Loss: 0.077534 | Weight: 0.529740 | Bias: 0.071061\n",
            "Iteration: 50084 | Cost/Loss: 0.077534 | Weight: 0.529741 | Bias: 0.071061\n",
            "Iteration: 50085 | Cost/Loss: 0.077534 | Weight: 0.529741 | Bias: 0.071061\n",
            "Iteration: 50086 | Cost/Loss: 0.077534 | Weight: 0.529741 | Bias: 0.071062\n",
            "Iteration: 50087 | Cost/Loss: 0.077534 | Weight: 0.529741 | Bias: 0.071062\n",
            "Iteration: 50088 | Cost/Loss: 0.077534 | Weight: 0.529742 | Bias: 0.071062\n",
            "Iteration: 50089 | Cost/Loss: 0.077534 | Weight: 0.529742 | Bias: 0.071063\n",
            "Iteration: 50090 | Cost/Loss: 0.077534 | Weight: 0.529742 | Bias: 0.071063\n",
            "Iteration: 50091 | Cost/Loss: 0.077534 | Weight: 0.529743 | Bias: 0.071063\n",
            "Iteration: 50092 | Cost/Loss: 0.077534 | Weight: 0.529743 | Bias: 0.071064\n",
            "Iteration: 50093 | Cost/Loss: 0.077534 | Weight: 0.529743 | Bias: 0.071064\n",
            "Iteration: 50094 | Cost/Loss: 0.077534 | Weight: 0.529744 | Bias: 0.071064\n",
            "Iteration: 50095 | Cost/Loss: 0.077534 | Weight: 0.529744 | Bias: 0.071065\n",
            "Iteration: 50096 | Cost/Loss: 0.077534 | Weight: 0.529744 | Bias: 0.071065\n",
            "Iteration: 50097 | Cost/Loss: 0.077534 | Weight: 0.529744 | Bias: 0.071065\n",
            "Iteration: 50098 | Cost/Loss: 0.077534 | Weight: 0.529745 | Bias: 0.071066\n",
            "Iteration: 50099 | Cost/Loss: 0.077534 | Weight: 0.529745 | Bias: 0.071066\n",
            "Iteration: 50100 | Cost/Loss: 0.077534 | Weight: 0.529745 | Bias: 0.071066\n",
            "Iteration: 50101 | Cost/Loss: 0.077534 | Weight: 0.529746 | Bias: 0.071066\n",
            "Iteration: 50102 | Cost/Loss: 0.077534 | Weight: 0.529746 | Bias: 0.071067\n",
            "Iteration: 50103 | Cost/Loss: 0.077534 | Weight: 0.529746 | Bias: 0.071067\n",
            "Iteration: 50104 | Cost/Loss: 0.077534 | Weight: 0.529747 | Bias: 0.071067\n",
            "Iteration: 50105 | Cost/Loss: 0.077534 | Weight: 0.529747 | Bias: 0.071068\n",
            "Iteration: 50106 | Cost/Loss: 0.077534 | Weight: 0.529747 | Bias: 0.071068\n",
            "Iteration: 50107 | Cost/Loss: 0.077534 | Weight: 0.529747 | Bias: 0.071068\n",
            "Iteration: 50108 | Cost/Loss: 0.077534 | Weight: 0.529748 | Bias: 0.071069\n",
            "Iteration: 50109 | Cost/Loss: 0.077534 | Weight: 0.529748 | Bias: 0.071069\n",
            "Iteration: 50110 | Cost/Loss: 0.077534 | Weight: 0.529748 | Bias: 0.071069\n",
            "Iteration: 50111 | Cost/Loss: 0.077534 | Weight: 0.529749 | Bias: 0.071070\n",
            "Iteration: 50112 | Cost/Loss: 0.077534 | Weight: 0.529749 | Bias: 0.071070\n",
            "Iteration: 50113 | Cost/Loss: 0.077534 | Weight: 0.529749 | Bias: 0.071070\n",
            "Iteration: 50114 | Cost/Loss: 0.077534 | Weight: 0.529750 | Bias: 0.071071\n",
            "Iteration: 50115 | Cost/Loss: 0.077534 | Weight: 0.529750 | Bias: 0.071071\n",
            "Iteration: 50116 | Cost/Loss: 0.077534 | Weight: 0.529750 | Bias: 0.071071\n",
            "Iteration: 50117 | Cost/Loss: 0.077534 | Weight: 0.529750 | Bias: 0.071072\n",
            "Iteration: 50118 | Cost/Loss: 0.077534 | Weight: 0.529751 | Bias: 0.071072\n",
            "Iteration: 50119 | Cost/Loss: 0.077534 | Weight: 0.529751 | Bias: 0.071072\n",
            "Iteration: 50120 | Cost/Loss: 0.077534 | Weight: 0.529751 | Bias: 0.071072\n",
            "Iteration: 50121 | Cost/Loss: 0.077534 | Weight: 0.529752 | Bias: 0.071073\n",
            "Iteration: 50122 | Cost/Loss: 0.077534 | Weight: 0.529752 | Bias: 0.071073\n",
            "Iteration: 50123 | Cost/Loss: 0.077533 | Weight: 0.529752 | Bias: 0.071073\n",
            "Iteration: 50124 | Cost/Loss: 0.077533 | Weight: 0.529752 | Bias: 0.071074\n",
            "Iteration: 50125 | Cost/Loss: 0.077533 | Weight: 0.529753 | Bias: 0.071074\n",
            "Iteration: 50126 | Cost/Loss: 0.077533 | Weight: 0.529753 | Bias: 0.071074\n",
            "Iteration: 50127 | Cost/Loss: 0.077533 | Weight: 0.529753 | Bias: 0.071075\n",
            "Iteration: 50128 | Cost/Loss: 0.077533 | Weight: 0.529754 | Bias: 0.071075\n",
            "Iteration: 50129 | Cost/Loss: 0.077533 | Weight: 0.529754 | Bias: 0.071075\n",
            "Iteration: 50130 | Cost/Loss: 0.077533 | Weight: 0.529754 | Bias: 0.071076\n",
            "Iteration: 50131 | Cost/Loss: 0.077533 | Weight: 0.529755 | Bias: 0.071076\n",
            "Iteration: 50132 | Cost/Loss: 0.077533 | Weight: 0.529755 | Bias: 0.071076\n",
            "Iteration: 50133 | Cost/Loss: 0.077533 | Weight: 0.529755 | Bias: 0.071077\n",
            "Iteration: 50134 | Cost/Loss: 0.077533 | Weight: 0.529755 | Bias: 0.071077\n",
            "Iteration: 50135 | Cost/Loss: 0.077533 | Weight: 0.529756 | Bias: 0.071077\n",
            "Iteration: 50136 | Cost/Loss: 0.077533 | Weight: 0.529756 | Bias: 0.071077\n",
            "Iteration: 50137 | Cost/Loss: 0.077533 | Weight: 0.529756 | Bias: 0.071078\n",
            "Iteration: 50138 | Cost/Loss: 0.077533 | Weight: 0.529757 | Bias: 0.071078\n",
            "Iteration: 50139 | Cost/Loss: 0.077533 | Weight: 0.529757 | Bias: 0.071078\n",
            "Iteration: 50140 | Cost/Loss: 0.077533 | Weight: 0.529757 | Bias: 0.071079\n",
            "Iteration: 50141 | Cost/Loss: 0.077533 | Weight: 0.529758 | Bias: 0.071079\n",
            "Iteration: 50142 | Cost/Loss: 0.077533 | Weight: 0.529758 | Bias: 0.071079\n",
            "Iteration: 50143 | Cost/Loss: 0.077533 | Weight: 0.529758 | Bias: 0.071080\n",
            "Iteration: 50144 | Cost/Loss: 0.077533 | Weight: 0.529758 | Bias: 0.071080\n",
            "Iteration: 50145 | Cost/Loss: 0.077533 | Weight: 0.529759 | Bias: 0.071080\n",
            "Iteration: 50146 | Cost/Loss: 0.077533 | Weight: 0.529759 | Bias: 0.071081\n",
            "Iteration: 50147 | Cost/Loss: 0.077533 | Weight: 0.529759 | Bias: 0.071081\n",
            "Iteration: 50148 | Cost/Loss: 0.077533 | Weight: 0.529760 | Bias: 0.071081\n",
            "Iteration: 50149 | Cost/Loss: 0.077533 | Weight: 0.529760 | Bias: 0.071082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "Iteration: 180325 | Cost/Loss: 0.074304 | Weight: 0.568555 | Bias: 0.111383\n",
            "Iteration: 180326 | Cost/Loss: 0.074304 | Weight: 0.568556 | Bias: 0.111383\n",
            "Iteration: 180327 | Cost/Loss: 0.074304 | Weight: 0.568556 | Bias: 0.111384\n",
            "Iteration: 180328 | Cost/Loss: 0.074304 | Weight: 0.568556 | Bias: 0.111384\n",
            "Iteration: 180329 | Cost/Loss: 0.074304 | Weight: 0.568557 | Bias: 0.111384\n",
            "Iteration: 180330 | Cost/Loss: 0.074304 | Weight: 0.568557 | Bias: 0.111385\n",
            "Iteration: 180331 | Cost/Loss: 0.074304 | Weight: 0.568557 | Bias: 0.111385\n",
            "Iteration: 180332 | Cost/Loss: 0.074304 | Weight: 0.568558 | Bias: 0.111385\n",
            "Iteration: 180333 | Cost/Loss: 0.074304 | Weight: 0.568558 | Bias: 0.111385\n",
            "Iteration: 180334 | Cost/Loss: 0.074304 | Weight: 0.568558 | Bias: 0.111386\n",
            "Iteration: 180335 | Cost/Loss: 0.074303 | Weight: 0.568558 | Bias: 0.111386\n",
            "Iteration: 180336 | Cost/Loss: 0.074303 | Weight: 0.568559 | Bias: 0.111386\n",
            "Iteration: 180337 | Cost/Loss: 0.074303 | Weight: 0.568559 | Bias: 0.111387\n",
            "Iteration: 180338 | Cost/Loss: 0.074303 | Weight: 0.568559 | Bias: 0.111387\n",
            "Iteration: 180339 | Cost/Loss: 0.074303 | Weight: 0.568560 | Bias: 0.111387\n",
            "Iteration: 180340 | Cost/Loss: 0.074303 | Weight: 0.568560 | Bias: 0.111388\n",
            "Iteration: 180341 | Cost/Loss: 0.074303 | Weight: 0.568560 | Bias: 0.111388\n",
            "Iteration: 180342 | Cost/Loss: 0.074303 | Weight: 0.568560 | Bias: 0.111388\n",
            "Iteration: 180343 | Cost/Loss: 0.074303 | Weight: 0.568561 | Bias: 0.111389\n",
            "Iteration: 180344 | Cost/Loss: 0.074303 | Weight: 0.568561 | Bias: 0.111389\n",
            "Iteration: 180345 | Cost/Loss: 0.074303 | Weight: 0.568561 | Bias: 0.111389\n",
            "Iteration: 180346 | Cost/Loss: 0.074303 | Weight: 0.568562 | Bias: 0.111389\n",
            "Iteration: 180347 | Cost/Loss: 0.074303 | Weight: 0.568562 | Bias: 0.111390\n",
            "Iteration: 180348 | Cost/Loss: 0.074303 | Weight: 0.568562 | Bias: 0.111390\n",
            "Iteration: 180349 | Cost/Loss: 0.074303 | Weight: 0.568563 | Bias: 0.111390\n",
            "Iteration: 180350 | Cost/Loss: 0.074303 | Weight: 0.568563 | Bias: 0.111391\n",
            "Iteration: 180351 | Cost/Loss: 0.074303 | Weight: 0.568563 | Bias: 0.111391\n",
            "Iteration: 180352 | Cost/Loss: 0.074303 | Weight: 0.568563 | Bias: 0.111391\n",
            "Iteration: 180353 | Cost/Loss: 0.074303 | Weight: 0.568564 | Bias: 0.111392\n",
            "Iteration: 180354 | Cost/Loss: 0.074303 | Weight: 0.568564 | Bias: 0.111392\n",
            "Iteration: 180355 | Cost/Loss: 0.074303 | Weight: 0.568564 | Bias: 0.111392\n",
            "Iteration: 180356 | Cost/Loss: 0.074303 | Weight: 0.568565 | Bias: 0.111392\n",
            "Iteration: 180357 | Cost/Loss: 0.074303 | Weight: 0.568565 | Bias: 0.111393\n",
            "Iteration: 180358 | Cost/Loss: 0.074303 | Weight: 0.568565 | Bias: 0.111393\n",
            "Iteration: 180359 | Cost/Loss: 0.074303 | Weight: 0.568566 | Bias: 0.111393\n",
            "Iteration: 180360 | Cost/Loss: 0.074303 | Weight: 0.568566 | Bias: 0.111394\n",
            "Iteration: 180361 | Cost/Loss: 0.074303 | Weight: 0.568566 | Bias: 0.111394\n",
            "Iteration: 180362 | Cost/Loss: 0.074303 | Weight: 0.568566 | Bias: 0.111394\n",
            "Iteration: 180363 | Cost/Loss: 0.074303 | Weight: 0.568567 | Bias: 0.111395\n",
            "Iteration: 180364 | Cost/Loss: 0.074303 | Weight: 0.568567 | Bias: 0.111395\n",
            "Iteration: 180365 | Cost/Loss: 0.074303 | Weight: 0.568567 | Bias: 0.111395\n",
            "Iteration: 180366 | Cost/Loss: 0.074303 | Weight: 0.568568 | Bias: 0.111396\n",
            "Iteration: 180367 | Cost/Loss: 0.074303 | Weight: 0.568568 | Bias: 0.111396\n",
            "Iteration: 180368 | Cost/Loss: 0.074303 | Weight: 0.568568 | Bias: 0.111396\n",
            "Iteration: 180369 | Cost/Loss: 0.074303 | Weight: 0.568569 | Bias: 0.111396\n",
            "Iteration: 180370 | Cost/Loss: 0.074303 | Weight: 0.568569 | Bias: 0.111397\n",
            "Iteration: 180371 | Cost/Loss: 0.074303 | Weight: 0.568569 | Bias: 0.111397\n",
            "Iteration: 180372 | Cost/Loss: 0.074303 | Weight: 0.568569 | Bias: 0.111397\n",
            "Iteration: 180373 | Cost/Loss: 0.074303 | Weight: 0.568570 | Bias: 0.111398\n",
            "Iteration: 180374 | Cost/Loss: 0.074303 | Weight: 0.568570 | Bias: 0.111398\n",
            "Iteration: 180375 | Cost/Loss: 0.074302 | Weight: 0.568570 | Bias: 0.111398\n",
            "Iteration: 180376 | Cost/Loss: 0.074302 | Weight: 0.568571 | Bias: 0.111399\n",
            "Iteration: 180377 | Cost/Loss: 0.074302 | Weight: 0.568571 | Bias: 0.111399\n",
            "Iteration: 180378 | Cost/Loss: 0.074302 | Weight: 0.568571 | Bias: 0.111399\n",
            "Iteration: 180379 | Cost/Loss: 0.074302 | Weight: 0.568572 | Bias: 0.111400\n",
            "Iteration: 180380 | Cost/Loss: 0.074302 | Weight: 0.568572 | Bias: 0.111400\n",
            "Iteration: 180381 | Cost/Loss: 0.074302 | Weight: 0.568572 | Bias: 0.111400\n",
            "Iteration: 180382 | Cost/Loss: 0.074302 | Weight: 0.568572 | Bias: 0.111400\n",
            "Iteration: 180383 | Cost/Loss: 0.074302 | Weight: 0.568573 | Bias: 0.111401\n",
            "Iteration: 180384 | Cost/Loss: 0.074302 | Weight: 0.568573 | Bias: 0.111401\n",
            "Iteration: 180385 | Cost/Loss: 0.074302 | Weight: 0.568573 | Bias: 0.111401\n",
            "Iteration: 180386 | Cost/Loss: 0.074302 | Weight: 0.568574 | Bias: 0.111402\n",
            "Iteration: 180387 | Cost/Loss: 0.074302 | Weight: 0.568574 | Bias: 0.111402\n",
            "Iteration: 180388 | Cost/Loss: 0.074302 | Weight: 0.568574 | Bias: 0.111402\n",
            "Iteration: 180389 | Cost/Loss: 0.074302 | Weight: 0.568574 | Bias: 0.111403\n",
            "Iteration: 180390 | Cost/Loss: 0.074302 | Weight: 0.568575 | Bias: 0.111403\n",
            "Iteration: 180391 | Cost/Loss: 0.074302 | Weight: 0.568575 | Bias: 0.111403\n",
            "Iteration: 180392 | Cost/Loss: 0.074302 | Weight: 0.568575 | Bias: 0.111403\n",
            "Iteration: 180393 | Cost/Loss: 0.074302 | Weight: 0.568576 | Bias: 0.111404\n",
            "Iteration: 180394 | Cost/Loss: 0.074302 | Weight: 0.568576 | Bias: 0.111404\n",
            "Iteration: 180395 | Cost/Loss: 0.074302 | Weight: 0.568576 | Bias: 0.111404\n",
            "Iteration: 180396 | Cost/Loss: 0.074302 | Weight: 0.568577 | Bias: 0.111405\n",
            "Iteration: 180397 | Cost/Loss: 0.074302 | Weight: 0.568577 | Bias: 0.111405\n",
            "Iteration: 180398 | Cost/Loss: 0.074302 | Weight: 0.568577 | Bias: 0.111405\n",
            "Iteration: 180399 | Cost/Loss: 0.074302 | Weight: 0.568577 | Bias: 0.111406\n",
            "Iteration: 180400 | Cost/Loss: 0.074302 | Weight: 0.568578 | Bias: 0.111406\n",
            "Iteration: 180401 | Cost/Loss: 0.074302 | Weight: 0.568578 | Bias: 0.111406\n",
            "Iteration: 180402 | Cost/Loss: 0.074302 | Weight: 0.568578 | Bias: 0.111407\n",
            "Iteration: 180403 | Cost/Loss: 0.074302 | Weight: 0.568579 | Bias: 0.111407\n",
            "Iteration: 180404 | Cost/Loss: 0.074302 | Weight: 0.568579 | Bias: 0.111407\n",
            "Iteration: 180405 | Cost/Loss: 0.074302 | Weight: 0.568579 | Bias: 0.111407\n",
            "Iteration: 180406 | Cost/Loss: 0.074302 | Weight: 0.568580 | Bias: 0.111408\n",
            "Iteration: 180407 | Cost/Loss: 0.074302 | Weight: 0.568580 | Bias: 0.111408\n",
            "Iteration: 180408 | Cost/Loss: 0.074302 | Weight: 0.568580 | Bias: 0.111408\n",
            "Iteration: 180409 | Cost/Loss: 0.074302 | Weight: 0.568580 | Bias: 0.111409\n",
            "Iteration: 180410 | Cost/Loss: 0.074302 | Weight: 0.568581 | Bias: 0.111409\n",
            "Iteration: 180411 | Cost/Loss: 0.074302 | Weight: 0.568581 | Bias: 0.111409\n",
            "Iteration: 180412 | Cost/Loss: 0.074302 | Weight: 0.568581 | Bias: 0.111410\n",
            "Iteration: 180413 | Cost/Loss: 0.074302 | Weight: 0.568582 | Bias: 0.111410\n",
            "Iteration: 180414 | Cost/Loss: 0.074302 | Weight: 0.568582 | Bias: 0.111410\n",
            "Iteration: 180415 | Cost/Loss: 0.074302 | Weight: 0.568582 | Bias: 0.111411\n",
            "Iteration: 180416 | Cost/Loss: 0.074301 | Weight: 0.568583 | Bias: 0.111411\n",
            "Iteration: 180417 | Cost/Loss: 0.074301 | Weight: 0.568583 | Bias: 0.111411\n",
            "Iteration: 180418 | Cost/Loss: 0.074301 | Weight: 0.568583 | Bias: 0.111411\n",
            "Iteration: 180419 | Cost/Loss: 0.074301 | Weight: 0.568583 | Bias: 0.111412\n",
            "Iteration: 180420 | Cost/Loss: 0.074301 | Weight: 0.568584 | Bias: 0.111412\n",
            "Iteration: 180421 | Cost/Loss: 0.074301 | Weight: 0.568584 | Bias: 0.111412\n",
            "Iteration: 180422 | Cost/Loss: 0.074301 | Weight: 0.568584 | Bias: 0.111413\n",
            "Iteration: 180423 | Cost/Loss: 0.074301 | Weight: 0.568585 | Bias: 0.111413\n",
            "Iteration: 180424 | Cost/Loss: 0.074301 | Weight: 0.568585 | Bias: 0.111413\n",
            "Iteration: 180425 | Cost/Loss: 0.074301 | Weight: 0.568585 | Bias: 0.111414\n",
            "Iteration: 180426 | Cost/Loss: 0.074301 | Weight: 0.568586 | Bias: 0.111414\n",
            "Iteration: 180427 | Cost/Loss: 0.074301 | Weight: 0.568586 | Bias: 0.111414\n",
            "Iteration: 180428 | Cost/Loss: 0.074301 | Weight: 0.568586 | Bias: 0.111414\n",
            "Iteration: 180429 | Cost/Loss: 0.074301 | Weight: 0.568586 | Bias: 0.111415\n",
            "Iteration: 180430 | Cost/Loss: 0.074301 | Weight: 0.568587 | Bias: 0.111415\n",
            "Iteration: 180431 | Cost/Loss: 0.074301 | Weight: 0.568587 | Bias: 0.111415\n",
            "Iteration: 180432 | Cost/Loss: 0.074301 | Weight: 0.568587 | Bias: 0.111416\n",
            "Iteration: 180433 | Cost/Loss: 0.074301 | Weight: 0.568588 | Bias: 0.111416\n",
            "Iteration: 180434 | Cost/Loss: 0.074301 | Weight: 0.568588 | Bias: 0.111416\n",
            "Iteration: 180435 | Cost/Loss: 0.074301 | Weight: 0.568588 | Bias: 0.111417\n",
            "Iteration: 180436 | Cost/Loss: 0.074301 | Weight: 0.568588 | Bias: 0.111417\n",
            "Iteration: 180437 | Cost/Loss: 0.074301 | Weight: 0.568589 | Bias: 0.111417\n",
            "Iteration: 180438 | Cost/Loss: 0.074301 | Weight: 0.568589 | Bias: 0.111418\n",
            "Iteration: 180439 | Cost/Loss: 0.074301 | Weight: 0.568589 | Bias: 0.111418\n",
            "Iteration: 180440 | Cost/Loss: 0.074301 | Weight: 0.568590 | Bias: 0.111418\n",
            "Iteration: 180441 | Cost/Loss: 0.074301 | Weight: 0.568590 | Bias: 0.111418\n",
            "Iteration: 180442 | Cost/Loss: 0.074301 | Weight: 0.568590 | Bias: 0.111419\n",
            "Iteration: 180443 | Cost/Loss: 0.074301 | Weight: 0.568591 | Bias: 0.111419\n",
            "Iteration: 180444 | Cost/Loss: 0.074301 | Weight: 0.568591 | Bias: 0.111419\n",
            "Iteration: 180445 | Cost/Loss: 0.074301 | Weight: 0.568591 | Bias: 0.111420\n",
            "Iteration: 180446 | Cost/Loss: 0.074301 | Weight: 0.568591 | Bias: 0.111420\n",
            "Iteration: 180447 | Cost/Loss: 0.074301 | Weight: 0.568592 | Bias: 0.111420\n",
            "Iteration: 180448 | Cost/Loss: 0.074301 | Weight: 0.568592 | Bias: 0.111421\n",
            "Iteration: 180449 | Cost/Loss: 0.074301 | Weight: 0.568592 | Bias: 0.111421\n",
            "Iteration: 180450 | Cost/Loss: 0.074301 | Weight: 0.568593 | Bias: 0.111421\n",
            "Iteration: 180451 | Cost/Loss: 0.074301 | Weight: 0.568593 | Bias: 0.111422\n",
            "Iteration: 180452 | Cost/Loss: 0.074301 | Weight: 0.568593 | Bias: 0.111422\n",
            "Iteration: 180453 | Cost/Loss: 0.074301 | Weight: 0.568594 | Bias: 0.111422\n",
            "Iteration: 180454 | Cost/Loss: 0.074301 | Weight: 0.568594 | Bias: 0.111422\n",
            "Iteration: 180455 | Cost/Loss: 0.074301 | Weight: 0.568594 | Bias: 0.111423\n",
            "Iteration: 180456 | Cost/Loss: 0.074300 | Weight: 0.568594 | Bias: 0.111423\n",
            "Iteration: 180457 | Cost/Loss: 0.074300 | Weight: 0.568595 | Bias: 0.111423\n",
            "Iteration: 180458 | Cost/Loss: 0.074300 | Weight: 0.568595 | Bias: 0.111424\n",
            "Iteration: 180459 | Cost/Loss: 0.074300 | Weight: 0.568595 | Bias: 0.111424\n",
            "Iteration: 180460 | Cost/Loss: 0.074300 | Weight: 0.568596 | Bias: 0.111424\n",
            "Iteration: 180461 | Cost/Loss: 0.074300 | Weight: 0.568596 | Bias: 0.111425\n",
            "Iteration: 180462 | Cost/Loss: 0.074300 | Weight: 0.568596 | Bias: 0.111425\n",
            "Iteration: 180463 | Cost/Loss: 0.074300 | Weight: 0.568597 | Bias: 0.111425\n",
            "Iteration: 180464 | Cost/Loss: 0.074300 | Weight: 0.568597 | Bias: 0.111425\n",
            "Iteration: 180465 | Cost/Loss: 0.074300 | Weight: 0.568597 | Bias: 0.111426\n",
            "Iteration: 180466 | Cost/Loss: 0.074300 | Weight: 0.568597 | Bias: 0.111426\n",
            "Iteration: 180467 | Cost/Loss: 0.074300 | Weight: 0.568598 | Bias: 0.111426\n",
            "Iteration: 180468 | Cost/Loss: 0.074300 | Weight: 0.568598 | Bias: 0.111427\n",
            "Iteration: 180469 | Cost/Loss: 0.074300 | Weight: 0.568598 | Bias: 0.111427\n",
            "Iteration: 180470 | Cost/Loss: 0.074300 | Weight: 0.568599 | Bias: 0.111427\n",
            "Iteration: 180471 | Cost/Loss: 0.074300 | Weight: 0.568599 | Bias: 0.111428\n",
            "Iteration: 180472 | Cost/Loss: 0.074300 | Weight: 0.568599 | Bias: 0.111428\n",
            "Iteration: 180473 | Cost/Loss: 0.074300 | Weight: 0.568600 | Bias: 0.111428\n",
            "Iteration: 180474 | Cost/Loss: 0.074300 | Weight: 0.568600 | Bias: 0.111429\n",
            "Iteration: 180475 | Cost/Loss: 0.074300 | Weight: 0.568600 | Bias: 0.111429\n",
            "Iteration: 180476 | Cost/Loss: 0.074300 | Weight: 0.568600 | Bias: 0.111429\n",
            "Iteration: 180477 | Cost/Loss: 0.074300 | Weight: 0.568601 | Bias: 0.111429\n",
            "Iteration: 180478 | Cost/Loss: 0.074300 | Weight: 0.568601 | Bias: 0.111430\n",
            "Iteration: 180479 | Cost/Loss: 0.074300 | Weight: 0.568601 | Bias: 0.111430\n",
            "Iteration: 180480 | Cost/Loss: 0.074300 | Weight: 0.568602 | Bias: 0.111430\n",
            "Iteration: 180481 | Cost/Loss: 0.074300 | Weight: 0.568602 | Bias: 0.111431\n",
            "Iteration: 180482 | Cost/Loss: 0.074300 | Weight: 0.568602 | Bias: 0.111431\n",
            "Iteration: 180483 | Cost/Loss: 0.074300 | Weight: 0.568603 | Bias: 0.111431\n",
            "Iteration: 180484 | Cost/Loss: 0.074300 | Weight: 0.568603 | Bias: 0.111432\n",
            "Iteration: 180485 | Cost/Loss: 0.074300 | Weight: 0.568603 | Bias: 0.111432\n",
            "Iteration: 180486 | Cost/Loss: 0.074300 | Weight: 0.568603 | Bias: 0.111432\n",
            "Iteration: 180487 | Cost/Loss: 0.074300 | Weight: 0.568604 | Bias: 0.111433\n",
            "Iteration: 180488 | Cost/Loss: 0.074300 | Weight: 0.568604 | Bias: 0.111433\n",
            "Iteration: 180489 | Cost/Loss: 0.074300 | Weight: 0.568604 | Bias: 0.111433\n",
            "Iteration: 180490 | Cost/Loss: 0.074300 | Weight: 0.568605 | Bias: 0.111433\n",
            "Iteration: 180491 | Cost/Loss: 0.074300 | Weight: 0.568605 | Bias: 0.111434\n",
            "Iteration: 180492 | Cost/Loss: 0.074300 | Weight: 0.568605 | Bias: 0.111434\n",
            "Iteration: 180493 | Cost/Loss: 0.074300 | Weight: 0.568605 | Bias: 0.111434\n",
            "Iteration: 180494 | Cost/Loss: 0.074300 | Weight: 0.568606 | Bias: 0.111435\n",
            "Iteration: 180495 | Cost/Loss: 0.074300 | Weight: 0.568606 | Bias: 0.111435\n",
            "Iteration: 180496 | Cost/Loss: 0.074300 | Weight: 0.568606 | Bias: 0.111435\n",
            "Iteration: 180497 | Cost/Loss: 0.074299 | Weight: 0.568607 | Bias: 0.111436\n",
            "Iteration: 180498 | Cost/Loss: 0.074299 | Weight: 0.568607 | Bias: 0.111436\n",
            "Iteration: 180499 | Cost/Loss: 0.074299 | Weight: 0.568607 | Bias: 0.111436\n",
            "Iteration: 180500 | Cost/Loss: 0.074299 | Weight: 0.568608 | Bias: 0.111436\n",
            "Iteration: 180501 | Cost/Loss: 0.074299 | Weight: 0.568608 | Bias: 0.111437\n",
            "Iteration: 180502 | Cost/Loss: 0.074299 | Weight: 0.568608 | Bias: 0.111437\n",
            "Iteration: 180503 | Cost/Loss: 0.074299 | Weight: 0.568608 | Bias: 0.111437\n",
            "Iteration: 180504 | Cost/Loss: 0.074299 | Weight: 0.568609 | Bias: 0.111438\n",
            "Iteration: 180505 | Cost/Loss: 0.074299 | Weight: 0.568609 | Bias: 0.111438\n",
            "Iteration: 180506 | Cost/Loss: 0.074299 | Weight: 0.568609 | Bias: 0.111438\n",
            "Iteration: 180507 | Cost/Loss: 0.074299 | Weight: 0.568610 | Bias: 0.111439\n",
            "Iteration: 180508 | Cost/Loss: 0.074299 | Weight: 0.568610 | Bias: 0.111439\n",
            "Iteration: 180509 | Cost/Loss: 0.074299 | Weight: 0.568610 | Bias: 0.111439\n",
            "Iteration: 180510 | Cost/Loss: 0.074299 | Weight: 0.568611 | Bias: 0.111440\n",
            "Iteration: 180511 | Cost/Loss: 0.074299 | Weight: 0.568611 | Bias: 0.111440\n",
            "Iteration: 180512 | Cost/Loss: 0.074299 | Weight: 0.568611 | Bias: 0.111440\n",
            "Iteration: 180513 | Cost/Loss: 0.074299 | Weight: 0.568611 | Bias: 0.111440\n",
            "Iteration: 180514 | Cost/Loss: 0.074299 | Weight: 0.568612 | Bias: 0.111441\n",
            "Iteration: 180515 | Cost/Loss: 0.074299 | Weight: 0.568612 | Bias: 0.111441\n",
            "Iteration: 180516 | Cost/Loss: 0.074299 | Weight: 0.568612 | Bias: 0.111441\n",
            "Iteration: 180517 | Cost/Loss: 0.074299 | Weight: 0.568613 | Bias: 0.111442\n",
            "Iteration: 180518 | Cost/Loss: 0.074299 | Weight: 0.568613 | Bias: 0.111442\n",
            "Iteration: 180519 | Cost/Loss: 0.074299 | Weight: 0.568613 | Bias: 0.111442\n",
            "Iteration: 180520 | Cost/Loss: 0.074299 | Weight: 0.568614 | Bias: 0.111443\n",
            "Iteration: 180521 | Cost/Loss: 0.074299 | Weight: 0.568614 | Bias: 0.111443\n",
            "Iteration: 180522 | Cost/Loss: 0.074299 | Weight: 0.568614 | Bias: 0.111443\n",
            "Iteration: 180523 | Cost/Loss: 0.074299 | Weight: 0.568614 | Bias: 0.111444\n",
            "Iteration: 180524 | Cost/Loss: 0.074299 | Weight: 0.568615 | Bias: 0.111444\n",
            "Iteration: 180525 | Cost/Loss: 0.074299 | Weight: 0.568615 | Bias: 0.111444\n",
            "Iteration: 180526 | Cost/Loss: 0.074299 | Weight: 0.568615 | Bias: 0.111444\n",
            "Iteration: 180527 | Cost/Loss: 0.074299 | Weight: 0.568616 | Bias: 0.111445\n",
            "Iteration: 180528 | Cost/Loss: 0.074299 | Weight: 0.568616 | Bias: 0.111445\n",
            "Iteration: 180529 | Cost/Loss: 0.074299 | Weight: 0.568616 | Bias: 0.111445\n",
            "Iteration: 180530 | Cost/Loss: 0.074299 | Weight: 0.568617 | Bias: 0.111446\n",
            "Iteration: 180531 | Cost/Loss: 0.074299 | Weight: 0.568617 | Bias: 0.111446\n",
            "Iteration: 180532 | Cost/Loss: 0.074299 | Weight: 0.568617 | Bias: 0.111446\n",
            "Iteration: 180533 | Cost/Loss: 0.074299 | Weight: 0.568617 | Bias: 0.111447\n",
            "Iteration: 180534 | Cost/Loss: 0.074299 | Weight: 0.568618 | Bias: 0.111447\n",
            "Iteration: 180535 | Cost/Loss: 0.074299 | Weight: 0.568618 | Bias: 0.111447\n",
            "Iteration: 180536 | Cost/Loss: 0.074299 | Weight: 0.568618 | Bias: 0.111447\n",
            "Iteration: 180537 | Cost/Loss: 0.074299 | Weight: 0.568619 | Bias: 0.111448\n",
            "Iteration: 180538 | Cost/Loss: 0.074298 | Weight: 0.568619 | Bias: 0.111448\n",
            "Iteration: 180539 | Cost/Loss: 0.074298 | Weight: 0.568619 | Bias: 0.111448\n",
            "Iteration: 180540 | Cost/Loss: 0.074298 | Weight: 0.568619 | Bias: 0.111449\n",
            "Iteration: 180541 | Cost/Loss: 0.074298 | Weight: 0.568620 | Bias: 0.111449\n",
            "Iteration: 180542 | Cost/Loss: 0.074298 | Weight: 0.568620 | Bias: 0.111449\n",
            "Iteration: 180543 | Cost/Loss: 0.074298 | Weight: 0.568620 | Bias: 0.111450\n",
            "Iteration: 180544 | Cost/Loss: 0.074298 | Weight: 0.568621 | Bias: 0.111450\n",
            "Iteration: 180545 | Cost/Loss: 0.074298 | Weight: 0.568621 | Bias: 0.111450\n",
            "Iteration: 180546 | Cost/Loss: 0.074298 | Weight: 0.568621 | Bias: 0.111451\n",
            "Iteration: 180547 | Cost/Loss: 0.074298 | Weight: 0.568622 | Bias: 0.111451\n",
            "Iteration: 180548 | Cost/Loss: 0.074298 | Weight: 0.568622 | Bias: 0.111451\n",
            "Iteration: 180549 | Cost/Loss: 0.074298 | Weight: 0.568622 | Bias: 0.111451\n",
            "Iteration: 180550 | Cost/Loss: 0.074298 | Weight: 0.568622 | Bias: 0.111452\n",
            "Iteration: 180551 | Cost/Loss: 0.074298 | Weight: 0.568623 | Bias: 0.111452\n",
            "Iteration: 180552 | Cost/Loss: 0.074298 | Weight: 0.568623 | Bias: 0.111452\n",
            "Iteration: 180553 | Cost/Loss: 0.074298 | Weight: 0.568623 | Bias: 0.111453\n",
            "Iteration: 180554 | Cost/Loss: 0.074298 | Weight: 0.568624 | Bias: 0.111453\n",
            "Iteration: 180555 | Cost/Loss: 0.074298 | Weight: 0.568624 | Bias: 0.111453\n",
            "Iteration: 180556 | Cost/Loss: 0.074298 | Weight: 0.568624 | Bias: 0.111454\n",
            "Iteration: 180557 | Cost/Loss: 0.074298 | Weight: 0.568625 | Bias: 0.111454\n",
            "Iteration: 180558 | Cost/Loss: 0.074298 | Weight: 0.568625 | Bias: 0.111454\n",
            "Iteration: 180559 | Cost/Loss: 0.074298 | Weight: 0.568625 | Bias: 0.111455\n",
            "Iteration: 180560 | Cost/Loss: 0.074298 | Weight: 0.568625 | Bias: 0.111455\n",
            "Iteration: 180561 | Cost/Loss: 0.074298 | Weight: 0.568626 | Bias: 0.111455\n",
            "Iteration: 180562 | Cost/Loss: 0.074298 | Weight: 0.568626 | Bias: 0.111455\n",
            "Iteration: 180563 | Cost/Loss: 0.074298 | Weight: 0.568626 | Bias: 0.111456\n",
            "Iteration: 180564 | Cost/Loss: 0.074298 | Weight: 0.568627 | Bias: 0.111456\n",
            "Iteration: 180565 | Cost/Loss: 0.074298 | Weight: 0.568627 | Bias: 0.111456\n",
            "Iteration: 180566 | Cost/Loss: 0.074298 | Weight: 0.568627 | Bias: 0.111457\n",
            "Iteration: 180567 | Cost/Loss: 0.074298 | Weight: 0.568628 | Bias: 0.111457\n",
            "Iteration: 180568 | Cost/Loss: 0.074298 | Weight: 0.568628 | Bias: 0.111457\n",
            "Iteration: 180569 | Cost/Loss: 0.074298 | Weight: 0.568628 | Bias: 0.111458\n",
            "Iteration: 180570 | Cost/Loss: 0.074298 | Weight: 0.568628 | Bias: 0.111458\n",
            "Iteration: 180571 | Cost/Loss: 0.074298 | Weight: 0.568629 | Bias: 0.111458\n",
            "Iteration: 180572 | Cost/Loss: 0.074298 | Weight: 0.568629 | Bias: 0.111458\n",
            "Iteration: 180573 | Cost/Loss: 0.074298 | Weight: 0.568629 | Bias: 0.111459\n",
            "Iteration: 180574 | Cost/Loss: 0.074298 | Weight: 0.568630 | Bias: 0.111459\n",
            "Iteration: 180575 | Cost/Loss: 0.074298 | Weight: 0.568630 | Bias: 0.111459\n",
            "Iteration: 180576 | Cost/Loss: 0.074298 | Weight: 0.568630 | Bias: 0.111460\n",
            "Iteration: 180577 | Cost/Loss: 0.074298 | Weight: 0.568631 | Bias: 0.111460\n",
            "Iteration: 180578 | Cost/Loss: 0.074297 | Weight: 0.568631 | Bias: 0.111460\n",
            "Iteration: 180579 | Cost/Loss: 0.074297 | Weight: 0.568631 | Bias: 0.111461\n",
            "Iteration: 180580 | Cost/Loss: 0.074297 | Weight: 0.568631 | Bias: 0.111461\n",
            "Iteration: 180581 | Cost/Loss: 0.074297 | Weight: 0.568632 | Bias: 0.111461\n",
            "Iteration: 180582 | Cost/Loss: 0.074297 | Weight: 0.568632 | Bias: 0.111462\n",
            "Iteration: 180583 | Cost/Loss: 0.074297 | Weight: 0.568632 | Bias: 0.111462\n",
            "Iteration: 180584 | Cost/Loss: 0.074297 | Weight: 0.568633 | Bias: 0.111462\n",
            "Iteration: 180585 | Cost/Loss: 0.074297 | Weight: 0.568633 | Bias: 0.111462\n",
            "Iteration: 180586 | Cost/Loss: 0.074297 | Weight: 0.568633 | Bias: 0.111463\n",
            "Iteration: 180587 | Cost/Loss: 0.074297 | Weight: 0.568633 | Bias: 0.111463\n",
            "Iteration: 180588 | Cost/Loss: 0.074297 | Weight: 0.568634 | Bias: 0.111463\n",
            "Iteration: 180589 | Cost/Loss: 0.074297 | Weight: 0.568634 | Bias: 0.111464\n",
            "Iteration: 180590 | Cost/Loss: 0.074297 | Weight: 0.568634 | Bias: 0.111464\n",
            "Iteration: 180591 | Cost/Loss: 0.074297 | Weight: 0.568635 | Bias: 0.111464\n",
            "Iteration: 180592 | Cost/Loss: 0.074297 | Weight: 0.568635 | Bias: 0.111465\n",
            "Iteration: 180593 | Cost/Loss: 0.074297 | Weight: 0.568635 | Bias: 0.111465\n",
            "Iteration: 180594 | Cost/Loss: 0.074297 | Weight: 0.568636 | Bias: 0.111465\n",
            "Iteration: 180595 | Cost/Loss: 0.074297 | Weight: 0.568636 | Bias: 0.111466\n",
            "Iteration: 180596 | Cost/Loss: 0.074297 | Weight: 0.568636 | Bias: 0.111466\n",
            "Iteration: 180597 | Cost/Loss: 0.074297 | Weight: 0.568636 | Bias: 0.111466\n",
            "Iteration: 180598 | Cost/Loss: 0.074297 | Weight: 0.568637 | Bias: 0.111466\n",
            "Iteration: 180599 | Cost/Loss: 0.074297 | Weight: 0.568637 | Bias: 0.111467\n",
            "Iteration: 180600 | Cost/Loss: 0.074297 | Weight: 0.568637 | Bias: 0.111467\n",
            "Iteration: 180601 | Cost/Loss: 0.074297 | Weight: 0.568638 | Bias: 0.111467\n",
            "Iteration: 180602 | Cost/Loss: 0.074297 | Weight: 0.568638 | Bias: 0.111468\n",
            "Iteration: 180603 | Cost/Loss: 0.074297 | Weight: 0.568638 | Bias: 0.111468\n",
            "Iteration: 180604 | Cost/Loss: 0.074297 | Weight: 0.568639 | Bias: 0.111468\n",
            "Iteration: 180605 | Cost/Loss: 0.074297 | Weight: 0.568639 | Bias: 0.111469\n",
            "Iteration: 180606 | Cost/Loss: 0.074297 | Weight: 0.568639 | Bias: 0.111469\n",
            "Iteration: 180607 | Cost/Loss: 0.074297 | Weight: 0.568639 | Bias: 0.111469\n",
            "Iteration: 180608 | Cost/Loss: 0.074297 | Weight: 0.568640 | Bias: 0.111469\n",
            "Iteration: 180609 | Cost/Loss: 0.074297 | Weight: 0.568640 | Bias: 0.111470\n",
            "Iteration: 180610 | Cost/Loss: 0.074297 | Weight: 0.568640 | Bias: 0.111470\n",
            "Iteration: 180611 | Cost/Loss: 0.074297 | Weight: 0.568641 | Bias: 0.111470\n",
            "Iteration: 180612 | Cost/Loss: 0.074297 | Weight: 0.568641 | Bias: 0.111471\n",
            "Iteration: 180613 | Cost/Loss: 0.074297 | Weight: 0.568641 | Bias: 0.111471\n",
            "Iteration: 180614 | Cost/Loss: 0.074297 | Weight: 0.568642 | Bias: 0.111471\n",
            "Iteration: 180615 | Cost/Loss: 0.074297 | Weight: 0.568642 | Bias: 0.111472\n",
            "Iteration: 180616 | Cost/Loss: 0.074297 | Weight: 0.568642 | Bias: 0.111472\n",
            "Iteration: 180617 | Cost/Loss: 0.074297 | Weight: 0.568642 | Bias: 0.111472\n",
            "Iteration: 180618 | Cost/Loss: 0.074297 | Weight: 0.568643 | Bias: 0.111473\n",
            "Iteration: 180619 | Cost/Loss: 0.074296 | Weight: 0.568643 | Bias: 0.111473\n",
            "Iteration: 180620 | Cost/Loss: 0.074296 | Weight: 0.568643 | Bias: 0.111473\n",
            "Iteration: 180621 | Cost/Loss: 0.074296 | Weight: 0.568644 | Bias: 0.111473\n",
            "Iteration: 180622 | Cost/Loss: 0.074296 | Weight: 0.568644 | Bias: 0.111474\n",
            "Iteration: 180623 | Cost/Loss: 0.074296 | Weight: 0.568644 | Bias: 0.111474\n",
            "Iteration: 180624 | Cost/Loss: 0.074296 | Weight: 0.568645 | Bias: 0.111474\n",
            "Iteration: 180625 | Cost/Loss: 0.074296 | Weight: 0.568645 | Bias: 0.111475\n",
            "Iteration: 180626 | Cost/Loss: 0.074296 | Weight: 0.568645 | Bias: 0.111475\n",
            "Iteration: 180627 | Cost/Loss: 0.074296 | Weight: 0.568645 | Bias: 0.111475\n",
            "Iteration: 180628 | Cost/Loss: 0.074296 | Weight: 0.568646 | Bias: 0.111476\n",
            "Iteration: 180629 | Cost/Loss: 0.074296 | Weight: 0.568646 | Bias: 0.111476\n",
            "Iteration: 180630 | Cost/Loss: 0.074296 | Weight: 0.568646 | Bias: 0.111476\n",
            "Iteration: 180631 | Cost/Loss: 0.074296 | Weight: 0.568647 | Bias: 0.111477\n",
            "Iteration: 180632 | Cost/Loss: 0.074296 | Weight: 0.568647 | Bias: 0.111477\n",
            "Iteration: 180633 | Cost/Loss: 0.074296 | Weight: 0.568647 | Bias: 0.111477\n",
            "Iteration: 180634 | Cost/Loss: 0.074296 | Weight: 0.568648 | Bias: 0.111477\n",
            "Iteration: 180635 | Cost/Loss: 0.074296 | Weight: 0.568648 | Bias: 0.111478\n",
            "Iteration: 180636 | Cost/Loss: 0.074296 | Weight: 0.568648 | Bias: 0.111478\n",
            "Iteration: 180637 | Cost/Loss: 0.074296 | Weight: 0.568648 | Bias: 0.111478\n",
            "Iteration: 180638 | Cost/Loss: 0.074296 | Weight: 0.568649 | Bias: 0.111479\n",
            "Iteration: 180639 | Cost/Loss: 0.074296 | Weight: 0.568649 | Bias: 0.111479\n",
            "Iteration: 180640 | Cost/Loss: 0.074296 | Weight: 0.568649 | Bias: 0.111479\n",
            "Iteration: 180641 | Cost/Loss: 0.074296 | Weight: 0.568650 | Bias: 0.111480\n",
            "Iteration: 180642 | Cost/Loss: 0.074296 | Weight: 0.568650 | Bias: 0.111480\n",
            "Iteration: 180643 | Cost/Loss: 0.074296 | Weight: 0.568650 | Bias: 0.111480\n",
            "Iteration: 180644 | Cost/Loss: 0.074296 | Weight: 0.568650 | Bias: 0.111480\n",
            "Iteration: 180645 | Cost/Loss: 0.074296 | Weight: 0.568651 | Bias: 0.111481\n",
            "Iteration: 180646 | Cost/Loss: 0.074296 | Weight: 0.568651 | Bias: 0.111481\n",
            "Iteration: 180647 | Cost/Loss: 0.074296 | Weight: 0.568651 | Bias: 0.111481\n",
            "Iteration: 180648 | Cost/Loss: 0.074296 | Weight: 0.568652 | Bias: 0.111482\n",
            "Iteration: 180649 | Cost/Loss: 0.074296 | Weight: 0.568652 | Bias: 0.111482\n",
            "Iteration: 180650 | Cost/Loss: 0.074296 | Weight: 0.568652 | Bias: 0.111482\n",
            "Iteration: 180651 | Cost/Loss: 0.074296 | Weight: 0.568653 | Bias: 0.111483\n",
            "Iteration: 180652 | Cost/Loss: 0.074296 | Weight: 0.568653 | Bias: 0.111483\n",
            "Iteration: 180653 | Cost/Loss: 0.074296 | Weight: 0.568653 | Bias: 0.111483\n",
            "Iteration: 180654 | Cost/Loss: 0.074296 | Weight: 0.568653 | Bias: 0.111484\n",
            "Iteration: 180655 | Cost/Loss: 0.074296 | Weight: 0.568654 | Bias: 0.111484\n",
            "Iteration: 180656 | Cost/Loss: 0.074296 | Weight: 0.568654 | Bias: 0.111484\n",
            "Iteration: 180657 | Cost/Loss: 0.074296 | Weight: 0.568654 | Bias: 0.111484\n",
            "Iteration: 180658 | Cost/Loss: 0.074296 | Weight: 0.568655 | Bias: 0.111485\n",
            "Iteration: 180659 | Cost/Loss: 0.074295 | Weight: 0.568655 | Bias: 0.111485\n",
            "Iteration: 180660 | Cost/Loss: 0.074295 | Weight: 0.568655 | Bias: 0.111485\n",
            "Iteration: 180661 | Cost/Loss: 0.074295 | Weight: 0.568656 | Bias: 0.111486\n",
            "Iteration: 180662 | Cost/Loss: 0.074295 | Weight: 0.568656 | Bias: 0.111486\n",
            "Iteration: 180663 | Cost/Loss: 0.074295 | Weight: 0.568656 | Bias: 0.111486\n",
            "Iteration: 180664 | Cost/Loss: 0.074295 | Weight: 0.568656 | Bias: 0.111487\n",
            "Iteration: 180665 | Cost/Loss: 0.074295 | Weight: 0.568657 | Bias: 0.111487\n",
            "Iteration: 180666 | Cost/Loss: 0.074295 | Weight: 0.568657 | Bias: 0.111487\n",
            "Iteration: 180667 | Cost/Loss: 0.074295 | Weight: 0.568657 | Bias: 0.111488\n",
            "Iteration: 180668 | Cost/Loss: 0.074295 | Weight: 0.568658 | Bias: 0.111488\n",
            "Iteration: 180669 | Cost/Loss: 0.074295 | Weight: 0.568658 | Bias: 0.111488\n",
            "Iteration: 180670 | Cost/Loss: 0.074295 | Weight: 0.568658 | Bias: 0.111488\n",
            "Iteration: 180671 | Cost/Loss: 0.074295 | Weight: 0.568659 | Bias: 0.111489\n",
            "Iteration: 180672 | Cost/Loss: 0.074295 | Weight: 0.568659 | Bias: 0.111489\n",
            "Iteration: 180673 | Cost/Loss: 0.074295 | Weight: 0.568659 | Bias: 0.111489\n",
            "Iteration: 180674 | Cost/Loss: 0.074295 | Weight: 0.568659 | Bias: 0.111490\n",
            "Iteration: 180675 | Cost/Loss: 0.074295 | Weight: 0.568660 | Bias: 0.111490\n",
            "Iteration: 180676 | Cost/Loss: 0.074295 | Weight: 0.568660 | Bias: 0.111490\n",
            "Iteration: 180677 | Cost/Loss: 0.074295 | Weight: 0.568660 | Bias: 0.111491\n",
            "Iteration: 180678 | Cost/Loss: 0.074295 | Weight: 0.568661 | Bias: 0.111491\n",
            "Iteration: 180679 | Cost/Loss: 0.074295 | Weight: 0.568661 | Bias: 0.111491\n",
            "Iteration: 180680 | Cost/Loss: 0.074295 | Weight: 0.568661 | Bias: 0.111491\n",
            "Iteration: 180681 | Cost/Loss: 0.074295 | Weight: 0.568662 | Bias: 0.111492\n",
            "Iteration: 180682 | Cost/Loss: 0.074295 | Weight: 0.568662 | Bias: 0.111492\n",
            "Iteration: 180683 | Cost/Loss: 0.074295 | Weight: 0.568662 | Bias: 0.111492\n",
            "Iteration: 180684 | Cost/Loss: 0.074295 | Weight: 0.568662 | Bias: 0.111493\n",
            "Iteration: 180685 | Cost/Loss: 0.074295 | Weight: 0.568663 | Bias: 0.111493\n",
            "Iteration: 180686 | Cost/Loss: 0.074295 | Weight: 0.568663 | Bias: 0.111493\n",
            "Iteration: 180687 | Cost/Loss: 0.074295 | Weight: 0.568663 | Bias: 0.111494\n",
            "Iteration: 180688 | Cost/Loss: 0.074295 | Weight: 0.568664 | Bias: 0.111494\n",
            "Iteration: 180689 | Cost/Loss: 0.074295 | Weight: 0.568664 | Bias: 0.111494\n",
            "Iteration: 180690 | Cost/Loss: 0.074295 | Weight: 0.568664 | Bias: 0.111495\n",
            "Iteration: 180691 | Cost/Loss: 0.074295 | Weight: 0.568664 | Bias: 0.111495\n",
            "Iteration: 180692 | Cost/Loss: 0.074295 | Weight: 0.568665 | Bias: 0.111495\n",
            "Iteration: 180693 | Cost/Loss: 0.074295 | Weight: 0.568665 | Bias: 0.111495\n",
            "Iteration: 180694 | Cost/Loss: 0.074295 | Weight: 0.568665 | Bias: 0.111496\n",
            "Iteration: 180695 | Cost/Loss: 0.074295 | Weight: 0.568666 | Bias: 0.111496\n",
            "Iteration: 180696 | Cost/Loss: 0.074295 | Weight: 0.568666 | Bias: 0.111496\n",
            "Iteration: 180697 | Cost/Loss: 0.074295 | Weight: 0.568666 | Bias: 0.111497\n",
            "Iteration: 180698 | Cost/Loss: 0.074295 | Weight: 0.568667 | Bias: 0.111497\n",
            "Iteration: 180699 | Cost/Loss: 0.074295 | Weight: 0.568667 | Bias: 0.111497\n",
            "Iteration: 180700 | Cost/Loss: 0.074294 | Weight: 0.568667 | Bias: 0.111498\n",
            "Iteration: 180701 | Cost/Loss: 0.074294 | Weight: 0.568667 | Bias: 0.111498\n",
            "Iteration: 180702 | Cost/Loss: 0.074294 | Weight: 0.568668 | Bias: 0.111498\n",
            "Iteration: 180703 | Cost/Loss: 0.074294 | Weight: 0.568668 | Bias: 0.111498\n",
            "Iteration: 180704 | Cost/Loss: 0.074294 | Weight: 0.568668 | Bias: 0.111499\n",
            "Iteration: 180705 | Cost/Loss: 0.074294 | Weight: 0.568669 | Bias: 0.111499\n",
            "Iteration: 180706 | Cost/Loss: 0.074294 | Weight: 0.568669 | Bias: 0.111499\n",
            "Iteration: 180707 | Cost/Loss: 0.074294 | Weight: 0.568669 | Bias: 0.111500\n",
            "Iteration: 180708 | Cost/Loss: 0.074294 | Weight: 0.568670 | Bias: 0.111500\n",
            "Iteration: 180709 | Cost/Loss: 0.074294 | Weight: 0.568670 | Bias: 0.111500\n",
            "Iteration: 180710 | Cost/Loss: 0.074294 | Weight: 0.568670 | Bias: 0.111501\n",
            "Iteration: 180711 | Cost/Loss: 0.074294 | Weight: 0.568670 | Bias: 0.111501\n",
            "Iteration: 180712 | Cost/Loss: 0.074294 | Weight: 0.568671 | Bias: 0.111501\n",
            "Iteration: 180713 | Cost/Loss: 0.074294 | Weight: 0.568671 | Bias: 0.111502\n",
            "Iteration: 180714 | Cost/Loss: 0.074294 | Weight: 0.568671 | Bias: 0.111502\n",
            "Iteration: 180715 | Cost/Loss: 0.074294 | Weight: 0.568672 | Bias: 0.111502\n",
            "Iteration: 180716 | Cost/Loss: 0.074294 | Weight: 0.568672 | Bias: 0.111502\n",
            "Iteration: 180717 | Cost/Loss: 0.074294 | Weight: 0.568672 | Bias: 0.111503\n",
            "Iteration: 180718 | Cost/Loss: 0.074294 | Weight: 0.568673 | Bias: 0.111503\n",
            "Iteration: 180719 | Cost/Loss: 0.074294 | Weight: 0.568673 | Bias: 0.111503\n",
            "Iteration: 180720 | Cost/Loss: 0.074294 | Weight: 0.568673 | Bias: 0.111504\n",
            "Iteration: 180721 | Cost/Loss: 0.074294 | Weight: 0.568673 | Bias: 0.111504\n",
            "Iteration: 180722 | Cost/Loss: 0.074294 | Weight: 0.568674 | Bias: 0.111504\n",
            "Iteration: 180723 | Cost/Loss: 0.074294 | Weight: 0.568674 | Bias: 0.111505\n",
            "Iteration: 180724 | Cost/Loss: 0.074294 | Weight: 0.568674 | Bias: 0.111505\n",
            "Iteration: 180725 | Cost/Loss: 0.074294 | Weight: 0.568675 | Bias: 0.111505\n",
            "Iteration: 180726 | Cost/Loss: 0.074294 | Weight: 0.568675 | Bias: 0.111506\n",
            "Iteration: 180727 | Cost/Loss: 0.074294 | Weight: 0.568675 | Bias: 0.111506\n",
            "Iteration: 180728 | Cost/Loss: 0.074294 | Weight: 0.568676 | Bias: 0.111506\n",
            "Iteration: 180729 | Cost/Loss: 0.074294 | Weight: 0.568676 | Bias: 0.111506\n",
            "Iteration: 180730 | Cost/Loss: 0.074294 | Weight: 0.568676 | Bias: 0.111507\n",
            "Iteration: 180731 | Cost/Loss: 0.074294 | Weight: 0.568676 | Bias: 0.111507\n",
            "Iteration: 180732 | Cost/Loss: 0.074294 | Weight: 0.568677 | Bias: 0.111507\n",
            "Iteration: 180733 | Cost/Loss: 0.074294 | Weight: 0.568677 | Bias: 0.111508\n",
            "Iteration: 180734 | Cost/Loss: 0.074294 | Weight: 0.568677 | Bias: 0.111508\n",
            "Iteration: 180735 | Cost/Loss: 0.074294 | Weight: 0.568678 | Bias: 0.111508\n",
            "Iteration: 180736 | Cost/Loss: 0.074294 | Weight: 0.568678 | Bias: 0.111509\n",
            "Iteration: 180737 | Cost/Loss: 0.074294 | Weight: 0.568678 | Bias: 0.111509\n",
            "Iteration: 180738 | Cost/Loss: 0.074294 | Weight: 0.568678 | Bias: 0.111509\n",
            "Iteration: 180739 | Cost/Loss: 0.074294 | Weight: 0.568679 | Bias: 0.111509\n",
            "Iteration: 180740 | Cost/Loss: 0.074294 | Weight: 0.568679 | Bias: 0.111510\n",
            "Iteration: 180741 | Cost/Loss: 0.074293 | Weight: 0.568679 | Bias: 0.111510\n",
            "Iteration: 180742 | Cost/Loss: 0.074293 | Weight: 0.568680 | Bias: 0.111510\n",
            "Iteration: 180743 | Cost/Loss: 0.074293 | Weight: 0.568680 | Bias: 0.111511\n",
            "Iteration: 180744 | Cost/Loss: 0.074293 | Weight: 0.568680 | Bias: 0.111511\n",
            "Iteration: 180745 | Cost/Loss: 0.074293 | Weight: 0.568681 | Bias: 0.111511\n",
            "Iteration: 180746 | Cost/Loss: 0.074293 | Weight: 0.568681 | Bias: 0.111512\n",
            "Iteration: 180747 | Cost/Loss: 0.074293 | Weight: 0.568681 | Bias: 0.111512\n",
            "Iteration: 180748 | Cost/Loss: 0.074293 | Weight: 0.568681 | Bias: 0.111512\n",
            "Iteration: 180749 | Cost/Loss: 0.074293 | Weight: 0.568682 | Bias: 0.111513\n",
            "Iteration: 180750 | Cost/Loss: 0.074293 | Weight: 0.568682 | Bias: 0.111513\n",
            "Iteration: 180751 | Cost/Loss: 0.074293 | Weight: 0.568682 | Bias: 0.111513\n",
            "Iteration: 180752 | Cost/Loss: 0.074293 | Weight: 0.568683 | Bias: 0.111513\n",
            "Iteration: 180753 | Cost/Loss: 0.074293 | Weight: 0.568683 | Bias: 0.111514\n",
            "Iteration: 180754 | Cost/Loss: 0.074293 | Weight: 0.568683 | Bias: 0.111514\n",
            "Iteration: 180755 | Cost/Loss: 0.074293 | Weight: 0.568684 | Bias: 0.111514\n",
            "Iteration: 180756 | Cost/Loss: 0.074293 | Weight: 0.568684 | Bias: 0.111515\n",
            "Iteration: 180757 | Cost/Loss: 0.074293 | Weight: 0.568684 | Bias: 0.111515\n",
            "Iteration: 180758 | Cost/Loss: 0.074293 | Weight: 0.568684 | Bias: 0.111515\n",
            "Iteration: 180759 | Cost/Loss: 0.074293 | Weight: 0.568685 | Bias: 0.111516\n",
            "Iteration: 180760 | Cost/Loss: 0.074293 | Weight: 0.568685 | Bias: 0.111516\n",
            "Iteration: 180761 | Cost/Loss: 0.074293 | Weight: 0.568685 | Bias: 0.111516\n",
            "Iteration: 180762 | Cost/Loss: 0.074293 | Weight: 0.568686 | Bias: 0.111517\n",
            "Iteration: 180763 | Cost/Loss: 0.074293 | Weight: 0.568686 | Bias: 0.111517\n",
            "Iteration: 180764 | Cost/Loss: 0.074293 | Weight: 0.568686 | Bias: 0.111517\n",
            "Iteration: 180765 | Cost/Loss: 0.074293 | Weight: 0.568687 | Bias: 0.111517\n",
            "Iteration: 180766 | Cost/Loss: 0.074293 | Weight: 0.568687 | Bias: 0.111518\n",
            "Iteration: 180767 | Cost/Loss: 0.074293 | Weight: 0.568687 | Bias: 0.111518\n",
            "Iteration: 180768 | Cost/Loss: 0.074293 | Weight: 0.568687 | Bias: 0.111518\n",
            "Iteration: 180769 | Cost/Loss: 0.074293 | Weight: 0.568688 | Bias: 0.111519\n",
            "Iteration: 180770 | Cost/Loss: 0.074293 | Weight: 0.568688 | Bias: 0.111519\n",
            "Iteration: 180771 | Cost/Loss: 0.074293 | Weight: 0.568688 | Bias: 0.111519\n",
            "Iteration: 180772 | Cost/Loss: 0.074293 | Weight: 0.568689 | Bias: 0.111520\n",
            "Iteration: 180773 | Cost/Loss: 0.074293 | Weight: 0.568689 | Bias: 0.111520\n",
            "Iteration: 180774 | Cost/Loss: 0.074293 | Weight: 0.568689 | Bias: 0.111520\n",
            "Iteration: 180775 | Cost/Loss: 0.074293 | Weight: 0.568690 | Bias: 0.111520\n",
            "Iteration: 180776 | Cost/Loss: 0.074293 | Weight: 0.568690 | Bias: 0.111521\n",
            "Iteration: 180777 | Cost/Loss: 0.074293 | Weight: 0.568690 | Bias: 0.111521\n",
            "Iteration: 180778 | Cost/Loss: 0.074293 | Weight: 0.568690 | Bias: 0.111521\n",
            "Iteration: 180779 | Cost/Loss: 0.074293 | Weight: 0.568691 | Bias: 0.111522\n",
            "Iteration: 180780 | Cost/Loss: 0.074293 | Weight: 0.568691 | Bias: 0.111522\n",
            "Iteration: 180781 | Cost/Loss: 0.074292 | Weight: 0.568691 | Bias: 0.111522\n",
            "Iteration: 180782 | Cost/Loss: 0.074292 | Weight: 0.568692 | Bias: 0.111523\n",
            "Iteration: 180783 | Cost/Loss: 0.074292 | Weight: 0.568692 | Bias: 0.111523\n",
            "Iteration: 180784 | Cost/Loss: 0.074292 | Weight: 0.568692 | Bias: 0.111523\n",
            "Iteration: 180785 | Cost/Loss: 0.074292 | Weight: 0.568693 | Bias: 0.111524\n",
            "Iteration: 180786 | Cost/Loss: 0.074292 | Weight: 0.568693 | Bias: 0.111524\n",
            "Iteration: 180787 | Cost/Loss: 0.074292 | Weight: 0.568693 | Bias: 0.111524\n",
            "Iteration: 180788 | Cost/Loss: 0.074292 | Weight: 0.568693 | Bias: 0.111524\n",
            "Iteration: 180789 | Cost/Loss: 0.074292 | Weight: 0.568694 | Bias: 0.111525\n",
            "Iteration: 180790 | Cost/Loss: 0.074292 | Weight: 0.568694 | Bias: 0.111525\n",
            "Iteration: 180791 | Cost/Loss: 0.074292 | Weight: 0.568694 | Bias: 0.111525\n",
            "Iteration: 180792 | Cost/Loss: 0.074292 | Weight: 0.568695 | Bias: 0.111526\n",
            "Iteration: 180793 | Cost/Loss: 0.074292 | Weight: 0.568695 | Bias: 0.111526\n",
            "Iteration: 180794 | Cost/Loss: 0.074292 | Weight: 0.568695 | Bias: 0.111526\n",
            "Iteration: 180795 | Cost/Loss: 0.074292 | Weight: 0.568695 | Bias: 0.111527\n",
            "Iteration: 180796 | Cost/Loss: 0.074292 | Weight: 0.568696 | Bias: 0.111527\n",
            "Iteration: 180797 | Cost/Loss: 0.074292 | Weight: 0.568696 | Bias: 0.111527\n",
            "Iteration: 180798 | Cost/Loss: 0.074292 | Weight: 0.568696 | Bias: 0.111528\n",
            "Iteration: 180799 | Cost/Loss: 0.074292 | Weight: 0.568697 | Bias: 0.111528\n",
            "Iteration: 180800 | Cost/Loss: 0.074292 | Weight: 0.568697 | Bias: 0.111528\n",
            "Iteration: 180801 | Cost/Loss: 0.074292 | Weight: 0.568697 | Bias: 0.111528\n",
            "Iteration: 180802 | Cost/Loss: 0.074292 | Weight: 0.568698 | Bias: 0.111529\n",
            "Iteration: 180803 | Cost/Loss: 0.074292 | Weight: 0.568698 | Bias: 0.111529\n",
            "Iteration: 180804 | Cost/Loss: 0.074292 | Weight: 0.568698 | Bias: 0.111529\n",
            "Iteration: 180805 | Cost/Loss: 0.074292 | Weight: 0.568698 | Bias: 0.111530\n",
            "Iteration: 180806 | Cost/Loss: 0.074292 | Weight: 0.568699 | Bias: 0.111530\n",
            "Iteration: 180807 | Cost/Loss: 0.074292 | Weight: 0.568699 | Bias: 0.111530\n",
            "Iteration: 180808 | Cost/Loss: 0.074292 | Weight: 0.568699 | Bias: 0.111531\n",
            "Iteration: 180809 | Cost/Loss: 0.074292 | Weight: 0.568700 | Bias: 0.111531\n",
            "Iteration: 180810 | Cost/Loss: 0.074292 | Weight: 0.568700 | Bias: 0.111531\n",
            "Iteration: 180811 | Cost/Loss: 0.074292 | Weight: 0.568700 | Bias: 0.111531\n",
            "Iteration: 180812 | Cost/Loss: 0.074292 | Weight: 0.568701 | Bias: 0.111532\n",
            "Iteration: 180813 | Cost/Loss: 0.074292 | Weight: 0.568701 | Bias: 0.111532\n",
            "Iteration: 180814 | Cost/Loss: 0.074292 | Weight: 0.568701 | Bias: 0.111532\n",
            "Iteration: 180815 | Cost/Loss: 0.074292 | Weight: 0.568701 | Bias: 0.111533\n",
            "Iteration: 180816 | Cost/Loss: 0.074292 | Weight: 0.568702 | Bias: 0.111533\n",
            "Iteration: 180817 | Cost/Loss: 0.074292 | Weight: 0.568702 | Bias: 0.111533\n",
            "Iteration: 180818 | Cost/Loss: 0.074292 | Weight: 0.568702 | Bias: 0.111534\n",
            "Iteration: 180819 | Cost/Loss: 0.074292 | Weight: 0.568703 | Bias: 0.111534\n",
            "Iteration: 180820 | Cost/Loss: 0.074292 | Weight: 0.568703 | Bias: 0.111534\n",
            "Iteration: 180821 | Cost/Loss: 0.074292 | Weight: 0.568703 | Bias: 0.111535\n",
            "Iteration: 180822 | Cost/Loss: 0.074291 | Weight: 0.568704 | Bias: 0.111535\n",
            "Iteration: 180823 | Cost/Loss: 0.074291 | Weight: 0.568704 | Bias: 0.111535\n",
            "Iteration: 180824 | Cost/Loss: 0.074291 | Weight: 0.568704 | Bias: 0.111535\n",
            "Iteration: 180825 | Cost/Loss: 0.074291 | Weight: 0.568704 | Bias: 0.111536\n",
            "Iteration: 180826 | Cost/Loss: 0.074291 | Weight: 0.568705 | Bias: 0.111536\n",
            "Iteration: 180827 | Cost/Loss: 0.074291 | Weight: 0.568705 | Bias: 0.111536\n",
            "Iteration: 180828 | Cost/Loss: 0.074291 | Weight: 0.568705 | Bias: 0.111537\n",
            "Iteration: 180829 | Cost/Loss: 0.074291 | Weight: 0.568706 | Bias: 0.111537\n",
            "Iteration: 180830 | Cost/Loss: 0.074291 | Weight: 0.568706 | Bias: 0.111537\n",
            "Iteration: 180831 | Cost/Loss: 0.074291 | Weight: 0.568706 | Bias: 0.111538\n",
            "Iteration: 180832 | Cost/Loss: 0.074291 | Weight: 0.568707 | Bias: 0.111538\n",
            "Iteration: 180833 | Cost/Loss: 0.074291 | Weight: 0.568707 | Bias: 0.111538\n",
            "Iteration: 180834 | Cost/Loss: 0.074291 | Weight: 0.568707 | Bias: 0.111539\n",
            "Iteration: 180835 | Cost/Loss: 0.074291 | Weight: 0.568707 | Bias: 0.111539\n",
            "Iteration: 180836 | Cost/Loss: 0.074291 | Weight: 0.568708 | Bias: 0.111539\n",
            "Iteration: 180837 | Cost/Loss: 0.074291 | Weight: 0.568708 | Bias: 0.111539\n",
            "Iteration: 180838 | Cost/Loss: 0.074291 | Weight: 0.568708 | Bias: 0.111540\n",
            "Iteration: 180839 | Cost/Loss: 0.074291 | Weight: 0.568709 | Bias: 0.111540\n",
            "Iteration: 180840 | Cost/Loss: 0.074291 | Weight: 0.568709 | Bias: 0.111540\n",
            "Iteration: 180841 | Cost/Loss: 0.074291 | Weight: 0.568709 | Bias: 0.111541\n",
            "Iteration: 180842 | Cost/Loss: 0.074291 | Weight: 0.568709 | Bias: 0.111541\n",
            "Iteration: 180843 | Cost/Loss: 0.074291 | Weight: 0.568710 | Bias: 0.111541\n",
            "Iteration: 180844 | Cost/Loss: 0.074291 | Weight: 0.568710 | Bias: 0.111542\n",
            "Iteration: 180845 | Cost/Loss: 0.074291 | Weight: 0.568710 | Bias: 0.111542\n",
            "Iteration: 180846 | Cost/Loss: 0.074291 | Weight: 0.568711 | Bias: 0.111542\n",
            "Iteration: 180847 | Cost/Loss: 0.074291 | Weight: 0.568711 | Bias: 0.111542\n",
            "Iteration: 180848 | Cost/Loss: 0.074291 | Weight: 0.568711 | Bias: 0.111543\n",
            "Iteration: 180849 | Cost/Loss: 0.074291 | Weight: 0.568712 | Bias: 0.111543\n",
            "Iteration: 180850 | Cost/Loss: 0.074291 | Weight: 0.568712 | Bias: 0.111543\n",
            "Iteration: 180851 | Cost/Loss: 0.074291 | Weight: 0.568712 | Bias: 0.111544\n",
            "Iteration: 180852 | Cost/Loss: 0.074291 | Weight: 0.568712 | Bias: 0.111544\n",
            "Iteration: 180853 | Cost/Loss: 0.074291 | Weight: 0.568713 | Bias: 0.111544\n",
            "Iteration: 180854 | Cost/Loss: 0.074291 | Weight: 0.568713 | Bias: 0.111545\n",
            "Iteration: 180855 | Cost/Loss: 0.074291 | Weight: 0.568713 | Bias: 0.111545\n",
            "Iteration: 180856 | Cost/Loss: 0.074291 | Weight: 0.568714 | Bias: 0.111545\n",
            "Iteration: 180857 | Cost/Loss: 0.074291 | Weight: 0.568714 | Bias: 0.111546\n",
            "Iteration: 180858 | Cost/Loss: 0.074291 | Weight: 0.568714 | Bias: 0.111546\n",
            "Iteration: 180859 | Cost/Loss: 0.074291 | Weight: 0.568715 | Bias: 0.111546\n",
            "Iteration: 180860 | Cost/Loss: 0.074291 | Weight: 0.568715 | Bias: 0.111546\n",
            "Iteration: 180861 | Cost/Loss: 0.074291 | Weight: 0.568715 | Bias: 0.111547\n",
            "Iteration: 180862 | Cost/Loss: 0.074290 | Weight: 0.568715 | Bias: 0.111547\n",
            "Iteration: 180863 | Cost/Loss: 0.074290 | Weight: 0.568716 | Bias: 0.111547\n",
            "Iteration: 180864 | Cost/Loss: 0.074290 | Weight: 0.568716 | Bias: 0.111548\n",
            "Iteration: 180865 | Cost/Loss: 0.074290 | Weight: 0.568716 | Bias: 0.111548\n",
            "Iteration: 180866 | Cost/Loss: 0.074290 | Weight: 0.568717 | Bias: 0.111548\n",
            "Iteration: 180867 | Cost/Loss: 0.074290 | Weight: 0.568717 | Bias: 0.111549\n",
            "Iteration: 180868 | Cost/Loss: 0.074290 | Weight: 0.568717 | Bias: 0.111549\n",
            "Iteration: 180869 | Cost/Loss: 0.074290 | Weight: 0.568718 | Bias: 0.111549\n",
            "Iteration: 180870 | Cost/Loss: 0.074290 | Weight: 0.568718 | Bias: 0.111550\n",
            "Iteration: 180871 | Cost/Loss: 0.074290 | Weight: 0.568718 | Bias: 0.111550\n",
            "Iteration: 180872 | Cost/Loss: 0.074290 | Weight: 0.568718 | Bias: 0.111550\n",
            "Iteration: 180873 | Cost/Loss: 0.074290 | Weight: 0.568719 | Bias: 0.111550\n",
            "Iteration: 180874 | Cost/Loss: 0.074290 | Weight: 0.568719 | Bias: 0.111551\n",
            "Iteration: 180875 | Cost/Loss: 0.074290 | Weight: 0.568719 | Bias: 0.111551\n",
            "Iteration: 180876 | Cost/Loss: 0.074290 | Weight: 0.568720 | Bias: 0.111551\n",
            "Iteration: 180877 | Cost/Loss: 0.074290 | Weight: 0.568720 | Bias: 0.111552\n",
            "Iteration: 180878 | Cost/Loss: 0.074290 | Weight: 0.568720 | Bias: 0.111552\n",
            "Iteration: 180879 | Cost/Loss: 0.074290 | Weight: 0.568721 | Bias: 0.111552\n",
            "Iteration: 180880 | Cost/Loss: 0.074290 | Weight: 0.568721 | Bias: 0.111553\n",
            "Iteration: 180881 | Cost/Loss: 0.074290 | Weight: 0.568721 | Bias: 0.111553\n",
            "Iteration: 180882 | Cost/Loss: 0.074290 | Weight: 0.568721 | Bias: 0.111553\n",
            "Iteration: 180883 | Cost/Loss: 0.074290 | Weight: 0.568722 | Bias: 0.111553\n",
            "Iteration: 180884 | Cost/Loss: 0.074290 | Weight: 0.568722 | Bias: 0.111554\n",
            "Iteration: 180885 | Cost/Loss: 0.074290 | Weight: 0.568722 | Bias: 0.111554\n",
            "Iteration: 180886 | Cost/Loss: 0.074290 | Weight: 0.568723 | Bias: 0.111554\n",
            "Iteration: 180887 | Cost/Loss: 0.074290 | Weight: 0.568723 | Bias: 0.111555\n",
            "Iteration: 180888 | Cost/Loss: 0.074290 | Weight: 0.568723 | Bias: 0.111555\n",
            "Iteration: 180889 | Cost/Loss: 0.074290 | Weight: 0.568723 | Bias: 0.111555\n",
            "Iteration: 180890 | Cost/Loss: 0.074290 | Weight: 0.568724 | Bias: 0.111556\n",
            "Iteration: 180891 | Cost/Loss: 0.074290 | Weight: 0.568724 | Bias: 0.111556\n",
            "Iteration: 180892 | Cost/Loss: 0.074290 | Weight: 0.568724 | Bias: 0.111556\n",
            "Iteration: 180893 | Cost/Loss: 0.074290 | Weight: 0.568725 | Bias: 0.111557\n",
            "Iteration: 180894 | Cost/Loss: 0.074290 | Weight: 0.568725 | Bias: 0.111557\n",
            "Iteration: 180895 | Cost/Loss: 0.074290 | Weight: 0.568725 | Bias: 0.111557\n",
            "Iteration: 180896 | Cost/Loss: 0.074290 | Weight: 0.568726 | Bias: 0.111557\n",
            "Iteration: 180897 | Cost/Loss: 0.074290 | Weight: 0.568726 | Bias: 0.111558\n",
            "Iteration: 180898 | Cost/Loss: 0.074290 | Weight: 0.568726 | Bias: 0.111558\n",
            "Iteration: 180899 | Cost/Loss: 0.074290 | Weight: 0.568726 | Bias: 0.111558\n",
            "Iteration: 180900 | Cost/Loss: 0.074290 | Weight: 0.568727 | Bias: 0.111559\n",
            "Iteration: 180901 | Cost/Loss: 0.074290 | Weight: 0.568727 | Bias: 0.111559\n",
            "Iteration: 180902 | Cost/Loss: 0.074290 | Weight: 0.568727 | Bias: 0.111559\n",
            "Iteration: 180903 | Cost/Loss: 0.074289 | Weight: 0.568728 | Bias: 0.111560\n",
            "Iteration: 180904 | Cost/Loss: 0.074289 | Weight: 0.568728 | Bias: 0.111560\n",
            "Iteration: 180905 | Cost/Loss: 0.074289 | Weight: 0.568728 | Bias: 0.111560\n",
            "Iteration: 180906 | Cost/Loss: 0.074289 | Weight: 0.568729 | Bias: 0.111561\n",
            "Iteration: 180907 | Cost/Loss: 0.074289 | Weight: 0.568729 | Bias: 0.111561\n",
            "Iteration: 180908 | Cost/Loss: 0.074289 | Weight: 0.568729 | Bias: 0.111561\n",
            "Iteration: 180909 | Cost/Loss: 0.074289 | Weight: 0.568729 | Bias: 0.111561\n",
            "Iteration: 180910 | Cost/Loss: 0.074289 | Weight: 0.568730 | Bias: 0.111562\n",
            "Iteration: 180911 | Cost/Loss: 0.074289 | Weight: 0.568730 | Bias: 0.111562\n",
            "Iteration: 180912 | Cost/Loss: 0.074289 | Weight: 0.568730 | Bias: 0.111562\n",
            "Iteration: 180913 | Cost/Loss: 0.074289 | Weight: 0.568731 | Bias: 0.111563\n",
            "Iteration: 180914 | Cost/Loss: 0.074289 | Weight: 0.568731 | Bias: 0.111563\n",
            "Iteration: 180915 | Cost/Loss: 0.074289 | Weight: 0.568731 | Bias: 0.111563\n",
            "Iteration: 180916 | Cost/Loss: 0.074289 | Weight: 0.568732 | Bias: 0.111564\n",
            "Iteration: 180917 | Cost/Loss: 0.074289 | Weight: 0.568732 | Bias: 0.111564\n",
            "Iteration: 180918 | Cost/Loss: 0.074289 | Weight: 0.568732 | Bias: 0.111564\n",
            "Iteration: 180919 | Cost/Loss: 0.074289 | Weight: 0.568732 | Bias: 0.111564\n",
            "Iteration: 180920 | Cost/Loss: 0.074289 | Weight: 0.568733 | Bias: 0.111565\n",
            "Iteration: 180921 | Cost/Loss: 0.074289 | Weight: 0.568733 | Bias: 0.111565\n",
            "Iteration: 180922 | Cost/Loss: 0.074289 | Weight: 0.568733 | Bias: 0.111565\n",
            "Iteration: 180923 | Cost/Loss: 0.074289 | Weight: 0.568734 | Bias: 0.111566\n",
            "Iteration: 180924 | Cost/Loss: 0.074289 | Weight: 0.568734 | Bias: 0.111566\n",
            "Iteration: 180925 | Cost/Loss: 0.074289 | Weight: 0.568734 | Bias: 0.111566\n",
            "Iteration: 180926 | Cost/Loss: 0.074289 | Weight: 0.568735 | Bias: 0.111567\n",
            "Iteration: 180927 | Cost/Loss: 0.074289 | Weight: 0.568735 | Bias: 0.111567\n",
            "Iteration: 180928 | Cost/Loss: 0.074289 | Weight: 0.568735 | Bias: 0.111567\n",
            "Iteration: 180929 | Cost/Loss: 0.074289 | Weight: 0.568735 | Bias: 0.111568\n",
            "Iteration: 180930 | Cost/Loss: 0.074289 | Weight: 0.568736 | Bias: 0.111568\n",
            "Iteration: 180931 | Cost/Loss: 0.074289 | Weight: 0.568736 | Bias: 0.111568\n",
            "Iteration: 180932 | Cost/Loss: 0.074289 | Weight: 0.568736 | Bias: 0.111568\n",
            "Iteration: 180933 | Cost/Loss: 0.074289 | Weight: 0.568737 | Bias: 0.111569\n",
            "Iteration: 180934 | Cost/Loss: 0.074289 | Weight: 0.568737 | Bias: 0.111569\n",
            "Iteration: 180935 | Cost/Loss: 0.074289 | Weight: 0.568737 | Bias: 0.111569\n",
            "Iteration: 180936 | Cost/Loss: 0.074289 | Weight: 0.568738 | Bias: 0.111570\n",
            "Iteration: 180937 | Cost/Loss: 0.074289 | Weight: 0.568738 | Bias: 0.111570\n",
            "Iteration: 180938 | Cost/Loss: 0.074289 | Weight: 0.568738 | Bias: 0.111570\n",
            "Iteration: 180939 | Cost/Loss: 0.074289 | Weight: 0.568738 | Bias: 0.111571\n",
            "Iteration: 180940 | Cost/Loss: 0.074289 | Weight: 0.568739 | Bias: 0.111571\n",
            "Iteration: 180941 | Cost/Loss: 0.074289 | Weight: 0.568739 | Bias: 0.111571\n",
            "Iteration: 180942 | Cost/Loss: 0.074289 | Weight: 0.568739 | Bias: 0.111572\n",
            "Iteration: 180943 | Cost/Loss: 0.074289 | Weight: 0.568740 | Bias: 0.111572\n",
            "Iteration: 180944 | Cost/Loss: 0.074288 | Weight: 0.568740 | Bias: 0.111572\n",
            "Iteration: 180945 | Cost/Loss: 0.074288 | Weight: 0.568740 | Bias: 0.111572\n",
            "Iteration: 180946 | Cost/Loss: 0.074288 | Weight: 0.568740 | Bias: 0.111573\n",
            "Iteration: 180947 | Cost/Loss: 0.074288 | Weight: 0.568741 | Bias: 0.111573\n",
            "Iteration: 180948 | Cost/Loss: 0.074288 | Weight: 0.568741 | Bias: 0.111573\n",
            "Iteration: 180949 | Cost/Loss: 0.074288 | Weight: 0.568741 | Bias: 0.111574\n",
            "Iteration: 180950 | Cost/Loss: 0.074288 | Weight: 0.568742 | Bias: 0.111574\n",
            "Iteration: 180951 | Cost/Loss: 0.074288 | Weight: 0.568742 | Bias: 0.111574\n",
            "Iteration: 180952 | Cost/Loss: 0.074288 | Weight: 0.568742 | Bias: 0.111575\n",
            "Iteration: 180953 | Cost/Loss: 0.074288 | Weight: 0.568743 | Bias: 0.111575\n",
            "Iteration: 180954 | Cost/Loss: 0.074288 | Weight: 0.568743 | Bias: 0.111575\n",
            "Iteration: 180955 | Cost/Loss: 0.074288 | Weight: 0.568743 | Bias: 0.111575\n",
            "Iteration: 180956 | Cost/Loss: 0.074288 | Weight: 0.568743 | Bias: 0.111576\n",
            "Iteration: 180957 | Cost/Loss: 0.074288 | Weight: 0.568744 | Bias: 0.111576\n",
            "Iteration: 180958 | Cost/Loss: 0.074288 | Weight: 0.568744 | Bias: 0.111576\n",
            "Iteration: 180959 | Cost/Loss: 0.074288 | Weight: 0.568744 | Bias: 0.111577\n",
            "Iteration: 180960 | Cost/Loss: 0.074288 | Weight: 0.568745 | Bias: 0.111577\n",
            "Iteration: 180961 | Cost/Loss: 0.074288 | Weight: 0.568745 | Bias: 0.111577\n",
            "Iteration: 180962 | Cost/Loss: 0.074288 | Weight: 0.568745 | Bias: 0.111578\n",
            "Iteration: 180963 | Cost/Loss: 0.074288 | Weight: 0.568746 | Bias: 0.111578\n",
            "Iteration: 180964 | Cost/Loss: 0.074288 | Weight: 0.568746 | Bias: 0.111578\n",
            "Iteration: 180965 | Cost/Loss: 0.074288 | Weight: 0.568746 | Bias: 0.111579\n",
            "Iteration: 180966 | Cost/Loss: 0.074288 | Weight: 0.568746 | Bias: 0.111579\n",
            "Iteration: 180967 | Cost/Loss: 0.074288 | Weight: 0.568747 | Bias: 0.111579\n",
            "Iteration: 180968 | Cost/Loss: 0.074288 | Weight: 0.568747 | Bias: 0.111579\n",
            "Iteration: 180969 | Cost/Loss: 0.074288 | Weight: 0.568747 | Bias: 0.111580\n",
            "Iteration: 180970 | Cost/Loss: 0.074288 | Weight: 0.568748 | Bias: 0.111580\n",
            "Iteration: 180971 | Cost/Loss: 0.074288 | Weight: 0.568748 | Bias: 0.111580\n",
            "Iteration: 180972 | Cost/Loss: 0.074288 | Weight: 0.568748 | Bias: 0.111581\n",
            "Iteration: 180973 | Cost/Loss: 0.074288 | Weight: 0.568749 | Bias: 0.111581\n",
            "Iteration: 180974 | Cost/Loss: 0.074288 | Weight: 0.568749 | Bias: 0.111581\n",
            "Iteration: 180975 | Cost/Loss: 0.074288 | Weight: 0.568749 | Bias: 0.111582\n",
            "Iteration: 180976 | Cost/Loss: 0.074288 | Weight: 0.568749 | Bias: 0.111582\n",
            "Iteration: 180977 | Cost/Loss: 0.074288 | Weight: 0.568750 | Bias: 0.111582\n",
            "Iteration: 180978 | Cost/Loss: 0.074288 | Weight: 0.568750 | Bias: 0.111583\n",
            "Iteration: 180979 | Cost/Loss: 0.074288 | Weight: 0.568750 | Bias: 0.111583\n",
            "Iteration: 180980 | Cost/Loss: 0.074288 | Weight: 0.568751 | Bias: 0.111583\n",
            "Iteration: 180981 | Cost/Loss: 0.074288 | Weight: 0.568751 | Bias: 0.111583\n",
            "Iteration: 180982 | Cost/Loss: 0.074288 | Weight: 0.568751 | Bias: 0.111584\n",
            "Iteration: 180983 | Cost/Loss: 0.074288 | Weight: 0.568752 | Bias: 0.111584\n",
            "Iteration: 180984 | Cost/Loss: 0.074287 | Weight: 0.568752 | Bias: 0.111584\n",
            "Iteration: 180985 | Cost/Loss: 0.074287 | Weight: 0.568752 | Bias: 0.111585\n",
            "Iteration: 180986 | Cost/Loss: 0.074287 | Weight: 0.568752 | Bias: 0.111585\n",
            "Iteration: 180987 | Cost/Loss: 0.074287 | Weight: 0.568753 | Bias: 0.111585\n",
            "Iteration: 180988 | Cost/Loss: 0.074287 | Weight: 0.568753 | Bias: 0.111586\n",
            "Iteration: 180989 | Cost/Loss: 0.074287 | Weight: 0.568753 | Bias: 0.111586\n",
            "Iteration: 180990 | Cost/Loss: 0.074287 | Weight: 0.568754 | Bias: 0.111586\n",
            "Iteration: 180991 | Cost/Loss: 0.074287 | Weight: 0.568754 | Bias: 0.111586\n",
            "Iteration: 180992 | Cost/Loss: 0.074287 | Weight: 0.568754 | Bias: 0.111587\n",
            "Iteration: 180993 | Cost/Loss: 0.074287 | Weight: 0.568754 | Bias: 0.111587\n",
            "Iteration: 180994 | Cost/Loss: 0.074287 | Weight: 0.568755 | Bias: 0.111587\n",
            "Iteration: 180995 | Cost/Loss: 0.074287 | Weight: 0.568755 | Bias: 0.111588\n",
            "Iteration: 180996 | Cost/Loss: 0.074287 | Weight: 0.568755 | Bias: 0.111588\n",
            "Iteration: 180997 | Cost/Loss: 0.074287 | Weight: 0.568756 | Bias: 0.111588\n",
            "Iteration: 180998 | Cost/Loss: 0.074287 | Weight: 0.568756 | Bias: 0.111589\n",
            "Iteration: 180999 | Cost/Loss: 0.074287 | Weight: 0.568756 | Bias: 0.111589\n",
            "Iteration: 181000 | Cost/Loss: 0.074287 | Weight: 0.568757 | Bias: 0.111589\n",
            "Iteration: 181001 | Cost/Loss: 0.074287 | Weight: 0.568757 | Bias: 0.111590\n",
            "Iteration: 181002 | Cost/Loss: 0.074287 | Weight: 0.568757 | Bias: 0.111590\n",
            "Iteration: 181003 | Cost/Loss: 0.074287 | Weight: 0.568757 | Bias: 0.111590\n",
            "Iteration: 181004 | Cost/Loss: 0.074287 | Weight: 0.568758 | Bias: 0.111590\n",
            "Iteration: 181005 | Cost/Loss: 0.074287 | Weight: 0.568758 | Bias: 0.111591\n",
            "Iteration: 181006 | Cost/Loss: 0.074287 | Weight: 0.568758 | Bias: 0.111591\n",
            "Iteration: 181007 | Cost/Loss: 0.074287 | Weight: 0.568759 | Bias: 0.111591\n",
            "Iteration: 181008 | Cost/Loss: 0.074287 | Weight: 0.568759 | Bias: 0.111592\n",
            "Iteration: 181009 | Cost/Loss: 0.074287 | Weight: 0.568759 | Bias: 0.111592\n",
            "Iteration: 181010 | Cost/Loss: 0.074287 | Weight: 0.568760 | Bias: 0.111592\n",
            "Iteration: 181011 | Cost/Loss: 0.074287 | Weight: 0.568760 | Bias: 0.111593\n",
            "Iteration: 181012 | Cost/Loss: 0.074287 | Weight: 0.568760 | Bias: 0.111593\n",
            "Iteration: 181013 | Cost/Loss: 0.074287 | Weight: 0.568760 | Bias: 0.111593\n",
            "Iteration: 181014 | Cost/Loss: 0.074287 | Weight: 0.568761 | Bias: 0.111593\n",
            "Iteration: 181015 | Cost/Loss: 0.074287 | Weight: 0.568761 | Bias: 0.111594\n",
            "Iteration: 181016 | Cost/Loss: 0.074287 | Weight: 0.568761 | Bias: 0.111594\n",
            "Iteration: 181017 | Cost/Loss: 0.074287 | Weight: 0.568762 | Bias: 0.111594\n",
            "Iteration: 181018 | Cost/Loss: 0.074287 | Weight: 0.568762 | Bias: 0.111595\n",
            "Iteration: 181019 | Cost/Loss: 0.074287 | Weight: 0.568762 | Bias: 0.111595\n",
            "Iteration: 181020 | Cost/Loss: 0.074287 | Weight: 0.568763 | Bias: 0.111595\n",
            "Iteration: 181021 | Cost/Loss: 0.074287 | Weight: 0.568763 | Bias: 0.111596\n",
            "Iteration: 181022 | Cost/Loss: 0.074287 | Weight: 0.568763 | Bias: 0.111596\n",
            "Iteration: 181023 | Cost/Loss: 0.074287 | Weight: 0.568763 | Bias: 0.111596\n",
            "Iteration: 181024 | Cost/Loss: 0.074287 | Weight: 0.568764 | Bias: 0.111597\n",
            "Iteration: 181025 | Cost/Loss: 0.074286 | Weight: 0.568764 | Bias: 0.111597\n",
            "Iteration: 181026 | Cost/Loss: 0.074286 | Weight: 0.568764 | Bias: 0.111597\n",
            "Iteration: 181027 | Cost/Loss: 0.074286 | Weight: 0.568765 | Bias: 0.111597\n",
            "Iteration: 181028 | Cost/Loss: 0.074286 | Weight: 0.568765 | Bias: 0.111598\n",
            "Iteration: 181029 | Cost/Loss: 0.074286 | Weight: 0.568765 | Bias: 0.111598\n",
            "Iteration: 181030 | Cost/Loss: 0.074286 | Weight: 0.568766 | Bias: 0.111598\n",
            "Iteration: 181031 | Cost/Loss: 0.074286 | Weight: 0.568766 | Bias: 0.111599\n",
            "Iteration: 181032 | Cost/Loss: 0.074286 | Weight: 0.568766 | Bias: 0.111599\n",
            "Iteration: 181033 | Cost/Loss: 0.074286 | Weight: 0.568766 | Bias: 0.111599\n",
            "Iteration: 181034 | Cost/Loss: 0.074286 | Weight: 0.568767 | Bias: 0.111600\n",
            "Iteration: 181035 | Cost/Loss: 0.074286 | Weight: 0.568767 | Bias: 0.111600\n",
            "Iteration: 181036 | Cost/Loss: 0.074286 | Weight: 0.568767 | Bias: 0.111600\n",
            "Iteration: 181037 | Cost/Loss: 0.074286 | Weight: 0.568768 | Bias: 0.111601\n",
            "Iteration: 181038 | Cost/Loss: 0.074286 | Weight: 0.568768 | Bias: 0.111601\n",
            "Iteration: 181039 | Cost/Loss: 0.074286 | Weight: 0.568768 | Bias: 0.111601\n",
            "Iteration: 181040 | Cost/Loss: 0.074286 | Weight: 0.568769 | Bias: 0.111601\n",
            "Iteration: 181041 | Cost/Loss: 0.074286 | Weight: 0.568769 | Bias: 0.111602\n",
            "Iteration: 181042 | Cost/Loss: 0.074286 | Weight: 0.568769 | Bias: 0.111602\n",
            "Iteration: 181043 | Cost/Loss: 0.074286 | Weight: 0.568769 | Bias: 0.111602\n",
            "Iteration: 181044 | Cost/Loss: 0.074286 | Weight: 0.568770 | Bias: 0.111603\n",
            "Iteration: 181045 | Cost/Loss: 0.074286 | Weight: 0.568770 | Bias: 0.111603\n",
            "Iteration: 181046 | Cost/Loss: 0.074286 | Weight: 0.568770 | Bias: 0.111603\n",
            "Iteration: 181047 | Cost/Loss: 0.074286 | Weight: 0.568771 | Bias: 0.111604\n",
            "Iteration: 181048 | Cost/Loss: 0.074286 | Weight: 0.568771 | Bias: 0.111604\n",
            "Iteration: 181049 | Cost/Loss: 0.074286 | Weight: 0.568771 | Bias: 0.111604\n",
            "Iteration: 181050 | Cost/Loss: 0.074286 | Weight: 0.568771 | Bias: 0.111604\n",
            "Iteration: 181051 | Cost/Loss: 0.074286 | Weight: 0.568772 | Bias: 0.111605\n",
            "Iteration: 181052 | Cost/Loss: 0.074286 | Weight: 0.568772 | Bias: 0.111605\n",
            "Iteration: 181053 | Cost/Loss: 0.074286 | Weight: 0.568772 | Bias: 0.111605\n",
            "Iteration: 181054 | Cost/Loss: 0.074286 | Weight: 0.568773 | Bias: 0.111606\n",
            "Iteration: 181055 | Cost/Loss: 0.074286 | Weight: 0.568773 | Bias: 0.111606\n",
            "Iteration: 181056 | Cost/Loss: 0.074286 | Weight: 0.568773 | Bias: 0.111606\n",
            "Iteration: 181057 | Cost/Loss: 0.074286 | Weight: 0.568774 | Bias: 0.111607\n",
            "Iteration: 181058 | Cost/Loss: 0.074286 | Weight: 0.568774 | Bias: 0.111607\n",
            "Iteration: 181059 | Cost/Loss: 0.074286 | Weight: 0.568774 | Bias: 0.111607\n",
            "Iteration: 181060 | Cost/Loss: 0.074286 | Weight: 0.568774 | Bias: 0.111608\n",
            "Iteration: 181061 | Cost/Loss: 0.074286 | Weight: 0.568775 | Bias: 0.111608\n",
            "Iteration: 181062 | Cost/Loss: 0.074286 | Weight: 0.568775 | Bias: 0.111608\n",
            "Iteration: 181063 | Cost/Loss: 0.074286 | Weight: 0.568775 | Bias: 0.111608\n",
            "Iteration: 181064 | Cost/Loss: 0.074286 | Weight: 0.568776 | Bias: 0.111609\n",
            "Iteration: 181065 | Cost/Loss: 0.074285 | Weight: 0.568776 | Bias: 0.111609\n",
            "Iteration: 181066 | Cost/Loss: 0.074285 | Weight: 0.568776 | Bias: 0.111609\n",
            "Iteration: 181067 | Cost/Loss: 0.074285 | Weight: 0.568777 | Bias: 0.111610\n",
            "Iteration: 181068 | Cost/Loss: 0.074285 | Weight: 0.568777 | Bias: 0.111610\n",
            "Iteration: 181069 | Cost/Loss: 0.074285 | Weight: 0.568777 | Bias: 0.111610\n",
            "Iteration: 181070 | Cost/Loss: 0.074285 | Weight: 0.568777 | Bias: 0.111611\n",
            "Iteration: 181071 | Cost/Loss: 0.074285 | Weight: 0.568778 | Bias: 0.111611\n",
            "Iteration: 181072 | Cost/Loss: 0.074285 | Weight: 0.568778 | Bias: 0.111611\n",
            "Iteration: 181073 | Cost/Loss: 0.074285 | Weight: 0.568778 | Bias: 0.111612\n",
            "Iteration: 181074 | Cost/Loss: 0.074285 | Weight: 0.568779 | Bias: 0.111612\n",
            "Iteration: 181075 | Cost/Loss: 0.074285 | Weight: 0.568779 | Bias: 0.111612\n",
            "Iteration: 181076 | Cost/Loss: 0.074285 | Weight: 0.568779 | Bias: 0.111612\n",
            "Iteration: 181077 | Cost/Loss: 0.074285 | Weight: 0.568780 | Bias: 0.111613\n",
            "Iteration: 181078 | Cost/Loss: 0.074285 | Weight: 0.568780 | Bias: 0.111613\n",
            "Iteration: 181079 | Cost/Loss: 0.074285 | Weight: 0.568780 | Bias: 0.111613\n",
            "Iteration: 181080 | Cost/Loss: 0.074285 | Weight: 0.568780 | Bias: 0.111614\n",
            "Iteration: 181081 | Cost/Loss: 0.074285 | Weight: 0.568781 | Bias: 0.111614\n",
            "Iteration: 181082 | Cost/Loss: 0.074285 | Weight: 0.568781 | Bias: 0.111614\n",
            "Iteration: 181083 | Cost/Loss: 0.074285 | Weight: 0.568781 | Bias: 0.111615\n",
            "Iteration: 181084 | Cost/Loss: 0.074285 | Weight: 0.568782 | Bias: 0.111615\n",
            "Iteration: 181085 | Cost/Loss: 0.074285 | Weight: 0.568782 | Bias: 0.111615\n",
            "Iteration: 181086 | Cost/Loss: 0.074285 | Weight: 0.568782 | Bias: 0.111615\n",
            "Iteration: 181087 | Cost/Loss: 0.074285 | Weight: 0.568783 | Bias: 0.111616\n",
            "Iteration: 181088 | Cost/Loss: 0.074285 | Weight: 0.568783 | Bias: 0.111616\n",
            "Iteration: 181089 | Cost/Loss: 0.074285 | Weight: 0.568783 | Bias: 0.111616\n",
            "Iteration: 181090 | Cost/Loss: 0.074285 | Weight: 0.568783 | Bias: 0.111617\n",
            "Iteration: 181091 | Cost/Loss: 0.074285 | Weight: 0.568784 | Bias: 0.111617\n",
            "Iteration: 181092 | Cost/Loss: 0.074285 | Weight: 0.568784 | Bias: 0.111617\n",
            "Iteration: 181093 | Cost/Loss: 0.074285 | Weight: 0.568784 | Bias: 0.111618\n",
            "Iteration: 181094 | Cost/Loss: 0.074285 | Weight: 0.568785 | Bias: 0.111618\n",
            "Iteration: 181095 | Cost/Loss: 0.074285 | Weight: 0.568785 | Bias: 0.111618\n",
            "Iteration: 181096 | Cost/Loss: 0.074285 | Weight: 0.568785 | Bias: 0.111619\n",
            "Iteration: 181097 | Cost/Loss: 0.074285 | Weight: 0.568785 | Bias: 0.111619\n",
            "Iteration: 181098 | Cost/Loss: 0.074285 | Weight: 0.568786 | Bias: 0.111619\n",
            "Iteration: 181099 | Cost/Loss: 0.074285 | Weight: 0.568786 | Bias: 0.111619\n",
            "Iteration: 181100 | Cost/Loss: 0.074285 | Weight: 0.568786 | Bias: 0.111620\n",
            "Iteration: 181101 | Cost/Loss: 0.074285 | Weight: 0.568787 | Bias: 0.111620\n",
            "Iteration: 181102 | Cost/Loss: 0.074285 | Weight: 0.568787 | Bias: 0.111620\n",
            "Iteration: 181103 | Cost/Loss: 0.074285 | Weight: 0.568787 | Bias: 0.111621\n",
            "Iteration: 181104 | Cost/Loss: 0.074285 | Weight: 0.568788 | Bias: 0.111621\n",
            "Iteration: 181105 | Cost/Loss: 0.074285 | Weight: 0.568788 | Bias: 0.111621\n",
            "Iteration: 181106 | Cost/Loss: 0.074284 | Weight: 0.568788 | Bias: 0.111622\n",
            "Iteration: 181107 | Cost/Loss: 0.074284 | Weight: 0.568788 | Bias: 0.111622\n",
            "Iteration: 181108 | Cost/Loss: 0.074284 | Weight: 0.568789 | Bias: 0.111622\n",
            "Iteration: 181109 | Cost/Loss: 0.074284 | Weight: 0.568789 | Bias: 0.111623\n",
            "Iteration: 181110 | Cost/Loss: 0.074284 | Weight: 0.568789 | Bias: 0.111623\n",
            "Iteration: 181111 | Cost/Loss: 0.074284 | Weight: 0.568790 | Bias: 0.111623\n",
            "Iteration: 181112 | Cost/Loss: 0.074284 | Weight: 0.568790 | Bias: 0.111623\n",
            "Iteration: 181113 | Cost/Loss: 0.074284 | Weight: 0.568790 | Bias: 0.111624\n",
            "Iteration: 181114 | Cost/Loss: 0.074284 | Weight: 0.568791 | Bias: 0.111624\n",
            "Iteration: 181115 | Cost/Loss: 0.074284 | Weight: 0.568791 | Bias: 0.111624\n",
            "Iteration: 181116 | Cost/Loss: 0.074284 | Weight: 0.568791 | Bias: 0.111625\n",
            "Iteration: 181117 | Cost/Loss: 0.074284 | Weight: 0.568791 | Bias: 0.111625\n",
            "Iteration: 181118 | Cost/Loss: 0.074284 | Weight: 0.568792 | Bias: 0.111625\n",
            "Iteration: 181119 | Cost/Loss: 0.074284 | Weight: 0.568792 | Bias: 0.111626\n",
            "Iteration: 181120 | Cost/Loss: 0.074284 | Weight: 0.568792 | Bias: 0.111626\n",
            "Iteration: 181121 | Cost/Loss: 0.074284 | Weight: 0.568793 | Bias: 0.111626\n",
            "Iteration: 181122 | Cost/Loss: 0.074284 | Weight: 0.568793 | Bias: 0.111626\n",
            "Iteration: 181123 | Cost/Loss: 0.074284 | Weight: 0.568793 | Bias: 0.111627\n",
            "Iteration: 181124 | Cost/Loss: 0.074284 | Weight: 0.568794 | Bias: 0.111627\n",
            "Iteration: 181125 | Cost/Loss: 0.074284 | Weight: 0.568794 | Bias: 0.111627\n",
            "Iteration: 181126 | Cost/Loss: 0.074284 | Weight: 0.568794 | Bias: 0.111628\n",
            "Iteration: 181127 | Cost/Loss: 0.074284 | Weight: 0.568794 | Bias: 0.111628\n",
            "Iteration: 181128 | Cost/Loss: 0.074284 | Weight: 0.568795 | Bias: 0.111628\n",
            "Iteration: 181129 | Cost/Loss: 0.074284 | Weight: 0.568795 | Bias: 0.111629\n",
            "Iteration: 181130 | Cost/Loss: 0.074284 | Weight: 0.568795 | Bias: 0.111629\n",
            "Iteration: 181131 | Cost/Loss: 0.074284 | Weight: 0.568796 | Bias: 0.111629\n",
            "Iteration: 181132 | Cost/Loss: 0.074284 | Weight: 0.568796 | Bias: 0.111630\n",
            "Iteration: 181133 | Cost/Loss: 0.074284 | Weight: 0.568796 | Bias: 0.111630\n",
            "Iteration: 181134 | Cost/Loss: 0.074284 | Weight: 0.568797 | Bias: 0.111630\n",
            "Iteration: 181135 | Cost/Loss: 0.074284 | Weight: 0.568797 | Bias: 0.111630\n",
            "Iteration: 181136 | Cost/Loss: 0.074284 | Weight: 0.568797 | Bias: 0.111631\n",
            "Iteration: 181137 | Cost/Loss: 0.074284 | Weight: 0.568797 | Bias: 0.111631\n",
            "Iteration: 181138 | Cost/Loss: 0.074284 | Weight: 0.568798 | Bias: 0.111631\n",
            "Iteration: 181139 | Cost/Loss: 0.074284 | Weight: 0.568798 | Bias: 0.111632\n",
            "Iteration: 181140 | Cost/Loss: 0.074284 | Weight: 0.568798 | Bias: 0.111632\n",
            "Iteration: 181141 | Cost/Loss: 0.074284 | Weight: 0.568799 | Bias: 0.111632\n",
            "Iteration: 181142 | Cost/Loss: 0.074284 | Weight: 0.568799 | Bias: 0.111633\n",
            "Iteration: 181143 | Cost/Loss: 0.074284 | Weight: 0.568799 | Bias: 0.111633\n",
            "Iteration: 181144 | Cost/Loss: 0.074284 | Weight: 0.568799 | Bias: 0.111633\n",
            "Iteration: 181145 | Cost/Loss: 0.074284 | Weight: 0.568800 | Bias: 0.111634\n",
            "Iteration: 181146 | Cost/Loss: 0.074284 | Weight: 0.568800 | Bias: 0.111634\n",
            "Iteration: 181147 | Cost/Loss: 0.074283 | Weight: 0.568800 | Bias: 0.111634\n",
            "Iteration: 181148 | Cost/Loss: 0.074283 | Weight: 0.568801 | Bias: 0.111634\n",
            "Iteration: 181149 | Cost/Loss: 0.074283 | Weight: 0.568801 | Bias: 0.111635\n",
            "Iteration: 181150 | Cost/Loss: 0.074283 | Weight: 0.568801 | Bias: 0.111635\n",
            "Iteration: 181151 | Cost/Loss: 0.074283 | Weight: 0.568802 | Bias: 0.111635\n",
            "Iteration: 181152 | Cost/Loss: 0.074283 | Weight: 0.568802 | Bias: 0.111636\n",
            "Iteration: 181153 | Cost/Loss: 0.074283 | Weight: 0.568802 | Bias: 0.111636\n",
            "Iteration: 181154 | Cost/Loss: 0.074283 | Weight: 0.568802 | Bias: 0.111636\n",
            "Iteration: 181155 | Cost/Loss: 0.074283 | Weight: 0.568803 | Bias: 0.111637\n",
            "Iteration: 181156 | Cost/Loss: 0.074283 | Weight: 0.568803 | Bias: 0.111637\n",
            "Iteration: 181157 | Cost/Loss: 0.074283 | Weight: 0.568803 | Bias: 0.111637\n",
            "Iteration: 181158 | Cost/Loss: 0.074283 | Weight: 0.568804 | Bias: 0.111637\n",
            "Iteration: 181159 | Cost/Loss: 0.074283 | Weight: 0.568804 | Bias: 0.111638\n",
            "Iteration: 181160 | Cost/Loss: 0.074283 | Weight: 0.568804 | Bias: 0.111638\n",
            "Iteration: 181161 | Cost/Loss: 0.074283 | Weight: 0.568805 | Bias: 0.111638\n",
            "Iteration: 181162 | Cost/Loss: 0.074283 | Weight: 0.568805 | Bias: 0.111639\n",
            "Iteration: 181163 | Cost/Loss: 0.074283 | Weight: 0.568805 | Bias: 0.111639\n",
            "Iteration: 181164 | Cost/Loss: 0.074283 | Weight: 0.568805 | Bias: 0.111639\n",
            "Iteration: 181165 | Cost/Loss: 0.074283 | Weight: 0.568806 | Bias: 0.111640\n",
            "Iteration: 181166 | Cost/Loss: 0.074283 | Weight: 0.568806 | Bias: 0.111640\n",
            "Iteration: 181167 | Cost/Loss: 0.074283 | Weight: 0.568806 | Bias: 0.111640\n",
            "Iteration: 181168 | Cost/Loss: 0.074283 | Weight: 0.568807 | Bias: 0.111641\n",
            "Iteration: 181169 | Cost/Loss: 0.074283 | Weight: 0.568807 | Bias: 0.111641\n",
            "Iteration: 181170 | Cost/Loss: 0.074283 | Weight: 0.568807 | Bias: 0.111641\n",
            "Iteration: 181171 | Cost/Loss: 0.074283 | Weight: 0.568808 | Bias: 0.111641\n",
            "Iteration: 181172 | Cost/Loss: 0.074283 | Weight: 0.568808 | Bias: 0.111642\n",
            "Iteration: 181173 | Cost/Loss: 0.074283 | Weight: 0.568808 | Bias: 0.111642\n",
            "Iteration: 181174 | Cost/Loss: 0.074283 | Weight: 0.568808 | Bias: 0.111642\n",
            "Iteration: 181175 | Cost/Loss: 0.074283 | Weight: 0.568809 | Bias: 0.111643\n",
            "Iteration: 181176 | Cost/Loss: 0.074283 | Weight: 0.568809 | Bias: 0.111643\n",
            "Iteration: 181177 | Cost/Loss: 0.074283 | Weight: 0.568809 | Bias: 0.111643\n",
            "Iteration: 181178 | Cost/Loss: 0.074283 | Weight: 0.568810 | Bias: 0.111644\n",
            "Iteration: 181179 | Cost/Loss: 0.074283 | Weight: 0.568810 | Bias: 0.111644\n",
            "Iteration: 181180 | Cost/Loss: 0.074283 | Weight: 0.568810 | Bias: 0.111644\n",
            "Iteration: 181181 | Cost/Loss: 0.074283 | Weight: 0.568811 | Bias: 0.111645\n",
            "Iteration: 181182 | Cost/Loss: 0.074283 | Weight: 0.568811 | Bias: 0.111645\n",
            "Iteration: 181183 | Cost/Loss: 0.074283 | Weight: 0.568811 | Bias: 0.111645\n",
            "Iteration: 181184 | Cost/Loss: 0.074283 | Weight: 0.568811 | Bias: 0.111645\n",
            "Iteration: 181185 | Cost/Loss: 0.074283 | Weight: 0.568812 | Bias: 0.111646\n",
            "Iteration: 181186 | Cost/Loss: 0.074283 | Weight: 0.568812 | Bias: 0.111646\n",
            "Iteration: 181187 | Cost/Loss: 0.074282 | Weight: 0.568812 | Bias: 0.111646\n",
            "Iteration: 181188 | Cost/Loss: 0.074282 | Weight: 0.568813 | Bias: 0.111647\n",
            "Iteration: 181189 | Cost/Loss: 0.074282 | Weight: 0.568813 | Bias: 0.111647\n",
            "Iteration: 181190 | Cost/Loss: 0.074282 | Weight: 0.568813 | Bias: 0.111647\n",
            "Iteration: 181191 | Cost/Loss: 0.074282 | Weight: 0.568814 | Bias: 0.111648\n",
            "Iteration: 181192 | Cost/Loss: 0.074282 | Weight: 0.568814 | Bias: 0.111648\n",
            "Iteration: 181193 | Cost/Loss: 0.074282 | Weight: 0.568814 | Bias: 0.111648\n",
            "Iteration: 181194 | Cost/Loss: 0.074282 | Weight: 0.568814 | Bias: 0.111648\n",
            "Iteration: 181195 | Cost/Loss: 0.074282 | Weight: 0.568815 | Bias: 0.111649\n",
            "Iteration: 181196 | Cost/Loss: 0.074282 | Weight: 0.568815 | Bias: 0.111649\n",
            "Iteration: 181197 | Cost/Loss: 0.074282 | Weight: 0.568815 | Bias: 0.111649\n",
            "Iteration: 181198 | Cost/Loss: 0.074282 | Weight: 0.568816 | Bias: 0.111650\n",
            "Iteration: 181199 | Cost/Loss: 0.074282 | Weight: 0.568816 | Bias: 0.111650\n",
            "Iteration: 181200 | Cost/Loss: 0.074282 | Weight: 0.568816 | Bias: 0.111650\n",
            "Iteration: 181201 | Cost/Loss: 0.074282 | Weight: 0.568816 | Bias: 0.111651\n",
            "Iteration: 181202 | Cost/Loss: 0.074282 | Weight: 0.568817 | Bias: 0.111651\n",
            "Iteration: 181203 | Cost/Loss: 0.074282 | Weight: 0.568817 | Bias: 0.111651\n",
            "Iteration: 181204 | Cost/Loss: 0.074282 | Weight: 0.568817 | Bias: 0.111652\n",
            "Iteration: 181205 | Cost/Loss: 0.074282 | Weight: 0.568818 | Bias: 0.111652\n",
            "Iteration: 181206 | Cost/Loss: 0.074282 | Weight: 0.568818 | Bias: 0.111652\n",
            "Iteration: 181207 | Cost/Loss: 0.074282 | Weight: 0.568818 | Bias: 0.111652\n",
            "Iteration: 181208 | Cost/Loss: 0.074282 | Weight: 0.568819 | Bias: 0.111653\n",
            "Iteration: 181209 | Cost/Loss: 0.074282 | Weight: 0.568819 | Bias: 0.111653\n",
            "Iteration: 181210 | Cost/Loss: 0.074282 | Weight: 0.568819 | Bias: 0.111653\n",
            "Iteration: 181211 | Cost/Loss: 0.074282 | Weight: 0.568819 | Bias: 0.111654\n",
            "Iteration: 181212 | Cost/Loss: 0.074282 | Weight: 0.568820 | Bias: 0.111654\n",
            "Iteration: 181213 | Cost/Loss: 0.074282 | Weight: 0.568820 | Bias: 0.111654\n",
            "Iteration: 181214 | Cost/Loss: 0.074282 | Weight: 0.568820 | Bias: 0.111655\n",
            "Iteration: 181215 | Cost/Loss: 0.074282 | Weight: 0.568821 | Bias: 0.111655\n",
            "Iteration: 181216 | Cost/Loss: 0.074282 | Weight: 0.568821 | Bias: 0.111655\n",
            "Iteration: 181217 | Cost/Loss: 0.074282 | Weight: 0.568821 | Bias: 0.111656\n",
            "Iteration: 181218 | Cost/Loss: 0.074282 | Weight: 0.568822 | Bias: 0.111656\n",
            "Iteration: 181219 | Cost/Loss: 0.074282 | Weight: 0.568822 | Bias: 0.111656\n",
            "Iteration: 181220 | Cost/Loss: 0.074282 | Weight: 0.568822 | Bias: 0.111656\n",
            "Iteration: 181221 | Cost/Loss: 0.074282 | Weight: 0.568822 | Bias: 0.111657\n",
            "Iteration: 181222 | Cost/Loss: 0.074282 | Weight: 0.568823 | Bias: 0.111657\n",
            "Iteration: 181223 | Cost/Loss: 0.074282 | Weight: 0.568823 | Bias: 0.111657\n",
            "Iteration: 181224 | Cost/Loss: 0.074282 | Weight: 0.568823 | Bias: 0.111658\n",
            "Iteration: 181225 | Cost/Loss: 0.074282 | Weight: 0.568824 | Bias: 0.111658\n",
            "Iteration: 181226 | Cost/Loss: 0.074282 | Weight: 0.568824 | Bias: 0.111658\n",
            "Iteration: 181227 | Cost/Loss: 0.074282 | Weight: 0.568824 | Bias: 0.111659\n",
            "Iteration: 181228 | Cost/Loss: 0.074281 | Weight: 0.568825 | Bias: 0.111659\n",
            "Iteration: 181229 | Cost/Loss: 0.074281 | Weight: 0.568825 | Bias: 0.111659\n",
            "Iteration: 181230 | Cost/Loss: 0.074281 | Weight: 0.568825 | Bias: 0.111659\n",
            "Iteration: 181231 | Cost/Loss: 0.074281 | Weight: 0.568825 | Bias: 0.111660\n",
            "Iteration: 181232 | Cost/Loss: 0.074281 | Weight: 0.568826 | Bias: 0.111660\n",
            "Iteration: 181233 | Cost/Loss: 0.074281 | Weight: 0.568826 | Bias: 0.111660\n",
            "Iteration: 181234 | Cost/Loss: 0.074281 | Weight: 0.568826 | Bias: 0.111661\n",
            "Iteration: 181235 | Cost/Loss: 0.074281 | Weight: 0.568827 | Bias: 0.111661\n",
            "Iteration: 181236 | Cost/Loss: 0.074281 | Weight: 0.568827 | Bias: 0.111661\n",
            "Iteration: 181237 | Cost/Loss: 0.074281 | Weight: 0.568827 | Bias: 0.111662\n",
            "Iteration: 181238 | Cost/Loss: 0.074281 | Weight: 0.568828 | Bias: 0.111662\n",
            "Iteration: 181239 | Cost/Loss: 0.074281 | Weight: 0.568828 | Bias: 0.111662\n",
            "Iteration: 181240 | Cost/Loss: 0.074281 | Weight: 0.568828 | Bias: 0.111663\n",
            "Iteration: 181241 | Cost/Loss: 0.074281 | Weight: 0.568828 | Bias: 0.111663\n",
            "Iteration: 181242 | Cost/Loss: 0.074281 | Weight: 0.568829 | Bias: 0.111663\n",
            "Iteration: 181243 | Cost/Loss: 0.074281 | Weight: 0.568829 | Bias: 0.111663\n",
            "Iteration: 181244 | Cost/Loss: 0.074281 | Weight: 0.568829 | Bias: 0.111664\n",
            "Iteration: 181245 | Cost/Loss: 0.074281 | Weight: 0.568830 | Bias: 0.111664\n",
            "Iteration: 181246 | Cost/Loss: 0.074281 | Weight: 0.568830 | Bias: 0.111664\n",
            "Iteration: 181247 | Cost/Loss: 0.074281 | Weight: 0.568830 | Bias: 0.111665\n",
            "Iteration: 181248 | Cost/Loss: 0.074281 | Weight: 0.568830 | Bias: 0.111665\n",
            "Iteration: 181249 | Cost/Loss: 0.074281 | Weight: 0.568831 | Bias: 0.111665\n",
            "Iteration: 181250 | Cost/Loss: 0.074281 | Weight: 0.568831 | Bias: 0.111666\n",
            "Iteration: 181251 | Cost/Loss: 0.074281 | Weight: 0.568831 | Bias: 0.111666\n",
            "Iteration: 181252 | Cost/Loss: 0.074281 | Weight: 0.568832 | Bias: 0.111666\n",
            "Iteration: 181253 | Cost/Loss: 0.074281 | Weight: 0.568832 | Bias: 0.111667\n",
            "Iteration: 181254 | Cost/Loss: 0.074281 | Weight: 0.568832 | Bias: 0.111667\n",
            "Iteration: 181255 | Cost/Loss: 0.074281 | Weight: 0.568833 | Bias: 0.111667\n",
            "Iteration: 181256 | Cost/Loss: 0.074281 | Weight: 0.568833 | Bias: 0.111667\n",
            "Iteration: 181257 | Cost/Loss: 0.074281 | Weight: 0.568833 | Bias: 0.111668\n",
            "Iteration: 181258 | Cost/Loss: 0.074281 | Weight: 0.568833 | Bias: 0.111668\n",
            "Iteration: 181259 | Cost/Loss: 0.074281 | Weight: 0.568834 | Bias: 0.111668\n",
            "Iteration: 181260 | Cost/Loss: 0.074281 | Weight: 0.568834 | Bias: 0.111669\n",
            "Iteration: 181261 | Cost/Loss: 0.074281 | Weight: 0.568834 | Bias: 0.111669\n",
            "Iteration: 181262 | Cost/Loss: 0.074281 | Weight: 0.568835 | Bias: 0.111669\n",
            "Iteration: 181263 | Cost/Loss: 0.074281 | Weight: 0.568835 | Bias: 0.111670\n",
            "Iteration: 181264 | Cost/Loss: 0.074281 | Weight: 0.568835 | Bias: 0.111670\n",
            "Iteration: 181265 | Cost/Loss: 0.074281 | Weight: 0.568836 | Bias: 0.111670\n",
            "Iteration: 181266 | Cost/Loss: 0.074281 | Weight: 0.568836 | Bias: 0.111670\n",
            "Iteration: 181267 | Cost/Loss: 0.074281 | Weight: 0.568836 | Bias: 0.111671\n",
            "Iteration: 181268 | Cost/Loss: 0.074280 | Weight: 0.568836 | Bias: 0.111671\n",
            "Iteration: 181269 | Cost/Loss: 0.074280 | Weight: 0.568837 | Bias: 0.111671\n",
            "Iteration: 181270 | Cost/Loss: 0.074280 | Weight: 0.568837 | Bias: 0.111672\n",
            "Iteration: 181271 | Cost/Loss: 0.074280 | Weight: 0.568837 | Bias: 0.111672\n",
            "Iteration: 181272 | Cost/Loss: 0.074280 | Weight: 0.568838 | Bias: 0.111672\n",
            "Iteration: 181273 | Cost/Loss: 0.074280 | Weight: 0.568838 | Bias: 0.111673\n",
            "Iteration: 181274 | Cost/Loss: 0.074280 | Weight: 0.568838 | Bias: 0.111673\n",
            "Iteration: 181275 | Cost/Loss: 0.074280 | Weight: 0.568839 | Bias: 0.111673\n",
            "Iteration: 181276 | Cost/Loss: 0.074280 | Weight: 0.568839 | Bias: 0.111674\n",
            "Iteration: 181277 | Cost/Loss: 0.074280 | Weight: 0.568839 | Bias: 0.111674\n",
            "Iteration: 181278 | Cost/Loss: 0.074280 | Weight: 0.568839 | Bias: 0.111674\n",
            "Iteration: 181279 | Cost/Loss: 0.074280 | Weight: 0.568840 | Bias: 0.111674\n",
            "Iteration: 181280 | Cost/Loss: 0.074280 | Weight: 0.568840 | Bias: 0.111675\n",
            "Iteration: 181281 | Cost/Loss: 0.074280 | Weight: 0.568840 | Bias: 0.111675\n",
            "Iteration: 181282 | Cost/Loss: 0.074280 | Weight: 0.568841 | Bias: 0.111675\n",
            "Iteration: 181283 | Cost/Loss: 0.074280 | Weight: 0.568841 | Bias: 0.111676\n",
            "Iteration: 181284 | Cost/Loss: 0.074280 | Weight: 0.568841 | Bias: 0.111676\n",
            "Iteration: 181285 | Cost/Loss: 0.074280 | Weight: 0.568842 | Bias: 0.111676\n",
            "Iteration: 181286 | Cost/Loss: 0.074280 | Weight: 0.568842 | Bias: 0.111677\n",
            "Iteration: 181287 | Cost/Loss: 0.074280 | Weight: 0.568842 | Bias: 0.111677\n",
            "Iteration: 181288 | Cost/Loss: 0.074280 | Weight: 0.568842 | Bias: 0.111677\n",
            "Iteration: 181289 | Cost/Loss: 0.074280 | Weight: 0.568843 | Bias: 0.111678\n",
            "Iteration: 181290 | Cost/Loss: 0.074280 | Weight: 0.568843 | Bias: 0.111678\n",
            "Iteration: 181291 | Cost/Loss: 0.074280 | Weight: 0.568843 | Bias: 0.111678\n",
            "Iteration: 181292 | Cost/Loss: 0.074280 | Weight: 0.568844 | Bias: 0.111678\n",
            "Iteration: 181293 | Cost/Loss: 0.074280 | Weight: 0.568844 | Bias: 0.111679\n",
            "Iteration: 181294 | Cost/Loss: 0.074280 | Weight: 0.568844 | Bias: 0.111679\n",
            "Iteration: 181295 | Cost/Loss: 0.074280 | Weight: 0.568844 | Bias: 0.111679\n",
            "Iteration: 181296 | Cost/Loss: 0.074280 | Weight: 0.568845 | Bias: 0.111680\n",
            "Iteration: 181297 | Cost/Loss: 0.074280 | Weight: 0.568845 | Bias: 0.111680\n",
            "Iteration: 181298 | Cost/Loss: 0.074280 | Weight: 0.568845 | Bias: 0.111680\n",
            "Iteration: 181299 | Cost/Loss: 0.074280 | Weight: 0.568846 | Bias: 0.111681\n",
            "Iteration: 181300 | Cost/Loss: 0.074280 | Weight: 0.568846 | Bias: 0.111681\n",
            "Iteration: 181301 | Cost/Loss: 0.074280 | Weight: 0.568846 | Bias: 0.111681\n",
            "Iteration: 181302 | Cost/Loss: 0.074280 | Weight: 0.568847 | Bias: 0.111681\n",
            "Iteration: 181303 | Cost/Loss: 0.074280 | Weight: 0.568847 | Bias: 0.111682\n",
            "Iteration: 181304 | Cost/Loss: 0.074280 | Weight: 0.568847 | Bias: 0.111682\n",
            "Iteration: 181305 | Cost/Loss: 0.074280 | Weight: 0.568847 | Bias: 0.111682\n",
            "Iteration: 181306 | Cost/Loss: 0.074280 | Weight: 0.568848 | Bias: 0.111683\n",
            "Iteration: 181307 | Cost/Loss: 0.074280 | Weight: 0.568848 | Bias: 0.111683\n",
            "Iteration: 181308 | Cost/Loss: 0.074280 | Weight: 0.568848 | Bias: 0.111683\n",
            "Iteration: 181309 | Cost/Loss: 0.074279 | Weight: 0.568849 | Bias: 0.111684\n",
            "Iteration: 181310 | Cost/Loss: 0.074279 | Weight: 0.568849 | Bias: 0.111684\n",
            "Iteration: 181311 | Cost/Loss: 0.074279 | Weight: 0.568849 | Bias: 0.111684\n",
            "Iteration: 181312 | Cost/Loss: 0.074279 | Weight: 0.568850 | Bias: 0.111685\n",
            "Iteration: 181313 | Cost/Loss: 0.074279 | Weight: 0.568850 | Bias: 0.111685\n",
            "Iteration: 181314 | Cost/Loss: 0.074279 | Weight: 0.568850 | Bias: 0.111685\n",
            "Iteration: 181315 | Cost/Loss: 0.074279 | Weight: 0.568850 | Bias: 0.111685\n",
            "Iteration: 181316 | Cost/Loss: 0.074279 | Weight: 0.568851 | Bias: 0.111686\n",
            "Iteration: 181317 | Cost/Loss: 0.074279 | Weight: 0.568851 | Bias: 0.111686\n",
            "Iteration: 181318 | Cost/Loss: 0.074279 | Weight: 0.568851 | Bias: 0.111686\n",
            "Iteration: 181319 | Cost/Loss: 0.074279 | Weight: 0.568852 | Bias: 0.111687\n",
            "Iteration: 181320 | Cost/Loss: 0.074279 | Weight: 0.568852 | Bias: 0.111687\n",
            "Iteration: 181321 | Cost/Loss: 0.074279 | Weight: 0.568852 | Bias: 0.111687\n",
            "Iteration: 181322 | Cost/Loss: 0.074279 | Weight: 0.568853 | Bias: 0.111688\n",
            "Iteration: 181323 | Cost/Loss: 0.074279 | Weight: 0.568853 | Bias: 0.111688\n",
            "Iteration: 181324 | Cost/Loss: 0.074279 | Weight: 0.568853 | Bias: 0.111688\n",
            "Iteration: 181325 | Cost/Loss: 0.074279 | Weight: 0.568853 | Bias: 0.111689\n",
            "Iteration: 181326 | Cost/Loss: 0.074279 | Weight: 0.568854 | Bias: 0.111689\n",
            "Iteration: 181327 | Cost/Loss: 0.074279 | Weight: 0.568854 | Bias: 0.111689\n",
            "Iteration: 181328 | Cost/Loss: 0.074279 | Weight: 0.568854 | Bias: 0.111689\n",
            "Iteration: 181329 | Cost/Loss: 0.074279 | Weight: 0.568855 | Bias: 0.111690\n",
            "Iteration: 181330 | Cost/Loss: 0.074279 | Weight: 0.568855 | Bias: 0.111690\n",
            "Iteration: 181331 | Cost/Loss: 0.074279 | Weight: 0.568855 | Bias: 0.111690\n",
            "Iteration: 181332 | Cost/Loss: 0.074279 | Weight: 0.568856 | Bias: 0.111691\n",
            "Iteration: 181333 | Cost/Loss: 0.074279 | Weight: 0.568856 | Bias: 0.111691\n",
            "Iteration: 181334 | Cost/Loss: 0.074279 | Weight: 0.568856 | Bias: 0.111691\n",
            "Iteration: 181335 | Cost/Loss: 0.074279 | Weight: 0.568856 | Bias: 0.111692\n",
            "Iteration: 181336 | Cost/Loss: 0.074279 | Weight: 0.568857 | Bias: 0.111692\n",
            "Iteration: 181337 | Cost/Loss: 0.074279 | Weight: 0.568857 | Bias: 0.111692\n",
            "Iteration: 181338 | Cost/Loss: 0.074279 | Weight: 0.568857 | Bias: 0.111692\n",
            "Iteration: 181339 | Cost/Loss: 0.074279 | Weight: 0.568858 | Bias: 0.111693\n",
            "Iteration: 181340 | Cost/Loss: 0.074279 | Weight: 0.568858 | Bias: 0.111693\n",
            "Iteration: 181341 | Cost/Loss: 0.074279 | Weight: 0.568858 | Bias: 0.111693\n",
            "Iteration: 181342 | Cost/Loss: 0.074279 | Weight: 0.568859 | Bias: 0.111694\n",
            "Iteration: 181343 | Cost/Loss: 0.074279 | Weight: 0.568859 | Bias: 0.111694\n",
            "Iteration: 181344 | Cost/Loss: 0.074279 | Weight: 0.568859 | Bias: 0.111694\n",
            "Iteration: 181345 | Cost/Loss: 0.074279 | Weight: 0.568859 | Bias: 0.111695\n",
            "Iteration: 181346 | Cost/Loss: 0.074279 | Weight: 0.568860 | Bias: 0.111695\n",
            "Iteration: 181347 | Cost/Loss: 0.074279 | Weight: 0.568860 | Bias: 0.111695\n",
            "Iteration: 181348 | Cost/Loss: 0.074279 | Weight: 0.568860 | Bias: 0.111696\n",
            "Iteration: 181349 | Cost/Loss: 0.074278 | Weight: 0.568861 | Bias: 0.111696\n",
            "Iteration: 181350 | Cost/Loss: 0.074278 | Weight: 0.568861 | Bias: 0.111696\n",
            "Iteration: 181351 | Cost/Loss: 0.074278 | Weight: 0.568861 | Bias: 0.111696\n",
            "Iteration: 181352 | Cost/Loss: 0.074278 | Weight: 0.568861 | Bias: 0.111697\n",
            "Iteration: 181353 | Cost/Loss: 0.074278 | Weight: 0.568862 | Bias: 0.111697\n",
            "Iteration: 181354 | Cost/Loss: 0.074278 | Weight: 0.568862 | Bias: 0.111697\n",
            "Iteration: 181355 | Cost/Loss: 0.074278 | Weight: 0.568862 | Bias: 0.111698\n",
            "Iteration: 181356 | Cost/Loss: 0.074278 | Weight: 0.568863 | Bias: 0.111698\n",
            "Iteration: 181357 | Cost/Loss: 0.074278 | Weight: 0.568863 | Bias: 0.111698\n",
            "Iteration: 181358 | Cost/Loss: 0.074278 | Weight: 0.568863 | Bias: 0.111699\n",
            "Iteration: 181359 | Cost/Loss: 0.074278 | Weight: 0.568864 | Bias: 0.111699\n",
            "Iteration: 181360 | Cost/Loss: 0.074278 | Weight: 0.568864 | Bias: 0.111699\n",
            "Iteration: 181361 | Cost/Loss: 0.074278 | Weight: 0.568864 | Bias: 0.111699\n",
            "Iteration: 181362 | Cost/Loss: 0.074278 | Weight: 0.568864 | Bias: 0.111700\n",
            "Iteration: 181363 | Cost/Loss: 0.074278 | Weight: 0.568865 | Bias: 0.111700\n",
            "Iteration: 181364 | Cost/Loss: 0.074278 | Weight: 0.568865 | Bias: 0.111700\n",
            "Iteration: 181365 | Cost/Loss: 0.074278 | Weight: 0.568865 | Bias: 0.111701\n",
            "Iteration: 181366 | Cost/Loss: 0.074278 | Weight: 0.568866 | Bias: 0.111701\n",
            "Iteration: 181367 | Cost/Loss: 0.074278 | Weight: 0.568866 | Bias: 0.111701\n",
            "Iteration: 181368 | Cost/Loss: 0.074278 | Weight: 0.568866 | Bias: 0.111702\n",
            "Iteration: 181369 | Cost/Loss: 0.074278 | Weight: 0.568867 | Bias: 0.111702\n",
            "Iteration: 181370 | Cost/Loss: 0.074278 | Weight: 0.568867 | Bias: 0.111702\n",
            "Iteration: 181371 | Cost/Loss: 0.074278 | Weight: 0.568867 | Bias: 0.111703\n",
            "Iteration: 181372 | Cost/Loss: 0.074278 | Weight: 0.568867 | Bias: 0.111703\n",
            "Iteration: 181373 | Cost/Loss: 0.074278 | Weight: 0.568868 | Bias: 0.111703\n",
            "Iteration: 181374 | Cost/Loss: 0.074278 | Weight: 0.568868 | Bias: 0.111703\n",
            "Iteration: 181375 | Cost/Loss: 0.074278 | Weight: 0.568868 | Bias: 0.111704\n",
            "Iteration: 181376 | Cost/Loss: 0.074278 | Weight: 0.568869 | Bias: 0.111704\n",
            "Iteration: 181377 | Cost/Loss: 0.074278 | Weight: 0.568869 | Bias: 0.111704\n",
            "Iteration: 181378 | Cost/Loss: 0.074278 | Weight: 0.568869 | Bias: 0.111705\n",
            "Iteration: 181379 | Cost/Loss: 0.074278 | Weight: 0.568870 | Bias: 0.111705\n",
            "Iteration: 181380 | Cost/Loss: 0.074278 | Weight: 0.568870 | Bias: 0.111705\n",
            "Iteration: 181381 | Cost/Loss: 0.074278 | Weight: 0.568870 | Bias: 0.111706\n",
            "Iteration: 181382 | Cost/Loss: 0.074278 | Weight: 0.568870 | Bias: 0.111706\n",
            "Iteration: 181383 | Cost/Loss: 0.074278 | Weight: 0.568871 | Bias: 0.111706\n",
            "Iteration: 181384 | Cost/Loss: 0.074278 | Weight: 0.568871 | Bias: 0.111707\n",
            "Iteration: 181385 | Cost/Loss: 0.074278 | Weight: 0.568871 | Bias: 0.111707\n",
            "Iteration: 181386 | Cost/Loss: 0.074278 | Weight: 0.568872 | Bias: 0.111707\n",
            "Iteration: 181387 | Cost/Loss: 0.074278 | Weight: 0.568872 | Bias: 0.111707\n",
            "Iteration: 181388 | Cost/Loss: 0.074278 | Weight: 0.568872 | Bias: 0.111708\n",
            "Iteration: 181389 | Cost/Loss: 0.074278 | Weight: 0.568873 | Bias: 0.111708\n",
            "Iteration: 181390 | Cost/Loss: 0.074277 | Weight: 0.568873 | Bias: 0.111708\n",
            "Iteration: 181391 | Cost/Loss: 0.074277 | Weight: 0.568873 | Bias: 0.111709\n",
            "Iteration: 181392 | Cost/Loss: 0.074277 | Weight: 0.568873 | Bias: 0.111709\n",
            "Iteration: 181393 | Cost/Loss: 0.074277 | Weight: 0.568874 | Bias: 0.111709\n",
            "Iteration: 181394 | Cost/Loss: 0.074277 | Weight: 0.568874 | Bias: 0.111710\n",
            "Iteration: 181395 | Cost/Loss: 0.074277 | Weight: 0.568874 | Bias: 0.111710\n",
            "Iteration: 181396 | Cost/Loss: 0.074277 | Weight: 0.568875 | Bias: 0.111710\n",
            "Iteration: 181397 | Cost/Loss: 0.074277 | Weight: 0.568875 | Bias: 0.111710\n",
            "Iteration: 181398 | Cost/Loss: 0.074277 | Weight: 0.568875 | Bias: 0.111711\n",
            "Iteration: 181399 | Cost/Loss: 0.074277 | Weight: 0.568875 | Bias: 0.111711\n",
            "Iteration: 181400 | Cost/Loss: 0.074277 | Weight: 0.568876 | Bias: 0.111711\n",
            "Iteration: 181401 | Cost/Loss: 0.074277 | Weight: 0.568876 | Bias: 0.111712\n",
            "Iteration: 181402 | Cost/Loss: 0.074277 | Weight: 0.568876 | Bias: 0.111712\n",
            "Iteration: 181403 | Cost/Loss: 0.074277 | Weight: 0.568877 | Bias: 0.111712\n",
            "Iteration: 181404 | Cost/Loss: 0.074277 | Weight: 0.568877 | Bias: 0.111713\n",
            "Iteration: 181405 | Cost/Loss: 0.074277 | Weight: 0.568877 | Bias: 0.111713\n",
            "Iteration: 181406 | Cost/Loss: 0.074277 | Weight: 0.568878 | Bias: 0.111713\n",
            "Iteration: 181407 | Cost/Loss: 0.074277 | Weight: 0.568878 | Bias: 0.111714\n",
            "Iteration: 181408 | Cost/Loss: 0.074277 | Weight: 0.568878 | Bias: 0.111714\n",
            "Iteration: 181409 | Cost/Loss: 0.074277 | Weight: 0.568878 | Bias: 0.111714\n",
            "Iteration: 181410 | Cost/Loss: 0.074277 | Weight: 0.568879 | Bias: 0.111714\n",
            "Iteration: 181411 | Cost/Loss: 0.074277 | Weight: 0.568879 | Bias: 0.111715\n",
            "Iteration: 181412 | Cost/Loss: 0.074277 | Weight: 0.568879 | Bias: 0.111715\n",
            "Iteration: 181413 | Cost/Loss: 0.074277 | Weight: 0.568880 | Bias: 0.111715\n",
            "Iteration: 181414 | Cost/Loss: 0.074277 | Weight: 0.568880 | Bias: 0.111716\n",
            "Iteration: 181415 | Cost/Loss: 0.074277 | Weight: 0.568880 | Bias: 0.111716\n",
            "Iteration: 181416 | Cost/Loss: 0.074277 | Weight: 0.568881 | Bias: 0.111716\n",
            "Iteration: 181417 | Cost/Loss: 0.074277 | Weight: 0.568881 | Bias: 0.111717\n",
            "Iteration: 181418 | Cost/Loss: 0.074277 | Weight: 0.568881 | Bias: 0.111717\n",
            "Iteration: 181419 | Cost/Loss: 0.074277 | Weight: 0.568881 | Bias: 0.111717\n",
            "Iteration: 181420 | Cost/Loss: 0.074277 | Weight: 0.568882 | Bias: 0.111718\n",
            "Iteration: 181421 | Cost/Loss: 0.074277 | Weight: 0.568882 | Bias: 0.111718\n",
            "Iteration: 181422 | Cost/Loss: 0.074277 | Weight: 0.568882 | Bias: 0.111718\n",
            "Iteration: 181423 | Cost/Loss: 0.074277 | Weight: 0.568883 | Bias: 0.111718\n",
            "Iteration: 181424 | Cost/Loss: 0.074277 | Weight: 0.568883 | Bias: 0.111719\n",
            "Iteration: 181425 | Cost/Loss: 0.074277 | Weight: 0.568883 | Bias: 0.111719\n",
            "Iteration: 181426 | Cost/Loss: 0.074277 | Weight: 0.568884 | Bias: 0.111719\n",
            "Iteration: 181427 | Cost/Loss: 0.074277 | Weight: 0.568884 | Bias: 0.111720\n",
            "Iteration: 181428 | Cost/Loss: 0.074277 | Weight: 0.568884 | Bias: 0.111720\n",
            "Iteration: 181429 | Cost/Loss: 0.074277 | Weight: 0.568884 | Bias: 0.111720\n",
            "Iteration: 181430 | Cost/Loss: 0.074277 | Weight: 0.568885 | Bias: 0.111721\n",
            "Iteration: 181431 | Cost/Loss: 0.074276 | Weight: 0.568885 | Bias: 0.111721\n",
            "Iteration: 181432 | Cost/Loss: 0.074276 | Weight: 0.568885 | Bias: 0.111721\n",
            "Iteration: 181433 | Cost/Loss: 0.074276 | Weight: 0.568886 | Bias: 0.111721\n",
            "Iteration: 181434 | Cost/Loss: 0.074276 | Weight: 0.568886 | Bias: 0.111722\n",
            "Iteration: 181435 | Cost/Loss: 0.074276 | Weight: 0.568886 | Bias: 0.111722\n",
            "Iteration: 181436 | Cost/Loss: 0.074276 | Weight: 0.568887 | Bias: 0.111722\n",
            "Iteration: 181437 | Cost/Loss: 0.074276 | Weight: 0.568887 | Bias: 0.111723\n",
            "Iteration: 181438 | Cost/Loss: 0.074276 | Weight: 0.568887 | Bias: 0.111723\n",
            "Iteration: 181439 | Cost/Loss: 0.074276 | Weight: 0.568887 | Bias: 0.111723\n",
            "Iteration: 181440 | Cost/Loss: 0.074276 | Weight: 0.568888 | Bias: 0.111724\n",
            "Iteration: 181441 | Cost/Loss: 0.074276 | Weight: 0.568888 | Bias: 0.111724\n",
            "Iteration: 181442 | Cost/Loss: 0.074276 | Weight: 0.568888 | Bias: 0.111724\n",
            "Iteration: 181443 | Cost/Loss: 0.074276 | Weight: 0.568889 | Bias: 0.111725\n",
            "Iteration: 181444 | Cost/Loss: 0.074276 | Weight: 0.568889 | Bias: 0.111725\n",
            "Iteration: 181445 | Cost/Loss: 0.074276 | Weight: 0.568889 | Bias: 0.111725\n",
            "Iteration: 181446 | Cost/Loss: 0.074276 | Weight: 0.568889 | Bias: 0.111725\n",
            "Iteration: 181447 | Cost/Loss: 0.074276 | Weight: 0.568890 | Bias: 0.111726\n",
            "Iteration: 181448 | Cost/Loss: 0.074276 | Weight: 0.568890 | Bias: 0.111726\n",
            "Iteration: 181449 | Cost/Loss: 0.074276 | Weight: 0.568890 | Bias: 0.111726\n",
            "Iteration: 181450 | Cost/Loss: 0.074276 | Weight: 0.568891 | Bias: 0.111727\n",
            "Iteration: 181451 | Cost/Loss: 0.074276 | Weight: 0.568891 | Bias: 0.111727\n",
            "Iteration: 181452 | Cost/Loss: 0.074276 | Weight: 0.568891 | Bias: 0.111727\n",
            "Iteration: 181453 | Cost/Loss: 0.074276 | Weight: 0.568892 | Bias: 0.111728\n",
            "Iteration: 181454 | Cost/Loss: 0.074276 | Weight: 0.568892 | Bias: 0.111728\n",
            "Iteration: 181455 | Cost/Loss: 0.074276 | Weight: 0.568892 | Bias: 0.111728\n",
            "Iteration: 181456 | Cost/Loss: 0.074276 | Weight: 0.568892 | Bias: 0.111729\n",
            "Iteration: 181457 | Cost/Loss: 0.074276 | Weight: 0.568893 | Bias: 0.111729\n",
            "Iteration: 181458 | Cost/Loss: 0.074276 | Weight: 0.568893 | Bias: 0.111729\n",
            "Iteration: 181459 | Cost/Loss: 0.074276 | Weight: 0.568893 | Bias: 0.111729\n",
            "Iteration: 181460 | Cost/Loss: 0.074276 | Weight: 0.568894 | Bias: 0.111730\n",
            "Iteration: 181461 | Cost/Loss: 0.074276 | Weight: 0.568894 | Bias: 0.111730\n",
            "Iteration: 181462 | Cost/Loss: 0.074276 | Weight: 0.568894 | Bias: 0.111730\n",
            "Iteration: 181463 | Cost/Loss: 0.074276 | Weight: 0.568895 | Bias: 0.111731\n",
            "Iteration: 181464 | Cost/Loss: 0.074276 | Weight: 0.568895 | Bias: 0.111731\n",
            "Iteration: 181465 | Cost/Loss: 0.074276 | Weight: 0.568895 | Bias: 0.111731\n",
            "Iteration: 181466 | Cost/Loss: 0.074276 | Weight: 0.568895 | Bias: 0.111732\n",
            "Iteration: 181467 | Cost/Loss: 0.074276 | Weight: 0.568896 | Bias: 0.111732\n",
            "Iteration: 181468 | Cost/Loss: 0.074276 | Weight: 0.568896 | Bias: 0.111732\n",
            "Iteration: 181469 | Cost/Loss: 0.074276 | Weight: 0.568896 | Bias: 0.111732\n",
            "Iteration: 181470 | Cost/Loss: 0.074276 | Weight: 0.568897 | Bias: 0.111733\n",
            "Iteration: 181471 | Cost/Loss: 0.074275 | Weight: 0.568897 | Bias: 0.111733\n",
            "Iteration: 181472 | Cost/Loss: 0.074275 | Weight: 0.568897 | Bias: 0.111733\n",
            "Iteration: 181473 | Cost/Loss: 0.074275 | Weight: 0.568898 | Bias: 0.111734\n",
            "Iteration: 181474 | Cost/Loss: 0.074275 | Weight: 0.568898 | Bias: 0.111734\n",
            "Iteration: 181475 | Cost/Loss: 0.074275 | Weight: 0.568898 | Bias: 0.111734\n",
            "Iteration: 181476 | Cost/Loss: 0.074275 | Weight: 0.568898 | Bias: 0.111735\n",
            "Iteration: 181477 | Cost/Loss: 0.074275 | Weight: 0.568899 | Bias: 0.111735\n",
            "Iteration: 181478 | Cost/Loss: 0.074275 | Weight: 0.568899 | Bias: 0.111735\n",
            "Iteration: 181479 | Cost/Loss: 0.074275 | Weight: 0.568899 | Bias: 0.111736\n",
            "Iteration: 181480 | Cost/Loss: 0.074275 | Weight: 0.568900 | Bias: 0.111736\n",
            "Iteration: 181481 | Cost/Loss: 0.074275 | Weight: 0.568900 | Bias: 0.111736\n",
            "Iteration: 181482 | Cost/Loss: 0.074275 | Weight: 0.568900 | Bias: 0.111736\n",
            "Iteration: 181483 | Cost/Loss: 0.074275 | Weight: 0.568901 | Bias: 0.111737\n",
            "Iteration: 181484 | Cost/Loss: 0.074275 | Weight: 0.568901 | Bias: 0.111737\n",
            "Iteration: 181485 | Cost/Loss: 0.074275 | Weight: 0.568901 | Bias: 0.111737\n",
            "Iteration: 181486 | Cost/Loss: 0.074275 | Weight: 0.568901 | Bias: 0.111738\n",
            "Iteration: 181487 | Cost/Loss: 0.074275 | Weight: 0.568902 | Bias: 0.111738\n",
            "Iteration: 181488 | Cost/Loss: 0.074275 | Weight: 0.568902 | Bias: 0.111738\n",
            "Iteration: 181489 | Cost/Loss: 0.074275 | Weight: 0.568902 | Bias: 0.111739\n",
            "Iteration: 181490 | Cost/Loss: 0.074275 | Weight: 0.568903 | Bias: 0.111739\n",
            "Iteration: 181491 | Cost/Loss: 0.074275 | Weight: 0.568903 | Bias: 0.111739\n",
            "Iteration: 181492 | Cost/Loss: 0.074275 | Weight: 0.568903 | Bias: 0.111740\n",
            "Iteration: 181493 | Cost/Loss: 0.074275 | Weight: 0.568904 | Bias: 0.111740\n",
            "Iteration: 181494 | Cost/Loss: 0.074275 | Weight: 0.568904 | Bias: 0.111740\n",
            "Iteration: 181495 | Cost/Loss: 0.074275 | Weight: 0.568904 | Bias: 0.111740\n",
            "Iteration: 181496 | Cost/Loss: 0.074275 | Weight: 0.568904 | Bias: 0.111741\n",
            "Iteration: 181497 | Cost/Loss: 0.074275 | Weight: 0.568905 | Bias: 0.111741\n",
            "Iteration: 181498 | Cost/Loss: 0.074275 | Weight: 0.568905 | Bias: 0.111741\n",
            "Iteration: 181499 | Cost/Loss: 0.074275 | Weight: 0.568905 | Bias: 0.111742\n",
            "Iteration: 181500 | Cost/Loss: 0.074275 | Weight: 0.568906 | Bias: 0.111742\n",
            "Iteration: 181501 | Cost/Loss: 0.074275 | Weight: 0.568906 | Bias: 0.111742\n",
            "Iteration: 181502 | Cost/Loss: 0.074275 | Weight: 0.568906 | Bias: 0.111743\n",
            "Iteration: 181503 | Cost/Loss: 0.074275 | Weight: 0.568906 | Bias: 0.111743\n",
            "Iteration: 181504 | Cost/Loss: 0.074275 | Weight: 0.568907 | Bias: 0.111743\n",
            "Iteration: 181505 | Cost/Loss: 0.074275 | Weight: 0.568907 | Bias: 0.111743\n",
            "Iteration: 181506 | Cost/Loss: 0.074275 | Weight: 0.568907 | Bias: 0.111744\n",
            "Iteration: 181507 | Cost/Loss: 0.074275 | Weight: 0.568908 | Bias: 0.111744\n",
            "Iteration: 181508 | Cost/Loss: 0.074275 | Weight: 0.568908 | Bias: 0.111744\n",
            "Iteration: 181509 | Cost/Loss: 0.074275 | Weight: 0.568908 | Bias: 0.111745\n",
            "Iteration: 181510 | Cost/Loss: 0.074275 | Weight: 0.568909 | Bias: 0.111745\n",
            "Iteration: 181511 | Cost/Loss: 0.074275 | Weight: 0.568909 | Bias: 0.111745\n",
            "Iteration: 181512 | Cost/Loss: 0.074274 | Weight: 0.568909 | Bias: 0.111746\n",
            "Iteration: 181513 | Cost/Loss: 0.074274 | Weight: 0.568909 | Bias: 0.111746\n",
            "Iteration: 181514 | Cost/Loss: 0.074274 | Weight: 0.568910 | Bias: 0.111746\n",
            "Iteration: 181515 | Cost/Loss: 0.074274 | Weight: 0.568910 | Bias: 0.111747\n",
            "Iteration: 181516 | Cost/Loss: 0.074274 | Weight: 0.568910 | Bias: 0.111747\n",
            "Iteration: 181517 | Cost/Loss: 0.074274 | Weight: 0.568911 | Bias: 0.111747\n",
            "Iteration: 181518 | Cost/Loss: 0.074274 | Weight: 0.568911 | Bias: 0.111747\n",
            "Iteration: 181519 | Cost/Loss: 0.074274 | Weight: 0.568911 | Bias: 0.111748\n",
            "Iteration: 181520 | Cost/Loss: 0.074274 | Weight: 0.568912 | Bias: 0.111748\n",
            "Iteration: 181521 | Cost/Loss: 0.074274 | Weight: 0.568912 | Bias: 0.111748\n",
            "Iteration: 181522 | Cost/Loss: 0.074274 | Weight: 0.568912 | Bias: 0.111749\n",
            "Iteration: 181523 | Cost/Loss: 0.074274 | Weight: 0.568912 | Bias: 0.111749\n",
            "Iteration: 181524 | Cost/Loss: 0.074274 | Weight: 0.568913 | Bias: 0.111749\n",
            "Iteration: 181525 | Cost/Loss: 0.074274 | Weight: 0.568913 | Bias: 0.111750\n",
            "Iteration: 181526 | Cost/Loss: 0.074274 | Weight: 0.568913 | Bias: 0.111750\n",
            "Iteration: 181527 | Cost/Loss: 0.074274 | Weight: 0.568914 | Bias: 0.111750\n",
            "Iteration: 181528 | Cost/Loss: 0.074274 | Weight: 0.568914 | Bias: 0.111751\n",
            "Iteration: 181529 | Cost/Loss: 0.074274 | Weight: 0.568914 | Bias: 0.111751\n",
            "Iteration: 181530 | Cost/Loss: 0.074274 | Weight: 0.568915 | Bias: 0.111751\n",
            "Iteration: 181531 | Cost/Loss: 0.074274 | Weight: 0.568915 | Bias: 0.111751\n",
            "Iteration: 181532 | Cost/Loss: 0.074274 | Weight: 0.568915 | Bias: 0.111752\n",
            "Iteration: 181533 | Cost/Loss: 0.074274 | Weight: 0.568915 | Bias: 0.111752\n",
            "Iteration: 181534 | Cost/Loss: 0.074274 | Weight: 0.568916 | Bias: 0.111752\n",
            "Iteration: 181535 | Cost/Loss: 0.074274 | Weight: 0.568916 | Bias: 0.111753\n",
            "Iteration: 181536 | Cost/Loss: 0.074274 | Weight: 0.568916 | Bias: 0.111753\n",
            "Iteration: 181537 | Cost/Loss: 0.074274 | Weight: 0.568917 | Bias: 0.111753\n",
            "Iteration: 181538 | Cost/Loss: 0.074274 | Weight: 0.568917 | Bias: 0.111754\n",
            "Iteration: 181539 | Cost/Loss: 0.074274 | Weight: 0.568917 | Bias: 0.111754\n",
            "Iteration: 181540 | Cost/Loss: 0.074274 | Weight: 0.568918 | Bias: 0.111754\n",
            "Iteration: 181541 | Cost/Loss: 0.074274 | Weight: 0.568918 | Bias: 0.111754\n",
            "Iteration: 181542 | Cost/Loss: 0.074274 | Weight: 0.568918 | Bias: 0.111755\n",
            "Iteration: 181543 | Cost/Loss: 0.074274 | Weight: 0.568918 | Bias: 0.111755\n",
            "Iteration: 181544 | Cost/Loss: 0.074274 | Weight: 0.568919 | Bias: 0.111755\n",
            "Iteration: 181545 | Cost/Loss: 0.074274 | Weight: 0.568919 | Bias: 0.111756\n",
            "Iteration: 181546 | Cost/Loss: 0.074274 | Weight: 0.568919 | Bias: 0.111756\n",
            "Iteration: 181547 | Cost/Loss: 0.074274 | Weight: 0.568920 | Bias: 0.111756\n",
            "Iteration: 181548 | Cost/Loss: 0.074274 | Weight: 0.568920 | Bias: 0.111757\n",
            "Iteration: 181549 | Cost/Loss: 0.074274 | Weight: 0.568920 | Bias: 0.111757\n",
            "Iteration: 181550 | Cost/Loss: 0.074274 | Weight: 0.568920 | Bias: 0.111757\n",
            "Iteration: 181551 | Cost/Loss: 0.074274 | Weight: 0.568921 | Bias: 0.111758\n",
            "Iteration: 181552 | Cost/Loss: 0.074273 | Weight: 0.568921 | Bias: 0.111758\n",
            "Iteration: 181553 | Cost/Loss: 0.074273 | Weight: 0.568921 | Bias: 0.111758\n",
            "Iteration: 181554 | Cost/Loss: 0.074273 | Weight: 0.568922 | Bias: 0.111758\n",
            "Iteration: 181555 | Cost/Loss: 0.074273 | Weight: 0.568922 | Bias: 0.111759\n",
            "Iteration: 181556 | Cost/Loss: 0.074273 | Weight: 0.568922 | Bias: 0.111759\n",
            "Iteration: 181557 | Cost/Loss: 0.074273 | Weight: 0.568923 | Bias: 0.111759\n",
            "Iteration: 181558 | Cost/Loss: 0.074273 | Weight: 0.568923 | Bias: 0.111760\n",
            "Iteration: 181559 | Cost/Loss: 0.074273 | Weight: 0.568923 | Bias: 0.111760\n",
            "Iteration: 181560 | Cost/Loss: 0.074273 | Weight: 0.568923 | Bias: 0.111760\n",
            "Iteration: 181561 | Cost/Loss: 0.074273 | Weight: 0.568924 | Bias: 0.111761\n",
            "Iteration: 181562 | Cost/Loss: 0.074273 | Weight: 0.568924 | Bias: 0.111761\n",
            "Iteration: 181563 | Cost/Loss: 0.074273 | Weight: 0.568924 | Bias: 0.111761\n",
            "Iteration: 181564 | Cost/Loss: 0.074273 | Weight: 0.568925 | Bias: 0.111762\n",
            "Iteration: 181565 | Cost/Loss: 0.074273 | Weight: 0.568925 | Bias: 0.111762\n",
            "Iteration: 181566 | Cost/Loss: 0.074273 | Weight: 0.568925 | Bias: 0.111762\n",
            "Iteration: 181567 | Cost/Loss: 0.074273 | Weight: 0.568926 | Bias: 0.111762\n",
            "Iteration: 181568 | Cost/Loss: 0.074273 | Weight: 0.568926 | Bias: 0.111763\n",
            "Iteration: 181569 | Cost/Loss: 0.074273 | Weight: 0.568926 | Bias: 0.111763\n",
            "Iteration: 181570 | Cost/Loss: 0.074273 | Weight: 0.568926 | Bias: 0.111763\n",
            "Iteration: 181571 | Cost/Loss: 0.074273 | Weight: 0.568927 | Bias: 0.111764\n",
            "Iteration: 181572 | Cost/Loss: 0.074273 | Weight: 0.568927 | Bias: 0.111764\n",
            "Iteration: 181573 | Cost/Loss: 0.074273 | Weight: 0.568927 | Bias: 0.111764\n",
            "Iteration: 181574 | Cost/Loss: 0.074273 | Weight: 0.568928 | Bias: 0.111765\n",
            "Iteration: 181575 | Cost/Loss: 0.074273 | Weight: 0.568928 | Bias: 0.111765\n",
            "Iteration: 181576 | Cost/Loss: 0.074273 | Weight: 0.568928 | Bias: 0.111765\n",
            "Iteration: 181577 | Cost/Loss: 0.074273 | Weight: 0.568929 | Bias: 0.111765\n",
            "Iteration: 181578 | Cost/Loss: 0.074273 | Weight: 0.568929 | Bias: 0.111766\n",
            "Iteration: 181579 | Cost/Loss: 0.074273 | Weight: 0.568929 | Bias: 0.111766\n",
            "Iteration: 181580 | Cost/Loss: 0.074273 | Weight: 0.568929 | Bias: 0.111766\n",
            "Iteration: 181581 | Cost/Loss: 0.074273 | Weight: 0.568930 | Bias: 0.111767\n",
            "Iteration: 181582 | Cost/Loss: 0.074273 | Weight: 0.568930 | Bias: 0.111767\n",
            "Iteration: 181583 | Cost/Loss: 0.074273 | Weight: 0.568930 | Bias: 0.111767\n",
            "Iteration: 181584 | Cost/Loss: 0.074273 | Weight: 0.568931 | Bias: 0.111768\n",
            "Iteration: 181585 | Cost/Loss: 0.074273 | Weight: 0.568931 | Bias: 0.111768\n",
            "Iteration: 181586 | Cost/Loss: 0.074273 | Weight: 0.568931 | Bias: 0.111768\n",
            "Iteration: 181587 | Cost/Loss: 0.074273 | Weight: 0.568932 | Bias: 0.111769\n",
            "Iteration: 181588 | Cost/Loss: 0.074273 | Weight: 0.568932 | Bias: 0.111769\n",
            "Iteration: 181589 | Cost/Loss: 0.074273 | Weight: 0.568932 | Bias: 0.111769\n",
            "Iteration: 181590 | Cost/Loss: 0.074273 | Weight: 0.568932 | Bias: 0.111769\n",
            "Iteration: 181591 | Cost/Loss: 0.074273 | Weight: 0.568933 | Bias: 0.111770\n",
            "Iteration: 181592 | Cost/Loss: 0.074273 | Weight: 0.568933 | Bias: 0.111770\n",
            "Iteration: 181593 | Cost/Loss: 0.074272 | Weight: 0.568933 | Bias: 0.111770\n",
            "Iteration: 181594 | Cost/Loss: 0.074272 | Weight: 0.568934 | Bias: 0.111771\n",
            "Iteration: 181595 | Cost/Loss: 0.074272 | Weight: 0.568934 | Bias: 0.111771\n",
            "Iteration: 181596 | Cost/Loss: 0.074272 | Weight: 0.568934 | Bias: 0.111771\n",
            "Iteration: 181597 | Cost/Loss: 0.074272 | Weight: 0.568935 | Bias: 0.111772\n",
            "Iteration: 181598 | Cost/Loss: 0.074272 | Weight: 0.568935 | Bias: 0.111772\n",
            "Iteration: 181599 | Cost/Loss: 0.074272 | Weight: 0.568935 | Bias: 0.111772\n",
            "Iteration: 181600 | Cost/Loss: 0.074272 | Weight: 0.568935 | Bias: 0.111773\n",
            "Iteration: 181601 | Cost/Loss: 0.074272 | Weight: 0.568936 | Bias: 0.111773\n",
            "Iteration: 181602 | Cost/Loss: 0.074272 | Weight: 0.568936 | Bias: 0.111773\n",
            "Iteration: 181603 | Cost/Loss: 0.074272 | Weight: 0.568936 | Bias: 0.111773\n",
            "Iteration: 181604 | Cost/Loss: 0.074272 | Weight: 0.568937 | Bias: 0.111774\n",
            "Iteration: 181605 | Cost/Loss: 0.074272 | Weight: 0.568937 | Bias: 0.111774\n",
            "Iteration: 181606 | Cost/Loss: 0.074272 | Weight: 0.568937 | Bias: 0.111774\n",
            "Iteration: 181607 | Cost/Loss: 0.074272 | Weight: 0.568937 | Bias: 0.111775\n",
            "Iteration: 181608 | Cost/Loss: 0.074272 | Weight: 0.568938 | Bias: 0.111775\n",
            "Iteration: 181609 | Cost/Loss: 0.074272 | Weight: 0.568938 | Bias: 0.111775\n",
            "Iteration: 181610 | Cost/Loss: 0.074272 | Weight: 0.568938 | Bias: 0.111776\n",
            "Iteration: 181611 | Cost/Loss: 0.074272 | Weight: 0.568939 | Bias: 0.111776\n",
            "Iteration: 181612 | Cost/Loss: 0.074272 | Weight: 0.568939 | Bias: 0.111776\n",
            "Iteration: 181613 | Cost/Loss: 0.074272 | Weight: 0.568939 | Bias: 0.111776\n",
            "Iteration: 181614 | Cost/Loss: 0.074272 | Weight: 0.568940 | Bias: 0.111777\n",
            "Iteration: 181615 | Cost/Loss: 0.074272 | Weight: 0.568940 | Bias: 0.111777\n",
            "Iteration: 181616 | Cost/Loss: 0.074272 | Weight: 0.568940 | Bias: 0.111777\n",
            "Iteration: 181617 | Cost/Loss: 0.074272 | Weight: 0.568940 | Bias: 0.111778\n",
            "Iteration: 181618 | Cost/Loss: 0.074272 | Weight: 0.568941 | Bias: 0.111778\n",
            "Iteration: 181619 | Cost/Loss: 0.074272 | Weight: 0.568941 | Bias: 0.111778\n",
            "Iteration: 181620 | Cost/Loss: 0.074272 | Weight: 0.568941 | Bias: 0.111779\n",
            "Iteration: 181621 | Cost/Loss: 0.074272 | Weight: 0.568942 | Bias: 0.111779\n",
            "Iteration: 181622 | Cost/Loss: 0.074272 | Weight: 0.568942 | Bias: 0.111779\n",
            "Iteration: 181623 | Cost/Loss: 0.074272 | Weight: 0.568942 | Bias: 0.111780\n",
            "Iteration: 181624 | Cost/Loss: 0.074272 | Weight: 0.568943 | Bias: 0.111780\n",
            "Iteration: 181625 | Cost/Loss: 0.074272 | Weight: 0.568943 | Bias: 0.111780\n",
            "Iteration: 181626 | Cost/Loss: 0.074272 | Weight: 0.568943 | Bias: 0.111780\n",
            "Iteration: 181627 | Cost/Loss: 0.074272 | Weight: 0.568943 | Bias: 0.111781\n",
            "Iteration: 181628 | Cost/Loss: 0.074272 | Weight: 0.568944 | Bias: 0.111781\n",
            "Iteration: 181629 | Cost/Loss: 0.074272 | Weight: 0.568944 | Bias: 0.111781\n",
            "Iteration: 181630 | Cost/Loss: 0.074272 | Weight: 0.568944 | Bias: 0.111782\n",
            "Iteration: 181631 | Cost/Loss: 0.074272 | Weight: 0.568945 | Bias: 0.111782\n",
            "Iteration: 181632 | Cost/Loss: 0.074272 | Weight: 0.568945 | Bias: 0.111782\n",
            "Iteration: 181633 | Cost/Loss: 0.074272 | Weight: 0.568945 | Bias: 0.111783\n",
            "Iteration: 181634 | Cost/Loss: 0.074271 | Weight: 0.568946 | Bias: 0.111783\n",
            "Iteration: 181635 | Cost/Loss: 0.074271 | Weight: 0.568946 | Bias: 0.111783\n",
            "Iteration: 181636 | Cost/Loss: 0.074271 | Weight: 0.568946 | Bias: 0.111784\n",
            "Iteration: 181637 | Cost/Loss: 0.074271 | Weight: 0.568946 | Bias: 0.111784\n",
            "Iteration: 181638 | Cost/Loss: 0.074271 | Weight: 0.568947 | Bias: 0.111784\n",
            "Iteration: 181639 | Cost/Loss: 0.074271 | Weight: 0.568947 | Bias: 0.111784\n",
            "Iteration: 181640 | Cost/Loss: 0.074271 | Weight: 0.568947 | Bias: 0.111785\n",
            "Iteration: 181641 | Cost/Loss: 0.074271 | Weight: 0.568948 | Bias: 0.111785\n",
            "Iteration: 181642 | Cost/Loss: 0.074271 | Weight: 0.568948 | Bias: 0.111785\n",
            "Iteration: 181643 | Cost/Loss: 0.074271 | Weight: 0.568948 | Bias: 0.111786\n",
            "Iteration: 181644 | Cost/Loss: 0.074271 | Weight: 0.568949 | Bias: 0.111786\n",
            "Iteration: 181645 | Cost/Loss: 0.074271 | Weight: 0.568949 | Bias: 0.111786\n",
            "Iteration: 181646 | Cost/Loss: 0.074271 | Weight: 0.568949 | Bias: 0.111787\n",
            "Iteration: 181647 | Cost/Loss: 0.074271 | Weight: 0.568949 | Bias: 0.111787\n",
            "Iteration: 181648 | Cost/Loss: 0.074271 | Weight: 0.568950 | Bias: 0.111787\n",
            "Iteration: 181649 | Cost/Loss: 0.074271 | Weight: 0.568950 | Bias: 0.111787\n",
            "Iteration: 181650 | Cost/Loss: 0.074271 | Weight: 0.568950 | Bias: 0.111788\n",
            "Iteration: 181651 | Cost/Loss: 0.074271 | Weight: 0.568951 | Bias: 0.111788\n",
            "Iteration: 181652 | Cost/Loss: 0.074271 | Weight: 0.568951 | Bias: 0.111788\n",
            "Iteration: 181653 | Cost/Loss: 0.074271 | Weight: 0.568951 | Bias: 0.111789\n",
            "Iteration: 181654 | Cost/Loss: 0.074271 | Weight: 0.568951 | Bias: 0.111789\n",
            "Iteration: 181655 | Cost/Loss: 0.074271 | Weight: 0.568952 | Bias: 0.111789\n",
            "Iteration: 181656 | Cost/Loss: 0.074271 | Weight: 0.568952 | Bias: 0.111790\n",
            "Iteration: 181657 | Cost/Loss: 0.074271 | Weight: 0.568952 | Bias: 0.111790\n",
            "Iteration: 181658 | Cost/Loss: 0.074271 | Weight: 0.568953 | Bias: 0.111790\n",
            "Iteration: 181659 | Cost/Loss: 0.074271 | Weight: 0.568953 | Bias: 0.111791\n",
            "Iteration: 181660 | Cost/Loss: 0.074271 | Weight: 0.568953 | Bias: 0.111791\n",
            "Iteration: 181661 | Cost/Loss: 0.074271 | Weight: 0.568954 | Bias: 0.111791\n",
            "Iteration: 181662 | Cost/Loss: 0.074271 | Weight: 0.568954 | Bias: 0.111791\n",
            "Iteration: 181663 | Cost/Loss: 0.074271 | Weight: 0.568954 | Bias: 0.111792\n",
            "Iteration: 181664 | Cost/Loss: 0.074271 | Weight: 0.568954 | Bias: 0.111792\n",
            "Iteration: 181665 | Cost/Loss: 0.074271 | Weight: 0.568955 | Bias: 0.111792\n",
            "Iteration: 181666 | Cost/Loss: 0.074271 | Weight: 0.568955 | Bias: 0.111793\n",
            "Iteration: 181667 | Cost/Loss: 0.074271 | Weight: 0.568955 | Bias: 0.111793\n",
            "Iteration: 181668 | Cost/Loss: 0.074271 | Weight: 0.568956 | Bias: 0.111793\n",
            "Iteration: 181669 | Cost/Loss: 0.074271 | Weight: 0.568956 | Bias: 0.111794\n",
            "Iteration: 181670 | Cost/Loss: 0.074271 | Weight: 0.568956 | Bias: 0.111794\n",
            "Iteration: 181671 | Cost/Loss: 0.074271 | Weight: 0.568957 | Bias: 0.111794\n",
            "Iteration: 181672 | Cost/Loss: 0.074271 | Weight: 0.568957 | Bias: 0.111795\n",
            "Iteration: 181673 | Cost/Loss: 0.074271 | Weight: 0.568957 | Bias: 0.111795\n",
            "Iteration: 181674 | Cost/Loss: 0.074270 | Weight: 0.568957 | Bias: 0.111795\n",
            "Iteration: 181675 | Cost/Loss: 0.074270 | Weight: 0.568958 | Bias: 0.111795\n",
            "Iteration: 181676 | Cost/Loss: 0.074270 | Weight: 0.568958 | Bias: 0.111796\n",
            "Iteration: 181677 | Cost/Loss: 0.074270 | Weight: 0.568958 | Bias: 0.111796\n",
            "Iteration: 181678 | Cost/Loss: 0.074270 | Weight: 0.568959 | Bias: 0.111796\n",
            "Iteration: 181679 | Cost/Loss: 0.074270 | Weight: 0.568959 | Bias: 0.111797\n",
            "Iteration: 181680 | Cost/Loss: 0.074270 | Weight: 0.568959 | Bias: 0.111797\n",
            "Iteration: 181681 | Cost/Loss: 0.074270 | Weight: 0.568960 | Bias: 0.111797\n",
            "Iteration: 181682 | Cost/Loss: 0.074270 | Weight: 0.568960 | Bias: 0.111798\n",
            "Iteration: 181683 | Cost/Loss: 0.074270 | Weight: 0.568960 | Bias: 0.111798\n",
            "Iteration: 181684 | Cost/Loss: 0.074270 | Weight: 0.568960 | Bias: 0.111798\n",
            "Iteration: 181685 | Cost/Loss: 0.074270 | Weight: 0.568961 | Bias: 0.111798\n",
            "Iteration: 181686 | Cost/Loss: 0.074270 | Weight: 0.568961 | Bias: 0.111799\n",
            "Iteration: 181687 | Cost/Loss: 0.074270 | Weight: 0.568961 | Bias: 0.111799\n",
            "Iteration: 181688 | Cost/Loss: 0.074270 | Weight: 0.568962 | Bias: 0.111799\n",
            "Iteration: 181689 | Cost/Loss: 0.074270 | Weight: 0.568962 | Bias: 0.111800\n",
            "Iteration: 181690 | Cost/Loss: 0.074270 | Weight: 0.568962 | Bias: 0.111800\n",
            "Iteration: 181691 | Cost/Loss: 0.074270 | Weight: 0.568963 | Bias: 0.111800\n",
            "Iteration: 181692 | Cost/Loss: 0.074270 | Weight: 0.568963 | Bias: 0.111801\n",
            "Iteration: 181693 | Cost/Loss: 0.074270 | Weight: 0.568963 | Bias: 0.111801\n",
            "Iteration: 181694 | Cost/Loss: 0.074270 | Weight: 0.568963 | Bias: 0.111801\n",
            "Iteration: 181695 | Cost/Loss: 0.074270 | Weight: 0.568964 | Bias: 0.111802\n",
            "Iteration: 181696 | Cost/Loss: 0.074270 | Weight: 0.568964 | Bias: 0.111802\n",
            "Iteration: 181697 | Cost/Loss: 0.074270 | Weight: 0.568964 | Bias: 0.111802\n",
            "Iteration: 181698 | Cost/Loss: 0.074270 | Weight: 0.568965 | Bias: 0.111802\n",
            "Iteration: 181699 | Cost/Loss: 0.074270 | Weight: 0.568965 | Bias: 0.111803\n",
            "Iteration: 181700 | Cost/Loss: 0.074270 | Weight: 0.568965 | Bias: 0.111803\n",
            "Iteration: 181701 | Cost/Loss: 0.074270 | Weight: 0.568965 | Bias: 0.111803\n",
            "Iteration: 181702 | Cost/Loss: 0.074270 | Weight: 0.568966 | Bias: 0.111804\n",
            "Iteration: 181703 | Cost/Loss: 0.074270 | Weight: 0.568966 | Bias: 0.111804\n",
            "Iteration: 181704 | Cost/Loss: 0.074270 | Weight: 0.568966 | Bias: 0.111804\n",
            "Iteration: 181705 | Cost/Loss: 0.074270 | Weight: 0.568967 | Bias: 0.111805\n",
            "Iteration: 181706 | Cost/Loss: 0.074270 | Weight: 0.568967 | Bias: 0.111805\n",
            "Iteration: 181707 | Cost/Loss: 0.074270 | Weight: 0.568967 | Bias: 0.111805\n",
            "Iteration: 181708 | Cost/Loss: 0.074270 | Weight: 0.568968 | Bias: 0.111805\n",
            "Iteration: 181709 | Cost/Loss: 0.074270 | Weight: 0.568968 | Bias: 0.111806\n",
            "Iteration: 181710 | Cost/Loss: 0.074270 | Weight: 0.568968 | Bias: 0.111806\n",
            "Iteration: 181711 | Cost/Loss: 0.074270 | Weight: 0.568968 | Bias: 0.111806\n",
            "Iteration: 181712 | Cost/Loss: 0.074270 | Weight: 0.568969 | Bias: 0.111807\n",
            "Iteration: 181713 | Cost/Loss: 0.074270 | Weight: 0.568969 | Bias: 0.111807\n",
            "Iteration: 181714 | Cost/Loss: 0.074270 | Weight: 0.568969 | Bias: 0.111807\n",
            "Iteration: 181715 | Cost/Loss: 0.074269 | Weight: 0.568970 | Bias: 0.111808\n",
            "Iteration: 181716 | Cost/Loss: 0.074269 | Weight: 0.568970 | Bias: 0.111808\n",
            "Iteration: 181717 | Cost/Loss: 0.074269 | Weight: 0.568970 | Bias: 0.111808\n",
            "Iteration: 181718 | Cost/Loss: 0.074269 | Weight: 0.568971 | Bias: 0.111809\n",
            "Iteration: 181719 | Cost/Loss: 0.074269 | Weight: 0.568971 | Bias: 0.111809\n",
            "Iteration: 181720 | Cost/Loss: 0.074269 | Weight: 0.568971 | Bias: 0.111809\n",
            "Iteration: 181721 | Cost/Loss: 0.074269 | Weight: 0.568971 | Bias: 0.111809\n",
            "Iteration: 181722 | Cost/Loss: 0.074269 | Weight: 0.568972 | Bias: 0.111810\n",
            "Iteration: 181723 | Cost/Loss: 0.074269 | Weight: 0.568972 | Bias: 0.111810\n",
            "Iteration: 181724 | Cost/Loss: 0.074269 | Weight: 0.568972 | Bias: 0.111810\n",
            "Iteration: 181725 | Cost/Loss: 0.074269 | Weight: 0.568973 | Bias: 0.111811\n",
            "Iteration: 181726 | Cost/Loss: 0.074269 | Weight: 0.568973 | Bias: 0.111811\n",
            "Iteration: 181727 | Cost/Loss: 0.074269 | Weight: 0.568973 | Bias: 0.111811\n",
            "Iteration: 181728 | Cost/Loss: 0.074269 | Weight: 0.568974 | Bias: 0.111812\n",
            "Iteration: 181729 | Cost/Loss: 0.074269 | Weight: 0.568974 | Bias: 0.111812\n",
            "Iteration: 181730 | Cost/Loss: 0.074269 | Weight: 0.568974 | Bias: 0.111812\n",
            "Iteration: 181731 | Cost/Loss: 0.074269 | Weight: 0.568974 | Bias: 0.111813\n",
            "Iteration: 181732 | Cost/Loss: 0.074269 | Weight: 0.568975 | Bias: 0.111813\n",
            "Iteration: 181733 | Cost/Loss: 0.074269 | Weight: 0.568975 | Bias: 0.111813\n",
            "Iteration: 181734 | Cost/Loss: 0.074269 | Weight: 0.568975 | Bias: 0.111813\n",
            "Iteration: 181735 | Cost/Loss: 0.074269 | Weight: 0.568976 | Bias: 0.111814\n",
            "Iteration: 181736 | Cost/Loss: 0.074269 | Weight: 0.568976 | Bias: 0.111814\n",
            "Iteration: 181737 | Cost/Loss: 0.074269 | Weight: 0.568976 | Bias: 0.111814\n",
            "Iteration: 181738 | Cost/Loss: 0.074269 | Weight: 0.568977 | Bias: 0.111815\n",
            "Iteration: 181739 | Cost/Loss: 0.074269 | Weight: 0.568977 | Bias: 0.111815\n",
            "Iteration: 181740 | Cost/Loss: 0.074269 | Weight: 0.568977 | Bias: 0.111815\n",
            "Iteration: 181741 | Cost/Loss: 0.074269 | Weight: 0.568977 | Bias: 0.111816\n",
            "Iteration: 181742 | Cost/Loss: 0.074269 | Weight: 0.568978 | Bias: 0.111816\n",
            "Iteration: 181743 | Cost/Loss: 0.074269 | Weight: 0.568978 | Bias: 0.111816\n",
            "Iteration: 181744 | Cost/Loss: 0.074269 | Weight: 0.568978 | Bias: 0.111816\n",
            "Iteration: 181745 | Cost/Loss: 0.074269 | Weight: 0.568979 | Bias: 0.111817\n",
            "Iteration: 181746 | Cost/Loss: 0.074269 | Weight: 0.568979 | Bias: 0.111817\n",
            "Iteration: 181747 | Cost/Loss: 0.074269 | Weight: 0.568979 | Bias: 0.111817\n",
            "Iteration: 181748 | Cost/Loss: 0.074269 | Weight: 0.568980 | Bias: 0.111818\n",
            "Iteration: 181749 | Cost/Loss: 0.074269 | Weight: 0.568980 | Bias: 0.111818\n",
            "Iteration: 181750 | Cost/Loss: 0.074269 | Weight: 0.568980 | Bias: 0.111818\n",
            "Iteration: 181751 | Cost/Loss: 0.074269 | Weight: 0.568980 | Bias: 0.111819\n",
            "Iteration: 181752 | Cost/Loss: 0.074269 | Weight: 0.568981 | Bias: 0.111819\n",
            "Iteration: 181753 | Cost/Loss: 0.074269 | Weight: 0.568981 | Bias: 0.111819\n",
            "Iteration: 181754 | Cost/Loss: 0.074269 | Weight: 0.568981 | Bias: 0.111820\n",
            "Iteration: 181755 | Cost/Loss: 0.074268 | Weight: 0.568982 | Bias: 0.111820\n",
            "Iteration: 181756 | Cost/Loss: 0.074268 | Weight: 0.568982 | Bias: 0.111820\n",
            "Iteration: 181757 | Cost/Loss: 0.074268 | Weight: 0.568982 | Bias: 0.111820\n",
            "Iteration: 181758 | Cost/Loss: 0.074268 | Weight: 0.568982 | Bias: 0.111821\n",
            "Iteration: 181759 | Cost/Loss: 0.074268 | Weight: 0.568983 | Bias: 0.111821\n",
            "Iteration: 181760 | Cost/Loss: 0.074268 | Weight: 0.568983 | Bias: 0.111821\n",
            "Iteration: 181761 | Cost/Loss: 0.074268 | Weight: 0.568983 | Bias: 0.111822\n",
            "Iteration: 181762 | Cost/Loss: 0.074268 | Weight: 0.568984 | Bias: 0.111822\n",
            "Iteration: 181763 | Cost/Loss: 0.074268 | Weight: 0.568984 | Bias: 0.111822\n",
            "Iteration: 181764 | Cost/Loss: 0.074268 | Weight: 0.568984 | Bias: 0.111823\n",
            "Iteration: 181765 | Cost/Loss: 0.074268 | Weight: 0.568985 | Bias: 0.111823\n",
            "Iteration: 181766 | Cost/Loss: 0.074268 | Weight: 0.568985 | Bias: 0.111823\n",
            "Iteration: 181767 | Cost/Loss: 0.074268 | Weight: 0.568985 | Bias: 0.111824\n",
            "Iteration: 181768 | Cost/Loss: 0.074268 | Weight: 0.568985 | Bias: 0.111824\n",
            "Iteration: 181769 | Cost/Loss: 0.074268 | Weight: 0.568986 | Bias: 0.111824\n",
            "Iteration: 181770 | Cost/Loss: 0.074268 | Weight: 0.568986 | Bias: 0.111824\n",
            "Iteration: 181771 | Cost/Loss: 0.074268 | Weight: 0.568986 | Bias: 0.111825\n",
            "Iteration: 181772 | Cost/Loss: 0.074268 | Weight: 0.568987 | Bias: 0.111825\n",
            "Iteration: 181773 | Cost/Loss: 0.074268 | Weight: 0.568987 | Bias: 0.111825\n",
            "Iteration: 181774 | Cost/Loss: 0.074268 | Weight: 0.568987 | Bias: 0.111826\n",
            "Iteration: 181775 | Cost/Loss: 0.074268 | Weight: 0.568988 | Bias: 0.111826\n",
            "Iteration: 181776 | Cost/Loss: 0.074268 | Weight: 0.568988 | Bias: 0.111826\n",
            "Iteration: 181777 | Cost/Loss: 0.074268 | Weight: 0.568988 | Bias: 0.111827\n",
            "Iteration: 181778 | Cost/Loss: 0.074268 | Weight: 0.568988 | Bias: 0.111827\n",
            "Iteration: 181779 | Cost/Loss: 0.074268 | Weight: 0.568989 | Bias: 0.111827\n",
            "Iteration: 181780 | Cost/Loss: 0.074268 | Weight: 0.568989 | Bias: 0.111827\n",
            "Iteration: 181781 | Cost/Loss: 0.074268 | Weight: 0.568989 | Bias: 0.111828\n",
            "Iteration: 181782 | Cost/Loss: 0.074268 | Weight: 0.568990 | Bias: 0.111828\n",
            "Iteration: 181783 | Cost/Loss: 0.074268 | Weight: 0.568990 | Bias: 0.111828\n",
            "Iteration: 181784 | Cost/Loss: 0.074268 | Weight: 0.568990 | Bias: 0.111829\n",
            "Iteration: 181785 | Cost/Loss: 0.074268 | Weight: 0.568991 | Bias: 0.111829\n",
            "Iteration: 181786 | Cost/Loss: 0.074268 | Weight: 0.568991 | Bias: 0.111829\n",
            "Iteration: 181787 | Cost/Loss: 0.074268 | Weight: 0.568991 | Bias: 0.111830\n",
            "Iteration: 181788 | Cost/Loss: 0.074268 | Weight: 0.568991 | Bias: 0.111830\n",
            "Iteration: 181789 | Cost/Loss: 0.074268 | Weight: 0.568992 | Bias: 0.111830\n",
            "Iteration: 181790 | Cost/Loss: 0.074268 | Weight: 0.568992 | Bias: 0.111831\n",
            "Iteration: 181791 | Cost/Loss: 0.074268 | Weight: 0.568992 | Bias: 0.111831\n",
            "Iteration: 181792 | Cost/Loss: 0.074268 | Weight: 0.568993 | Bias: 0.111831\n",
            "Iteration: 181793 | Cost/Loss: 0.074268 | Weight: 0.568993 | Bias: 0.111831\n",
            "Iteration: 181794 | Cost/Loss: 0.074268 | Weight: 0.568993 | Bias: 0.111832\n",
            "Iteration: 181795 | Cost/Loss: 0.074268 | Weight: 0.568994 | Bias: 0.111832\n",
            "Iteration: 181796 | Cost/Loss: 0.074267 | Weight: 0.568994 | Bias: 0.111832\n",
            "Iteration: 181797 | Cost/Loss: 0.074267 | Weight: 0.568994 | Bias: 0.111833\n",
            "Iteration: 181798 | Cost/Loss: 0.074267 | Weight: 0.568994 | Bias: 0.111833\n",
            "Iteration: 181799 | Cost/Loss: 0.074267 | Weight: 0.568995 | Bias: 0.111833\n",
            "Iteration: 181800 | Cost/Loss: 0.074267 | Weight: 0.568995 | Bias: 0.111834\n",
            "Iteration: 181801 | Cost/Loss: 0.074267 | Weight: 0.568995 | Bias: 0.111834\n",
            "Iteration: 181802 | Cost/Loss: 0.074267 | Weight: 0.568996 | Bias: 0.111834\n",
            "Iteration: 181803 | Cost/Loss: 0.074267 | Weight: 0.568996 | Bias: 0.111835\n",
            "Iteration: 181804 | Cost/Loss: 0.074267 | Weight: 0.568996 | Bias: 0.111835\n",
            "Iteration: 181805 | Cost/Loss: 0.074267 | Weight: 0.568996 | Bias: 0.111835\n",
            "Iteration: 181806 | Cost/Loss: 0.074267 | Weight: 0.568997 | Bias: 0.111835\n",
            "Iteration: 181807 | Cost/Loss: 0.074267 | Weight: 0.568997 | Bias: 0.111836\n",
            "Iteration: 181808 | Cost/Loss: 0.074267 | Weight: 0.568997 | Bias: 0.111836\n",
            "Iteration: 181809 | Cost/Loss: 0.074267 | Weight: 0.568998 | Bias: 0.111836\n",
            "Iteration: 181810 | Cost/Loss: 0.074267 | Weight: 0.568998 | Bias: 0.111837\n",
            "Iteration: 181811 | Cost/Loss: 0.074267 | Weight: 0.568998 | Bias: 0.111837\n",
            "Iteration: 181812 | Cost/Loss: 0.074267 | Weight: 0.568999 | Bias: 0.111837\n",
            "Iteration: 181813 | Cost/Loss: 0.074267 | Weight: 0.568999 | Bias: 0.111838\n",
            "Iteration: 181814 | Cost/Loss: 0.074267 | Weight: 0.568999 | Bias: 0.111838\n",
            "Iteration: 181815 | Cost/Loss: 0.074267 | Weight: 0.568999 | Bias: 0.111838\n",
            "Iteration: 181816 | Cost/Loss: 0.074267 | Weight: 0.569000 | Bias: 0.111838\n",
            "Iteration: 181817 | Cost/Loss: 0.074267 | Weight: 0.569000 | Bias: 0.111839\n",
            "Iteration: 181818 | Cost/Loss: 0.074267 | Weight: 0.569000 | Bias: 0.111839\n",
            "Iteration: 181819 | Cost/Loss: 0.074267 | Weight: 0.569001 | Bias: 0.111839\n",
            "Iteration: 181820 | Cost/Loss: 0.074267 | Weight: 0.569001 | Bias: 0.111840\n",
            "Iteration: 181821 | Cost/Loss: 0.074267 | Weight: 0.569001 | Bias: 0.111840\n",
            "Iteration: 181822 | Cost/Loss: 0.074267 | Weight: 0.569002 | Bias: 0.111840\n",
            "Iteration: 181823 | Cost/Loss: 0.074267 | Weight: 0.569002 | Bias: 0.111841\n",
            "Iteration: 181824 | Cost/Loss: 0.074267 | Weight: 0.569002 | Bias: 0.111841\n",
            "Iteration: 181825 | Cost/Loss: 0.074267 | Weight: 0.569002 | Bias: 0.111841\n",
            "Iteration: 181826 | Cost/Loss: 0.074267 | Weight: 0.569003 | Bias: 0.111842\n",
            "Iteration: 181827 | Cost/Loss: 0.074267 | Weight: 0.569003 | Bias: 0.111842\n",
            "Iteration: 181828 | Cost/Loss: 0.074267 | Weight: 0.569003 | Bias: 0.111842\n",
            "Iteration: 181829 | Cost/Loss: 0.074267 | Weight: 0.569004 | Bias: 0.111842\n",
            "Iteration: 181830 | Cost/Loss: 0.074267 | Weight: 0.569004 | Bias: 0.111843\n",
            "Iteration: 181831 | Cost/Loss: 0.074267 | Weight: 0.569004 | Bias: 0.111843\n",
            "Iteration: 181832 | Cost/Loss: 0.074267 | Weight: 0.569005 | Bias: 0.111843\n",
            "Iteration: 181833 | Cost/Loss: 0.074267 | Weight: 0.569005 | Bias: 0.111844\n",
            "Iteration: 181834 | Cost/Loss: 0.074267 | Weight: 0.569005 | Bias: 0.111844\n",
            "Iteration: 181835 | Cost/Loss: 0.074267 | Weight: 0.569005 | Bias: 0.111844\n",
            "Iteration: 181836 | Cost/Loss: 0.074266 | Weight: 0.569006 | Bias: 0.111845\n",
            "Iteration: 181837 | Cost/Loss: 0.074266 | Weight: 0.569006 | Bias: 0.111845\n",
            "Iteration: 181838 | Cost/Loss: 0.074266 | Weight: 0.569006 | Bias: 0.111845\n",
            "Iteration: 181839 | Cost/Loss: 0.074266 | Weight: 0.569007 | Bias: 0.111846\n",
            "Iteration: 181840 | Cost/Loss: 0.074266 | Weight: 0.569007 | Bias: 0.111846\n",
            "Iteration: 181841 | Cost/Loss: 0.074266 | Weight: 0.569007 | Bias: 0.111846\n",
            "Iteration: 181842 | Cost/Loss: 0.074266 | Weight: 0.569008 | Bias: 0.111846\n",
            "Iteration: 181843 | Cost/Loss: 0.074266 | Weight: 0.569008 | Bias: 0.111847\n",
            "Iteration: 181844 | Cost/Loss: 0.074266 | Weight: 0.569008 | Bias: 0.111847\n",
            "Iteration: 181845 | Cost/Loss: 0.074266 | Weight: 0.569008 | Bias: 0.111847\n",
            "Iteration: 181846 | Cost/Loss: 0.074266 | Weight: 0.569009 | Bias: 0.111848\n",
            "Iteration: 181847 | Cost/Loss: 0.074266 | Weight: 0.569009 | Bias: 0.111848\n",
            "Iteration: 181848 | Cost/Loss: 0.074266 | Weight: 0.569009 | Bias: 0.111848\n",
            "Iteration: 181849 | Cost/Loss: 0.074266 | Weight: 0.569010 | Bias: 0.111849\n",
            "Iteration: 181850 | Cost/Loss: 0.074266 | Weight: 0.569010 | Bias: 0.111849\n",
            "Iteration: 181851 | Cost/Loss: 0.074266 | Weight: 0.569010 | Bias: 0.111849\n",
            "Iteration: 181852 | Cost/Loss: 0.074266 | Weight: 0.569010 | Bias: 0.111849\n",
            "Iteration: 181853 | Cost/Loss: 0.074266 | Weight: 0.569011 | Bias: 0.111850\n",
            "Iteration: 181854 | Cost/Loss: 0.074266 | Weight: 0.569011 | Bias: 0.111850\n",
            "Iteration: 181855 | Cost/Loss: 0.074266 | Weight: 0.569011 | Bias: 0.111850\n",
            "Iteration: 181856 | Cost/Loss: 0.074266 | Weight: 0.569012 | Bias: 0.111851\n",
            "Iteration: 181857 | Cost/Loss: 0.074266 | Weight: 0.569012 | Bias: 0.111851\n",
            "Iteration: 181858 | Cost/Loss: 0.074266 | Weight: 0.569012 | Bias: 0.111851\n",
            "Iteration: 181859 | Cost/Loss: 0.074266 | Weight: 0.569013 | Bias: 0.111852\n",
            "Iteration: 181860 | Cost/Loss: 0.074266 | Weight: 0.569013 | Bias: 0.111852\n",
            "Iteration: 181861 | Cost/Loss: 0.074266 | Weight: 0.569013 | Bias: 0.111852\n",
            "Iteration: 181862 | Cost/Loss: 0.074266 | Weight: 0.569013 | Bias: 0.111853\n",
            "Iteration: 181863 | Cost/Loss: 0.074266 | Weight: 0.569014 | Bias: 0.111853\n",
            "Iteration: 181864 | Cost/Loss: 0.074266 | Weight: 0.569014 | Bias: 0.111853\n",
            "Iteration: 181865 | Cost/Loss: 0.074266 | Weight: 0.569014 | Bias: 0.111853\n",
            "Iteration: 181866 | Cost/Loss: 0.074266 | Weight: 0.569015 | Bias: 0.111854\n",
            "Iteration: 181867 | Cost/Loss: 0.074266 | Weight: 0.569015 | Bias: 0.111854\n",
            "Iteration: 181868 | Cost/Loss: 0.074266 | Weight: 0.569015 | Bias: 0.111854\n",
            "Iteration: 181869 | Cost/Loss: 0.074266 | Weight: 0.569016 | Bias: 0.111855\n",
            "Iteration: 181870 | Cost/Loss: 0.074266 | Weight: 0.569016 | Bias: 0.111855\n",
            "Iteration: 181871 | Cost/Loss: 0.074266 | Weight: 0.569016 | Bias: 0.111855\n",
            "Iteration: 181872 | Cost/Loss: 0.074266 | Weight: 0.569016 | Bias: 0.111856\n",
            "Iteration: 181873 | Cost/Loss: 0.074266 | Weight: 0.569017 | Bias: 0.111856\n",
            "Iteration: 181874 | Cost/Loss: 0.074266 | Weight: 0.569017 | Bias: 0.111856\n",
            "Iteration: 181875 | Cost/Loss: 0.074266 | Weight: 0.569017 | Bias: 0.111857\n",
            "Iteration: 181876 | Cost/Loss: 0.074266 | Weight: 0.569018 | Bias: 0.111857\n",
            "Iteration: 181877 | Cost/Loss: 0.074265 | Weight: 0.569018 | Bias: 0.111857\n",
            "Iteration: 181878 | Cost/Loss: 0.074265 | Weight: 0.569018 | Bias: 0.111857\n",
            "Iteration: 181879 | Cost/Loss: 0.074265 | Weight: 0.569019 | Bias: 0.111858\n",
            "Iteration: 181880 | Cost/Loss: 0.074265 | Weight: 0.569019 | Bias: 0.111858\n",
            "Iteration: 181881 | Cost/Loss: 0.074265 | Weight: 0.569019 | Bias: 0.111858\n",
            "Iteration: 181882 | Cost/Loss: 0.074265 | Weight: 0.569019 | Bias: 0.111859\n",
            "Iteration: 181883 | Cost/Loss: 0.074265 | Weight: 0.569020 | Bias: 0.111859\n",
            "Iteration: 181884 | Cost/Loss: 0.074265 | Weight: 0.569020 | Bias: 0.111859\n",
            "Iteration: 181885 | Cost/Loss: 0.074265 | Weight: 0.569020 | Bias: 0.111860\n",
            "Iteration: 181886 | Cost/Loss: 0.074265 | Weight: 0.569021 | Bias: 0.111860\n",
            "Iteration: 181887 | Cost/Loss: 0.074265 | Weight: 0.569021 | Bias: 0.111860\n",
            "Iteration: 181888 | Cost/Loss: 0.074265 | Weight: 0.569021 | Bias: 0.111860\n",
            "Iteration: 181889 | Cost/Loss: 0.074265 | Weight: 0.569022 | Bias: 0.111861\n",
            "Iteration: 181890 | Cost/Loss: 0.074265 | Weight: 0.569022 | Bias: 0.111861\n",
            "Iteration: 181891 | Cost/Loss: 0.074265 | Weight: 0.569022 | Bias: 0.111861\n",
            "Iteration: 181892 | Cost/Loss: 0.074265 | Weight: 0.569022 | Bias: 0.111862\n",
            "Iteration: 181893 | Cost/Loss: 0.074265 | Weight: 0.569023 | Bias: 0.111862\n",
            "Iteration: 181894 | Cost/Loss: 0.074265 | Weight: 0.569023 | Bias: 0.111862\n",
            "Iteration: 181895 | Cost/Loss: 0.074265 | Weight: 0.569023 | Bias: 0.111863\n",
            "Iteration: 181896 | Cost/Loss: 0.074265 | Weight: 0.569024 | Bias: 0.111863\n",
            "Iteration: 181897 | Cost/Loss: 0.074265 | Weight: 0.569024 | Bias: 0.111863\n",
            "Iteration: 181898 | Cost/Loss: 0.074265 | Weight: 0.569024 | Bias: 0.111864\n",
            "Iteration: 181899 | Cost/Loss: 0.074265 | Weight: 0.569025 | Bias: 0.111864\n",
            "Iteration: 181900 | Cost/Loss: 0.074265 | Weight: 0.569025 | Bias: 0.111864\n",
            "Iteration: 181901 | Cost/Loss: 0.074265 | Weight: 0.569025 | Bias: 0.111864\n",
            "Iteration: 181902 | Cost/Loss: 0.074265 | Weight: 0.569025 | Bias: 0.111865\n",
            "Iteration: 181903 | Cost/Loss: 0.074265 | Weight: 0.569026 | Bias: 0.111865\n",
            "Iteration: 181904 | Cost/Loss: 0.074265 | Weight: 0.569026 | Bias: 0.111865\n",
            "Iteration: 181905 | Cost/Loss: 0.074265 | Weight: 0.569026 | Bias: 0.111866\n",
            "Iteration: 181906 | Cost/Loss: 0.074265 | Weight: 0.569027 | Bias: 0.111866\n",
            "Iteration: 181907 | Cost/Loss: 0.074265 | Weight: 0.569027 | Bias: 0.111866\n",
            "Iteration: 181908 | Cost/Loss: 0.074265 | Weight: 0.569027 | Bias: 0.111867\n",
            "Iteration: 181909 | Cost/Loss: 0.074265 | Weight: 0.569027 | Bias: 0.111867\n",
            "Iteration: 181910 | Cost/Loss: 0.074265 | Weight: 0.569028 | Bias: 0.111867\n",
            "Iteration: 181911 | Cost/Loss: 0.074265 | Weight: 0.569028 | Bias: 0.111868\n",
            "Iteration: 181912 | Cost/Loss: 0.074265 | Weight: 0.569028 | Bias: 0.111868\n",
            "Iteration: 181913 | Cost/Loss: 0.074265 | Weight: 0.569029 | Bias: 0.111868\n",
            "Iteration: 181914 | Cost/Loss: 0.074265 | Weight: 0.569029 | Bias: 0.111868\n",
            "Iteration: 181915 | Cost/Loss: 0.074265 | Weight: 0.569029 | Bias: 0.111869\n",
            "Iteration: 181916 | Cost/Loss: 0.074265 | Weight: 0.569030 | Bias: 0.111869\n",
            "Iteration: 181917 | Cost/Loss: 0.074265 | Weight: 0.569030 | Bias: 0.111869\n",
            "Iteration: 181918 | Cost/Loss: 0.074264 | Weight: 0.569030 | Bias: 0.111870\n",
            "Iteration: 181919 | Cost/Loss: 0.074264 | Weight: 0.569030 | Bias: 0.111870\n",
            "Iteration: 181920 | Cost/Loss: 0.074264 | Weight: 0.569031 | Bias: 0.111870\n",
            "Iteration: 181921 | Cost/Loss: 0.074264 | Weight: 0.569031 | Bias: 0.111871\n",
            "Iteration: 181922 | Cost/Loss: 0.074264 | Weight: 0.569031 | Bias: 0.111871\n",
            "Iteration: 181923 | Cost/Loss: 0.074264 | Weight: 0.569032 | Bias: 0.111871\n",
            "Iteration: 181924 | Cost/Loss: 0.074264 | Weight: 0.569032 | Bias: 0.111871\n",
            "Iteration: 181925 | Cost/Loss: 0.074264 | Weight: 0.569032 | Bias: 0.111872\n",
            "Iteration: 181926 | Cost/Loss: 0.074264 | Weight: 0.569033 | Bias: 0.111872\n",
            "Iteration: 181927 | Cost/Loss: 0.074264 | Weight: 0.569033 | Bias: 0.111872\n",
            "Iteration: 181928 | Cost/Loss: 0.074264 | Weight: 0.569033 | Bias: 0.111873\n",
            "Iteration: 181929 | Cost/Loss: 0.074264 | Weight: 0.569033 | Bias: 0.111873\n",
            "Iteration: 181930 | Cost/Loss: 0.074264 | Weight: 0.569034 | Bias: 0.111873\n",
            "Iteration: 181931 | Cost/Loss: 0.074264 | Weight: 0.569034 | Bias: 0.111874\n",
            "Iteration: 181932 | Cost/Loss: 0.074264 | Weight: 0.569034 | Bias: 0.111874\n",
            "Iteration: 181933 | Cost/Loss: 0.074264 | Weight: 0.569035 | Bias: 0.111874\n",
            "Iteration: 181934 | Cost/Loss: 0.074264 | Weight: 0.569035 | Bias: 0.111875\n",
            "Iteration: 181935 | Cost/Loss: 0.074264 | Weight: 0.569035 | Bias: 0.111875\n",
            "Iteration: 181936 | Cost/Loss: 0.074264 | Weight: 0.569036 | Bias: 0.111875\n",
            "Iteration: 181937 | Cost/Loss: 0.074264 | Weight: 0.569036 | Bias: 0.111875\n",
            "Iteration: 181938 | Cost/Loss: 0.074264 | Weight: 0.569036 | Bias: 0.111876\n",
            "Iteration: 181939 | Cost/Loss: 0.074264 | Weight: 0.569036 | Bias: 0.111876\n",
            "Iteration: 181940 | Cost/Loss: 0.074264 | Weight: 0.569037 | Bias: 0.111876\n",
            "Iteration: 181941 | Cost/Loss: 0.074264 | Weight: 0.569037 | Bias: 0.111877\n",
            "Iteration: 181942 | Cost/Loss: 0.074264 | Weight: 0.569037 | Bias: 0.111877\n",
            "Iteration: 181943 | Cost/Loss: 0.074264 | Weight: 0.569038 | Bias: 0.111877\n",
            "Iteration: 181944 | Cost/Loss: 0.074264 | Weight: 0.569038 | Bias: 0.111878\n",
            "Iteration: 181945 | Cost/Loss: 0.074264 | Weight: 0.569038 | Bias: 0.111878\n",
            "Iteration: 181946 | Cost/Loss: 0.074264 | Weight: 0.569039 | Bias: 0.111878\n",
            "Iteration: 181947 | Cost/Loss: 0.074264 | Weight: 0.569039 | Bias: 0.111879\n",
            "Iteration: 181948 | Cost/Loss: 0.074264 | Weight: 0.569039 | Bias: 0.111879\n",
            "Iteration: 181949 | Cost/Loss: 0.074264 | Weight: 0.569039 | Bias: 0.111879\n",
            "Iteration: 181950 | Cost/Loss: 0.074264 | Weight: 0.569040 | Bias: 0.111879\n",
            "Iteration: 181951 | Cost/Loss: 0.074264 | Weight: 0.569040 | Bias: 0.111880\n",
            "Iteration: 181952 | Cost/Loss: 0.074264 | Weight: 0.569040 | Bias: 0.111880\n",
            "Iteration: 181953 | Cost/Loss: 0.074264 | Weight: 0.569041 | Bias: 0.111880\n",
            "Iteration: 181954 | Cost/Loss: 0.074264 | Weight: 0.569041 | Bias: 0.111881\n",
            "Iteration: 181955 | Cost/Loss: 0.074264 | Weight: 0.569041 | Bias: 0.111881\n",
            "Iteration: 181956 | Cost/Loss: 0.074264 | Weight: 0.569041 | Bias: 0.111881\n",
            "Iteration: 181957 | Cost/Loss: 0.074264 | Weight: 0.569042 | Bias: 0.111882\n",
            "Iteration: 181958 | Cost/Loss: 0.074263 | Weight: 0.569042 | Bias: 0.111882\n",
            "Iteration: 181959 | Cost/Loss: 0.074263 | Weight: 0.569042 | Bias: 0.111882\n",
            "Iteration: 181960 | Cost/Loss: 0.074263 | Weight: 0.569043 | Bias: 0.111882\n",
            "Iteration: 181961 | Cost/Loss: 0.074263 | Weight: 0.569043 | Bias: 0.111883\n",
            "Iteration: 181962 | Cost/Loss: 0.074263 | Weight: 0.569043 | Bias: 0.111883\n",
            "Iteration: 181963 | Cost/Loss: 0.074263 | Weight: 0.569044 | Bias: 0.111883\n",
            "Iteration: 181964 | Cost/Loss: 0.074263 | Weight: 0.569044 | Bias: 0.111884\n",
            "Iteration: 181965 | Cost/Loss: 0.074263 | Weight: 0.569044 | Bias: 0.111884\n",
            "Iteration: 181966 | Cost/Loss: 0.074263 | Weight: 0.569044 | Bias: 0.111884\n",
            "Iteration: 181967 | Cost/Loss: 0.074263 | Weight: 0.569045 | Bias: 0.111885\n",
            "Iteration: 181968 | Cost/Loss: 0.074263 | Weight: 0.569045 | Bias: 0.111885\n",
            "Iteration: 181969 | Cost/Loss: 0.074263 | Weight: 0.569045 | Bias: 0.111885\n",
            "Iteration: 181970 | Cost/Loss: 0.074263 | Weight: 0.569046 | Bias: 0.111886\n",
            "Iteration: 181971 | Cost/Loss: 0.074263 | Weight: 0.569046 | Bias: 0.111886\n",
            "Iteration: 181972 | Cost/Loss: 0.074263 | Weight: 0.569046 | Bias: 0.111886\n",
            "Iteration: 181973 | Cost/Loss: 0.074263 | Weight: 0.569047 | Bias: 0.111886\n",
            "Iteration: 181974 | Cost/Loss: 0.074263 | Weight: 0.569047 | Bias: 0.111887\n",
            "Iteration: 181975 | Cost/Loss: 0.074263 | Weight: 0.569047 | Bias: 0.111887\n",
            "Iteration: 181976 | Cost/Loss: 0.074263 | Weight: 0.569047 | Bias: 0.111887\n",
            "Iteration: 181977 | Cost/Loss: 0.074263 | Weight: 0.569048 | Bias: 0.111888\n",
            "Iteration: 181978 | Cost/Loss: 0.074263 | Weight: 0.569048 | Bias: 0.111888\n",
            "Iteration: 181979 | Cost/Loss: 0.074263 | Weight: 0.569048 | Bias: 0.111888\n",
            "Iteration: 181980 | Cost/Loss: 0.074263 | Weight: 0.569049 | Bias: 0.111889\n",
            "Iteration: 181981 | Cost/Loss: 0.074263 | Weight: 0.569049 | Bias: 0.111889\n",
            "Iteration: 181982 | Cost/Loss: 0.074263 | Weight: 0.569049 | Bias: 0.111889\n",
            "Iteration: 181983 | Cost/Loss: 0.074263 | Weight: 0.569050 | Bias: 0.111890\n",
            "Iteration: 181984 | Cost/Loss: 0.074263 | Weight: 0.569050 | Bias: 0.111890\n",
            "Iteration: 181985 | Cost/Loss: 0.074263 | Weight: 0.569050 | Bias: 0.111890\n",
            "Iteration: 181986 | Cost/Loss: 0.074263 | Weight: 0.569050 | Bias: 0.111890\n",
            "Iteration: 181987 | Cost/Loss: 0.074263 | Weight: 0.569051 | Bias: 0.111891\n",
            "Iteration: 181988 | Cost/Loss: 0.074263 | Weight: 0.569051 | Bias: 0.111891\n",
            "Iteration: 181989 | Cost/Loss: 0.074263 | Weight: 0.569051 | Bias: 0.111891\n",
            "Iteration: 181990 | Cost/Loss: 0.074263 | Weight: 0.569052 | Bias: 0.111892\n",
            "Iteration: 181991 | Cost/Loss: 0.074263 | Weight: 0.569052 | Bias: 0.111892\n",
            "Iteration: 181992 | Cost/Loss: 0.074263 | Weight: 0.569052 | Bias: 0.111892\n",
            "Iteration: 181993 | Cost/Loss: 0.074263 | Weight: 0.569053 | Bias: 0.111893\n",
            "Iteration: 181994 | Cost/Loss: 0.074263 | Weight: 0.569053 | Bias: 0.111893\n",
            "Iteration: 181995 | Cost/Loss: 0.074263 | Weight: 0.569053 | Bias: 0.111893\n",
            "Iteration: 181996 | Cost/Loss: 0.074263 | Weight: 0.569053 | Bias: 0.111893\n",
            "Iteration: 181997 | Cost/Loss: 0.074263 | Weight: 0.569054 | Bias: 0.111894\n",
            "Iteration: 181998 | Cost/Loss: 0.074263 | Weight: 0.569054 | Bias: 0.111894\n",
            "Iteration: 181999 | Cost/Loss: 0.074262 | Weight: 0.569054 | Bias: 0.111894\n",
            "Iteration: 182000 | Cost/Loss: 0.074262 | Weight: 0.569055 | Bias: 0.111895\n",
            "Iteration: 182001 | Cost/Loss: 0.074262 | Weight: 0.569055 | Bias: 0.111895\n",
            "Iteration: 182002 | Cost/Loss: 0.074262 | Weight: 0.569055 | Bias: 0.111895\n",
            "Iteration: 182003 | Cost/Loss: 0.074262 | Weight: 0.569055 | Bias: 0.111896\n",
            "Iteration: 182004 | Cost/Loss: 0.074262 | Weight: 0.569056 | Bias: 0.111896\n",
            "Iteration: 182005 | Cost/Loss: 0.074262 | Weight: 0.569056 | Bias: 0.111896\n",
            "Iteration: 182006 | Cost/Loss: 0.074262 | Weight: 0.569056 | Bias: 0.111897\n",
            "Iteration: 182007 | Cost/Loss: 0.074262 | Weight: 0.569057 | Bias: 0.111897\n",
            "Iteration: 182008 | Cost/Loss: 0.074262 | Weight: 0.569057 | Bias: 0.111897\n",
            "Iteration: 182009 | Cost/Loss: 0.074262 | Weight: 0.569057 | Bias: 0.111897\n",
            "Iteration: 182010 | Cost/Loss: 0.074262 | Weight: 0.569058 | Bias: 0.111898\n",
            "Iteration: 182011 | Cost/Loss: 0.074262 | Weight: 0.569058 | Bias: 0.111898\n",
            "Iteration: 182012 | Cost/Loss: 0.074262 | Weight: 0.569058 | Bias: 0.111898\n",
            "Iteration: 182013 | Cost/Loss: 0.074262 | Weight: 0.569058 | Bias: 0.111899\n",
            "Iteration: 182014 | Cost/Loss: 0.074262 | Weight: 0.569059 | Bias: 0.111899\n",
            "Iteration: 182015 | Cost/Loss: 0.074262 | Weight: 0.569059 | Bias: 0.111899\n",
            "Iteration: 182016 | Cost/Loss: 0.074262 | Weight: 0.569059 | Bias: 0.111900\n",
            "Iteration: 182017 | Cost/Loss: 0.074262 | Weight: 0.569060 | Bias: 0.111900\n",
            "Iteration: 182018 | Cost/Loss: 0.074262 | Weight: 0.569060 | Bias: 0.111900\n",
            "Iteration: 182019 | Cost/Loss: 0.074262 | Weight: 0.569060 | Bias: 0.111901\n",
            "Iteration: 182020 | Cost/Loss: 0.074262 | Weight: 0.569061 | Bias: 0.111901\n",
            "Iteration: 182021 | Cost/Loss: 0.074262 | Weight: 0.569061 | Bias: 0.111901\n",
            "Iteration: 182022 | Cost/Loss: 0.074262 | Weight: 0.569061 | Bias: 0.111901\n",
            "Iteration: 182023 | Cost/Loss: 0.074262 | Weight: 0.569061 | Bias: 0.111902\n",
            "Iteration: 182024 | Cost/Loss: 0.074262 | Weight: 0.569062 | Bias: 0.111902\n",
            "Iteration: 182025 | Cost/Loss: 0.074262 | Weight: 0.569062 | Bias: 0.111902\n",
            "Iteration: 182026 | Cost/Loss: 0.074262 | Weight: 0.569062 | Bias: 0.111903\n",
            "Iteration: 182027 | Cost/Loss: 0.074262 | Weight: 0.569063 | Bias: 0.111903\n",
            "Iteration: 182028 | Cost/Loss: 0.074262 | Weight: 0.569063 | Bias: 0.111903\n",
            "Iteration: 182029 | Cost/Loss: 0.074262 | Weight: 0.569063 | Bias: 0.111904\n",
            "Iteration: 182030 | Cost/Loss: 0.074262 | Weight: 0.569064 | Bias: 0.111904\n",
            "Iteration: 182031 | Cost/Loss: 0.074262 | Weight: 0.569064 | Bias: 0.111904\n",
            "Iteration: 182032 | Cost/Loss: 0.074262 | Weight: 0.569064 | Bias: 0.111904\n",
            "Iteration: 182033 | Cost/Loss: 0.074262 | Weight: 0.569064 | Bias: 0.111905\n",
            "Iteration: 182034 | Cost/Loss: 0.074262 | Weight: 0.569065 | Bias: 0.111905\n",
            "Iteration: 182035 | Cost/Loss: 0.074262 | Weight: 0.569065 | Bias: 0.111905\n",
            "Iteration: 182036 | Cost/Loss: 0.074262 | Weight: 0.569065 | Bias: 0.111906\n",
            "Iteration: 182037 | Cost/Loss: 0.074262 | Weight: 0.569066 | Bias: 0.111906\n",
            "Iteration: 182038 | Cost/Loss: 0.074262 | Weight: 0.569066 | Bias: 0.111906\n",
            "Iteration: 182039 | Cost/Loss: 0.074262 | Weight: 0.569066 | Bias: 0.111907\n",
            "Iteration: 182040 | Cost/Loss: 0.074261 | Weight: 0.569067 | Bias: 0.111907\n",
            "Iteration: 182041 | Cost/Loss: 0.074261 | Weight: 0.569067 | Bias: 0.111907\n",
            "Iteration: 182042 | Cost/Loss: 0.074261 | Weight: 0.569067 | Bias: 0.111908\n",
            "Iteration: 182043 | Cost/Loss: 0.074261 | Weight: 0.569067 | Bias: 0.111908\n",
            "Iteration: 182044 | Cost/Loss: 0.074261 | Weight: 0.569068 | Bias: 0.111908\n",
            "Iteration: 182045 | Cost/Loss: 0.074261 | Weight: 0.569068 | Bias: 0.111908\n",
            "Iteration: 182046 | Cost/Loss: 0.074261 | Weight: 0.569068 | Bias: 0.111909\n",
            "Iteration: 182047 | Cost/Loss: 0.074261 | Weight: 0.569069 | Bias: 0.111909\n",
            "Iteration: 182048 | Cost/Loss: 0.074261 | Weight: 0.569069 | Bias: 0.111909\n",
            "Iteration: 182049 | Cost/Loss: 0.074261 | Weight: 0.569069 | Bias: 0.111910\n",
            "Iteration: 182050 | Cost/Loss: 0.074261 | Weight: 0.569070 | Bias: 0.111910\n",
            "Iteration: 182051 | Cost/Loss: 0.074261 | Weight: 0.569070 | Bias: 0.111910\n",
            "Iteration: 182052 | Cost/Loss: 0.074261 | Weight: 0.569070 | Bias: 0.111911\n",
            "Iteration: 182053 | Cost/Loss: 0.074261 | Weight: 0.569070 | Bias: 0.111911\n",
            "Iteration: 182054 | Cost/Loss: 0.074261 | Weight: 0.569071 | Bias: 0.111911\n",
            "Iteration: 182055 | Cost/Loss: 0.074261 | Weight: 0.569071 | Bias: 0.111911\n",
            "Iteration: 182056 | Cost/Loss: 0.074261 | Weight: 0.569071 | Bias: 0.111912\n",
            "Iteration: 182057 | Cost/Loss: 0.074261 | Weight: 0.569072 | Bias: 0.111912\n",
            "Iteration: 182058 | Cost/Loss: 0.074261 | Weight: 0.569072 | Bias: 0.111912\n",
            "Iteration: 182059 | Cost/Loss: 0.074261 | Weight: 0.569072 | Bias: 0.111913\n",
            "Iteration: 182060 | Cost/Loss: 0.074261 | Weight: 0.569072 | Bias: 0.111913\n",
            "Iteration: 182061 | Cost/Loss: 0.074261 | Weight: 0.569073 | Bias: 0.111913\n",
            "Iteration: 182062 | Cost/Loss: 0.074261 | Weight: 0.569073 | Bias: 0.111914\n",
            "Iteration: 182063 | Cost/Loss: 0.074261 | Weight: 0.569073 | Bias: 0.111914\n",
            "Iteration: 182064 | Cost/Loss: 0.074261 | Weight: 0.569074 | Bias: 0.111914\n",
            "Iteration: 182065 | Cost/Loss: 0.074261 | Weight: 0.569074 | Bias: 0.111915\n",
            "Iteration: 182066 | Cost/Loss: 0.074261 | Weight: 0.569074 | Bias: 0.111915\n",
            "Iteration: 182067 | Cost/Loss: 0.074261 | Weight: 0.569075 | Bias: 0.111915\n",
            "Iteration: 182068 | Cost/Loss: 0.074261 | Weight: 0.569075 | Bias: 0.111915\n",
            "Iteration: 182069 | Cost/Loss: 0.074261 | Weight: 0.569075 | Bias: 0.111916\n",
            "Iteration: 182070 | Cost/Loss: 0.074261 | Weight: 0.569075 | Bias: 0.111916\n",
            "Iteration: 182071 | Cost/Loss: 0.074261 | Weight: 0.569076 | Bias: 0.111916\n",
            "Iteration: 182072 | Cost/Loss: 0.074261 | Weight: 0.569076 | Bias: 0.111917\n",
            "Iteration: 182073 | Cost/Loss: 0.074261 | Weight: 0.569076 | Bias: 0.111917\n",
            "Iteration: 182074 | Cost/Loss: 0.074261 | Weight: 0.569077 | Bias: 0.111917\n",
            "Iteration: 182075 | Cost/Loss: 0.074261 | Weight: 0.569077 | Bias: 0.111918\n",
            "Iteration: 182076 | Cost/Loss: 0.074261 | Weight: 0.569077 | Bias: 0.111918\n",
            "Iteration: 182077 | Cost/Loss: 0.074261 | Weight: 0.569078 | Bias: 0.111918\n",
            "Iteration: 182078 | Cost/Loss: 0.074261 | Weight: 0.569078 | Bias: 0.111919\n",
            "Iteration: 182079 | Cost/Loss: 0.074261 | Weight: 0.569078 | Bias: 0.111919\n",
            "Iteration: 182080 | Cost/Loss: 0.074260 | Weight: 0.569078 | Bias: 0.111919\n",
            "Iteration: 182081 | Cost/Loss: 0.074260 | Weight: 0.569079 | Bias: 0.111919\n",
            "Iteration: 182082 | Cost/Loss: 0.074260 | Weight: 0.569079 | Bias: 0.111920\n",
            "Iteration: 182083 | Cost/Loss: 0.074260 | Weight: 0.569079 | Bias: 0.111920\n",
            "Iteration: 182084 | Cost/Loss: 0.074260 | Weight: 0.569080 | Bias: 0.111920\n",
            "Iteration: 182085 | Cost/Loss: 0.074260 | Weight: 0.569080 | Bias: 0.111921\n",
            "Iteration: 182086 | Cost/Loss: 0.074260 | Weight: 0.569080 | Bias: 0.111921\n",
            "Iteration: 182087 | Cost/Loss: 0.074260 | Weight: 0.569081 | Bias: 0.111921\n",
            "Iteration: 182088 | Cost/Loss: 0.074260 | Weight: 0.569081 | Bias: 0.111922\n",
            "Iteration: 182089 | Cost/Loss: 0.074260 | Weight: 0.569081 | Bias: 0.111922\n",
            "Iteration: 182090 | Cost/Loss: 0.074260 | Weight: 0.569081 | Bias: 0.111922\n",
            "Iteration: 182091 | Cost/Loss: 0.074260 | Weight: 0.569082 | Bias: 0.111922\n",
            "Iteration: 182092 | Cost/Loss: 0.074260 | Weight: 0.569082 | Bias: 0.111923\n",
            "Iteration: 182093 | Cost/Loss: 0.074260 | Weight: 0.569082 | Bias: 0.111923\n",
            "Iteration: 182094 | Cost/Loss: 0.074260 | Weight: 0.569083 | Bias: 0.111923\n",
            "Iteration: 182095 | Cost/Loss: 0.074260 | Weight: 0.569083 | Bias: 0.111924\n",
            "Iteration: 182096 | Cost/Loss: 0.074260 | Weight: 0.569083 | Bias: 0.111924\n",
            "Iteration: 182097 | Cost/Loss: 0.074260 | Weight: 0.569084 | Bias: 0.111924\n",
            "Iteration: 182098 | Cost/Loss: 0.074260 | Weight: 0.569084 | Bias: 0.111925\n",
            "Iteration: 182099 | Cost/Loss: 0.074260 | Weight: 0.569084 | Bias: 0.111925\n",
            "Iteration: 182100 | Cost/Loss: 0.074260 | Weight: 0.569084 | Bias: 0.111925\n",
            "Iteration: 182101 | Cost/Loss: 0.074260 | Weight: 0.569085 | Bias: 0.111926\n",
            "Iteration: 182102 | Cost/Loss: 0.074260 | Weight: 0.569085 | Bias: 0.111926\n",
            "Iteration: 182103 | Cost/Loss: 0.074260 | Weight: 0.569085 | Bias: 0.111926\n",
            "Iteration: 182104 | Cost/Loss: 0.074260 | Weight: 0.569086 | Bias: 0.111926\n",
            "Iteration: 182105 | Cost/Loss: 0.074260 | Weight: 0.569086 | Bias: 0.111927\n",
            "Iteration: 182106 | Cost/Loss: 0.074260 | Weight: 0.569086 | Bias: 0.111927\n",
            "Iteration: 182107 | Cost/Loss: 0.074260 | Weight: 0.569086 | Bias: 0.111927\n",
            "Iteration: 182108 | Cost/Loss: 0.074260 | Weight: 0.569087 | Bias: 0.111928\n",
            "Iteration: 182109 | Cost/Loss: 0.074260 | Weight: 0.569087 | Bias: 0.111928\n",
            "Iteration: 182110 | Cost/Loss: 0.074260 | Weight: 0.569087 | Bias: 0.111928\n",
            "Iteration: 182111 | Cost/Loss: 0.074260 | Weight: 0.569088 | Bias: 0.111929\n",
            "Iteration: 182112 | Cost/Loss: 0.074260 | Weight: 0.569088 | Bias: 0.111929\n",
            "Iteration: 182113 | Cost/Loss: 0.074260 | Weight: 0.569088 | Bias: 0.111929\n",
            "Iteration: 182114 | Cost/Loss: 0.074260 | Weight: 0.569089 | Bias: 0.111930\n",
            "Iteration: 182115 | Cost/Loss: 0.074260 | Weight: 0.569089 | Bias: 0.111930\n",
            "Iteration: 182116 | Cost/Loss: 0.074260 | Weight: 0.569089 | Bias: 0.111930\n",
            "Iteration: 182117 | Cost/Loss: 0.074260 | Weight: 0.569089 | Bias: 0.111930\n",
            "Iteration: 182118 | Cost/Loss: 0.074260 | Weight: 0.569090 | Bias: 0.111931\n",
            "Iteration: 182119 | Cost/Loss: 0.074260 | Weight: 0.569090 | Bias: 0.111931\n",
            "Iteration: 182120 | Cost/Loss: 0.074260 | Weight: 0.569090 | Bias: 0.111931\n",
            "Iteration: 182121 | Cost/Loss: 0.074259 | Weight: 0.569091 | Bias: 0.111932\n",
            "Iteration: 182122 | Cost/Loss: 0.074259 | Weight: 0.569091 | Bias: 0.111932\n",
            "Iteration: 182123 | Cost/Loss: 0.074259 | Weight: 0.569091 | Bias: 0.111932\n",
            "Iteration: 182124 | Cost/Loss: 0.074259 | Weight: 0.569092 | Bias: 0.111933\n",
            "Iteration: 182125 | Cost/Loss: 0.074259 | Weight: 0.569092 | Bias: 0.111933\n",
            "Iteration: 182126 | Cost/Loss: 0.074259 | Weight: 0.569092 | Bias: 0.111933\n",
            "Iteration: 182127 | Cost/Loss: 0.074259 | Weight: 0.569092 | Bias: 0.111933\n",
            "Iteration: 182128 | Cost/Loss: 0.074259 | Weight: 0.569093 | Bias: 0.111934\n",
            "Iteration: 182129 | Cost/Loss: 0.074259 | Weight: 0.569093 | Bias: 0.111934\n",
            "Iteration: 182130 | Cost/Loss: 0.074259 | Weight: 0.569093 | Bias: 0.111934\n",
            "Iteration: 182131 | Cost/Loss: 0.074259 | Weight: 0.569094 | Bias: 0.111935\n",
            "Iteration: 182132 | Cost/Loss: 0.074259 | Weight: 0.569094 | Bias: 0.111935\n",
            "Iteration: 182133 | Cost/Loss: 0.074259 | Weight: 0.569094 | Bias: 0.111935\n",
            "Iteration: 182134 | Cost/Loss: 0.074259 | Weight: 0.569095 | Bias: 0.111936\n",
            "Iteration: 182135 | Cost/Loss: 0.074259 | Weight: 0.569095 | Bias: 0.111936\n",
            "Iteration: 182136 | Cost/Loss: 0.074259 | Weight: 0.569095 | Bias: 0.111936\n",
            "Iteration: 182137 | Cost/Loss: 0.074259 | Weight: 0.569095 | Bias: 0.111937\n",
            "Iteration: 182138 | Cost/Loss: 0.074259 | Weight: 0.569096 | Bias: 0.111937\n",
            "Iteration: 182139 | Cost/Loss: 0.074259 | Weight: 0.569096 | Bias: 0.111937\n",
            "Iteration: 182140 | Cost/Loss: 0.074259 | Weight: 0.569096 | Bias: 0.111937\n",
            "Iteration: 182141 | Cost/Loss: 0.074259 | Weight: 0.569097 | Bias: 0.111938\n",
            "Iteration: 182142 | Cost/Loss: 0.074259 | Weight: 0.569097 | Bias: 0.111938\n",
            "Iteration: 182143 | Cost/Loss: 0.074259 | Weight: 0.569097 | Bias: 0.111938\n",
            "Iteration: 182144 | Cost/Loss: 0.074259 | Weight: 0.569098 | Bias: 0.111939\n",
            "Iteration: 182145 | Cost/Loss: 0.074259 | Weight: 0.569098 | Bias: 0.111939\n",
            "Iteration: 182146 | Cost/Loss: 0.074259 | Weight: 0.569098 | Bias: 0.111939\n",
            "Iteration: 182147 | Cost/Loss: 0.074259 | Weight: 0.569098 | Bias: 0.111940\n",
            "Iteration: 182148 | Cost/Loss: 0.074259 | Weight: 0.569099 | Bias: 0.111940\n",
            "Iteration: 182149 | Cost/Loss: 0.074259 | Weight: 0.569099 | Bias: 0.111940\n",
            "Iteration: 182150 | Cost/Loss: 0.074259 | Weight: 0.569099 | Bias: 0.111941\n",
            "Iteration: 182151 | Cost/Loss: 0.074259 | Weight: 0.569100 | Bias: 0.111941\n",
            "Iteration: 182152 | Cost/Loss: 0.074259 | Weight: 0.569100 | Bias: 0.111941\n",
            "Iteration: 182153 | Cost/Loss: 0.074259 | Weight: 0.569100 | Bias: 0.111941\n",
            "Iteration: 182154 | Cost/Loss: 0.074259 | Weight: 0.569100 | Bias: 0.111942\n",
            "Iteration: 182155 | Cost/Loss: 0.074259 | Weight: 0.569101 | Bias: 0.111942\n",
            "Iteration: 182156 | Cost/Loss: 0.074259 | Weight: 0.569101 | Bias: 0.111942\n",
            "Iteration: 182157 | Cost/Loss: 0.074259 | Weight: 0.569101 | Bias: 0.111943\n",
            "Iteration: 182158 | Cost/Loss: 0.074259 | Weight: 0.569102 | Bias: 0.111943\n",
            "Iteration: 182159 | Cost/Loss: 0.074259 | Weight: 0.569102 | Bias: 0.111943\n",
            "Iteration: 182160 | Cost/Loss: 0.074259 | Weight: 0.569102 | Bias: 0.111944\n",
            "Iteration: 182161 | Cost/Loss: 0.074258 | Weight: 0.569103 | Bias: 0.111944\n",
            "Iteration: 182162 | Cost/Loss: 0.074258 | Weight: 0.569103 | Bias: 0.111944\n",
            "Iteration: 182163 | Cost/Loss: 0.074258 | Weight: 0.569103 | Bias: 0.111944\n",
            "Iteration: 182164 | Cost/Loss: 0.074258 | Weight: 0.569103 | Bias: 0.111945\n",
            "Iteration: 182165 | Cost/Loss: 0.074258 | Weight: 0.569104 | Bias: 0.111945\n",
            "Iteration: 182166 | Cost/Loss: 0.074258 | Weight: 0.569104 | Bias: 0.111945\n",
            "Iteration: 182167 | Cost/Loss: 0.074258 | Weight: 0.569104 | Bias: 0.111946\n",
            "Iteration: 182168 | Cost/Loss: 0.074258 | Weight: 0.569105 | Bias: 0.111946\n",
            "Iteration: 182169 | Cost/Loss: 0.074258 | Weight: 0.569105 | Bias: 0.111946\n",
            "Iteration: 182170 | Cost/Loss: 0.074258 | Weight: 0.569105 | Bias: 0.111947\n",
            "Iteration: 182171 | Cost/Loss: 0.074258 | Weight: 0.569106 | Bias: 0.111947\n",
            "Iteration: 182172 | Cost/Loss: 0.074258 | Weight: 0.569106 | Bias: 0.111947\n",
            "Iteration: 182173 | Cost/Loss: 0.074258 | Weight: 0.569106 | Bias: 0.111948\n",
            "Iteration: 182174 | Cost/Loss: 0.074258 | Weight: 0.569106 | Bias: 0.111948\n",
            "Iteration: 182175 | Cost/Loss: 0.074258 | Weight: 0.569107 | Bias: 0.111948\n",
            "Iteration: 182176 | Cost/Loss: 0.074258 | Weight: 0.569107 | Bias: 0.111948\n",
            "Iteration: 182177 | Cost/Loss: 0.074258 | Weight: 0.569107 | Bias: 0.111949\n",
            "Iteration: 182178 | Cost/Loss: 0.074258 | Weight: 0.569108 | Bias: 0.111949\n",
            "Iteration: 182179 | Cost/Loss: 0.074258 | Weight: 0.569108 | Bias: 0.111949\n",
            "Iteration: 182180 | Cost/Loss: 0.074258 | Weight: 0.569108 | Bias: 0.111950\n",
            "Iteration: 182181 | Cost/Loss: 0.074258 | Weight: 0.569109 | Bias: 0.111950\n",
            "Iteration: 182182 | Cost/Loss: 0.074258 | Weight: 0.569109 | Bias: 0.111950\n",
            "Iteration: 182183 | Cost/Loss: 0.074258 | Weight: 0.569109 | Bias: 0.111951\n",
            "Iteration: 182184 | Cost/Loss: 0.074258 | Weight: 0.569109 | Bias: 0.111951\n",
            "Iteration: 182185 | Cost/Loss: 0.074258 | Weight: 0.569110 | Bias: 0.111951\n",
            "Iteration: 182186 | Cost/Loss: 0.074258 | Weight: 0.569110 | Bias: 0.111952\n",
            "Iteration: 182187 | Cost/Loss: 0.074258 | Weight: 0.569110 | Bias: 0.111952\n",
            "Iteration: 182188 | Cost/Loss: 0.074258 | Weight: 0.569111 | Bias: 0.111952\n",
            "Iteration: 182189 | Cost/Loss: 0.074258 | Weight: 0.569111 | Bias: 0.111952\n",
            "Iteration: 182190 | Cost/Loss: 0.074258 | Weight: 0.569111 | Bias: 0.111953\n",
            "Iteration: 182191 | Cost/Loss: 0.074258 | Weight: 0.569112 | Bias: 0.111953\n",
            "Iteration: 182192 | Cost/Loss: 0.074258 | Weight: 0.569112 | Bias: 0.111953\n",
            "Iteration: 182193 | Cost/Loss: 0.074258 | Weight: 0.569112 | Bias: 0.111954\n",
            "Iteration: 182194 | Cost/Loss: 0.074258 | Weight: 0.569112 | Bias: 0.111954\n",
            "Iteration: 182195 | Cost/Loss: 0.074258 | Weight: 0.569113 | Bias: 0.111954\n",
            "Iteration: 182196 | Cost/Loss: 0.074258 | Weight: 0.569113 | Bias: 0.111955\n",
            "Iteration: 182197 | Cost/Loss: 0.074258 | Weight: 0.569113 | Bias: 0.111955\n",
            "Iteration: 182198 | Cost/Loss: 0.074258 | Weight: 0.569114 | Bias: 0.111955\n",
            "Iteration: 182199 | Cost/Loss: 0.074258 | Weight: 0.569114 | Bias: 0.111955\n",
            "Iteration: 182200 | Cost/Loss: 0.074258 | Weight: 0.569114 | Bias: 0.111956\n",
            "Iteration: 182201 | Cost/Loss: 0.074258 | Weight: 0.569115 | Bias: 0.111956\n",
            "Iteration: 182202 | Cost/Loss: 0.074257 | Weight: 0.569115 | Bias: 0.111956\n",
            "Iteration: 182203 | Cost/Loss: 0.074257 | Weight: 0.569115 | Bias: 0.111957\n",
            "Iteration: 182204 | Cost/Loss: 0.074257 | Weight: 0.569115 | Bias: 0.111957\n",
            "Iteration: 182205 | Cost/Loss: 0.074257 | Weight: 0.569116 | Bias: 0.111957\n",
            "Iteration: 182206 | Cost/Loss: 0.074257 | Weight: 0.569116 | Bias: 0.111958\n",
            "Iteration: 182207 | Cost/Loss: 0.074257 | Weight: 0.569116 | Bias: 0.111958\n",
            "Iteration: 182208 | Cost/Loss: 0.074257 | Weight: 0.569117 | Bias: 0.111958\n",
            "Iteration: 182209 | Cost/Loss: 0.074257 | Weight: 0.569117 | Bias: 0.111959\n",
            "Iteration: 182210 | Cost/Loss: 0.074257 | Weight: 0.569117 | Bias: 0.111959\n",
            "Iteration: 182211 | Cost/Loss: 0.074257 | Weight: 0.569117 | Bias: 0.111959\n",
            "Iteration: 182212 | Cost/Loss: 0.074257 | Weight: 0.569118 | Bias: 0.111959\n",
            "Iteration: 182213 | Cost/Loss: 0.074257 | Weight: 0.569118 | Bias: 0.111960\n",
            "Iteration: 182214 | Cost/Loss: 0.074257 | Weight: 0.569118 | Bias: 0.111960\n",
            "Iteration: 182215 | Cost/Loss: 0.074257 | Weight: 0.569119 | Bias: 0.111960\n",
            "Iteration: 182216 | Cost/Loss: 0.074257 | Weight: 0.569119 | Bias: 0.111961\n",
            "Iteration: 182217 | Cost/Loss: 0.074257 | Weight: 0.569119 | Bias: 0.111961\n",
            "Iteration: 182218 | Cost/Loss: 0.074257 | Weight: 0.569120 | Bias: 0.111961\n",
            "Iteration: 182219 | Cost/Loss: 0.074257 | Weight: 0.569120 | Bias: 0.111962\n",
            "Iteration: 182220 | Cost/Loss: 0.074257 | Weight: 0.569120 | Bias: 0.111962\n",
            "Iteration: 182221 | Cost/Loss: 0.074257 | Weight: 0.569120 | Bias: 0.111962\n",
            "Iteration: 182222 | Cost/Loss: 0.074257 | Weight: 0.569121 | Bias: 0.111963\n",
            "Iteration: 182223 | Cost/Loss: 0.074257 | Weight: 0.569121 | Bias: 0.111963\n",
            "Iteration: 182224 | Cost/Loss: 0.074257 | Weight: 0.569121 | Bias: 0.111963\n",
            "Iteration: 182225 | Cost/Loss: 0.074257 | Weight: 0.569122 | Bias: 0.111963\n",
            "Iteration: 182226 | Cost/Loss: 0.074257 | Weight: 0.569122 | Bias: 0.111964\n",
            "Iteration: 182227 | Cost/Loss: 0.074257 | Weight: 0.569122 | Bias: 0.111964\n",
            "Iteration: 182228 | Cost/Loss: 0.074257 | Weight: 0.569123 | Bias: 0.111964\n",
            "Iteration: 182229 | Cost/Loss: 0.074257 | Weight: 0.569123 | Bias: 0.111965\n",
            "Iteration: 182230 | Cost/Loss: 0.074257 | Weight: 0.569123 | Bias: 0.111965\n",
            "Iteration: 182231 | Cost/Loss: 0.074257 | Weight: 0.569123 | Bias: 0.111965\n",
            "Iteration: 182232 | Cost/Loss: 0.074257 | Weight: 0.569124 | Bias: 0.111966\n",
            "Iteration: 182233 | Cost/Loss: 0.074257 | Weight: 0.569124 | Bias: 0.111966\n",
            "Iteration: 182234 | Cost/Loss: 0.074257 | Weight: 0.569124 | Bias: 0.111966\n",
            "Iteration: 182235 | Cost/Loss: 0.074257 | Weight: 0.569125 | Bias: 0.111966\n",
            "Iteration: 182236 | Cost/Loss: 0.074257 | Weight: 0.569125 | Bias: 0.111967\n",
            "Iteration: 182237 | Cost/Loss: 0.074257 | Weight: 0.569125 | Bias: 0.111967\n",
            "Iteration: 182238 | Cost/Loss: 0.074257 | Weight: 0.569126 | Bias: 0.111967\n",
            "Iteration: 182239 | Cost/Loss: 0.074257 | Weight: 0.569126 | Bias: 0.111968\n",
            "Iteration: 182240 | Cost/Loss: 0.074257 | Weight: 0.569126 | Bias: 0.111968\n",
            "Iteration: 182241 | Cost/Loss: 0.074257 | Weight: 0.569126 | Bias: 0.111968\n",
            "Iteration: 182242 | Cost/Loss: 0.074256 | Weight: 0.569127 | Bias: 0.111969\n",
            "Iteration: 182243 | Cost/Loss: 0.074256 | Weight: 0.569127 | Bias: 0.111969\n",
            "Iteration: 182244 | Cost/Loss: 0.074256 | Weight: 0.569127 | Bias: 0.111969\n",
            "Iteration: 182245 | Cost/Loss: 0.074256 | Weight: 0.569128 | Bias: 0.111970\n",
            "Iteration: 182246 | Cost/Loss: 0.074256 | Weight: 0.569128 | Bias: 0.111970\n",
            "Iteration: 182247 | Cost/Loss: 0.074256 | Weight: 0.569128 | Bias: 0.111970\n",
            "Iteration: 182248 | Cost/Loss: 0.074256 | Weight: 0.569129 | Bias: 0.111970\n",
            "Iteration: 182249 | Cost/Loss: 0.074256 | Weight: 0.569129 | Bias: 0.111971\n",
            "Iteration: 182250 | Cost/Loss: 0.074256 | Weight: 0.569129 | Bias: 0.111971\n",
            "Iteration: 182251 | Cost/Loss: 0.074256 | Weight: 0.569129 | Bias: 0.111971\n",
            "Iteration: 182252 | Cost/Loss: 0.074256 | Weight: 0.569130 | Bias: 0.111972\n",
            "Iteration: 182253 | Cost/Loss: 0.074256 | Weight: 0.569130 | Bias: 0.111972\n",
            "Iteration: 182254 | Cost/Loss: 0.074256 | Weight: 0.569130 | Bias: 0.111972\n",
            "Iteration: 182255 | Cost/Loss: 0.074256 | Weight: 0.569131 | Bias: 0.111973\n",
            "Iteration: 182256 | Cost/Loss: 0.074256 | Weight: 0.569131 | Bias: 0.111973\n",
            "Iteration: 182257 | Cost/Loss: 0.074256 | Weight: 0.569131 | Bias: 0.111973\n",
            "Iteration: 182258 | Cost/Loss: 0.074256 | Weight: 0.569131 | Bias: 0.111974\n",
            "Iteration: 182259 | Cost/Loss: 0.074256 | Weight: 0.569132 | Bias: 0.111974\n",
            "Iteration: 182260 | Cost/Loss: 0.074256 | Weight: 0.569132 | Bias: 0.111974\n",
            "Iteration: 182261 | Cost/Loss: 0.074256 | Weight: 0.569132 | Bias: 0.111974\n",
            "Iteration: 182262 | Cost/Loss: 0.074256 | Weight: 0.569133 | Bias: 0.111975\n",
            "Iteration: 182263 | Cost/Loss: 0.074256 | Weight: 0.569133 | Bias: 0.111975\n",
            "Iteration: 182264 | Cost/Loss: 0.074256 | Weight: 0.569133 | Bias: 0.111975\n",
            "Iteration: 182265 | Cost/Loss: 0.074256 | Weight: 0.569134 | Bias: 0.111976\n",
            "Iteration: 182266 | Cost/Loss: 0.074256 | Weight: 0.569134 | Bias: 0.111976\n",
            "Iteration: 182267 | Cost/Loss: 0.074256 | Weight: 0.569134 | Bias: 0.111976\n",
            "Iteration: 182268 | Cost/Loss: 0.074256 | Weight: 0.569134 | Bias: 0.111977\n",
            "Iteration: 182269 | Cost/Loss: 0.074256 | Weight: 0.569135 | Bias: 0.111977\n",
            "Iteration: 182270 | Cost/Loss: 0.074256 | Weight: 0.569135 | Bias: 0.111977\n",
            "Iteration: 182271 | Cost/Loss: 0.074256 | Weight: 0.569135 | Bias: 0.111977\n",
            "Iteration: 182272 | Cost/Loss: 0.074256 | Weight: 0.569136 | Bias: 0.111978\n",
            "Iteration: 182273 | Cost/Loss: 0.074256 | Weight: 0.569136 | Bias: 0.111978\n",
            "Iteration: 182274 | Cost/Loss: 0.074256 | Weight: 0.569136 | Bias: 0.111978\n",
            "Iteration: 182275 | Cost/Loss: 0.074256 | Weight: 0.569137 | Bias: 0.111979\n",
            "Iteration: 182276 | Cost/Loss: 0.074256 | Weight: 0.569137 | Bias: 0.111979\n",
            "Iteration: 182277 | Cost/Loss: 0.074256 | Weight: 0.569137 | Bias: 0.111979\n",
            "Iteration: 182278 | Cost/Loss: 0.074256 | Weight: 0.569137 | Bias: 0.111980\n",
            "Iteration: 182279 | Cost/Loss: 0.074256 | Weight: 0.569138 | Bias: 0.111980\n",
            "Iteration: 182280 | Cost/Loss: 0.074256 | Weight: 0.569138 | Bias: 0.111980\n",
            "Iteration: 182281 | Cost/Loss: 0.074256 | Weight: 0.569138 | Bias: 0.111981\n",
            "Iteration: 182282 | Cost/Loss: 0.074256 | Weight: 0.569139 | Bias: 0.111981\n",
            "Iteration: 182283 | Cost/Loss: 0.074255 | Weight: 0.569139 | Bias: 0.111981\n",
            "Iteration: 182284 | Cost/Loss: 0.074255 | Weight: 0.569139 | Bias: 0.111981\n",
            "Iteration: 182285 | Cost/Loss: 0.074255 | Weight: 0.569140 | Bias: 0.111982\n",
            "Iteration: 182286 | Cost/Loss: 0.074255 | Weight: 0.569140 | Bias: 0.111982\n",
            "Iteration: 182287 | Cost/Loss: 0.074255 | Weight: 0.569140 | Bias: 0.111982\n",
            "Iteration: 182288 | Cost/Loss: 0.074255 | Weight: 0.569140 | Bias: 0.111983\n",
            "Iteration: 182289 | Cost/Loss: 0.074255 | Weight: 0.569141 | Bias: 0.111983\n",
            "Iteration: 182290 | Cost/Loss: 0.074255 | Weight: 0.569141 | Bias: 0.111983\n",
            "Iteration: 182291 | Cost/Loss: 0.074255 | Weight: 0.569141 | Bias: 0.111984\n",
            "Iteration: 182292 | Cost/Loss: 0.074255 | Weight: 0.569142 | Bias: 0.111984\n",
            "Iteration: 182293 | Cost/Loss: 0.074255 | Weight: 0.569142 | Bias: 0.111984\n",
            "Iteration: 182294 | Cost/Loss: 0.074255 | Weight: 0.569142 | Bias: 0.111985\n",
            "Iteration: 182295 | Cost/Loss: 0.074255 | Weight: 0.569143 | Bias: 0.111985\n",
            "Iteration: 182296 | Cost/Loss: 0.074255 | Weight: 0.569143 | Bias: 0.111985\n",
            "Iteration: 182297 | Cost/Loss: 0.074255 | Weight: 0.569143 | Bias: 0.111985\n",
            "Iteration: 182298 | Cost/Loss: 0.074255 | Weight: 0.569143 | Bias: 0.111986\n",
            "Iteration: 182299 | Cost/Loss: 0.074255 | Weight: 0.569144 | Bias: 0.111986\n",
            "Iteration: 182300 | Cost/Loss: 0.074255 | Weight: 0.569144 | Bias: 0.111986\n",
            "Iteration: 182301 | Cost/Loss: 0.074255 | Weight: 0.569144 | Bias: 0.111987\n",
            "Iteration: 182302 | Cost/Loss: 0.074255 | Weight: 0.569145 | Bias: 0.111987\n",
            "Iteration: 182303 | Cost/Loss: 0.074255 | Weight: 0.569145 | Bias: 0.111987\n",
            "Iteration: 182304 | Cost/Loss: 0.074255 | Weight: 0.569145 | Bias: 0.111988\n",
            "Iteration: 182305 | Cost/Loss: 0.074255 | Weight: 0.569146 | Bias: 0.111988\n",
            "Iteration: 182306 | Cost/Loss: 0.074255 | Weight: 0.569146 | Bias: 0.111988\n",
            "Iteration: 182307 | Cost/Loss: 0.074255 | Weight: 0.569146 | Bias: 0.111988\n",
            "Iteration: 182308 | Cost/Loss: 0.074255 | Weight: 0.569146 | Bias: 0.111989\n",
            "Iteration: 182309 | Cost/Loss: 0.074255 | Weight: 0.569147 | Bias: 0.111989\n",
            "Iteration: 182310 | Cost/Loss: 0.074255 | Weight: 0.569147 | Bias: 0.111989\n",
            "Iteration: 182311 | Cost/Loss: 0.074255 | Weight: 0.569147 | Bias: 0.111990\n",
            "Iteration: 182312 | Cost/Loss: 0.074255 | Weight: 0.569148 | Bias: 0.111990\n",
            "Iteration: 182313 | Cost/Loss: 0.074255 | Weight: 0.569148 | Bias: 0.111990\n",
            "Iteration: 182314 | Cost/Loss: 0.074255 | Weight: 0.569148 | Bias: 0.111991\n",
            "Iteration: 182315 | Cost/Loss: 0.074255 | Weight: 0.569148 | Bias: 0.111991\n",
            "Iteration: 182316 | Cost/Loss: 0.074255 | Weight: 0.569149 | Bias: 0.111991\n",
            "Iteration: 182317 | Cost/Loss: 0.074255 | Weight: 0.569149 | Bias: 0.111992\n",
            "Iteration: 182318 | Cost/Loss: 0.074255 | Weight: 0.569149 | Bias: 0.111992\n",
            "Iteration: 182319 | Cost/Loss: 0.074255 | Weight: 0.569150 | Bias: 0.111992\n",
            "Iteration: 182320 | Cost/Loss: 0.074255 | Weight: 0.569150 | Bias: 0.111992\n",
            "Iteration: 182321 | Cost/Loss: 0.074255 | Weight: 0.569150 | Bias: 0.111993\n",
            "Iteration: 182322 | Cost/Loss: 0.074255 | Weight: 0.569151 | Bias: 0.111993\n",
            "Iteration: 182323 | Cost/Loss: 0.074254 | Weight: 0.569151 | Bias: 0.111993\n",
            "Iteration: 182324 | Cost/Loss: 0.074254 | Weight: 0.569151 | Bias: 0.111994\n",
            "Iteration: 182325 | Cost/Loss: 0.074254 | Weight: 0.569151 | Bias: 0.111994\n",
            "Iteration: 182326 | Cost/Loss: 0.074254 | Weight: 0.569152 | Bias: 0.111994\n",
            "Iteration: 182327 | Cost/Loss: 0.074254 | Weight: 0.569152 | Bias: 0.111995\n",
            "Iteration: 182328 | Cost/Loss: 0.074254 | Weight: 0.569152 | Bias: 0.111995\n",
            "Iteration: 182329 | Cost/Loss: 0.074254 | Weight: 0.569153 | Bias: 0.111995\n",
            "Iteration: 182330 | Cost/Loss: 0.074254 | Weight: 0.569153 | Bias: 0.111996\n",
            "Iteration: 182331 | Cost/Loss: 0.074254 | Weight: 0.569153 | Bias: 0.111996\n",
            "Iteration: 182332 | Cost/Loss: 0.074254 | Weight: 0.569154 | Bias: 0.111996\n",
            "Iteration: 182333 | Cost/Loss: 0.074254 | Weight: 0.569154 | Bias: 0.111996\n",
            "Iteration: 182334 | Cost/Loss: 0.074254 | Weight: 0.569154 | Bias: 0.111997\n",
            "Iteration: 182335 | Cost/Loss: 0.074254 | Weight: 0.569154 | Bias: 0.111997\n",
            "Iteration: 182336 | Cost/Loss: 0.074254 | Weight: 0.569155 | Bias: 0.111997\n",
            "Iteration: 182337 | Cost/Loss: 0.074254 | Weight: 0.569155 | Bias: 0.111998\n",
            "Iteration: 182338 | Cost/Loss: 0.074254 | Weight: 0.569155 | Bias: 0.111998\n",
            "Iteration: 182339 | Cost/Loss: 0.074254 | Weight: 0.569156 | Bias: 0.111998\n",
            "Iteration: 182340 | Cost/Loss: 0.074254 | Weight: 0.569156 | Bias: 0.111999\n",
            "Iteration: 182341 | Cost/Loss: 0.074254 | Weight: 0.569156 | Bias: 0.111999\n",
            "Iteration: 182342 | Cost/Loss: 0.074254 | Weight: 0.569157 | Bias: 0.111999\n",
            "Iteration: 182343 | Cost/Loss: 0.074254 | Weight: 0.569157 | Bias: 0.111999\n",
            "Iteration: 182344 | Cost/Loss: 0.074254 | Weight: 0.569157 | Bias: 0.112000\n",
            "Iteration: 182345 | Cost/Loss: 0.074254 | Weight: 0.569157 | Bias: 0.112000\n",
            "Iteration: 182346 | Cost/Loss: 0.074254 | Weight: 0.569158 | Bias: 0.112000\n",
            "Iteration: 182347 | Cost/Loss: 0.074254 | Weight: 0.569158 | Bias: 0.112001\n",
            "Iteration: 182348 | Cost/Loss: 0.074254 | Weight: 0.569158 | Bias: 0.112001\n",
            "Iteration: 182349 | Cost/Loss: 0.074254 | Weight: 0.569159 | Bias: 0.112001\n",
            "Iteration: 182350 | Cost/Loss: 0.074254 | Weight: 0.569159 | Bias: 0.112002\n",
            "Iteration: 182351 | Cost/Loss: 0.074254 | Weight: 0.569159 | Bias: 0.112002\n",
            "Iteration: 182352 | Cost/Loss: 0.074254 | Weight: 0.569160 | Bias: 0.112002\n",
            "Iteration: 182353 | Cost/Loss: 0.074254 | Weight: 0.569160 | Bias: 0.112003\n",
            "Iteration: 182354 | Cost/Loss: 0.074254 | Weight: 0.569160 | Bias: 0.112003\n",
            "Iteration: 182355 | Cost/Loss: 0.074254 | Weight: 0.569160 | Bias: 0.112003\n",
            "Iteration: 182356 | Cost/Loss: 0.074254 | Weight: 0.569161 | Bias: 0.112003\n",
            "Iteration: 182357 | Cost/Loss: 0.074254 | Weight: 0.569161 | Bias: 0.112004\n",
            "Iteration: 182358 | Cost/Loss: 0.074254 | Weight: 0.569161 | Bias: 0.112004\n",
            "Iteration: 182359 | Cost/Loss: 0.074254 | Weight: 0.569162 | Bias: 0.112004\n",
            "Iteration: 182360 | Cost/Loss: 0.074254 | Weight: 0.569162 | Bias: 0.112005\n",
            "Iteration: 182361 | Cost/Loss: 0.074254 | Weight: 0.569162 | Bias: 0.112005\n",
            "Iteration: 182362 | Cost/Loss: 0.074254 | Weight: 0.569162 | Bias: 0.112005\n",
            "Iteration: 182363 | Cost/Loss: 0.074254 | Weight: 0.569163 | Bias: 0.112006\n",
            "Iteration: 182364 | Cost/Loss: 0.074253 | Weight: 0.569163 | Bias: 0.112006\n",
            "Iteration: 182365 | Cost/Loss: 0.074253 | Weight: 0.569163 | Bias: 0.112006\n",
            "Iteration: 182366 | Cost/Loss: 0.074253 | Weight: 0.569164 | Bias: 0.112007\n",
            "Iteration: 182367 | Cost/Loss: 0.074253 | Weight: 0.569164 | Bias: 0.112007\n",
            "Iteration: 182368 | Cost/Loss: 0.074253 | Weight: 0.569164 | Bias: 0.112007\n",
            "Iteration: 182369 | Cost/Loss: 0.074253 | Weight: 0.569165 | Bias: 0.112007\n",
            "Iteration: 182370 | Cost/Loss: 0.074253 | Weight: 0.569165 | Bias: 0.112008\n",
            "Iteration: 182371 | Cost/Loss: 0.074253 | Weight: 0.569165 | Bias: 0.112008\n",
            "Iteration: 182372 | Cost/Loss: 0.074253 | Weight: 0.569165 | Bias: 0.112008\n",
            "Iteration: 182373 | Cost/Loss: 0.074253 | Weight: 0.569166 | Bias: 0.112009\n",
            "Iteration: 182374 | Cost/Loss: 0.074253 | Weight: 0.569166 | Bias: 0.112009\n",
            "Iteration: 182375 | Cost/Loss: 0.074253 | Weight: 0.569166 | Bias: 0.112009\n",
            "Iteration: 182376 | Cost/Loss: 0.074253 | Weight: 0.569167 | Bias: 0.112010\n",
            "Iteration: 182377 | Cost/Loss: 0.074253 | Weight: 0.569167 | Bias: 0.112010\n",
            "Iteration: 182378 | Cost/Loss: 0.074253 | Weight: 0.569167 | Bias: 0.112010\n",
            "Iteration: 182379 | Cost/Loss: 0.074253 | Weight: 0.569168 | Bias: 0.112010\n",
            "Iteration: 182380 | Cost/Loss: 0.074253 | Weight: 0.569168 | Bias: 0.112011\n",
            "Iteration: 182381 | Cost/Loss: 0.074253 | Weight: 0.569168 | Bias: 0.112011\n",
            "Iteration: 182382 | Cost/Loss: 0.074253 | Weight: 0.569168 | Bias: 0.112011\n",
            "Iteration: 182383 | Cost/Loss: 0.074253 | Weight: 0.569169 | Bias: 0.112012\n",
            "Iteration: 182384 | Cost/Loss: 0.074253 | Weight: 0.569169 | Bias: 0.112012\n",
            "Iteration: 182385 | Cost/Loss: 0.074253 | Weight: 0.569169 | Bias: 0.112012\n",
            "Iteration: 182386 | Cost/Loss: 0.074253 | Weight: 0.569170 | Bias: 0.112013\n",
            "Iteration: 182387 | Cost/Loss: 0.074253 | Weight: 0.569170 | Bias: 0.112013\n",
            "Iteration: 182388 | Cost/Loss: 0.074253 | Weight: 0.569170 | Bias: 0.112013\n",
            "Iteration: 182389 | Cost/Loss: 0.074253 | Weight: 0.569171 | Bias: 0.112014\n",
            "Iteration: 182390 | Cost/Loss: 0.074253 | Weight: 0.569171 | Bias: 0.112014\n",
            "Iteration: 182391 | Cost/Loss: 0.074253 | Weight: 0.569171 | Bias: 0.112014\n",
            "Iteration: 182392 | Cost/Loss: 0.074253 | Weight: 0.569171 | Bias: 0.112014\n",
            "Iteration: 182393 | Cost/Loss: 0.074253 | Weight: 0.569172 | Bias: 0.112015\n",
            "Iteration: 182394 | Cost/Loss: 0.074253 | Weight: 0.569172 | Bias: 0.112015\n",
            "Iteration: 182395 | Cost/Loss: 0.074253 | Weight: 0.569172 | Bias: 0.112015\n",
            "Iteration: 182396 | Cost/Loss: 0.074253 | Weight: 0.569173 | Bias: 0.112016\n",
            "Iteration: 182397 | Cost/Loss: 0.074253 | Weight: 0.569173 | Bias: 0.112016\n",
            "Iteration: 182398 | Cost/Loss: 0.074253 | Weight: 0.569173 | Bias: 0.112016\n",
            "Iteration: 182399 | Cost/Loss: 0.074253 | Weight: 0.569174 | Bias: 0.112017\n",
            "Iteration: 182400 | Cost/Loss: 0.074253 | Weight: 0.569174 | Bias: 0.112017\n",
            "Iteration: 182401 | Cost/Loss: 0.074253 | Weight: 0.569174 | Bias: 0.112017\n",
            "Iteration: 182402 | Cost/Loss: 0.074253 | Weight: 0.569174 | Bias: 0.112017\n",
            "Iteration: 182403 | Cost/Loss: 0.074253 | Weight: 0.569175 | Bias: 0.112018\n",
            "Iteration: 182404 | Cost/Loss: 0.074253 | Weight: 0.569175 | Bias: 0.112018\n",
            "Iteration: 182405 | Cost/Loss: 0.074252 | Weight: 0.569175 | Bias: 0.112018\n",
            "Iteration: 182406 | Cost/Loss: 0.074252 | Weight: 0.569176 | Bias: 0.112019\n",
            "Iteration: 182407 | Cost/Loss: 0.074252 | Weight: 0.569176 | Bias: 0.112019\n",
            "Iteration: 182408 | Cost/Loss: 0.074252 | Weight: 0.569176 | Bias: 0.112019\n",
            "Iteration: 182409 | Cost/Loss: 0.074252 | Weight: 0.569176 | Bias: 0.112020\n",
            "Iteration: 182410 | Cost/Loss: 0.074252 | Weight: 0.569177 | Bias: 0.112020\n",
            "Iteration: 182411 | Cost/Loss: 0.074252 | Weight: 0.569177 | Bias: 0.112020\n",
            "Iteration: 182412 | Cost/Loss: 0.074252 | Weight: 0.569177 | Bias: 0.112021\n",
            "Iteration: 182413 | Cost/Loss: 0.074252 | Weight: 0.569178 | Bias: 0.112021\n",
            "Iteration: 182414 | Cost/Loss: 0.074252 | Weight: 0.569178 | Bias: 0.112021\n",
            "Iteration: 182415 | Cost/Loss: 0.074252 | Weight: 0.569178 | Bias: 0.112021\n",
            "Iteration: 182416 | Cost/Loss: 0.074252 | Weight: 0.569179 | Bias: 0.112022\n",
            "Iteration: 182417 | Cost/Loss: 0.074252 | Weight: 0.569179 | Bias: 0.112022\n",
            "Iteration: 182418 | Cost/Loss: 0.074252 | Weight: 0.569179 | Bias: 0.112022\n",
            "Iteration: 182419 | Cost/Loss: 0.074252 | Weight: 0.569179 | Bias: 0.112023\n",
            "Iteration: 182420 | Cost/Loss: 0.074252 | Weight: 0.569180 | Bias: 0.112023\n",
            "Iteration: 182421 | Cost/Loss: 0.074252 | Weight: 0.569180 | Bias: 0.112023\n",
            "Iteration: 182422 | Cost/Loss: 0.074252 | Weight: 0.569180 | Bias: 0.112024\n",
            "Iteration: 182423 | Cost/Loss: 0.074252 | Weight: 0.569181 | Bias: 0.112024\n",
            "Iteration: 182424 | Cost/Loss: 0.074252 | Weight: 0.569181 | Bias: 0.112024\n",
            "Iteration: 182425 | Cost/Loss: 0.074252 | Weight: 0.569181 | Bias: 0.112025\n",
            "Iteration: 182426 | Cost/Loss: 0.074252 | Weight: 0.569182 | Bias: 0.112025\n",
            "Iteration: 182427 | Cost/Loss: 0.074252 | Weight: 0.569182 | Bias: 0.112025\n",
            "Iteration: 182428 | Cost/Loss: 0.074252 | Weight: 0.569182 | Bias: 0.112025\n",
            "Iteration: 182429 | Cost/Loss: 0.074252 | Weight: 0.569182 | Bias: 0.112026\n",
            "Iteration: 182430 | Cost/Loss: 0.074252 | Weight: 0.569183 | Bias: 0.112026\n",
            "Iteration: 182431 | Cost/Loss: 0.074252 | Weight: 0.569183 | Bias: 0.112026\n",
            "Iteration: 182432 | Cost/Loss: 0.074252 | Weight: 0.569183 | Bias: 0.112027\n",
            "Iteration: 182433 | Cost/Loss: 0.074252 | Weight: 0.569184 | Bias: 0.112027\n",
            "Iteration: 182434 | Cost/Loss: 0.074252 | Weight: 0.569184 | Bias: 0.112027\n",
            "Iteration: 182435 | Cost/Loss: 0.074252 | Weight: 0.569184 | Bias: 0.112028\n",
            "Iteration: 182436 | Cost/Loss: 0.074252 | Weight: 0.569185 | Bias: 0.112028\n",
            "Iteration: 182437 | Cost/Loss: 0.074252 | Weight: 0.569185 | Bias: 0.112028\n",
            "Iteration: 182438 | Cost/Loss: 0.074252 | Weight: 0.569185 | Bias: 0.112028\n",
            "Iteration: 182439 | Cost/Loss: 0.074252 | Weight: 0.569185 | Bias: 0.112029\n",
            "Iteration: 182440 | Cost/Loss: 0.074252 | Weight: 0.569186 | Bias: 0.112029\n",
            "Iteration: 182441 | Cost/Loss: 0.074252 | Weight: 0.569186 | Bias: 0.112029\n",
            "Iteration: 182442 | Cost/Loss: 0.074252 | Weight: 0.569186 | Bias: 0.112030\n",
            "Iteration: 182443 | Cost/Loss: 0.074252 | Weight: 0.569187 | Bias: 0.112030\n",
            "Iteration: 182444 | Cost/Loss: 0.074252 | Weight: 0.569187 | Bias: 0.112030\n",
            "Iteration: 182445 | Cost/Loss: 0.074251 | Weight: 0.569187 | Bias: 0.112031\n",
            "Iteration: 182446 | Cost/Loss: 0.074251 | Weight: 0.569188 | Bias: 0.112031\n",
            "Iteration: 182447 | Cost/Loss: 0.074251 | Weight: 0.569188 | Bias: 0.112031\n",
            "Iteration: 182448 | Cost/Loss: 0.074251 | Weight: 0.569188 | Bias: 0.112032\n",
            "Iteration: 182449 | Cost/Loss: 0.074251 | Weight: 0.569188 | Bias: 0.112032\n",
            "Iteration: 182450 | Cost/Loss: 0.074251 | Weight: 0.569189 | Bias: 0.112032\n",
            "Iteration: 182451 | Cost/Loss: 0.074251 | Weight: 0.569189 | Bias: 0.112032\n",
            "Iteration: 182452 | Cost/Loss: 0.074251 | Weight: 0.569189 | Bias: 0.112033\n",
            "Iteration: 182453 | Cost/Loss: 0.074251 | Weight: 0.569190 | Bias: 0.112033\n",
            "Iteration: 182454 | Cost/Loss: 0.074251 | Weight: 0.569190 | Bias: 0.112033\n",
            "Iteration: 182455 | Cost/Loss: 0.074251 | Weight: 0.569190 | Bias: 0.112034\n",
            "Iteration: 182456 | Cost/Loss: 0.074251 | Weight: 0.569191 | Bias: 0.112034\n",
            "Iteration: 182457 | Cost/Loss: 0.074251 | Weight: 0.569191 | Bias: 0.112034\n",
            "Iteration: 182458 | Cost/Loss: 0.074251 | Weight: 0.569191 | Bias: 0.112035\n",
            "Iteration: 182459 | Cost/Loss: 0.074251 | Weight: 0.569191 | Bias: 0.112035\n",
            "Iteration: 182460 | Cost/Loss: 0.074251 | Weight: 0.569192 | Bias: 0.112035\n",
            "Iteration: 182461 | Cost/Loss: 0.074251 | Weight: 0.569192 | Bias: 0.112036\n",
            "Iteration: 182462 | Cost/Loss: 0.074251 | Weight: 0.569192 | Bias: 0.112036\n",
            "Iteration: 182463 | Cost/Loss: 0.074251 | Weight: 0.569193 | Bias: 0.112036\n",
            "Iteration: 182464 | Cost/Loss: 0.074251 | Weight: 0.569193 | Bias: 0.112036\n",
            "Iteration: 182465 | Cost/Loss: 0.074251 | Weight: 0.569193 | Bias: 0.112037\n",
            "Iteration: 182466 | Cost/Loss: 0.074251 | Weight: 0.569193 | Bias: 0.112037\n",
            "Iteration: 182467 | Cost/Loss: 0.074251 | Weight: 0.569194 | Bias: 0.112037\n",
            "Iteration: 182468 | Cost/Loss: 0.074251 | Weight: 0.569194 | Bias: 0.112038\n",
            "Iteration: 182469 | Cost/Loss: 0.074251 | Weight: 0.569194 | Bias: 0.112038\n",
            "Iteration: 182470 | Cost/Loss: 0.074251 | Weight: 0.569195 | Bias: 0.112038\n",
            "Iteration: 182471 | Cost/Loss: 0.074251 | Weight: 0.569195 | Bias: 0.112039\n",
            "Iteration: 182472 | Cost/Loss: 0.074251 | Weight: 0.569195 | Bias: 0.112039\n",
            "Iteration: 182473 | Cost/Loss: 0.074251 | Weight: 0.569196 | Bias: 0.112039\n",
            "Iteration: 182474 | Cost/Loss: 0.074251 | Weight: 0.569196 | Bias: 0.112039\n",
            "Iteration: 182475 | Cost/Loss: 0.074251 | Weight: 0.569196 | Bias: 0.112040\n",
            "Iteration: 182476 | Cost/Loss: 0.074251 | Weight: 0.569196 | Bias: 0.112040\n",
            "Iteration: 182477 | Cost/Loss: 0.074251 | Weight: 0.569197 | Bias: 0.112040\n",
            "Iteration: 182478 | Cost/Loss: 0.074251 | Weight: 0.569197 | Bias: 0.112041\n",
            "Iteration: 182479 | Cost/Loss: 0.074251 | Weight: 0.569197 | Bias: 0.112041\n",
            "Iteration: 182480 | Cost/Loss: 0.074251 | Weight: 0.569198 | Bias: 0.112041\n",
            "Iteration: 182481 | Cost/Loss: 0.074251 | Weight: 0.569198 | Bias: 0.112042\n",
            "Iteration: 182482 | Cost/Loss: 0.074251 | Weight: 0.569198 | Bias: 0.112042\n",
            "Iteration: 182483 | Cost/Loss: 0.074251 | Weight: 0.569199 | Bias: 0.112042\n",
            "Iteration: 182484 | Cost/Loss: 0.074251 | Weight: 0.569199 | Bias: 0.112043\n",
            "Iteration: 182485 | Cost/Loss: 0.074251 | Weight: 0.569199 | Bias: 0.112043\n",
            "Iteration: 182486 | Cost/Loss: 0.074250 | Weight: 0.569199 | Bias: 0.112043\n",
            "Iteration: 182487 | Cost/Loss: 0.074250 | Weight: 0.569200 | Bias: 0.112043\n",
            "Iteration: 182488 | Cost/Loss: 0.074250 | Weight: 0.569200 | Bias: 0.112044\n",
            "Iteration: 182489 | Cost/Loss: 0.074250 | Weight: 0.569200 | Bias: 0.112044\n",
            "Iteration: 182490 | Cost/Loss: 0.074250 | Weight: 0.569201 | Bias: 0.112044\n",
            "Iteration: 182491 | Cost/Loss: 0.074250 | Weight: 0.569201 | Bias: 0.112045\n",
            "Iteration: 182492 | Cost/Loss: 0.074250 | Weight: 0.569201 | Bias: 0.112045\n",
            "Iteration: 182493 | Cost/Loss: 0.074250 | Weight: 0.569202 | Bias: 0.112045\n",
            "Iteration: 182494 | Cost/Loss: 0.074250 | Weight: 0.569202 | Bias: 0.112046\n",
            "Iteration: 182495 | Cost/Loss: 0.074250 | Weight: 0.569202 | Bias: 0.112046\n",
            "Iteration: 182496 | Cost/Loss: 0.074250 | Weight: 0.569202 | Bias: 0.112046\n",
            "Iteration: 182497 | Cost/Loss: 0.074250 | Weight: 0.569203 | Bias: 0.112047\n",
            "Iteration: 182498 | Cost/Loss: 0.074250 | Weight: 0.569203 | Bias: 0.112047\n",
            "Iteration: 182499 | Cost/Loss: 0.074250 | Weight: 0.569203 | Bias: 0.112047\n",
            "Iteration: 182500 | Cost/Loss: 0.074250 | Weight: 0.569204 | Bias: 0.112047\n",
            "Iteration: 182501 | Cost/Loss: 0.074250 | Weight: 0.569204 | Bias: 0.112048\n",
            "Iteration: 182502 | Cost/Loss: 0.074250 | Weight: 0.569204 | Bias: 0.112048\n",
            "Iteration: 182503 | Cost/Loss: 0.074250 | Weight: 0.569205 | Bias: 0.112048\n",
            "Iteration: 182504 | Cost/Loss: 0.074250 | Weight: 0.569205 | Bias: 0.112049\n",
            "Iteration: 182505 | Cost/Loss: 0.074250 | Weight: 0.569205 | Bias: 0.112049\n",
            "Iteration: 182506 | Cost/Loss: 0.074250 | Weight: 0.569205 | Bias: 0.112049\n",
            "Iteration: 182507 | Cost/Loss: 0.074250 | Weight: 0.569206 | Bias: 0.112050\n",
            "Iteration: 182508 | Cost/Loss: 0.074250 | Weight: 0.569206 | Bias: 0.112050\n",
            "Iteration: 182509 | Cost/Loss: 0.074250 | Weight: 0.569206 | Bias: 0.112050\n",
            "Iteration: 182510 | Cost/Loss: 0.074250 | Weight: 0.569207 | Bias: 0.112050\n",
            "Iteration: 182511 | Cost/Loss: 0.074250 | Weight: 0.569207 | Bias: 0.112051\n",
            "Iteration: 182512 | Cost/Loss: 0.074250 | Weight: 0.569207 | Bias: 0.112051\n",
            "Iteration: 182513 | Cost/Loss: 0.074250 | Weight: 0.569207 | Bias: 0.112051\n",
            "Iteration: 182514 | Cost/Loss: 0.074250 | Weight: 0.569208 | Bias: 0.112052\n",
            "Iteration: 182515 | Cost/Loss: 0.074250 | Weight: 0.569208 | Bias: 0.112052\n",
            "Iteration: 182516 | Cost/Loss: 0.074250 | Weight: 0.569208 | Bias: 0.112052\n",
            "Iteration: 182517 | Cost/Loss: 0.074250 | Weight: 0.569209 | Bias: 0.112053\n",
            "Iteration: 182518 | Cost/Loss: 0.074250 | Weight: 0.569209 | Bias: 0.112053\n",
            "Iteration: 182519 | Cost/Loss: 0.074250 | Weight: 0.569209 | Bias: 0.112053\n",
            "Iteration: 182520 | Cost/Loss: 0.074250 | Weight: 0.569210 | Bias: 0.112054\n",
            "Iteration: 182521 | Cost/Loss: 0.074250 | Weight: 0.569210 | Bias: 0.112054\n",
            "Iteration: 182522 | Cost/Loss: 0.074250 | Weight: 0.569210 | Bias: 0.112054\n",
            "Iteration: 182523 | Cost/Loss: 0.074250 | Weight: 0.569210 | Bias: 0.112054\n",
            "Iteration: 182524 | Cost/Loss: 0.074250 | Weight: 0.569211 | Bias: 0.112055\n",
            "Iteration: 182525 | Cost/Loss: 0.074250 | Weight: 0.569211 | Bias: 0.112055\n",
            "Iteration: 182526 | Cost/Loss: 0.074250 | Weight: 0.569211 | Bias: 0.112055\n",
            "Iteration: 182527 | Cost/Loss: 0.074249 | Weight: 0.569212 | Bias: 0.112056\n",
            "Iteration: 182528 | Cost/Loss: 0.074249 | Weight: 0.569212 | Bias: 0.112056\n",
            "Iteration: 182529 | Cost/Loss: 0.074249 | Weight: 0.569212 | Bias: 0.112056\n",
            "Iteration: 182530 | Cost/Loss: 0.074249 | Weight: 0.569213 | Bias: 0.112057\n",
            "Iteration: 182531 | Cost/Loss: 0.074249 | Weight: 0.569213 | Bias: 0.112057\n",
            "Iteration: 182532 | Cost/Loss: 0.074249 | Weight: 0.569213 | Bias: 0.112057\n",
            "Iteration: 182533 | Cost/Loss: 0.074249 | Weight: 0.569213 | Bias: 0.112058\n",
            "Iteration: 182534 | Cost/Loss: 0.074249 | Weight: 0.569214 | Bias: 0.112058\n",
            "Iteration: 182535 | Cost/Loss: 0.074249 | Weight: 0.569214 | Bias: 0.112058\n",
            "Iteration: 182536 | Cost/Loss: 0.074249 | Weight: 0.569214 | Bias: 0.112058\n",
            "Iteration: 182537 | Cost/Loss: 0.074249 | Weight: 0.569215 | Bias: 0.112059\n",
            "Iteration: 182538 | Cost/Loss: 0.074249 | Weight: 0.569215 | Bias: 0.112059\n",
            "Iteration: 182539 | Cost/Loss: 0.074249 | Weight: 0.569215 | Bias: 0.112059\n",
            "Iteration: 182540 | Cost/Loss: 0.074249 | Weight: 0.569216 | Bias: 0.112060\n",
            "Iteration: 182541 | Cost/Loss: 0.074249 | Weight: 0.569216 | Bias: 0.112060\n",
            "Iteration: 182542 | Cost/Loss: 0.074249 | Weight: 0.569216 | Bias: 0.112060\n",
            "Iteration: 182543 | Cost/Loss: 0.074249 | Weight: 0.569216 | Bias: 0.112061\n",
            "Iteration: 182544 | Cost/Loss: 0.074249 | Weight: 0.569217 | Bias: 0.112061\n",
            "Iteration: 182545 | Cost/Loss: 0.074249 | Weight: 0.569217 | Bias: 0.112061\n",
            "Iteration: 182546 | Cost/Loss: 0.074249 | Weight: 0.569217 | Bias: 0.112061\n",
            "Iteration: 182547 | Cost/Loss: 0.074249 | Weight: 0.569218 | Bias: 0.112062\n",
            "Iteration: 182548 | Cost/Loss: 0.074249 | Weight: 0.569218 | Bias: 0.112062\n",
            "Iteration: 182549 | Cost/Loss: 0.074249 | Weight: 0.569218 | Bias: 0.112062\n",
            "Iteration: 182550 | Cost/Loss: 0.074249 | Weight: 0.569219 | Bias: 0.112063\n",
            "Iteration: 182551 | Cost/Loss: 0.074249 | Weight: 0.569219 | Bias: 0.112063\n",
            "Iteration: 182552 | Cost/Loss: 0.074249 | Weight: 0.569219 | Bias: 0.112063\n",
            "Iteration: 182553 | Cost/Loss: 0.074249 | Weight: 0.569219 | Bias: 0.112064\n",
            "Iteration: 182554 | Cost/Loss: 0.074249 | Weight: 0.569220 | Bias: 0.112064\n",
            "Iteration: 182555 | Cost/Loss: 0.074249 | Weight: 0.569220 | Bias: 0.112064\n",
            "Iteration: 182556 | Cost/Loss: 0.074249 | Weight: 0.569220 | Bias: 0.112065\n",
            "Iteration: 182557 | Cost/Loss: 0.074249 | Weight: 0.569221 | Bias: 0.112065\n",
            "Iteration: 182558 | Cost/Loss: 0.074249 | Weight: 0.569221 | Bias: 0.112065\n",
            "Iteration: 182559 | Cost/Loss: 0.074249 | Weight: 0.569221 | Bias: 0.112065\n",
            "Iteration: 182560 | Cost/Loss: 0.074249 | Weight: 0.569221 | Bias: 0.112066\n",
            "Iteration: 182561 | Cost/Loss: 0.074249 | Weight: 0.569222 | Bias: 0.112066\n",
            "Iteration: 182562 | Cost/Loss: 0.074249 | Weight: 0.569222 | Bias: 0.112066\n",
            "Iteration: 182563 | Cost/Loss: 0.074249 | Weight: 0.569222 | Bias: 0.112067\n",
            "Iteration: 182564 | Cost/Loss: 0.074249 | Weight: 0.569223 | Bias: 0.112067\n",
            "Iteration: 182565 | Cost/Loss: 0.074249 | Weight: 0.569223 | Bias: 0.112067\n",
            "Iteration: 182566 | Cost/Loss: 0.074249 | Weight: 0.569223 | Bias: 0.112068\n",
            "Iteration: 182567 | Cost/Loss: 0.074248 | Weight: 0.569224 | Bias: 0.112068\n",
            "Iteration: 182568 | Cost/Loss: 0.074248 | Weight: 0.569224 | Bias: 0.112068\n",
            "Iteration: 182569 | Cost/Loss: 0.074248 | Weight: 0.569224 | Bias: 0.112069\n",
            "Iteration: 182570 | Cost/Loss: 0.074248 | Weight: 0.569224 | Bias: 0.112069\n",
            "Iteration: 182571 | Cost/Loss: 0.074248 | Weight: 0.569225 | Bias: 0.112069\n",
            "Iteration: 182572 | Cost/Loss: 0.074248 | Weight: 0.569225 | Bias: 0.112069\n",
            "Iteration: 182573 | Cost/Loss: 0.074248 | Weight: 0.569225 | Bias: 0.112070\n",
            "Iteration: 182574 | Cost/Loss: 0.074248 | Weight: 0.569226 | Bias: 0.112070\n",
            "Iteration: 182575 | Cost/Loss: 0.074248 | Weight: 0.569226 | Bias: 0.112070\n",
            "Iteration: 182576 | Cost/Loss: 0.074248 | Weight: 0.569226 | Bias: 0.112071\n",
            "Iteration: 182577 | Cost/Loss: 0.074248 | Weight: 0.569227 | Bias: 0.112071\n",
            "Iteration: 182578 | Cost/Loss: 0.074248 | Weight: 0.569227 | Bias: 0.112071\n",
            "Iteration: 182579 | Cost/Loss: 0.074248 | Weight: 0.569227 | Bias: 0.112072\n",
            "Iteration: 182580 | Cost/Loss: 0.074248 | Weight: 0.569227 | Bias: 0.112072\n",
            "Iteration: 182581 | Cost/Loss: 0.074248 | Weight: 0.569228 | Bias: 0.112072\n",
            "Iteration: 182582 | Cost/Loss: 0.074248 | Weight: 0.569228 | Bias: 0.112072\n",
            "Iteration: 182583 | Cost/Loss: 0.074248 | Weight: 0.569228 | Bias: 0.112073\n",
            "Iteration: 182584 | Cost/Loss: 0.074248 | Weight: 0.569229 | Bias: 0.112073\n",
            "Iteration: 182585 | Cost/Loss: 0.074248 | Weight: 0.569229 | Bias: 0.112073\n",
            "Iteration: 182586 | Cost/Loss: 0.074248 | Weight: 0.569229 | Bias: 0.112074\n",
            "Iteration: 182587 | Cost/Loss: 0.074248 | Weight: 0.569230 | Bias: 0.112074\n",
            "Iteration: 182588 | Cost/Loss: 0.074248 | Weight: 0.569230 | Bias: 0.112074\n",
            "Iteration: 182589 | Cost/Loss: 0.074248 | Weight: 0.569230 | Bias: 0.112075\n",
            "Iteration: 182590 | Cost/Loss: 0.074248 | Weight: 0.569230 | Bias: 0.112075\n",
            "Iteration: 182591 | Cost/Loss: 0.074248 | Weight: 0.569231 | Bias: 0.112075\n",
            "Iteration: 182592 | Cost/Loss: 0.074248 | Weight: 0.569231 | Bias: 0.112076\n",
            "Iteration: 182593 | Cost/Loss: 0.074248 | Weight: 0.569231 | Bias: 0.112076\n",
            "Iteration: 182594 | Cost/Loss: 0.074248 | Weight: 0.569232 | Bias: 0.112076\n",
            "Iteration: 182595 | Cost/Loss: 0.074248 | Weight: 0.569232 | Bias: 0.112076\n",
            "Iteration: 182596 | Cost/Loss: 0.074248 | Weight: 0.569232 | Bias: 0.112077\n",
            "Iteration: 182597 | Cost/Loss: 0.074248 | Weight: 0.569233 | Bias: 0.112077\n",
            "Iteration: 182598 | Cost/Loss: 0.074248 | Weight: 0.569233 | Bias: 0.112077\n",
            "Iteration: 182599 | Cost/Loss: 0.074248 | Weight: 0.569233 | Bias: 0.112078\n",
            "Iteration: 182600 | Cost/Loss: 0.074248 | Weight: 0.569233 | Bias: 0.112078\n",
            "Iteration: 182601 | Cost/Loss: 0.074248 | Weight: 0.569234 | Bias: 0.112078\n",
            "Iteration: 182602 | Cost/Loss: 0.074248 | Weight: 0.569234 | Bias: 0.112079\n",
            "Iteration: 182603 | Cost/Loss: 0.074248 | Weight: 0.569234 | Bias: 0.112079\n",
            "Iteration: 182604 | Cost/Loss: 0.074248 | Weight: 0.569235 | Bias: 0.112079\n",
            "Iteration: 182605 | Cost/Loss: 0.074248 | Weight: 0.569235 | Bias: 0.112080\n",
            "Iteration: 182606 | Cost/Loss: 0.074248 | Weight: 0.569235 | Bias: 0.112080\n",
            "Iteration: 182607 | Cost/Loss: 0.074248 | Weight: 0.569236 | Bias: 0.112080\n",
            "Iteration: 182608 | Cost/Loss: 0.074247 | Weight: 0.569236 | Bias: 0.112080\n",
            "Iteration: 182609 | Cost/Loss: 0.074247 | Weight: 0.569236 | Bias: 0.112081\n",
            "Iteration: 182610 | Cost/Loss: 0.074247 | Weight: 0.569236 | Bias: 0.112081\n",
            "Iteration: 182611 | Cost/Loss: 0.074247 | Weight: 0.569237 | Bias: 0.112081\n",
            "Iteration: 182612 | Cost/Loss: 0.074247 | Weight: 0.569237 | Bias: 0.112082\n",
            "Iteration: 182613 | Cost/Loss: 0.074247 | Weight: 0.569237 | Bias: 0.112082\n",
            "Iteration: 182614 | Cost/Loss: 0.074247 | Weight: 0.569238 | Bias: 0.112082\n",
            "Iteration: 182615 | Cost/Loss: 0.074247 | Weight: 0.569238 | Bias: 0.112083\n",
            "Iteration: 182616 | Cost/Loss: 0.074247 | Weight: 0.569238 | Bias: 0.112083\n",
            "Iteration: 182617 | Cost/Loss: 0.074247 | Weight: 0.569238 | Bias: 0.112083\n",
            "Iteration: 182618 | Cost/Loss: 0.074247 | Weight: 0.569239 | Bias: 0.112083\n",
            "Iteration: 182619 | Cost/Loss: 0.074247 | Weight: 0.569239 | Bias: 0.112084\n",
            "Iteration: 182620 | Cost/Loss: 0.074247 | Weight: 0.569239 | Bias: 0.112084\n",
            "Iteration: 182621 | Cost/Loss: 0.074247 | Weight: 0.569240 | Bias: 0.112084\n",
            "Iteration: 182622 | Cost/Loss: 0.074247 | Weight: 0.569240 | Bias: 0.112085\n",
            "Iteration: 182623 | Cost/Loss: 0.074247 | Weight: 0.569240 | Bias: 0.112085\n",
            "Iteration: 182624 | Cost/Loss: 0.074247 | Weight: 0.569241 | Bias: 0.112085\n",
            "Iteration: 182625 | Cost/Loss: 0.074247 | Weight: 0.569241 | Bias: 0.112086\n",
            "Iteration: 182626 | Cost/Loss: 0.074247 | Weight: 0.569241 | Bias: 0.112086\n",
            "Iteration: 182627 | Cost/Loss: 0.074247 | Weight: 0.569241 | Bias: 0.112086\n",
            "Iteration: 182628 | Cost/Loss: 0.074247 | Weight: 0.569242 | Bias: 0.112087\n",
            "Iteration: 182629 | Cost/Loss: 0.074247 | Weight: 0.569242 | Bias: 0.112087\n",
            "Iteration: 182630 | Cost/Loss: 0.074247 | Weight: 0.569242 | Bias: 0.112087\n",
            "Iteration: 182631 | Cost/Loss: 0.074247 | Weight: 0.569243 | Bias: 0.112087\n",
            "Iteration: 182632 | Cost/Loss: 0.074247 | Weight: 0.569243 | Bias: 0.112088\n",
            "Iteration: 182633 | Cost/Loss: 0.074247 | Weight: 0.569243 | Bias: 0.112088\n",
            "Iteration: 182634 | Cost/Loss: 0.074247 | Weight: 0.569244 | Bias: 0.112088\n",
            "Iteration: 182635 | Cost/Loss: 0.074247 | Weight: 0.569244 | Bias: 0.112089\n",
            "Iteration: 182636 | Cost/Loss: 0.074247 | Weight: 0.569244 | Bias: 0.112089\n",
            "Iteration: 182637 | Cost/Loss: 0.074247 | Weight: 0.569244 | Bias: 0.112089\n",
            "Iteration: 182638 | Cost/Loss: 0.074247 | Weight: 0.569245 | Bias: 0.112090\n",
            "Iteration: 182639 | Cost/Loss: 0.074247 | Weight: 0.569245 | Bias: 0.112090\n",
            "Iteration: 182640 | Cost/Loss: 0.074247 | Weight: 0.569245 | Bias: 0.112090\n",
            "Iteration: 182641 | Cost/Loss: 0.074247 | Weight: 0.569246 | Bias: 0.112091\n",
            "Iteration: 182642 | Cost/Loss: 0.074247 | Weight: 0.569246 | Bias: 0.112091\n",
            "Iteration: 182643 | Cost/Loss: 0.074247 | Weight: 0.569246 | Bias: 0.112091\n",
            "Iteration: 182644 | Cost/Loss: 0.074247 | Weight: 0.569247 | Bias: 0.112091\n",
            "Iteration: 182645 | Cost/Loss: 0.074247 | Weight: 0.569247 | Bias: 0.112092\n",
            "Iteration: 182646 | Cost/Loss: 0.074247 | Weight: 0.569247 | Bias: 0.112092\n",
            "Iteration: 182647 | Cost/Loss: 0.074247 | Weight: 0.569247 | Bias: 0.112092\n",
            "Iteration: 182648 | Cost/Loss: 0.074246 | Weight: 0.569248 | Bias: 0.112093\n",
            "Iteration: 182649 | Cost/Loss: 0.074246 | Weight: 0.569248 | Bias: 0.112093\n",
            "Iteration: 182650 | Cost/Loss: 0.074246 | Weight: 0.569248 | Bias: 0.112093\n",
            "Iteration: 182651 | Cost/Loss: 0.074246 | Weight: 0.569249 | Bias: 0.112094\n",
            "Iteration: 182652 | Cost/Loss: 0.074246 | Weight: 0.569249 | Bias: 0.112094\n",
            "Iteration: 182653 | Cost/Loss: 0.074246 | Weight: 0.569249 | Bias: 0.112094\n",
            "Iteration: 182654 | Cost/Loss: 0.074246 | Weight: 0.569250 | Bias: 0.112094\n",
            "Iteration: 182655 | Cost/Loss: 0.074246 | Weight: 0.569250 | Bias: 0.112095\n",
            "Iteration: 182656 | Cost/Loss: 0.074246 | Weight: 0.569250 | Bias: 0.112095\n",
            "Iteration: 182657 | Cost/Loss: 0.074246 | Weight: 0.569250 | Bias: 0.112095\n",
            "Iteration: 182658 | Cost/Loss: 0.074246 | Weight: 0.569251 | Bias: 0.112096\n",
            "Iteration: 182659 | Cost/Loss: 0.074246 | Weight: 0.569251 | Bias: 0.112096\n",
            "Iteration: 182660 | Cost/Loss: 0.074246 | Weight: 0.569251 | Bias: 0.112096\n",
            "Iteration: 182661 | Cost/Loss: 0.074246 | Weight: 0.569252 | Bias: 0.112097\n",
            "Iteration: 182662 | Cost/Loss: 0.074246 | Weight: 0.569252 | Bias: 0.112097\n",
            "Iteration: 182663 | Cost/Loss: 0.074246 | Weight: 0.569252 | Bias: 0.112097\n",
            "Iteration: 182664 | Cost/Loss: 0.074246 | Weight: 0.569252 | Bias: 0.112098\n",
            "Iteration: 182665 | Cost/Loss: 0.074246 | Weight: 0.569253 | Bias: 0.112098\n",
            "Iteration: 182666 | Cost/Loss: 0.074246 | Weight: 0.569253 | Bias: 0.112098\n",
            "Iteration: 182667 | Cost/Loss: 0.074246 | Weight: 0.569253 | Bias: 0.112098\n",
            "Iteration: 182668 | Cost/Loss: 0.074246 | Weight: 0.569254 | Bias: 0.112099\n",
            "Iteration: 182669 | Cost/Loss: 0.074246 | Weight: 0.569254 | Bias: 0.112099\n",
            "Iteration: 182670 | Cost/Loss: 0.074246 | Weight: 0.569254 | Bias: 0.112099\n",
            "Iteration: 182671 | Cost/Loss: 0.074246 | Weight: 0.569255 | Bias: 0.112100\n",
            "Iteration: 182672 | Cost/Loss: 0.074246 | Weight: 0.569255 | Bias: 0.112100\n",
            "Iteration: 182673 | Cost/Loss: 0.074246 | Weight: 0.569255 | Bias: 0.112100\n",
            "Iteration: 182674 | Cost/Loss: 0.074246 | Weight: 0.569255 | Bias: 0.112101\n",
            "Iteration: 182675 | Cost/Loss: 0.074246 | Weight: 0.569256 | Bias: 0.112101\n",
            "Iteration: 182676 | Cost/Loss: 0.074246 | Weight: 0.569256 | Bias: 0.112101\n",
            "Iteration: 182677 | Cost/Loss: 0.074246 | Weight: 0.569256 | Bias: 0.112102\n",
            "Iteration: 182678 | Cost/Loss: 0.074246 | Weight: 0.569257 | Bias: 0.112102\n",
            "Iteration: 182679 | Cost/Loss: 0.074246 | Weight: 0.569257 | Bias: 0.112102\n",
            "Iteration: 182680 | Cost/Loss: 0.074246 | Weight: 0.569257 | Bias: 0.112102\n",
            "Iteration: 182681 | Cost/Loss: 0.074246 | Weight: 0.569258 | Bias: 0.112103\n",
            "Iteration: 182682 | Cost/Loss: 0.074246 | Weight: 0.569258 | Bias: 0.112103\n",
            "Iteration: 182683 | Cost/Loss: 0.074246 | Weight: 0.569258 | Bias: 0.112103\n",
            "Iteration: 182684 | Cost/Loss: 0.074246 | Weight: 0.569258 | Bias: 0.112104\n",
            "Iteration: 182685 | Cost/Loss: 0.074246 | Weight: 0.569259 | Bias: 0.112104\n",
            "Iteration: 182686 | Cost/Loss: 0.074246 | Weight: 0.569259 | Bias: 0.112104\n",
            "Iteration: 182687 | Cost/Loss: 0.074246 | Weight: 0.569259 | Bias: 0.112105\n",
            "Iteration: 182688 | Cost/Loss: 0.074246 | Weight: 0.569260 | Bias: 0.112105\n",
            "Iteration: 182689 | Cost/Loss: 0.074245 | Weight: 0.569260 | Bias: 0.112105\n",
            "Iteration: 182690 | Cost/Loss: 0.074245 | Weight: 0.569260 | Bias: 0.112105\n",
            "Iteration: 182691 | Cost/Loss: 0.074245 | Weight: 0.569261 | Bias: 0.112106\n",
            "Iteration: 182692 | Cost/Loss: 0.074245 | Weight: 0.569261 | Bias: 0.112106\n",
            "Iteration: 182693 | Cost/Loss: 0.074245 | Weight: 0.569261 | Bias: 0.112106\n",
            "Iteration: 182694 | Cost/Loss: 0.074245 | Weight: 0.569261 | Bias: 0.112107\n",
            "Iteration: 182695 | Cost/Loss: 0.074245 | Weight: 0.569262 | Bias: 0.112107\n",
            "Iteration: 182696 | Cost/Loss: 0.074245 | Weight: 0.569262 | Bias: 0.112107\n",
            "Iteration: 182697 | Cost/Loss: 0.074245 | Weight: 0.569262 | Bias: 0.112108\n",
            "Iteration: 182698 | Cost/Loss: 0.074245 | Weight: 0.569263 | Bias: 0.112108\n",
            "Iteration: 182699 | Cost/Loss: 0.074245 | Weight: 0.569263 | Bias: 0.112108\n",
            "Iteration: 182700 | Cost/Loss: 0.074245 | Weight: 0.569263 | Bias: 0.112109\n",
            "Iteration: 182701 | Cost/Loss: 0.074245 | Weight: 0.569264 | Bias: 0.112109\n",
            "Iteration: 182702 | Cost/Loss: 0.074245 | Weight: 0.569264 | Bias: 0.112109\n",
            "Iteration: 182703 | Cost/Loss: 0.074245 | Weight: 0.569264 | Bias: 0.112109\n",
            "Iteration: 182704 | Cost/Loss: 0.074245 | Weight: 0.569264 | Bias: 0.112110\n",
            "Iteration: 182705 | Cost/Loss: 0.074245 | Weight: 0.569265 | Bias: 0.112110\n",
            "Iteration: 182706 | Cost/Loss: 0.074245 | Weight: 0.569265 | Bias: 0.112110\n",
            "Iteration: 182707 | Cost/Loss: 0.074245 | Weight: 0.569265 | Bias: 0.112111\n",
            "Iteration: 182708 | Cost/Loss: 0.074245 | Weight: 0.569266 | Bias: 0.112111\n",
            "Iteration: 182709 | Cost/Loss: 0.074245 | Weight: 0.569266 | Bias: 0.112111\n",
            "Iteration: 182710 | Cost/Loss: 0.074245 | Weight: 0.569266 | Bias: 0.112112\n",
            "Iteration: 182711 | Cost/Loss: 0.074245 | Weight: 0.569266 | Bias: 0.112112\n",
            "Iteration: 182712 | Cost/Loss: 0.074245 | Weight: 0.569267 | Bias: 0.112112\n",
            "Iteration: 182713 | Cost/Loss: 0.074245 | Weight: 0.569267 | Bias: 0.112112\n",
            "Iteration: 182714 | Cost/Loss: 0.074245 | Weight: 0.569267 | Bias: 0.112113\n",
            "Iteration: 182715 | Cost/Loss: 0.074245 | Weight: 0.569268 | Bias: 0.112113\n",
            "Iteration: 182716 | Cost/Loss: 0.074245 | Weight: 0.569268 | Bias: 0.112113\n",
            "Iteration: 182717 | Cost/Loss: 0.074245 | Weight: 0.569268 | Bias: 0.112114\n",
            "Iteration: 182718 | Cost/Loss: 0.074245 | Weight: 0.569269 | Bias: 0.112114\n",
            "Iteration: 182719 | Cost/Loss: 0.074245 | Weight: 0.569269 | Bias: 0.112114\n",
            "Iteration: 182720 | Cost/Loss: 0.074245 | Weight: 0.569269 | Bias: 0.112115\n",
            "Iteration: 182721 | Cost/Loss: 0.074245 | Weight: 0.569269 | Bias: 0.112115\n",
            "Iteration: 182722 | Cost/Loss: 0.074245 | Weight: 0.569270 | Bias: 0.112115\n",
            "Iteration: 182723 | Cost/Loss: 0.074245 | Weight: 0.569270 | Bias: 0.112116\n",
            "Iteration: 182724 | Cost/Loss: 0.074245 | Weight: 0.569270 | Bias: 0.112116\n",
            "Iteration: 182725 | Cost/Loss: 0.074245 | Weight: 0.569271 | Bias: 0.112116\n",
            "Iteration: 182726 | Cost/Loss: 0.074245 | Weight: 0.569271 | Bias: 0.112116\n",
            "Iteration: 182727 | Cost/Loss: 0.074245 | Weight: 0.569271 | Bias: 0.112117\n",
            "Iteration: 182728 | Cost/Loss: 0.074245 | Weight: 0.569272 | Bias: 0.112117\n",
            "Iteration: 182729 | Cost/Loss: 0.074244 | Weight: 0.569272 | Bias: 0.112117\n",
            "Iteration: 182730 | Cost/Loss: 0.074244 | Weight: 0.569272 | Bias: 0.112118\n",
            "Iteration: 182731 | Cost/Loss: 0.074244 | Weight: 0.569272 | Bias: 0.112118\n",
            "Iteration: 182732 | Cost/Loss: 0.074244 | Weight: 0.569273 | Bias: 0.112118\n",
            "Iteration: 182733 | Cost/Loss: 0.074244 | Weight: 0.569273 | Bias: 0.112119\n",
            "Iteration: 182734 | Cost/Loss: 0.074244 | Weight: 0.569273 | Bias: 0.112119\n",
            "Iteration: 182735 | Cost/Loss: 0.074244 | Weight: 0.569274 | Bias: 0.112119\n",
            "Iteration: 182736 | Cost/Loss: 0.074244 | Weight: 0.569274 | Bias: 0.112120\n",
            "Iteration: 182737 | Cost/Loss: 0.074244 | Weight: 0.569274 | Bias: 0.112120\n",
            "Iteration: 182738 | Cost/Loss: 0.074244 | Weight: 0.569275 | Bias: 0.112120\n",
            "Iteration: 182739 | Cost/Loss: 0.074244 | Weight: 0.569275 | Bias: 0.112120\n",
            "Iteration: 182740 | Cost/Loss: 0.074244 | Weight: 0.569275 | Bias: 0.112121\n",
            "Iteration: 182741 | Cost/Loss: 0.074244 | Weight: 0.569275 | Bias: 0.112121\n",
            "Iteration: 182742 | Cost/Loss: 0.074244 | Weight: 0.569276 | Bias: 0.112121\n",
            "Iteration: 182743 | Cost/Loss: 0.074244 | Weight: 0.569276 | Bias: 0.112122\n",
            "Iteration: 182744 | Cost/Loss: 0.074244 | Weight: 0.569276 | Bias: 0.112122\n",
            "Iteration: 182745 | Cost/Loss: 0.074244 | Weight: 0.569277 | Bias: 0.112122\n",
            "Iteration: 182746 | Cost/Loss: 0.074244 | Weight: 0.569277 | Bias: 0.112123\n",
            "Iteration: 182747 | Cost/Loss: 0.074244 | Weight: 0.569277 | Bias: 0.112123\n",
            "Iteration: 182748 | Cost/Loss: 0.074244 | Weight: 0.569278 | Bias: 0.112123\n",
            "Iteration: 182749 | Cost/Loss: 0.074244 | Weight: 0.569278 | Bias: 0.112123\n",
            "Iteration: 182750 | Cost/Loss: 0.074244 | Weight: 0.569278 | Bias: 0.112124\n",
            "Iteration: 182751 | Cost/Loss: 0.074244 | Weight: 0.569278 | Bias: 0.112124\n",
            "Iteration: 182752 | Cost/Loss: 0.074244 | Weight: 0.569279 | Bias: 0.112124\n",
            "Iteration: 182753 | Cost/Loss: 0.074244 | Weight: 0.569279 | Bias: 0.112125\n",
            "Iteration: 182754 | Cost/Loss: 0.074244 | Weight: 0.569279 | Bias: 0.112125\n",
            "Iteration: 182755 | Cost/Loss: 0.074244 | Weight: 0.569280 | Bias: 0.112125\n",
            "Iteration: 182756 | Cost/Loss: 0.074244 | Weight: 0.569280 | Bias: 0.112126\n",
            "Iteration: 182757 | Cost/Loss: 0.074244 | Weight: 0.569280 | Bias: 0.112126\n",
            "Iteration: 182758 | Cost/Loss: 0.074244 | Weight: 0.569281 | Bias: 0.112126\n",
            "Iteration: 182759 | Cost/Loss: 0.074244 | Weight: 0.569281 | Bias: 0.112127\n",
            "Iteration: 182760 | Cost/Loss: 0.074244 | Weight: 0.569281 | Bias: 0.112127\n",
            "Iteration: 182761 | Cost/Loss: 0.074244 | Weight: 0.569281 | Bias: 0.112127\n",
            "Iteration: 182762 | Cost/Loss: 0.074244 | Weight: 0.569282 | Bias: 0.112127\n",
            "Iteration: 182763 | Cost/Loss: 0.074244 | Weight: 0.569282 | Bias: 0.112128\n",
            "Iteration: 182764 | Cost/Loss: 0.074244 | Weight: 0.569282 | Bias: 0.112128\n",
            "Iteration: 182765 | Cost/Loss: 0.074244 | Weight: 0.569283 | Bias: 0.112128\n",
            "Iteration: 182766 | Cost/Loss: 0.074244 | Weight: 0.569283 | Bias: 0.112129\n",
            "Iteration: 182767 | Cost/Loss: 0.074244 | Weight: 0.569283 | Bias: 0.112129\n",
            "Iteration: 182768 | Cost/Loss: 0.074244 | Weight: 0.569283 | Bias: 0.112129\n",
            "Iteration: 182769 | Cost/Loss: 0.074244 | Weight: 0.569284 | Bias: 0.112130\n",
            "Iteration: 182770 | Cost/Loss: 0.074243 | Weight: 0.569284 | Bias: 0.112130\n",
            "Iteration: 182771 | Cost/Loss: 0.074243 | Weight: 0.569284 | Bias: 0.112130\n",
            "Iteration: 182772 | Cost/Loss: 0.074243 | Weight: 0.569285 | Bias: 0.112131\n",
            "Iteration: 182773 | Cost/Loss: 0.074243 | Weight: 0.569285 | Bias: 0.112131\n",
            "Iteration: 182774 | Cost/Loss: 0.074243 | Weight: 0.569285 | Bias: 0.112131\n",
            "Iteration: 182775 | Cost/Loss: 0.074243 | Weight: 0.569286 | Bias: 0.112131\n",
            "Iteration: 182776 | Cost/Loss: 0.074243 | Weight: 0.569286 | Bias: 0.112132\n",
            "Iteration: 182777 | Cost/Loss: 0.074243 | Weight: 0.569286 | Bias: 0.112132\n",
            "Iteration: 182778 | Cost/Loss: 0.074243 | Weight: 0.569286 | Bias: 0.112132\n",
            "Iteration: 182779 | Cost/Loss: 0.074243 | Weight: 0.569287 | Bias: 0.112133\n",
            "Iteration: 182780 | Cost/Loss: 0.074243 | Weight: 0.569287 | Bias: 0.112133\n",
            "Iteration: 182781 | Cost/Loss: 0.074243 | Weight: 0.569287 | Bias: 0.112133\n",
            "Iteration: 182782 | Cost/Loss: 0.074243 | Weight: 0.569288 | Bias: 0.112134\n",
            "Iteration: 182783 | Cost/Loss: 0.074243 | Weight: 0.569288 | Bias: 0.112134\n",
            "Iteration: 182784 | Cost/Loss: 0.074243 | Weight: 0.569288 | Bias: 0.112134\n",
            "Iteration: 182785 | Cost/Loss: 0.074243 | Weight: 0.569289 | Bias: 0.112134\n",
            "Iteration: 182786 | Cost/Loss: 0.074243 | Weight: 0.569289 | Bias: 0.112135\n",
            "Iteration: 182787 | Cost/Loss: 0.074243 | Weight: 0.569289 | Bias: 0.112135\n",
            "Iteration: 182788 | Cost/Loss: 0.074243 | Weight: 0.569289 | Bias: 0.112135\n",
            "Iteration: 182789 | Cost/Loss: 0.074243 | Weight: 0.569290 | Bias: 0.112136\n",
            "Iteration: 182790 | Cost/Loss: 0.074243 | Weight: 0.569290 | Bias: 0.112136\n",
            "Iteration: 182791 | Cost/Loss: 0.074243 | Weight: 0.569290 | Bias: 0.112136\n",
            "Iteration: 182792 | Cost/Loss: 0.074243 | Weight: 0.569291 | Bias: 0.112137\n",
            "Iteration: 182793 | Cost/Loss: 0.074243 | Weight: 0.569291 | Bias: 0.112137\n",
            "Iteration: 182794 | Cost/Loss: 0.074243 | Weight: 0.569291 | Bias: 0.112137\n",
            "Iteration: 182795 | Cost/Loss: 0.074243 | Weight: 0.569292 | Bias: 0.112138\n",
            "Iteration: 182796 | Cost/Loss: 0.074243 | Weight: 0.569292 | Bias: 0.112138\n",
            "Iteration: 182797 | Cost/Loss: 0.074243 | Weight: 0.569292 | Bias: 0.112138\n",
            "Iteration: 182798 | Cost/Loss: 0.074243 | Weight: 0.569292 | Bias: 0.112138\n",
            "Iteration: 182799 | Cost/Loss: 0.074243 | Weight: 0.569293 | Bias: 0.112139\n",
            "Iteration: 182800 | Cost/Loss: 0.074243 | Weight: 0.569293 | Bias: 0.112139\n",
            "Iteration: 182801 | Cost/Loss: 0.074243 | Weight: 0.569293 | Bias: 0.112139\n",
            "Iteration: 182802 | Cost/Loss: 0.074243 | Weight: 0.569294 | Bias: 0.112140\n",
            "Iteration: 182803 | Cost/Loss: 0.074243 | Weight: 0.569294 | Bias: 0.112140\n",
            "Iteration: 182804 | Cost/Loss: 0.074243 | Weight: 0.569294 | Bias: 0.112140\n",
            "Iteration: 182805 | Cost/Loss: 0.074243 | Weight: 0.569295 | Bias: 0.112141\n",
            "Iteration: 182806 | Cost/Loss: 0.074243 | Weight: 0.569295 | Bias: 0.112141\n",
            "Iteration: 182807 | Cost/Loss: 0.074243 | Weight: 0.569295 | Bias: 0.112141\n",
            "Iteration: 182808 | Cost/Loss: 0.074243 | Weight: 0.569295 | Bias: 0.112142\n",
            "Iteration: 182809 | Cost/Loss: 0.074243 | Weight: 0.569296 | Bias: 0.112142\n",
            "Iteration: 182810 | Cost/Loss: 0.074243 | Weight: 0.569296 | Bias: 0.112142\n",
            "Iteration: 182811 | Cost/Loss: 0.074242 | Weight: 0.569296 | Bias: 0.112142\n",
            "Iteration: 182812 | Cost/Loss: 0.074242 | Weight: 0.569297 | Bias: 0.112143\n",
            "Iteration: 182813 | Cost/Loss: 0.074242 | Weight: 0.569297 | Bias: 0.112143\n",
            "Iteration: 182814 | Cost/Loss: 0.074242 | Weight: 0.569297 | Bias: 0.112143\n",
            "Iteration: 182815 | Cost/Loss: 0.074242 | Weight: 0.569297 | Bias: 0.112144\n",
            "Iteration: 182816 | Cost/Loss: 0.074242 | Weight: 0.569298 | Bias: 0.112144\n",
            "Iteration: 182817 | Cost/Loss: 0.074242 | Weight: 0.569298 | Bias: 0.112144\n",
            "Iteration: 182818 | Cost/Loss: 0.074242 | Weight: 0.569298 | Bias: 0.112145\n",
            "Iteration: 182819 | Cost/Loss: 0.074242 | Weight: 0.569299 | Bias: 0.112145\n",
            "Iteration: 182820 | Cost/Loss: 0.074242 | Weight: 0.569299 | Bias: 0.112145\n",
            "Iteration: 182821 | Cost/Loss: 0.074242 | Weight: 0.569299 | Bias: 0.112145\n",
            "Iteration: 182822 | Cost/Loss: 0.074242 | Weight: 0.569300 | Bias: 0.112146\n",
            "Iteration: 182823 | Cost/Loss: 0.074242 | Weight: 0.569300 | Bias: 0.112146\n",
            "Iteration: 182824 | Cost/Loss: 0.074242 | Weight: 0.569300 | Bias: 0.112146\n",
            "Iteration: 182825 | Cost/Loss: 0.074242 | Weight: 0.569300 | Bias: 0.112147\n",
            "Iteration: 182826 | Cost/Loss: 0.074242 | Weight: 0.569301 | Bias: 0.112147\n",
            "Iteration: 182827 | Cost/Loss: 0.074242 | Weight: 0.569301 | Bias: 0.112147\n",
            "Iteration: 182828 | Cost/Loss: 0.074242 | Weight: 0.569301 | Bias: 0.112148\n",
            "Iteration: 182829 | Cost/Loss: 0.074242 | Weight: 0.569302 | Bias: 0.112148\n",
            "Iteration: 182830 | Cost/Loss: 0.074242 | Weight: 0.569302 | Bias: 0.112148\n",
            "Iteration: 182831 | Cost/Loss: 0.074242 | Weight: 0.569302 | Bias: 0.112149\n",
            "Iteration: 182832 | Cost/Loss: 0.074242 | Weight: 0.569303 | Bias: 0.112149\n",
            "Iteration: 182833 | Cost/Loss: 0.074242 | Weight: 0.569303 | Bias: 0.112149\n",
            "Iteration: 182834 | Cost/Loss: 0.074242 | Weight: 0.569303 | Bias: 0.112149\n",
            "Iteration: 182835 | Cost/Loss: 0.074242 | Weight: 0.569303 | Bias: 0.112150\n",
            "Iteration: 182836 | Cost/Loss: 0.074242 | Weight: 0.569304 | Bias: 0.112150\n",
            "Iteration: 182837 | Cost/Loss: 0.074242 | Weight: 0.569304 | Bias: 0.112150\n",
            "Iteration: 182838 | Cost/Loss: 0.074242 | Weight: 0.569304 | Bias: 0.112151\n",
            "Iteration: 182839 | Cost/Loss: 0.074242 | Weight: 0.569305 | Bias: 0.112151\n",
            "Iteration: 182840 | Cost/Loss: 0.074242 | Weight: 0.569305 | Bias: 0.112151\n",
            "Iteration: 182841 | Cost/Loss: 0.074242 | Weight: 0.569305 | Bias: 0.112152\n",
            "Iteration: 182842 | Cost/Loss: 0.074242 | Weight: 0.569306 | Bias: 0.112152\n",
            "Iteration: 182843 | Cost/Loss: 0.074242 | Weight: 0.569306 | Bias: 0.112152\n",
            "Iteration: 182844 | Cost/Loss: 0.074242 | Weight: 0.569306 | Bias: 0.112153\n",
            "Iteration: 182845 | Cost/Loss: 0.074242 | Weight: 0.569306 | Bias: 0.112153\n",
            "Iteration: 182846 | Cost/Loss: 0.074242 | Weight: 0.569307 | Bias: 0.112153\n",
            "Iteration: 182847 | Cost/Loss: 0.074242 | Weight: 0.569307 | Bias: 0.112153\n",
            "Iteration: 182848 | Cost/Loss: 0.074242 | Weight: 0.569307 | Bias: 0.112154\n",
            "Iteration: 182849 | Cost/Loss: 0.074242 | Weight: 0.569308 | Bias: 0.112154\n",
            "Iteration: 182850 | Cost/Loss: 0.074242 | Weight: 0.569308 | Bias: 0.112154\n",
            "Iteration: 182851 | Cost/Loss: 0.074241 | Weight: 0.569308 | Bias: 0.112155\n",
            "Iteration: 182852 | Cost/Loss: 0.074241 | Weight: 0.569309 | Bias: 0.112155\n",
            "Iteration: 182853 | Cost/Loss: 0.074241 | Weight: 0.569309 | Bias: 0.112155\n",
            "Iteration: 182854 | Cost/Loss: 0.074241 | Weight: 0.569309 | Bias: 0.112156\n",
            "Iteration: 182855 | Cost/Loss: 0.074241 | Weight: 0.569309 | Bias: 0.112156\n",
            "Iteration: 182856 | Cost/Loss: 0.074241 | Weight: 0.569310 | Bias: 0.112156\n",
            "Iteration: 182857 | Cost/Loss: 0.074241 | Weight: 0.569310 | Bias: 0.112156\n",
            "Iteration: 182858 | Cost/Loss: 0.074241 | Weight: 0.569310 | Bias: 0.112157\n",
            "Iteration: 182859 | Cost/Loss: 0.074241 | Weight: 0.569311 | Bias: 0.112157\n",
            "Iteration: 182860 | Cost/Loss: 0.074241 | Weight: 0.569311 | Bias: 0.112157\n",
            "Iteration: 182861 | Cost/Loss: 0.074241 | Weight: 0.569311 | Bias: 0.112158\n",
            "Iteration: 182862 | Cost/Loss: 0.074241 | Weight: 0.569311 | Bias: 0.112158\n",
            "Iteration: 182863 | Cost/Loss: 0.074241 | Weight: 0.569312 | Bias: 0.112158\n",
            "Iteration: 182864 | Cost/Loss: 0.074241 | Weight: 0.569312 | Bias: 0.112159\n",
            "Iteration: 182865 | Cost/Loss: 0.074241 | Weight: 0.569312 | Bias: 0.112159\n",
            "Iteration: 182866 | Cost/Loss: 0.074241 | Weight: 0.569313 | Bias: 0.112159\n",
            "Iteration: 182867 | Cost/Loss: 0.074241 | Weight: 0.569313 | Bias: 0.112160\n",
            "Iteration: 182868 | Cost/Loss: 0.074241 | Weight: 0.569313 | Bias: 0.112160\n",
            "Iteration: 182869 | Cost/Loss: 0.074241 | Weight: 0.569314 | Bias: 0.112160\n",
            "Iteration: 182870 | Cost/Loss: 0.074241 | Weight: 0.569314 | Bias: 0.112160\n",
            "Iteration: 182871 | Cost/Loss: 0.074241 | Weight: 0.569314 | Bias: 0.112161\n",
            "Iteration: 182872 | Cost/Loss: 0.074241 | Weight: 0.569314 | Bias: 0.112161\n",
            "Iteration: 182873 | Cost/Loss: 0.074241 | Weight: 0.569315 | Bias: 0.112161\n",
            "Iteration: 182874 | Cost/Loss: 0.074241 | Weight: 0.569315 | Bias: 0.112162\n",
            "Iteration: 182875 | Cost/Loss: 0.074241 | Weight: 0.569315 | Bias: 0.112162\n",
            "Iteration: 182876 | Cost/Loss: 0.074241 | Weight: 0.569316 | Bias: 0.112162\n",
            "Iteration: 182877 | Cost/Loss: 0.074241 | Weight: 0.569316 | Bias: 0.112163\n",
            "Iteration: 182878 | Cost/Loss: 0.074241 | Weight: 0.569316 | Bias: 0.112163\n",
            "Iteration: 182879 | Cost/Loss: 0.074241 | Weight: 0.569317 | Bias: 0.112163\n",
            "Iteration: 182880 | Cost/Loss: 0.074241 | Weight: 0.569317 | Bias: 0.112164\n",
            "Iteration: 182881 | Cost/Loss: 0.074241 | Weight: 0.569317 | Bias: 0.112164\n",
            "Iteration: 182882 | Cost/Loss: 0.074241 | Weight: 0.569317 | Bias: 0.112164\n",
            "Iteration: 182883 | Cost/Loss: 0.074241 | Weight: 0.569318 | Bias: 0.112164\n",
            "Iteration: 182884 | Cost/Loss: 0.074241 | Weight: 0.569318 | Bias: 0.112165\n",
            "Iteration: 182885 | Cost/Loss: 0.074241 | Weight: 0.569318 | Bias: 0.112165\n",
            "Iteration: 182886 | Cost/Loss: 0.074241 | Weight: 0.569319 | Bias: 0.112165\n",
            "Iteration: 182887 | Cost/Loss: 0.074241 | Weight: 0.569319 | Bias: 0.112166\n",
            "Iteration: 182888 | Cost/Loss: 0.074241 | Weight: 0.569319 | Bias: 0.112166\n",
            "Iteration: 182889 | Cost/Loss: 0.074241 | Weight: 0.569320 | Bias: 0.112166\n",
            "Iteration: 182890 | Cost/Loss: 0.074241 | Weight: 0.569320 | Bias: 0.112167\n",
            "Iteration: 182891 | Cost/Loss: 0.074241 | Weight: 0.569320 | Bias: 0.112167\n",
            "Iteration: 182892 | Cost/Loss: 0.074240 | Weight: 0.569320 | Bias: 0.112167\n",
            "Iteration: 182893 | Cost/Loss: 0.074240 | Weight: 0.569321 | Bias: 0.112167\n",
            "Iteration: 182894 | Cost/Loss: 0.074240 | Weight: 0.569321 | Bias: 0.112168\n",
            "Iteration: 182895 | Cost/Loss: 0.074240 | Weight: 0.569321 | Bias: 0.112168\n",
            "Iteration: 182896 | Cost/Loss: 0.074240 | Weight: 0.569322 | Bias: 0.112168\n",
            "Iteration: 182897 | Cost/Loss: 0.074240 | Weight: 0.569322 | Bias: 0.112169\n",
            "Iteration: 182898 | Cost/Loss: 0.074240 | Weight: 0.569322 | Bias: 0.112169\n",
            "Iteration: 182899 | Cost/Loss: 0.074240 | Weight: 0.569323 | Bias: 0.112169\n",
            "Iteration: 182900 | Cost/Loss: 0.074240 | Weight: 0.569323 | Bias: 0.112170\n",
            "Iteration: 182901 | Cost/Loss: 0.074240 | Weight: 0.569323 | Bias: 0.112170\n",
            "Iteration: 182902 | Cost/Loss: 0.074240 | Weight: 0.569323 | Bias: 0.112170\n",
            "Iteration: 182903 | Cost/Loss: 0.074240 | Weight: 0.569324 | Bias: 0.112171\n",
            "Iteration: 182904 | Cost/Loss: 0.074240 | Weight: 0.569324 | Bias: 0.112171\n",
            "Iteration: 182905 | Cost/Loss: 0.074240 | Weight: 0.569324 | Bias: 0.112171\n",
            "Iteration: 182906 | Cost/Loss: 0.074240 | Weight: 0.569325 | Bias: 0.112171\n",
            "Iteration: 182907 | Cost/Loss: 0.074240 | Weight: 0.569325 | Bias: 0.112172\n",
            "Iteration: 182908 | Cost/Loss: 0.074240 | Weight: 0.569325 | Bias: 0.112172\n",
            "Iteration: 182909 | Cost/Loss: 0.074240 | Weight: 0.569326 | Bias: 0.112172\n",
            "Iteration: 182910 | Cost/Loss: 0.074240 | Weight: 0.569326 | Bias: 0.112173\n",
            "Iteration: 182911 | Cost/Loss: 0.074240 | Weight: 0.569326 | Bias: 0.112173\n",
            "Iteration: 182912 | Cost/Loss: 0.074240 | Weight: 0.569326 | Bias: 0.112173\n",
            "Iteration: 182913 | Cost/Loss: 0.074240 | Weight: 0.569327 | Bias: 0.112174\n",
            "Iteration: 182914 | Cost/Loss: 0.074240 | Weight: 0.569327 | Bias: 0.112174\n",
            "Iteration: 182915 | Cost/Loss: 0.074240 | Weight: 0.569327 | Bias: 0.112174\n",
            "Iteration: 182916 | Cost/Loss: 0.074240 | Weight: 0.569328 | Bias: 0.112175\n",
            "Iteration: 182917 | Cost/Loss: 0.074240 | Weight: 0.569328 | Bias: 0.112175\n",
            "Iteration: 182918 | Cost/Loss: 0.074240 | Weight: 0.569328 | Bias: 0.112175\n",
            "Iteration: 182919 | Cost/Loss: 0.074240 | Weight: 0.569328 | Bias: 0.112175\n",
            "Iteration: 182920 | Cost/Loss: 0.074240 | Weight: 0.569329 | Bias: 0.112176\n",
            "Iteration: 182921 | Cost/Loss: 0.074240 | Weight: 0.569329 | Bias: 0.112176\n",
            "Iteration: 182922 | Cost/Loss: 0.074240 | Weight: 0.569329 | Bias: 0.112176\n",
            "Iteration: 182923 | Cost/Loss: 0.074240 | Weight: 0.569330 | Bias: 0.112177\n",
            "Iteration: 182924 | Cost/Loss: 0.074240 | Weight: 0.569330 | Bias: 0.112177\n",
            "Iteration: 182925 | Cost/Loss: 0.074240 | Weight: 0.569330 | Bias: 0.112177\n",
            "Iteration: 182926 | Cost/Loss: 0.074240 | Weight: 0.569331 | Bias: 0.112178\n",
            "Iteration: 182927 | Cost/Loss: 0.074240 | Weight: 0.569331 | Bias: 0.112178\n",
            "Iteration: 182928 | Cost/Loss: 0.074240 | Weight: 0.569331 | Bias: 0.112178\n",
            "Iteration: 182929 | Cost/Loss: 0.074240 | Weight: 0.569331 | Bias: 0.112178\n",
            "Iteration: 182930 | Cost/Loss: 0.074240 | Weight: 0.569332 | Bias: 0.112179\n",
            "Iteration: 182931 | Cost/Loss: 0.074240 | Weight: 0.569332 | Bias: 0.112179\n",
            "Iteration: 182932 | Cost/Loss: 0.074239 | Weight: 0.569332 | Bias: 0.112179\n",
            "Iteration: 182933 | Cost/Loss: 0.074239 | Weight: 0.569333 | Bias: 0.112180\n",
            "Iteration: 182934 | Cost/Loss: 0.074239 | Weight: 0.569333 | Bias: 0.112180\n",
            "Iteration: 182935 | Cost/Loss: 0.074239 | Weight: 0.569333 | Bias: 0.112180\n",
            "Iteration: 182936 | Cost/Loss: 0.074239 | Weight: 0.569334 | Bias: 0.112181\n",
            "Iteration: 182937 | Cost/Loss: 0.074239 | Weight: 0.569334 | Bias: 0.112181\n",
            "Iteration: 182938 | Cost/Loss: 0.074239 | Weight: 0.569334 | Bias: 0.112181\n",
            "Iteration: 182939 | Cost/Loss: 0.074239 | Weight: 0.569334 | Bias: 0.112182\n",
            "Iteration: 182940 | Cost/Loss: 0.074239 | Weight: 0.569335 | Bias: 0.112182\n",
            "Iteration: 182941 | Cost/Loss: 0.074239 | Weight: 0.569335 | Bias: 0.112182\n",
            "Iteration: 182942 | Cost/Loss: 0.074239 | Weight: 0.569335 | Bias: 0.112182\n",
            "Iteration: 182943 | Cost/Loss: 0.074239 | Weight: 0.569336 | Bias: 0.112183\n",
            "Iteration: 182944 | Cost/Loss: 0.074239 | Weight: 0.569336 | Bias: 0.112183\n",
            "Iteration: 182945 | Cost/Loss: 0.074239 | Weight: 0.569336 | Bias: 0.112183\n",
            "Iteration: 182946 | Cost/Loss: 0.074239 | Weight: 0.569337 | Bias: 0.112184\n",
            "Iteration: 182947 | Cost/Loss: 0.074239 | Weight: 0.569337 | Bias: 0.112184\n",
            "Iteration: 182948 | Cost/Loss: 0.074239 | Weight: 0.569337 | Bias: 0.112184\n",
            "Iteration: 182949 | Cost/Loss: 0.074239 | Weight: 0.569337 | Bias: 0.112185\n",
            "Iteration: 182950 | Cost/Loss: 0.074239 | Weight: 0.569338 | Bias: 0.112185\n",
            "Iteration: 182951 | Cost/Loss: 0.074239 | Weight: 0.569338 | Bias: 0.112185\n",
            "Iteration: 182952 | Cost/Loss: 0.074239 | Weight: 0.569338 | Bias: 0.112186\n",
            "Iteration: 182953 | Cost/Loss: 0.074239 | Weight: 0.569339 | Bias: 0.112186\n",
            "Iteration: 182954 | Cost/Loss: 0.074239 | Weight: 0.569339 | Bias: 0.112186\n",
            "Iteration: 182955 | Cost/Loss: 0.074239 | Weight: 0.569339 | Bias: 0.112186\n",
            "Iteration: 182956 | Cost/Loss: 0.074239 | Weight: 0.569340 | Bias: 0.112187\n",
            "Iteration: 182957 | Cost/Loss: 0.074239 | Weight: 0.569340 | Bias: 0.112187\n",
            "Iteration: 182958 | Cost/Loss: 0.074239 | Weight: 0.569340 | Bias: 0.112187\n",
            "Iteration: 182959 | Cost/Loss: 0.074239 | Weight: 0.569340 | Bias: 0.112188\n",
            "Iteration: 182960 | Cost/Loss: 0.074239 | Weight: 0.569341 | Bias: 0.112188\n",
            "Iteration: 182961 | Cost/Loss: 0.074239 | Weight: 0.569341 | Bias: 0.112188\n",
            "Iteration: 182962 | Cost/Loss: 0.074239 | Weight: 0.569341 | Bias: 0.112189\n",
            "Iteration: 182963 | Cost/Loss: 0.074239 | Weight: 0.569342 | Bias: 0.112189\n",
            "Iteration: 182964 | Cost/Loss: 0.074239 | Weight: 0.569342 | Bias: 0.112189\n",
            "Iteration: 182965 | Cost/Loss: 0.074239 | Weight: 0.569342 | Bias: 0.112189\n",
            "Iteration: 182966 | Cost/Loss: 0.074239 | Weight: 0.569342 | Bias: 0.112190\n",
            "Iteration: 182967 | Cost/Loss: 0.074239 | Weight: 0.569343 | Bias: 0.112190\n",
            "Iteration: 182968 | Cost/Loss: 0.074239 | Weight: 0.569343 | Bias: 0.112190\n",
            "Iteration: 182969 | Cost/Loss: 0.074239 | Weight: 0.569343 | Bias: 0.112191\n",
            "Iteration: 182970 | Cost/Loss: 0.074239 | Weight: 0.569344 | Bias: 0.112191\n",
            "Iteration: 182971 | Cost/Loss: 0.074239 | Weight: 0.569344 | Bias: 0.112191\n",
            "Iteration: 182972 | Cost/Loss: 0.074239 | Weight: 0.569344 | Bias: 0.112192\n",
            "Iteration: 182973 | Cost/Loss: 0.074238 | Weight: 0.569345 | Bias: 0.112192\n",
            "Iteration: 182974 | Cost/Loss: 0.074238 | Weight: 0.569345 | Bias: 0.112192\n",
            "Iteration: 182975 | Cost/Loss: 0.074238 | Weight: 0.569345 | Bias: 0.112193\n",
            "Iteration: 182976 | Cost/Loss: 0.074238 | Weight: 0.569345 | Bias: 0.112193\n",
            "Iteration: 182977 | Cost/Loss: 0.074238 | Weight: 0.569346 | Bias: 0.112193\n",
            "Iteration: 182978 | Cost/Loss: 0.074238 | Weight: 0.569346 | Bias: 0.112193\n",
            "Iteration: 182979 | Cost/Loss: 0.074238 | Weight: 0.569346 | Bias: 0.112194\n",
            "Iteration: 182980 | Cost/Loss: 0.074238 | Weight: 0.569347 | Bias: 0.112194\n",
            "Iteration: 182981 | Cost/Loss: 0.074238 | Weight: 0.569347 | Bias: 0.112194\n",
            "Iteration: 182982 | Cost/Loss: 0.074238 | Weight: 0.569347 | Bias: 0.112195\n",
            "Iteration: 182983 | Cost/Loss: 0.074238 | Weight: 0.569348 | Bias: 0.112195\n",
            "Iteration: 182984 | Cost/Loss: 0.074238 | Weight: 0.569348 | Bias: 0.112195\n",
            "Iteration: 182985 | Cost/Loss: 0.074238 | Weight: 0.569348 | Bias: 0.112196\n",
            "Iteration: 182986 | Cost/Loss: 0.074238 | Weight: 0.569348 | Bias: 0.112196\n",
            "Iteration: 182987 | Cost/Loss: 0.074238 | Weight: 0.569349 | Bias: 0.112196\n",
            "Iteration: 182988 | Cost/Loss: 0.074238 | Weight: 0.569349 | Bias: 0.112197\n",
            "Iteration: 182989 | Cost/Loss: 0.074238 | Weight: 0.569349 | Bias: 0.112197\n",
            "Iteration: 182990 | Cost/Loss: 0.074238 | Weight: 0.569350 | Bias: 0.112197\n",
            "Iteration: 182991 | Cost/Loss: 0.074238 | Weight: 0.569350 | Bias: 0.112197\n",
            "Iteration: 182992 | Cost/Loss: 0.074238 | Weight: 0.569350 | Bias: 0.112198\n",
            "Iteration: 182993 | Cost/Loss: 0.074238 | Weight: 0.569351 | Bias: 0.112198\n",
            "Iteration: 182994 | Cost/Loss: 0.074238 | Weight: 0.569351 | Bias: 0.112198\n",
            "Iteration: 182995 | Cost/Loss: 0.074238 | Weight: 0.569351 | Bias: 0.112199\n",
            "Iteration: 182996 | Cost/Loss: 0.074238 | Weight: 0.569351 | Bias: 0.112199\n",
            "Iteration: 182997 | Cost/Loss: 0.074238 | Weight: 0.569352 | Bias: 0.112199\n",
            "Iteration: 182998 | Cost/Loss: 0.074238 | Weight: 0.569352 | Bias: 0.112200\n",
            "Iteration: 182999 | Cost/Loss: 0.074238 | Weight: 0.569352 | Bias: 0.112200\n",
            "Iteration: 183000 | Cost/Loss: 0.074238 | Weight: 0.569353 | Bias: 0.112200\n",
            "Iteration: 183001 | Cost/Loss: 0.074238 | Weight: 0.569353 | Bias: 0.112200\n",
            "Iteration: 183002 | Cost/Loss: 0.074238 | Weight: 0.569353 | Bias: 0.112201\n",
            "Iteration: 183003 | Cost/Loss: 0.074238 | Weight: 0.569354 | Bias: 0.112201\n",
            "Iteration: 183004 | Cost/Loss: 0.074238 | Weight: 0.569354 | Bias: 0.112201\n",
            "Iteration: 183005 | Cost/Loss: 0.074238 | Weight: 0.569354 | Bias: 0.112202\n",
            "Iteration: 183006 | Cost/Loss: 0.074238 | Weight: 0.569354 | Bias: 0.112202\n",
            "Iteration: 183007 | Cost/Loss: 0.074238 | Weight: 0.569355 | Bias: 0.112202\n",
            "Iteration: 183008 | Cost/Loss: 0.074238 | Weight: 0.569355 | Bias: 0.112203\n",
            "Iteration: 183009 | Cost/Loss: 0.074238 | Weight: 0.569355 | Bias: 0.112203\n",
            "Iteration: 183010 | Cost/Loss: 0.074238 | Weight: 0.569356 | Bias: 0.112203\n",
            "Iteration: 183011 | Cost/Loss: 0.074238 | Weight: 0.569356 | Bias: 0.112204\n",
            "Iteration: 183012 | Cost/Loss: 0.074238 | Weight: 0.569356 | Bias: 0.112204\n",
            "Iteration: 183013 | Cost/Loss: 0.074238 | Weight: 0.569357 | Bias: 0.112204\n",
            "Iteration: 183014 | Cost/Loss: 0.074237 | Weight: 0.569357 | Bias: 0.112204\n",
            "Iteration: 183015 | Cost/Loss: 0.074237 | Weight: 0.569357 | Bias: 0.112205\n",
            "Iteration: 183016 | Cost/Loss: 0.074237 | Weight: 0.569357 | Bias: 0.112205\n",
            "Iteration: 183017 | Cost/Loss: 0.074237 | Weight: 0.569358 | Bias: 0.112205\n",
            "Iteration: 183018 | Cost/Loss: 0.074237 | Weight: 0.569358 | Bias: 0.112206\n",
            "Iteration: 183019 | Cost/Loss: 0.074237 | Weight: 0.569358 | Bias: 0.112206\n",
            "Iteration: 183020 | Cost/Loss: 0.074237 | Weight: 0.569359 | Bias: 0.112206\n",
            "Iteration: 183021 | Cost/Loss: 0.074237 | Weight: 0.569359 | Bias: 0.112207\n",
            "Iteration: 183022 | Cost/Loss: 0.074237 | Weight: 0.569359 | Bias: 0.112207\n",
            "Iteration: 183023 | Cost/Loss: 0.074237 | Weight: 0.569359 | Bias: 0.112207\n",
            "Iteration: 183024 | Cost/Loss: 0.074237 | Weight: 0.569360 | Bias: 0.112208\n",
            "Iteration: 183025 | Cost/Loss: 0.074237 | Weight: 0.569360 | Bias: 0.112208\n",
            "Iteration: 183026 | Cost/Loss: 0.074237 | Weight: 0.569360 | Bias: 0.112208\n",
            "Iteration: 183027 | Cost/Loss: 0.074237 | Weight: 0.569361 | Bias: 0.112208\n",
            "Iteration: 183028 | Cost/Loss: 0.074237 | Weight: 0.569361 | Bias: 0.112209\n",
            "Iteration: 183029 | Cost/Loss: 0.074237 | Weight: 0.569361 | Bias: 0.112209\n",
            "Iteration: 183030 | Cost/Loss: 0.074237 | Weight: 0.569362 | Bias: 0.112209\n",
            "Iteration: 183031 | Cost/Loss: 0.074237 | Weight: 0.569362 | Bias: 0.112210\n",
            "Iteration: 183032 | Cost/Loss: 0.074237 | Weight: 0.569362 | Bias: 0.112210\n",
            "Iteration: 183033 | Cost/Loss: 0.074237 | Weight: 0.569362 | Bias: 0.112210\n",
            "Iteration: 183034 | Cost/Loss: 0.074237 | Weight: 0.569363 | Bias: 0.112211\n",
            "Iteration: 183035 | Cost/Loss: 0.074237 | Weight: 0.569363 | Bias: 0.112211\n",
            "Iteration: 183036 | Cost/Loss: 0.074237 | Weight: 0.569363 | Bias: 0.112211\n",
            "Iteration: 183037 | Cost/Loss: 0.074237 | Weight: 0.569364 | Bias: 0.112211\n",
            "Iteration: 183038 | Cost/Loss: 0.074237 | Weight: 0.569364 | Bias: 0.112212\n",
            "Iteration: 183039 | Cost/Loss: 0.074237 | Weight: 0.569364 | Bias: 0.112212\n",
            "Iteration: 183040 | Cost/Loss: 0.074237 | Weight: 0.569365 | Bias: 0.112212\n",
            "Iteration: 183041 | Cost/Loss: 0.074237 | Weight: 0.569365 | Bias: 0.112213\n",
            "Iteration: 183042 | Cost/Loss: 0.074237 | Weight: 0.569365 | Bias: 0.112213\n",
            "Iteration: 183043 | Cost/Loss: 0.074237 | Weight: 0.569365 | Bias: 0.112213\n",
            "Iteration: 183044 | Cost/Loss: 0.074237 | Weight: 0.569366 | Bias: 0.112214\n",
            "Iteration: 183045 | Cost/Loss: 0.074237 | Weight: 0.569366 | Bias: 0.112214\n",
            "Iteration: 183046 | Cost/Loss: 0.074237 | Weight: 0.569366 | Bias: 0.112214\n",
            "Iteration: 183047 | Cost/Loss: 0.074237 | Weight: 0.569367 | Bias: 0.112215\n",
            "Iteration: 183048 | Cost/Loss: 0.074237 | Weight: 0.569367 | Bias: 0.112215\n",
            "Iteration: 183049 | Cost/Loss: 0.074237 | Weight: 0.569367 | Bias: 0.112215\n",
            "Iteration: 183050 | Cost/Loss: 0.074237 | Weight: 0.569368 | Bias: 0.112215\n",
            "Iteration: 183051 | Cost/Loss: 0.074237 | Weight: 0.569368 | Bias: 0.112216\n",
            "Iteration: 183052 | Cost/Loss: 0.074237 | Weight: 0.569368 | Bias: 0.112216\n",
            "Iteration: 183053 | Cost/Loss: 0.074237 | Weight: 0.569368 | Bias: 0.112216\n",
            "Iteration: 183054 | Cost/Loss: 0.074236 | Weight: 0.569369 | Bias: 0.112217\n",
            "Iteration: 183055 | Cost/Loss: 0.074236 | Weight: 0.569369 | Bias: 0.112217\n",
            "Iteration: 183056 | Cost/Loss: 0.074236 | Weight: 0.569369 | Bias: 0.112217\n",
            "Iteration: 183057 | Cost/Loss: 0.074236 | Weight: 0.569370 | Bias: 0.112218\n",
            "Iteration: 183058 | Cost/Loss: 0.074236 | Weight: 0.569370 | Bias: 0.112218\n",
            "Iteration: 183059 | Cost/Loss: 0.074236 | Weight: 0.569370 | Bias: 0.112218\n",
            "Iteration: 183060 | Cost/Loss: 0.074236 | Weight: 0.569371 | Bias: 0.112218\n",
            "Iteration: 183061 | Cost/Loss: 0.074236 | Weight: 0.569371 | Bias: 0.112219\n",
            "Iteration: 183062 | Cost/Loss: 0.074236 | Weight: 0.569371 | Bias: 0.112219\n",
            "Iteration: 183063 | Cost/Loss: 0.074236 | Weight: 0.569371 | Bias: 0.112219\n",
            "Iteration: 183064 | Cost/Loss: 0.074236 | Weight: 0.569372 | Bias: 0.112220\n",
            "Iteration: 183065 | Cost/Loss: 0.074236 | Weight: 0.569372 | Bias: 0.112220\n",
            "Iteration: 183066 | Cost/Loss: 0.074236 | Weight: 0.569372 | Bias: 0.112220\n",
            "Iteration: 183067 | Cost/Loss: 0.074236 | Weight: 0.569373 | Bias: 0.112221\n",
            "Iteration: 183068 | Cost/Loss: 0.074236 | Weight: 0.569373 | Bias: 0.112221\n",
            "Iteration: 183069 | Cost/Loss: 0.074236 | Weight: 0.569373 | Bias: 0.112221\n",
            "Iteration: 183070 | Cost/Loss: 0.074236 | Weight: 0.569373 | Bias: 0.112222\n",
            "Iteration: 183071 | Cost/Loss: 0.074236 | Weight: 0.569374 | Bias: 0.112222\n",
            "Iteration: 183072 | Cost/Loss: 0.074236 | Weight: 0.569374 | Bias: 0.112222\n",
            "Iteration: 183073 | Cost/Loss: 0.074236 | Weight: 0.569374 | Bias: 0.112222\n",
            "Iteration: 183074 | Cost/Loss: 0.074236 | Weight: 0.569375 | Bias: 0.112223\n",
            "Iteration: 183075 | Cost/Loss: 0.074236 | Weight: 0.569375 | Bias: 0.112223\n",
            "Iteration: 183076 | Cost/Loss: 0.074236 | Weight: 0.569375 | Bias: 0.112223\n",
            "Iteration: 183077 | Cost/Loss: 0.074236 | Weight: 0.569376 | Bias: 0.112224\n",
            "Iteration: 183078 | Cost/Loss: 0.074236 | Weight: 0.569376 | Bias: 0.112224\n",
            "Iteration: 183079 | Cost/Loss: 0.074236 | Weight: 0.569376 | Bias: 0.112224\n",
            "Iteration: 183080 | Cost/Loss: 0.074236 | Weight: 0.569376 | Bias: 0.112225\n",
            "Iteration: 183081 | Cost/Loss: 0.074236 | Weight: 0.569377 | Bias: 0.112225\n",
            "Iteration: 183082 | Cost/Loss: 0.074236 | Weight: 0.569377 | Bias: 0.112225\n",
            "Iteration: 183083 | Cost/Loss: 0.074236 | Weight: 0.569377 | Bias: 0.112226\n",
            "Iteration: 183084 | Cost/Loss: 0.074236 | Weight: 0.569378 | Bias: 0.112226\n",
            "Iteration: 183085 | Cost/Loss: 0.074236 | Weight: 0.569378 | Bias: 0.112226\n",
            "Iteration: 183086 | Cost/Loss: 0.074236 | Weight: 0.569378 | Bias: 0.112226\n",
            "Iteration: 183087 | Cost/Loss: 0.074236 | Weight: 0.569379 | Bias: 0.112227\n",
            "Iteration: 183088 | Cost/Loss: 0.074236 | Weight: 0.569379 | Bias: 0.112227\n",
            "Iteration: 183089 | Cost/Loss: 0.074236 | Weight: 0.569379 | Bias: 0.112227\n",
            "Iteration: 183090 | Cost/Loss: 0.074236 | Weight: 0.569379 | Bias: 0.112228\n",
            "Iteration: 183091 | Cost/Loss: 0.074236 | Weight: 0.569380 | Bias: 0.112228\n",
            "Iteration: 183092 | Cost/Loss: 0.074236 | Weight: 0.569380 | Bias: 0.112228\n",
            "Iteration: 183093 | Cost/Loss: 0.074236 | Weight: 0.569380 | Bias: 0.112229\n",
            "Iteration: 183094 | Cost/Loss: 0.074236 | Weight: 0.569381 | Bias: 0.112229\n",
            "Iteration: 183095 | Cost/Loss: 0.074235 | Weight: 0.569381 | Bias: 0.112229\n",
            "Iteration: 183096 | Cost/Loss: 0.074235 | Weight: 0.569381 | Bias: 0.112229\n",
            "Iteration: 183097 | Cost/Loss: 0.074235 | Weight: 0.569382 | Bias: 0.112230\n",
            "Iteration: 183098 | Cost/Loss: 0.074235 | Weight: 0.569382 | Bias: 0.112230\n",
            "Iteration: 183099 | Cost/Loss: 0.074235 | Weight: 0.569382 | Bias: 0.112230\n",
            "Iteration: 183100 | Cost/Loss: 0.074235 | Weight: 0.569382 | Bias: 0.112231\n",
            "Iteration: 183101 | Cost/Loss: 0.074235 | Weight: 0.569383 | Bias: 0.112231\n",
            "Iteration: 183102 | Cost/Loss: 0.074235 | Weight: 0.569383 | Bias: 0.112231\n",
            "Iteration: 183103 | Cost/Loss: 0.074235 | Weight: 0.569383 | Bias: 0.112232\n",
            "Iteration: 183104 | Cost/Loss: 0.074235 | Weight: 0.569384 | Bias: 0.112232\n",
            "Iteration: 183105 | Cost/Loss: 0.074235 | Weight: 0.569384 | Bias: 0.112232\n",
            "Iteration: 183106 | Cost/Loss: 0.074235 | Weight: 0.569384 | Bias: 0.112233\n",
            "Iteration: 183107 | Cost/Loss: 0.074235 | Weight: 0.569385 | Bias: 0.112233\n",
            "Iteration: 183108 | Cost/Loss: 0.074235 | Weight: 0.569385 | Bias: 0.112233\n",
            "Iteration: 183109 | Cost/Loss: 0.074235 | Weight: 0.569385 | Bias: 0.112233\n",
            "Iteration: 183110 | Cost/Loss: 0.074235 | Weight: 0.569385 | Bias: 0.112234\n",
            "Iteration: 183111 | Cost/Loss: 0.074235 | Weight: 0.569386 | Bias: 0.112234\n",
            "Iteration: 183112 | Cost/Loss: 0.074235 | Weight: 0.569386 | Bias: 0.112234\n",
            "Iteration: 183113 | Cost/Loss: 0.074235 | Weight: 0.569386 | Bias: 0.112235\n",
            "Iteration: 183114 | Cost/Loss: 0.074235 | Weight: 0.569387 | Bias: 0.112235\n",
            "Iteration: 183115 | Cost/Loss: 0.074235 | Weight: 0.569387 | Bias: 0.112235\n",
            "Iteration: 183116 | Cost/Loss: 0.074235 | Weight: 0.569387 | Bias: 0.112236\n",
            "Iteration: 183117 | Cost/Loss: 0.074235 | Weight: 0.569387 | Bias: 0.112236\n",
            "Iteration: 183118 | Cost/Loss: 0.074235 | Weight: 0.569388 | Bias: 0.112236\n",
            "Iteration: 183119 | Cost/Loss: 0.074235 | Weight: 0.569388 | Bias: 0.112237\n",
            "Iteration: 183120 | Cost/Loss: 0.074235 | Weight: 0.569388 | Bias: 0.112237\n",
            "Iteration: 183121 | Cost/Loss: 0.074235 | Weight: 0.569389 | Bias: 0.112237\n",
            "Iteration: 183122 | Cost/Loss: 0.074235 | Weight: 0.569389 | Bias: 0.112237\n",
            "Iteration: 183123 | Cost/Loss: 0.074235 | Weight: 0.569389 | Bias: 0.112238\n",
            "Iteration: 183124 | Cost/Loss: 0.074235 | Weight: 0.569390 | Bias: 0.112238\n",
            "Iteration: 183125 | Cost/Loss: 0.074235 | Weight: 0.569390 | Bias: 0.112238\n",
            "Iteration: 183126 | Cost/Loss: 0.074235 | Weight: 0.569390 | Bias: 0.112239\n",
            "Iteration: 183127 | Cost/Loss: 0.074235 | Weight: 0.569390 | Bias: 0.112239\n",
            "Iteration: 183128 | Cost/Loss: 0.074235 | Weight: 0.569391 | Bias: 0.112239\n",
            "Iteration: 183129 | Cost/Loss: 0.074235 | Weight: 0.569391 | Bias: 0.112240\n",
            "Iteration: 183130 | Cost/Loss: 0.074235 | Weight: 0.569391 | Bias: 0.112240\n",
            "Iteration: 183131 | Cost/Loss: 0.074235 | Weight: 0.569392 | Bias: 0.112240\n",
            "Iteration: 183132 | Cost/Loss: 0.074235 | Weight: 0.569392 | Bias: 0.112240\n",
            "Iteration: 183133 | Cost/Loss: 0.074235 | Weight: 0.569392 | Bias: 0.112241\n",
            "Iteration: 183134 | Cost/Loss: 0.074235 | Weight: 0.569393 | Bias: 0.112241\n",
            "Iteration: 183135 | Cost/Loss: 0.074234 | Weight: 0.569393 | Bias: 0.112241\n",
            "Iteration: 183136 | Cost/Loss: 0.074234 | Weight: 0.569393 | Bias: 0.112242\n",
            "Iteration: 183137 | Cost/Loss: 0.074234 | Weight: 0.569393 | Bias: 0.112242\n",
            "Iteration: 183138 | Cost/Loss: 0.074234 | Weight: 0.569394 | Bias: 0.112242\n",
            "Iteration: 183139 | Cost/Loss: 0.074234 | Weight: 0.569394 | Bias: 0.112243\n",
            "Iteration: 183140 | Cost/Loss: 0.074234 | Weight: 0.569394 | Bias: 0.112243\n",
            "Iteration: 183141 | Cost/Loss: 0.074234 | Weight: 0.569395 | Bias: 0.112243\n",
            "Iteration: 183142 | Cost/Loss: 0.074234 | Weight: 0.569395 | Bias: 0.112244\n",
            "Iteration: 183143 | Cost/Loss: 0.074234 | Weight: 0.569395 | Bias: 0.112244\n",
            "Iteration: 183144 | Cost/Loss: 0.074234 | Weight: 0.569396 | Bias: 0.112244\n",
            "Iteration: 183145 | Cost/Loss: 0.074234 | Weight: 0.569396 | Bias: 0.112244\n",
            "Iteration: 183146 | Cost/Loss: 0.074234 | Weight: 0.569396 | Bias: 0.112245\n",
            "Iteration: 183147 | Cost/Loss: 0.074234 | Weight: 0.569396 | Bias: 0.112245\n",
            "Iteration: 183148 | Cost/Loss: 0.074234 | Weight: 0.569397 | Bias: 0.112245\n",
            "Iteration: 183149 | Cost/Loss: 0.074234 | Weight: 0.569397 | Bias: 0.112246\n",
            "Iteration: 183150 | Cost/Loss: 0.074234 | Weight: 0.569397 | Bias: 0.112246\n",
            "Iteration: 183151 | Cost/Loss: 0.074234 | Weight: 0.569398 | Bias: 0.112246\n",
            "Iteration: 183152 | Cost/Loss: 0.074234 | Weight: 0.569398 | Bias: 0.112247\n",
            "Iteration: 183153 | Cost/Loss: 0.074234 | Weight: 0.569398 | Bias: 0.112247\n",
            "Iteration: 183154 | Cost/Loss: 0.074234 | Weight: 0.569399 | Bias: 0.112247\n",
            "Iteration: 183155 | Cost/Loss: 0.074234 | Weight: 0.569399 | Bias: 0.112248\n",
            "Iteration: 183156 | Cost/Loss: 0.074234 | Weight: 0.569399 | Bias: 0.112248\n",
            "Iteration: 183157 | Cost/Loss: 0.074234 | Weight: 0.569399 | Bias: 0.112248\n",
            "Iteration: 183158 | Cost/Loss: 0.074234 | Weight: 0.569400 | Bias: 0.112248\n",
            "Iteration: 183159 | Cost/Loss: 0.074234 | Weight: 0.569400 | Bias: 0.112249\n",
            "Iteration: 183160 | Cost/Loss: 0.074234 | Weight: 0.569400 | Bias: 0.112249\n",
            "Iteration: 183161 | Cost/Loss: 0.074234 | Weight: 0.569401 | Bias: 0.112249\n",
            "Iteration: 183162 | Cost/Loss: 0.074234 | Weight: 0.569401 | Bias: 0.112250\n",
            "Iteration: 183163 | Cost/Loss: 0.074234 | Weight: 0.569401 | Bias: 0.112250\n",
            "Iteration: 183164 | Cost/Loss: 0.074234 | Weight: 0.569402 | Bias: 0.112250\n",
            "Iteration: 183165 | Cost/Loss: 0.074234 | Weight: 0.569402 | Bias: 0.112251\n",
            "Iteration: 183166 | Cost/Loss: 0.074234 | Weight: 0.569402 | Bias: 0.112251\n",
            "Iteration: 183167 | Cost/Loss: 0.074234 | Weight: 0.569402 | Bias: 0.112251\n",
            "Iteration: 183168 | Cost/Loss: 0.074234 | Weight: 0.569403 | Bias: 0.112251\n",
            "Iteration: 183169 | Cost/Loss: 0.074234 | Weight: 0.569403 | Bias: 0.112252\n",
            "Iteration: 183170 | Cost/Loss: 0.074234 | Weight: 0.569403 | Bias: 0.112252\n",
            "Iteration: 183171 | Cost/Loss: 0.074234 | Weight: 0.569404 | Bias: 0.112252\n",
            "Iteration: 183172 | Cost/Loss: 0.074234 | Weight: 0.569404 | Bias: 0.112253\n",
            "Iteration: 183173 | Cost/Loss: 0.074234 | Weight: 0.569404 | Bias: 0.112253\n",
            "Iteration: 183174 | Cost/Loss: 0.074234 | Weight: 0.569404 | Bias: 0.112253\n",
            "Iteration: 183175 | Cost/Loss: 0.074234 | Weight: 0.569405 | Bias: 0.112254\n",
            "Iteration: 183176 | Cost/Loss: 0.074233 | Weight: 0.569405 | Bias: 0.112254\n",
            "Iteration: 183177 | Cost/Loss: 0.074233 | Weight: 0.569405 | Bias: 0.112254\n",
            "Iteration: 183178 | Cost/Loss: 0.074233 | Weight: 0.569406 | Bias: 0.112255\n",
            "Iteration: 183179 | Cost/Loss: 0.074233 | Weight: 0.569406 | Bias: 0.112255\n",
            "Iteration: 183180 | Cost/Loss: 0.074233 | Weight: 0.569406 | Bias: 0.112255\n",
            "Iteration: 183181 | Cost/Loss: 0.074233 | Weight: 0.569407 | Bias: 0.112255\n",
            "Iteration: 183182 | Cost/Loss: 0.074233 | Weight: 0.569407 | Bias: 0.112256\n",
            "Iteration: 183183 | Cost/Loss: 0.074233 | Weight: 0.569407 | Bias: 0.112256\n",
            "Iteration: 183184 | Cost/Loss: 0.074233 | Weight: 0.569407 | Bias: 0.112256\n",
            "Iteration: 183185 | Cost/Loss: 0.074233 | Weight: 0.569408 | Bias: 0.112257\n",
            "Iteration: 183186 | Cost/Loss: 0.074233 | Weight: 0.569408 | Bias: 0.112257\n",
            "Iteration: 183187 | Cost/Loss: 0.074233 | Weight: 0.569408 | Bias: 0.112257\n",
            "Iteration: 183188 | Cost/Loss: 0.074233 | Weight: 0.569409 | Bias: 0.112258\n",
            "Iteration: 183189 | Cost/Loss: 0.074233 | Weight: 0.569409 | Bias: 0.112258\n",
            "Iteration: 183190 | Cost/Loss: 0.074233 | Weight: 0.569409 | Bias: 0.112258\n",
            "Iteration: 183191 | Cost/Loss: 0.074233 | Weight: 0.569410 | Bias: 0.112259\n",
            "Iteration: 183192 | Cost/Loss: 0.074233 | Weight: 0.569410 | Bias: 0.112259\n",
            "Iteration: 183193 | Cost/Loss: 0.074233 | Weight: 0.569410 | Bias: 0.112259\n",
            "Iteration: 183194 | Cost/Loss: 0.074233 | Weight: 0.569410 | Bias: 0.112259\n",
            "Iteration: 183195 | Cost/Loss: 0.074233 | Weight: 0.569411 | Bias: 0.112260\n",
            "Iteration: 183196 | Cost/Loss: 0.074233 | Weight: 0.569411 | Bias: 0.112260\n",
            "Iteration: 183197 | Cost/Loss: 0.074233 | Weight: 0.569411 | Bias: 0.112260\n",
            "Iteration: 183198 | Cost/Loss: 0.074233 | Weight: 0.569412 | Bias: 0.112261\n",
            "Iteration: 183199 | Cost/Loss: 0.074233 | Weight: 0.569412 | Bias: 0.112261\n",
            "Iteration: 183200 | Cost/Loss: 0.074233 | Weight: 0.569412 | Bias: 0.112261\n",
            "Iteration: 183201 | Cost/Loss: 0.074233 | Weight: 0.569413 | Bias: 0.112262\n",
            "Iteration: 183202 | Cost/Loss: 0.074233 | Weight: 0.569413 | Bias: 0.112262\n",
            "Iteration: 183203 | Cost/Loss: 0.074233 | Weight: 0.569413 | Bias: 0.112262\n",
            "Iteration: 183204 | Cost/Loss: 0.074233 | Weight: 0.569413 | Bias: 0.112262\n",
            "Iteration: 183205 | Cost/Loss: 0.074233 | Weight: 0.569414 | Bias: 0.112263\n",
            "Iteration: 183206 | Cost/Loss: 0.074233 | Weight: 0.569414 | Bias: 0.112263\n",
            "Iteration: 183207 | Cost/Loss: 0.074233 | Weight: 0.569414 | Bias: 0.112263\n",
            "Iteration: 183208 | Cost/Loss: 0.074233 | Weight: 0.569415 | Bias: 0.112264\n",
            "Iteration: 183209 | Cost/Loss: 0.074233 | Weight: 0.569415 | Bias: 0.112264\n",
            "Iteration: 183210 | Cost/Loss: 0.074233 | Weight: 0.569415 | Bias: 0.112264\n",
            "Iteration: 183211 | Cost/Loss: 0.074233 | Weight: 0.569416 | Bias: 0.112265\n",
            "Iteration: 183212 | Cost/Loss: 0.074233 | Weight: 0.569416 | Bias: 0.112265\n",
            "Iteration: 183213 | Cost/Loss: 0.074233 | Weight: 0.569416 | Bias: 0.112265\n",
            "Iteration: 183214 | Cost/Loss: 0.074233 | Weight: 0.569416 | Bias: 0.112266\n",
            "Iteration: 183215 | Cost/Loss: 0.074233 | Weight: 0.569417 | Bias: 0.112266\n",
            "Iteration: 183216 | Cost/Loss: 0.074232 | Weight: 0.569417 | Bias: 0.112266\n",
            "Iteration: 183217 | Cost/Loss: 0.074232 | Weight: 0.569417 | Bias: 0.112266\n",
            "Iteration: 183218 | Cost/Loss: 0.074232 | Weight: 0.569418 | Bias: 0.112267\n",
            "Iteration: 183219 | Cost/Loss: 0.074232 | Weight: 0.569418 | Bias: 0.112267\n",
            "Iteration: 183220 | Cost/Loss: 0.074232 | Weight: 0.569418 | Bias: 0.112267\n",
            "Iteration: 183221 | Cost/Loss: 0.074232 | Weight: 0.569418 | Bias: 0.112268\n",
            "Iteration: 183222 | Cost/Loss: 0.074232 | Weight: 0.569419 | Bias: 0.112268\n",
            "Iteration: 183223 | Cost/Loss: 0.074232 | Weight: 0.569419 | Bias: 0.112268\n",
            "Iteration: 183224 | Cost/Loss: 0.074232 | Weight: 0.569419 | Bias: 0.112269\n",
            "Iteration: 183225 | Cost/Loss: 0.074232 | Weight: 0.569420 | Bias: 0.112269\n",
            "Iteration: 183226 | Cost/Loss: 0.074232 | Weight: 0.569420 | Bias: 0.112269\n",
            "Iteration: 183227 | Cost/Loss: 0.074232 | Weight: 0.569420 | Bias: 0.112270\n",
            "Iteration: 183228 | Cost/Loss: 0.074232 | Weight: 0.569421 | Bias: 0.112270\n",
            "Iteration: 183229 | Cost/Loss: 0.074232 | Weight: 0.569421 | Bias: 0.112270\n",
            "Iteration: 183230 | Cost/Loss: 0.074232 | Weight: 0.569421 | Bias: 0.112270\n",
            "Iteration: 183231 | Cost/Loss: 0.074232 | Weight: 0.569421 | Bias: 0.112271\n",
            "Iteration: 183232 | Cost/Loss: 0.074232 | Weight: 0.569422 | Bias: 0.112271\n",
            "Iteration: 183233 | Cost/Loss: 0.074232 | Weight: 0.569422 | Bias: 0.112271\n",
            "Iteration: 183234 | Cost/Loss: 0.074232 | Weight: 0.569422 | Bias: 0.112272\n",
            "Iteration: 183235 | Cost/Loss: 0.074232 | Weight: 0.569423 | Bias: 0.112272\n",
            "Iteration: 183236 | Cost/Loss: 0.074232 | Weight: 0.569423 | Bias: 0.112272\n",
            "Iteration: 183237 | Cost/Loss: 0.074232 | Weight: 0.569423 | Bias: 0.112273\n",
            "Iteration: 183238 | Cost/Loss: 0.074232 | Weight: 0.569424 | Bias: 0.112273\n",
            "Iteration: 183239 | Cost/Loss: 0.074232 | Weight: 0.569424 | Bias: 0.112273\n",
            "Iteration: 183240 | Cost/Loss: 0.074232 | Weight: 0.569424 | Bias: 0.112273\n",
            "Iteration: 183241 | Cost/Loss: 0.074232 | Weight: 0.569424 | Bias: 0.112274\n",
            "Iteration: 183242 | Cost/Loss: 0.074232 | Weight: 0.569425 | Bias: 0.112274\n",
            "Iteration: 183243 | Cost/Loss: 0.074232 | Weight: 0.569425 | Bias: 0.112274\n",
            "Iteration: 183244 | Cost/Loss: 0.074232 | Weight: 0.569425 | Bias: 0.112275\n",
            "Iteration: 183245 | Cost/Loss: 0.074232 | Weight: 0.569426 | Bias: 0.112275\n",
            "Iteration: 183246 | Cost/Loss: 0.074232 | Weight: 0.569426 | Bias: 0.112275\n",
            "Iteration: 183247 | Cost/Loss: 0.074232 | Weight: 0.569426 | Bias: 0.112276\n",
            "Iteration: 183248 | Cost/Loss: 0.074232 | Weight: 0.569427 | Bias: 0.112276\n",
            "Iteration: 183249 | Cost/Loss: 0.074232 | Weight: 0.569427 | Bias: 0.112276\n",
            "Iteration: 183250 | Cost/Loss: 0.074232 | Weight: 0.569427 | Bias: 0.112277\n",
            "Iteration: 183251 | Cost/Loss: 0.074232 | Weight: 0.569427 | Bias: 0.112277\n",
            "Iteration: 183252 | Cost/Loss: 0.074232 | Weight: 0.569428 | Bias: 0.112277\n",
            "Iteration: 183253 | Cost/Loss: 0.074232 | Weight: 0.569428 | Bias: 0.112277\n",
            "Iteration: 183254 | Cost/Loss: 0.074232 | Weight: 0.569428 | Bias: 0.112278\n",
            "Iteration: 183255 | Cost/Loss: 0.074232 | Weight: 0.569429 | Bias: 0.112278\n",
            "Iteration: 183256 | Cost/Loss: 0.074232 | Weight: 0.569429 | Bias: 0.112278\n",
            "Iteration: 183257 | Cost/Loss: 0.074231 | Weight: 0.569429 | Bias: 0.112279\n",
            "Iteration: 183258 | Cost/Loss: 0.074231 | Weight: 0.569430 | Bias: 0.112279\n",
            "Iteration: 183259 | Cost/Loss: 0.074231 | Weight: 0.569430 | Bias: 0.112279\n",
            "Iteration: 183260 | Cost/Loss: 0.074231 | Weight: 0.569430 | Bias: 0.112280\n",
            "Iteration: 183261 | Cost/Loss: 0.074231 | Weight: 0.569430 | Bias: 0.112280\n",
            "Iteration: 183262 | Cost/Loss: 0.074231 | Weight: 0.569431 | Bias: 0.112280\n",
            "Iteration: 183263 | Cost/Loss: 0.074231 | Weight: 0.569431 | Bias: 0.112281\n",
            "Iteration: 183264 | Cost/Loss: 0.074231 | Weight: 0.569431 | Bias: 0.112281\n",
            "Iteration: 183265 | Cost/Loss: 0.074231 | Weight: 0.569432 | Bias: 0.112281\n",
            "Iteration: 183266 | Cost/Loss: 0.074231 | Weight: 0.569432 | Bias: 0.112281\n",
            "Iteration: 183267 | Cost/Loss: 0.074231 | Weight: 0.569432 | Bias: 0.112282\n",
            "Iteration: 183268 | Cost/Loss: 0.074231 | Weight: 0.569432 | Bias: 0.112282\n",
            "Iteration: 183269 | Cost/Loss: 0.074231 | Weight: 0.569433 | Bias: 0.112282\n",
            "Iteration: 183270 | Cost/Loss: 0.074231 | Weight: 0.569433 | Bias: 0.112283\n",
            "Iteration: 183271 | Cost/Loss: 0.074231 | Weight: 0.569433 | Bias: 0.112283\n",
            "Iteration: 183272 | Cost/Loss: 0.074231 | Weight: 0.569434 | Bias: 0.112283\n",
            "Iteration: 183273 | Cost/Loss: 0.074231 | Weight: 0.569434 | Bias: 0.112284\n",
            "Iteration: 183274 | Cost/Loss: 0.074231 | Weight: 0.569434 | Bias: 0.112284\n",
            "Iteration: 183275 | Cost/Loss: 0.074231 | Weight: 0.569435 | Bias: 0.112284\n",
            "Iteration: 183276 | Cost/Loss: 0.074231 | Weight: 0.569435 | Bias: 0.112284\n",
            "Iteration: 183277 | Cost/Loss: 0.074231 | Weight: 0.569435 | Bias: 0.112285\n",
            "Iteration: 183278 | Cost/Loss: 0.074231 | Weight: 0.569435 | Bias: 0.112285\n",
            "Iteration: 183279 | Cost/Loss: 0.074231 | Weight: 0.569436 | Bias: 0.112285\n",
            "Iteration: 183280 | Cost/Loss: 0.074231 | Weight: 0.569436 | Bias: 0.112286\n",
            "Iteration: 183281 | Cost/Loss: 0.074231 | Weight: 0.569436 | Bias: 0.112286\n",
            "Iteration: 183282 | Cost/Loss: 0.074231 | Weight: 0.569437 | Bias: 0.112286\n",
            "Iteration: 183283 | Cost/Loss: 0.074231 | Weight: 0.569437 | Bias: 0.112287\n",
            "Iteration: 183284 | Cost/Loss: 0.074231 | Weight: 0.569437 | Bias: 0.112287\n",
            "Iteration: 183285 | Cost/Loss: 0.074231 | Weight: 0.569438 | Bias: 0.112287\n",
            "Iteration: 183286 | Cost/Loss: 0.074231 | Weight: 0.569438 | Bias: 0.112288\n",
            "Iteration: 183287 | Cost/Loss: 0.074231 | Weight: 0.569438 | Bias: 0.112288\n",
            "Iteration: 183288 | Cost/Loss: 0.074231 | Weight: 0.569438 | Bias: 0.112288\n",
            "Iteration: 183289 | Cost/Loss: 0.074231 | Weight: 0.569439 | Bias: 0.112288\n",
            "Iteration: 183290 | Cost/Loss: 0.074231 | Weight: 0.569439 | Bias: 0.112289\n",
            "Iteration: 183291 | Cost/Loss: 0.074231 | Weight: 0.569439 | Bias: 0.112289\n",
            "Iteration: 183292 | Cost/Loss: 0.074231 | Weight: 0.569440 | Bias: 0.112289\n",
            "Iteration: 183293 | Cost/Loss: 0.074231 | Weight: 0.569440 | Bias: 0.112290\n",
            "Iteration: 183294 | Cost/Loss: 0.074231 | Weight: 0.569440 | Bias: 0.112290\n",
            "Iteration: 183295 | Cost/Loss: 0.074231 | Weight: 0.569441 | Bias: 0.112290\n",
            "Iteration: 183296 | Cost/Loss: 0.074231 | Weight: 0.569441 | Bias: 0.112291\n",
            "Iteration: 183297 | Cost/Loss: 0.074230 | Weight: 0.569441 | Bias: 0.112291\n",
            "Iteration: 183298 | Cost/Loss: 0.074230 | Weight: 0.569441 | Bias: 0.112291\n",
            "Iteration: 183299 | Cost/Loss: 0.074230 | Weight: 0.569442 | Bias: 0.112292\n",
            "Iteration: 183300 | Cost/Loss: 0.074230 | Weight: 0.569442 | Bias: 0.112292\n",
            "Iteration: 183301 | Cost/Loss: 0.074230 | Weight: 0.569442 | Bias: 0.112292\n",
            "Iteration: 183302 | Cost/Loss: 0.074230 | Weight: 0.569443 | Bias: 0.112292\n",
            "Iteration: 183303 | Cost/Loss: 0.074230 | Weight: 0.569443 | Bias: 0.112293\n",
            "Iteration: 183304 | Cost/Loss: 0.074230 | Weight: 0.569443 | Bias: 0.112293\n",
            "Iteration: 183305 | Cost/Loss: 0.074230 | Weight: 0.569444 | Bias: 0.112293\n",
            "Iteration: 183306 | Cost/Loss: 0.074230 | Weight: 0.569444 | Bias: 0.112294\n",
            "Iteration: 183307 | Cost/Loss: 0.074230 | Weight: 0.569444 | Bias: 0.112294\n",
            "Iteration: 183308 | Cost/Loss: 0.074230 | Weight: 0.569444 | Bias: 0.112294\n",
            "Iteration: 183309 | Cost/Loss: 0.074230 | Weight: 0.569445 | Bias: 0.112295\n",
            "Iteration: 183310 | Cost/Loss: 0.074230 | Weight: 0.569445 | Bias: 0.112295\n",
            "Iteration: 183311 | Cost/Loss: 0.074230 | Weight: 0.569445 | Bias: 0.112295\n",
            "Iteration: 183312 | Cost/Loss: 0.074230 | Weight: 0.569446 | Bias: 0.112295\n",
            "Iteration: 183313 | Cost/Loss: 0.074230 | Weight: 0.569446 | Bias: 0.112296\n",
            "Iteration: 183314 | Cost/Loss: 0.074230 | Weight: 0.569446 | Bias: 0.112296\n",
            "Iteration: 183315 | Cost/Loss: 0.074230 | Weight: 0.569447 | Bias: 0.112296\n",
            "Iteration: 183316 | Cost/Loss: 0.074230 | Weight: 0.569447 | Bias: 0.112297\n",
            "Iteration: 183317 | Cost/Loss: 0.074230 | Weight: 0.569447 | Bias: 0.112297\n",
            "Iteration: 183318 | Cost/Loss: 0.074230 | Weight: 0.569447 | Bias: 0.112297\n",
            "Iteration: 183319 | Cost/Loss: 0.074230 | Weight: 0.569448 | Bias: 0.112298\n",
            "Iteration: 183320 | Cost/Loss: 0.074230 | Weight: 0.569448 | Bias: 0.112298\n",
            "Iteration: 183321 | Cost/Loss: 0.074230 | Weight: 0.569448 | Bias: 0.112298\n",
            "Iteration: 183322 | Cost/Loss: 0.074230 | Weight: 0.569449 | Bias: 0.112299\n",
            "Iteration: 183323 | Cost/Loss: 0.074230 | Weight: 0.569449 | Bias: 0.112299\n",
            "Iteration: 183324 | Cost/Loss: 0.074230 | Weight: 0.569449 | Bias: 0.112299\n",
            "Iteration: 183325 | Cost/Loss: 0.074230 | Weight: 0.569449 | Bias: 0.112299\n",
            "Iteration: 183326 | Cost/Loss: 0.074230 | Weight: 0.569450 | Bias: 0.112300\n",
            "Iteration: 183327 | Cost/Loss: 0.074230 | Weight: 0.569450 | Bias: 0.112300\n",
            "Iteration: 183328 | Cost/Loss: 0.074230 | Weight: 0.569450 | Bias: 0.112300\n",
            "Iteration: 183329 | Cost/Loss: 0.074230 | Weight: 0.569451 | Bias: 0.112301\n",
            "Iteration: 183330 | Cost/Loss: 0.074230 | Weight: 0.569451 | Bias: 0.112301\n",
            "Iteration: 183331 | Cost/Loss: 0.074230 | Weight: 0.569451 | Bias: 0.112301\n",
            "Iteration: 183332 | Cost/Loss: 0.074230 | Weight: 0.569452 | Bias: 0.112302\n",
            "Iteration: 183333 | Cost/Loss: 0.074230 | Weight: 0.569452 | Bias: 0.112302\n",
            "Iteration: 183334 | Cost/Loss: 0.074230 | Weight: 0.569452 | Bias: 0.112302\n",
            "Iteration: 183335 | Cost/Loss: 0.074230 | Weight: 0.569452 | Bias: 0.112303\n",
            "Iteration: 183336 | Cost/Loss: 0.074230 | Weight: 0.569453 | Bias: 0.112303\n",
            "Iteration: 183337 | Cost/Loss: 0.074230 | Weight: 0.569453 | Bias: 0.112303\n",
            "Iteration: 183338 | Cost/Loss: 0.074229 | Weight: 0.569453 | Bias: 0.112303\n",
            "Iteration: 183339 | Cost/Loss: 0.074229 | Weight: 0.569454 | Bias: 0.112304\n",
            "Iteration: 183340 | Cost/Loss: 0.074229 | Weight: 0.569454 | Bias: 0.112304\n",
            "Iteration: 183341 | Cost/Loss: 0.074229 | Weight: 0.569454 | Bias: 0.112304\n",
            "Iteration: 183342 | Cost/Loss: 0.074229 | Weight: 0.569455 | Bias: 0.112305\n",
            "Iteration: 183343 | Cost/Loss: 0.074229 | Weight: 0.569455 | Bias: 0.112305\n",
            "Iteration: 183344 | Cost/Loss: 0.074229 | Weight: 0.569455 | Bias: 0.112305\n",
            "Iteration: 183345 | Cost/Loss: 0.074229 | Weight: 0.569455 | Bias: 0.112306\n",
            "Iteration: 183346 | Cost/Loss: 0.074229 | Weight: 0.569456 | Bias: 0.112306\n",
            "Iteration: 183347 | Cost/Loss: 0.074229 | Weight: 0.569456 | Bias: 0.112306\n",
            "Iteration: 183348 | Cost/Loss: 0.074229 | Weight: 0.569456 | Bias: 0.112306\n",
            "Iteration: 183349 | Cost/Loss: 0.074229 | Weight: 0.569457 | Bias: 0.112307\n",
            "Iteration: 183350 | Cost/Loss: 0.074229 | Weight: 0.569457 | Bias: 0.112307\n",
            "Iteration: 183351 | Cost/Loss: 0.074229 | Weight: 0.569457 | Bias: 0.112307\n",
            "Iteration: 183352 | Cost/Loss: 0.074229 | Weight: 0.569458 | Bias: 0.112308\n",
            "Iteration: 183353 | Cost/Loss: 0.074229 | Weight: 0.569458 | Bias: 0.112308\n",
            "Iteration: 183354 | Cost/Loss: 0.074229 | Weight: 0.569458 | Bias: 0.112308\n",
            "Iteration: 183355 | Cost/Loss: 0.074229 | Weight: 0.569458 | Bias: 0.112309\n",
            "Iteration: 183356 | Cost/Loss: 0.074229 | Weight: 0.569459 | Bias: 0.112309\n",
            "Iteration: 183357 | Cost/Loss: 0.074229 | Weight: 0.569459 | Bias: 0.112309\n",
            "Iteration: 183358 | Cost/Loss: 0.074229 | Weight: 0.569459 | Bias: 0.112310\n",
            "Iteration: 183359 | Cost/Loss: 0.074229 | Weight: 0.569460 | Bias: 0.112310\n",
            "Iteration: 183360 | Cost/Loss: 0.074229 | Weight: 0.569460 | Bias: 0.112310\n",
            "Iteration: 183361 | Cost/Loss: 0.074229 | Weight: 0.569460 | Bias: 0.112310\n",
            "Iteration: 183362 | Cost/Loss: 0.074229 | Weight: 0.569461 | Bias: 0.112311\n",
            "Iteration: 183363 | Cost/Loss: 0.074229 | Weight: 0.569461 | Bias: 0.112311\n",
            "Iteration: 183364 | Cost/Loss: 0.074229 | Weight: 0.569461 | Bias: 0.112311\n",
            "Iteration: 183365 | Cost/Loss: 0.074229 | Weight: 0.569461 | Bias: 0.112312\n",
            "Iteration: 183366 | Cost/Loss: 0.074229 | Weight: 0.569462 | Bias: 0.112312\n",
            "Iteration: 183367 | Cost/Loss: 0.074229 | Weight: 0.569462 | Bias: 0.112312\n",
            "Iteration: 183368 | Cost/Loss: 0.074229 | Weight: 0.569462 | Bias: 0.112313\n",
            "Iteration: 183369 | Cost/Loss: 0.074229 | Weight: 0.569463 | Bias: 0.112313\n",
            "Iteration: 183370 | Cost/Loss: 0.074229 | Weight: 0.569463 | Bias: 0.112313\n",
            "Iteration: 183371 | Cost/Loss: 0.074229 | Weight: 0.569463 | Bias: 0.112314\n",
            "Iteration: 183372 | Cost/Loss: 0.074229 | Weight: 0.569463 | Bias: 0.112314\n",
            "Iteration: 183373 | Cost/Loss: 0.074229 | Weight: 0.569464 | Bias: 0.112314\n",
            "Iteration: 183374 | Cost/Loss: 0.074229 | Weight: 0.569464 | Bias: 0.112314\n",
            "Iteration: 183375 | Cost/Loss: 0.074229 | Weight: 0.569464 | Bias: 0.112315\n",
            "Iteration: 183376 | Cost/Loss: 0.074229 | Weight: 0.569465 | Bias: 0.112315\n",
            "Iteration: 183377 | Cost/Loss: 0.074229 | Weight: 0.569465 | Bias: 0.112315\n",
            "Iteration: 183378 | Cost/Loss: 0.074229 | Weight: 0.569465 | Bias: 0.112316\n",
            "Iteration: 183379 | Cost/Loss: 0.074228 | Weight: 0.569466 | Bias: 0.112316\n",
            "Iteration: 183380 | Cost/Loss: 0.074228 | Weight: 0.569466 | Bias: 0.112316\n",
            "Iteration: 183381 | Cost/Loss: 0.074228 | Weight: 0.569466 | Bias: 0.112317\n",
            "Iteration: 183382 | Cost/Loss: 0.074228 | Weight: 0.569466 | Bias: 0.112317\n",
            "Iteration: 183383 | Cost/Loss: 0.074228 | Weight: 0.569467 | Bias: 0.112317\n",
            "Iteration: 183384 | Cost/Loss: 0.074228 | Weight: 0.569467 | Bias: 0.112317\n",
            "Iteration: 183385 | Cost/Loss: 0.074228 | Weight: 0.569467 | Bias: 0.112318\n",
            "Iteration: 183386 | Cost/Loss: 0.074228 | Weight: 0.569468 | Bias: 0.112318\n",
            "Iteration: 183387 | Cost/Loss: 0.074228 | Weight: 0.569468 | Bias: 0.112318\n",
            "Iteration: 183388 | Cost/Loss: 0.074228 | Weight: 0.569468 | Bias: 0.112319\n",
            "Iteration: 183389 | Cost/Loss: 0.074228 | Weight: 0.569469 | Bias: 0.112319\n",
            "Iteration: 183390 | Cost/Loss: 0.074228 | Weight: 0.569469 | Bias: 0.112319\n",
            "Iteration: 183391 | Cost/Loss: 0.074228 | Weight: 0.569469 | Bias: 0.112320\n",
            "Iteration: 183392 | Cost/Loss: 0.074228 | Weight: 0.569469 | Bias: 0.112320\n",
            "Iteration: 183393 | Cost/Loss: 0.074228 | Weight: 0.569470 | Bias: 0.112320\n",
            "Iteration: 183394 | Cost/Loss: 0.074228 | Weight: 0.569470 | Bias: 0.112321\n",
            "Iteration: 183395 | Cost/Loss: 0.074228 | Weight: 0.569470 | Bias: 0.112321\n",
            "Iteration: 183396 | Cost/Loss: 0.074228 | Weight: 0.569471 | Bias: 0.112321\n",
            "Iteration: 183397 | Cost/Loss: 0.074228 | Weight: 0.569471 | Bias: 0.112321\n",
            "Iteration: 183398 | Cost/Loss: 0.074228 | Weight: 0.569471 | Bias: 0.112322\n",
            "Iteration: 183399 | Cost/Loss: 0.074228 | Weight: 0.569472 | Bias: 0.112322\n",
            "Iteration: 183400 | Cost/Loss: 0.074228 | Weight: 0.569472 | Bias: 0.112322\n",
            "Iteration: 183401 | Cost/Loss: 0.074228 | Weight: 0.569472 | Bias: 0.112323\n",
            "Iteration: 183402 | Cost/Loss: 0.074228 | Weight: 0.569472 | Bias: 0.112323\n",
            "Iteration: 183403 | Cost/Loss: 0.074228 | Weight: 0.569473 | Bias: 0.112323\n",
            "Iteration: 183404 | Cost/Loss: 0.074228 | Weight: 0.569473 | Bias: 0.112324\n",
            "Iteration: 183405 | Cost/Loss: 0.074228 | Weight: 0.569473 | Bias: 0.112324\n",
            "Iteration: 183406 | Cost/Loss: 0.074228 | Weight: 0.569474 | Bias: 0.112324\n",
            "Iteration: 183407 | Cost/Loss: 0.074228 | Weight: 0.569474 | Bias: 0.112324\n",
            "Iteration: 183408 | Cost/Loss: 0.074228 | Weight: 0.569474 | Bias: 0.112325\n",
            "Iteration: 183409 | Cost/Loss: 0.074228 | Weight: 0.569475 | Bias: 0.112325\n",
            "Iteration: 183410 | Cost/Loss: 0.074228 | Weight: 0.569475 | Bias: 0.112325\n",
            "Iteration: 183411 | Cost/Loss: 0.074228 | Weight: 0.569475 | Bias: 0.112326\n",
            "Iteration: 183412 | Cost/Loss: 0.074228 | Weight: 0.569475 | Bias: 0.112326\n",
            "Iteration: 183413 | Cost/Loss: 0.074228 | Weight: 0.569476 | Bias: 0.112326\n",
            "Iteration: 183414 | Cost/Loss: 0.074228 | Weight: 0.569476 | Bias: 0.112327\n",
            "Iteration: 183415 | Cost/Loss: 0.074228 | Weight: 0.569476 | Bias: 0.112327\n",
            "Iteration: 183416 | Cost/Loss: 0.074228 | Weight: 0.569477 | Bias: 0.112327\n",
            "Iteration: 183417 | Cost/Loss: 0.074228 | Weight: 0.569477 | Bias: 0.112328\n",
            "Iteration: 183418 | Cost/Loss: 0.074228 | Weight: 0.569477 | Bias: 0.112328\n",
            "Iteration: 183419 | Cost/Loss: 0.074227 | Weight: 0.569477 | Bias: 0.112328\n",
            "Iteration: 183420 | Cost/Loss: 0.074227 | Weight: 0.569478 | Bias: 0.112328\n",
            "Iteration: 183421 | Cost/Loss: 0.074227 | Weight: 0.569478 | Bias: 0.112329\n",
            "Iteration: 183422 | Cost/Loss: 0.074227 | Weight: 0.569478 | Bias: 0.112329\n",
            "Iteration: 183423 | Cost/Loss: 0.074227 | Weight: 0.569479 | Bias: 0.112329\n",
            "Iteration: 183424 | Cost/Loss: 0.074227 | Weight: 0.569479 | Bias: 0.112330\n",
            "Iteration: 183425 | Cost/Loss: 0.074227 | Weight: 0.569479 | Bias: 0.112330\n",
            "Iteration: 183426 | Cost/Loss: 0.074227 | Weight: 0.569480 | Bias: 0.112330\n",
            "Iteration: 183427 | Cost/Loss: 0.074227 | Weight: 0.569480 | Bias: 0.112331\n",
            "Iteration: 183428 | Cost/Loss: 0.074227 | Weight: 0.569480 | Bias: 0.112331\n",
            "Iteration: 183429 | Cost/Loss: 0.074227 | Weight: 0.569480 | Bias: 0.112331\n",
            "Iteration: 183430 | Cost/Loss: 0.074227 | Weight: 0.569481 | Bias: 0.112332\n",
            "Iteration: 183431 | Cost/Loss: 0.074227 | Weight: 0.569481 | Bias: 0.112332\n",
            "Iteration: 183432 | Cost/Loss: 0.074227 | Weight: 0.569481 | Bias: 0.112332\n",
            "Iteration: 183433 | Cost/Loss: 0.074227 | Weight: 0.569482 | Bias: 0.112332\n",
            "Iteration: 183434 | Cost/Loss: 0.074227 | Weight: 0.569482 | Bias: 0.112333\n",
            "Iteration: 183435 | Cost/Loss: 0.074227 | Weight: 0.569482 | Bias: 0.112333\n",
            "Iteration: 183436 | Cost/Loss: 0.074227 | Weight: 0.569483 | Bias: 0.112333\n",
            "Iteration: 183437 | Cost/Loss: 0.074227 | Weight: 0.569483 | Bias: 0.112334\n",
            "Iteration: 183438 | Cost/Loss: 0.074227 | Weight: 0.569483 | Bias: 0.112334\n",
            "Iteration: 183439 | Cost/Loss: 0.074227 | Weight: 0.569483 | Bias: 0.112334\n",
            "Iteration: 183440 | Cost/Loss: 0.074227 | Weight: 0.569484 | Bias: 0.112335\n",
            "Iteration: 183441 | Cost/Loss: 0.074227 | Weight: 0.569484 | Bias: 0.112335\n",
            "Iteration: 183442 | Cost/Loss: 0.074227 | Weight: 0.569484 | Bias: 0.112335\n",
            "Iteration: 183443 | Cost/Loss: 0.074227 | Weight: 0.569485 | Bias: 0.112335\n",
            "Iteration: 183444 | Cost/Loss: 0.074227 | Weight: 0.569485 | Bias: 0.112336\n",
            "Iteration: 183445 | Cost/Loss: 0.074227 | Weight: 0.569485 | Bias: 0.112336\n",
            "Iteration: 183446 | Cost/Loss: 0.074227 | Weight: 0.569486 | Bias: 0.112336\n",
            "Iteration: 183447 | Cost/Loss: 0.074227 | Weight: 0.569486 | Bias: 0.112337\n",
            "Iteration: 183448 | Cost/Loss: 0.074227 | Weight: 0.569486 | Bias: 0.112337\n",
            "Iteration: 183449 | Cost/Loss: 0.074227 | Weight: 0.569486 | Bias: 0.112337\n",
            "Iteration: 183450 | Cost/Loss: 0.074227 | Weight: 0.569487 | Bias: 0.112338\n",
            "Iteration: 183451 | Cost/Loss: 0.074227 | Weight: 0.569487 | Bias: 0.112338\n",
            "Iteration: 183452 | Cost/Loss: 0.074227 | Weight: 0.569487 | Bias: 0.112338\n",
            "Iteration: 183453 | Cost/Loss: 0.074227 | Weight: 0.569488 | Bias: 0.112339\n",
            "Iteration: 183454 | Cost/Loss: 0.074227 | Weight: 0.569488 | Bias: 0.112339\n",
            "Iteration: 183455 | Cost/Loss: 0.074227 | Weight: 0.569488 | Bias: 0.112339\n",
            "Iteration: 183456 | Cost/Loss: 0.074227 | Weight: 0.569489 | Bias: 0.112339\n",
            "Iteration: 183457 | Cost/Loss: 0.074227 | Weight: 0.569489 | Bias: 0.112340\n",
            "Iteration: 183458 | Cost/Loss: 0.074227 | Weight: 0.569489 | Bias: 0.112340\n",
            "Iteration: 183459 | Cost/Loss: 0.074227 | Weight: 0.569489 | Bias: 0.112340\n",
            "Iteration: 183460 | Cost/Loss: 0.074226 | Weight: 0.569490 | Bias: 0.112341\n",
            "Iteration: 183461 | Cost/Loss: 0.074226 | Weight: 0.569490 | Bias: 0.112341\n",
            "Iteration: 183462 | Cost/Loss: 0.074226 | Weight: 0.569490 | Bias: 0.112341\n",
            "Iteration: 183463 | Cost/Loss: 0.074226 | Weight: 0.569491 | Bias: 0.112342\n",
            "Iteration: 183464 | Cost/Loss: 0.074226 | Weight: 0.569491 | Bias: 0.112342\n",
            "Iteration: 183465 | Cost/Loss: 0.074226 | Weight: 0.569491 | Bias: 0.112342\n",
            "Iteration: 183466 | Cost/Loss: 0.074226 | Weight: 0.569492 | Bias: 0.112343\n",
            "Iteration: 183467 | Cost/Loss: 0.074226 | Weight: 0.569492 | Bias: 0.112343\n",
            "Iteration: 183468 | Cost/Loss: 0.074226 | Weight: 0.569492 | Bias: 0.112343\n",
            "Iteration: 183469 | Cost/Loss: 0.074226 | Weight: 0.569492 | Bias: 0.112343\n",
            "Iteration: 183470 | Cost/Loss: 0.074226 | Weight: 0.569493 | Bias: 0.112344\n",
            "Iteration: 183471 | Cost/Loss: 0.074226 | Weight: 0.569493 | Bias: 0.112344\n",
            "Iteration: 183472 | Cost/Loss: 0.074226 | Weight: 0.569493 | Bias: 0.112344\n",
            "Iteration: 183473 | Cost/Loss: 0.074226 | Weight: 0.569494 | Bias: 0.112345\n",
            "Iteration: 183474 | Cost/Loss: 0.074226 | Weight: 0.569494 | Bias: 0.112345\n",
            "Iteration: 183475 | Cost/Loss: 0.074226 | Weight: 0.569494 | Bias: 0.112345\n",
            "Iteration: 183476 | Cost/Loss: 0.074226 | Weight: 0.569494 | Bias: 0.112346\n",
            "Iteration: 183477 | Cost/Loss: 0.074226 | Weight: 0.569495 | Bias: 0.112346\n",
            "Iteration: 183478 | Cost/Loss: 0.074226 | Weight: 0.569495 | Bias: 0.112346\n",
            "Iteration: 183479 | Cost/Loss: 0.074226 | Weight: 0.569495 | Bias: 0.112346\n",
            "Iteration: 183480 | Cost/Loss: 0.074226 | Weight: 0.569496 | Bias: 0.112347\n",
            "Iteration: 183481 | Cost/Loss: 0.074226 | Weight: 0.569496 | Bias: 0.112347\n",
            "Iteration: 183482 | Cost/Loss: 0.074226 | Weight: 0.569496 | Bias: 0.112347\n",
            "Iteration: 183483 | Cost/Loss: 0.074226 | Weight: 0.569497 | Bias: 0.112348\n",
            "Iteration: 183484 | Cost/Loss: 0.074226 | Weight: 0.569497 | Bias: 0.112348\n",
            "Iteration: 183485 | Cost/Loss: 0.074226 | Weight: 0.569497 | Bias: 0.112348\n",
            "Iteration: 183486 | Cost/Loss: 0.074226 | Weight: 0.569497 | Bias: 0.112349\n",
            "Iteration: 183487 | Cost/Loss: 0.074226 | Weight: 0.569498 | Bias: 0.112349\n",
            "Iteration: 183488 | Cost/Loss: 0.074226 | Weight: 0.569498 | Bias: 0.112349\n",
            "Iteration: 183489 | Cost/Loss: 0.074226 | Weight: 0.569498 | Bias: 0.112350\n",
            "Iteration: 183490 | Cost/Loss: 0.074226 | Weight: 0.569499 | Bias: 0.112350\n",
            "Iteration: 183491 | Cost/Loss: 0.074226 | Weight: 0.569499 | Bias: 0.112350\n",
            "Iteration: 183492 | Cost/Loss: 0.074226 | Weight: 0.569499 | Bias: 0.112350\n",
            "Iteration: 183493 | Cost/Loss: 0.074226 | Weight: 0.569500 | Bias: 0.112351\n",
            "Iteration: 183494 | Cost/Loss: 0.074226 | Weight: 0.569500 | Bias: 0.112351\n",
            "Iteration: 183495 | Cost/Loss: 0.074226 | Weight: 0.569500 | Bias: 0.112351\n",
            "Iteration: 183496 | Cost/Loss: 0.074226 | Weight: 0.569500 | Bias: 0.112352\n",
            "Iteration: 183497 | Cost/Loss: 0.074226 | Weight: 0.569501 | Bias: 0.112352\n",
            "Iteration: 183498 | Cost/Loss: 0.074226 | Weight: 0.569501 | Bias: 0.112352\n",
            "Iteration: 183499 | Cost/Loss: 0.074226 | Weight: 0.569501 | Bias: 0.112353\n",
            "Iteration: 183500 | Cost/Loss: 0.074226 | Weight: 0.569502 | Bias: 0.112353\n",
            "Iteration: 183501 | Cost/Loss: 0.074225 | Weight: 0.569502 | Bias: 0.112353\n",
            "Iteration: 183502 | Cost/Loss: 0.074225 | Weight: 0.569502 | Bias: 0.112354\n",
            "Iteration: 183503 | Cost/Loss: 0.074225 | Weight: 0.569503 | Bias: 0.112354\n",
            "Iteration: 183504 | Cost/Loss: 0.074225 | Weight: 0.569503 | Bias: 0.112354\n",
            "Iteration: 183505 | Cost/Loss: 0.074225 | Weight: 0.569503 | Bias: 0.112354\n",
            "Iteration: 183506 | Cost/Loss: 0.074225 | Weight: 0.569503 | Bias: 0.112355\n",
            "Iteration: 183507 | Cost/Loss: 0.074225 | Weight: 0.569504 | Bias: 0.112355\n",
            "Iteration: 183508 | Cost/Loss: 0.074225 | Weight: 0.569504 | Bias: 0.112355\n",
            "Iteration: 183509 | Cost/Loss: 0.074225 | Weight: 0.569504 | Bias: 0.112356\n",
            "Iteration: 183510 | Cost/Loss: 0.074225 | Weight: 0.569505 | Bias: 0.112356\n",
            "Iteration: 183511 | Cost/Loss: 0.074225 | Weight: 0.569505 | Bias: 0.112356\n",
            "Iteration: 183512 | Cost/Loss: 0.074225 | Weight: 0.569505 | Bias: 0.112357\n",
            "Iteration: 183513 | Cost/Loss: 0.074225 | Weight: 0.569506 | Bias: 0.112357\n",
            "Iteration: 183514 | Cost/Loss: 0.074225 | Weight: 0.569506 | Bias: 0.112357\n",
            "Iteration: 183515 | Cost/Loss: 0.074225 | Weight: 0.569506 | Bias: 0.112357\n",
            "Iteration: 183516 | Cost/Loss: 0.074225 | Weight: 0.569506 | Bias: 0.112358\n",
            "Iteration: 183517 | Cost/Loss: 0.074225 | Weight: 0.569507 | Bias: 0.112358\n",
            "Iteration: 183518 | Cost/Loss: 0.074225 | Weight: 0.569507 | Bias: 0.112358\n",
            "Iteration: 183519 | Cost/Loss: 0.074225 | Weight: 0.569507 | Bias: 0.112359\n",
            "Iteration: 183520 | Cost/Loss: 0.074225 | Weight: 0.569508 | Bias: 0.112359\n",
            "Iteration: 183521 | Cost/Loss: 0.074225 | Weight: 0.569508 | Bias: 0.112359\n",
            "Iteration: 183522 | Cost/Loss: 0.074225 | Weight: 0.569508 | Bias: 0.112360\n",
            "Iteration: 183523 | Cost/Loss: 0.074225 | Weight: 0.569508 | Bias: 0.112360\n",
            "Iteration: 183524 | Cost/Loss: 0.074225 | Weight: 0.569509 | Bias: 0.112360\n",
            "Iteration: 183525 | Cost/Loss: 0.074225 | Weight: 0.569509 | Bias: 0.112361\n",
            "Iteration: 183526 | Cost/Loss: 0.074225 | Weight: 0.569509 | Bias: 0.112361\n",
            "Iteration: 183527 | Cost/Loss: 0.074225 | Weight: 0.569510 | Bias: 0.112361\n",
            "Iteration: 183528 | Cost/Loss: 0.074225 | Weight: 0.569510 | Bias: 0.112361\n",
            "Iteration: 183529 | Cost/Loss: 0.074225 | Weight: 0.569510 | Bias: 0.112362\n",
            "Iteration: 183530 | Cost/Loss: 0.074225 | Weight: 0.569511 | Bias: 0.112362\n",
            "Iteration: 183531 | Cost/Loss: 0.074225 | Weight: 0.569511 | Bias: 0.112362\n",
            "Iteration: 183532 | Cost/Loss: 0.074225 | Weight: 0.569511 | Bias: 0.112363\n",
            "Iteration: 183533 | Cost/Loss: 0.074225 | Weight: 0.569511 | Bias: 0.112363\n",
            "Iteration: 183534 | Cost/Loss: 0.074225 | Weight: 0.569512 | Bias: 0.112363\n",
            "Iteration: 183535 | Cost/Loss: 0.074225 | Weight: 0.569512 | Bias: 0.112364\n",
            "Iteration: 183536 | Cost/Loss: 0.074225 | Weight: 0.569512 | Bias: 0.112364\n",
            "Iteration: 183537 | Cost/Loss: 0.074225 | Weight: 0.569513 | Bias: 0.112364\n",
            "Iteration: 183538 | Cost/Loss: 0.074225 | Weight: 0.569513 | Bias: 0.112365\n",
            "Iteration: 183539 | Cost/Loss: 0.074225 | Weight: 0.569513 | Bias: 0.112365\n",
            "Iteration: 183540 | Cost/Loss: 0.074225 | Weight: 0.569514 | Bias: 0.112365\n",
            "Iteration: 183541 | Cost/Loss: 0.074224 | Weight: 0.569514 | Bias: 0.112365\n",
            "Iteration: 183542 | Cost/Loss: 0.074224 | Weight: 0.569514 | Bias: 0.112366\n",
            "Iteration: 183543 | Cost/Loss: 0.074224 | Weight: 0.569514 | Bias: 0.112366\n",
            "Iteration: 183544 | Cost/Loss: 0.074224 | Weight: 0.569515 | Bias: 0.112366\n",
            "Iteration: 183545 | Cost/Loss: 0.074224 | Weight: 0.569515 | Bias: 0.112367\n",
            "Iteration: 183546 | Cost/Loss: 0.074224 | Weight: 0.569515 | Bias: 0.112367\n",
            "Iteration: 183547 | Cost/Loss: 0.074224 | Weight: 0.569516 | Bias: 0.112367\n",
            "Iteration: 183548 | Cost/Loss: 0.074224 | Weight: 0.569516 | Bias: 0.112368\n",
            "Iteration: 183549 | Cost/Loss: 0.074224 | Weight: 0.569516 | Bias: 0.112368\n",
            "Iteration: 183550 | Cost/Loss: 0.074224 | Weight: 0.569517 | Bias: 0.112368\n",
            "Iteration: 183551 | Cost/Loss: 0.074224 | Weight: 0.569517 | Bias: 0.112368\n",
            "Iteration: 183552 | Cost/Loss: 0.074224 | Weight: 0.569517 | Bias: 0.112369\n",
            "Iteration: 183553 | Cost/Loss: 0.074224 | Weight: 0.569517 | Bias: 0.112369\n",
            "Iteration: 183554 | Cost/Loss: 0.074224 | Weight: 0.569518 | Bias: 0.112369\n",
            "Iteration: 183555 | Cost/Loss: 0.074224 | Weight: 0.569518 | Bias: 0.112370\n",
            "Iteration: 183556 | Cost/Loss: 0.074224 | Weight: 0.569518 | Bias: 0.112370\n",
            "Iteration: 183557 | Cost/Loss: 0.074224 | Weight: 0.569519 | Bias: 0.112370\n",
            "Iteration: 183558 | Cost/Loss: 0.074224 | Weight: 0.569519 | Bias: 0.112371\n",
            "Iteration: 183559 | Cost/Loss: 0.074224 | Weight: 0.569519 | Bias: 0.112371\n",
            "Iteration: 183560 | Cost/Loss: 0.074224 | Weight: 0.569520 | Bias: 0.112371\n",
            "Iteration: 183561 | Cost/Loss: 0.074224 | Weight: 0.569520 | Bias: 0.112372\n",
            "Iteration: 183562 | Cost/Loss: 0.074224 | Weight: 0.569520 | Bias: 0.112372\n",
            "Iteration: 183563 | Cost/Loss: 0.074224 | Weight: 0.569520 | Bias: 0.112372\n",
            "Iteration: 183564 | Cost/Loss: 0.074224 | Weight: 0.569521 | Bias: 0.112372\n",
            "Iteration: 183565 | Cost/Loss: 0.074224 | Weight: 0.569521 | Bias: 0.112373\n",
            "Iteration: 183566 | Cost/Loss: 0.074224 | Weight: 0.569521 | Bias: 0.112373\n",
            "Iteration: 183567 | Cost/Loss: 0.074224 | Weight: 0.569522 | Bias: 0.112373\n",
            "Iteration: 183568 | Cost/Loss: 0.074224 | Weight: 0.569522 | Bias: 0.112374\n",
            "Iteration: 183569 | Cost/Loss: 0.074224 | Weight: 0.569522 | Bias: 0.112374\n",
            "Iteration: 183570 | Cost/Loss: 0.074224 | Weight: 0.569523 | Bias: 0.112374\n",
            "Iteration: 183571 | Cost/Loss: 0.074224 | Weight: 0.569523 | Bias: 0.112375\n",
            "Iteration: 183572 | Cost/Loss: 0.074224 | Weight: 0.569523 | Bias: 0.112375\n",
            "Iteration: 183573 | Cost/Loss: 0.074224 | Weight: 0.569523 | Bias: 0.112375\n",
            "Iteration: 183574 | Cost/Loss: 0.074224 | Weight: 0.569524 | Bias: 0.112376\n",
            "Iteration: 183575 | Cost/Loss: 0.074224 | Weight: 0.569524 | Bias: 0.112376\n",
            "Iteration: 183576 | Cost/Loss: 0.074224 | Weight: 0.569524 | Bias: 0.112376\n",
            "Iteration: 183577 | Cost/Loss: 0.074224 | Weight: 0.569525 | Bias: 0.112376\n",
            "Iteration: 183578 | Cost/Loss: 0.074224 | Weight: 0.569525 | Bias: 0.112377\n",
            "Iteration: 183579 | Cost/Loss: 0.074224 | Weight: 0.569525 | Bias: 0.112377\n",
            "Iteration: 183580 | Cost/Loss: 0.074224 | Weight: 0.569525 | Bias: 0.112377\n",
            "Iteration: 183581 | Cost/Loss: 0.074224 | Weight: 0.569526 | Bias: 0.112378\n",
            "Iteration: 183582 | Cost/Loss: 0.074223 | Weight: 0.569526 | Bias: 0.112378\n",
            "Iteration: 183583 | Cost/Loss: 0.074223 | Weight: 0.569526 | Bias: 0.112378\n",
            "Iteration: 183584 | Cost/Loss: 0.074223 | Weight: 0.569527 | Bias: 0.112379\n",
            "Iteration: 183585 | Cost/Loss: 0.074223 | Weight: 0.569527 | Bias: 0.112379\n",
            "Iteration: 183586 | Cost/Loss: 0.074223 | Weight: 0.569527 | Bias: 0.112379\n",
            "Iteration: 183587 | Cost/Loss: 0.074223 | Weight: 0.569528 | Bias: 0.112379\n",
            "Iteration: 183588 | Cost/Loss: 0.074223 | Weight: 0.569528 | Bias: 0.112380\n",
            "Iteration: 183589 | Cost/Loss: 0.074223 | Weight: 0.569528 | Bias: 0.112380\n",
            "Iteration: 183590 | Cost/Loss: 0.074223 | Weight: 0.569528 | Bias: 0.112380\n",
            "Iteration: 183591 | Cost/Loss: 0.074223 | Weight: 0.569529 | Bias: 0.112381\n",
            "Iteration: 183592 | Cost/Loss: 0.074223 | Weight: 0.569529 | Bias: 0.112381\n",
            "Iteration: 183593 | Cost/Loss: 0.074223 | Weight: 0.569529 | Bias: 0.112381\n",
            "Iteration: 183594 | Cost/Loss: 0.074223 | Weight: 0.569530 | Bias: 0.112382\n",
            "Iteration: 183595 | Cost/Loss: 0.074223 | Weight: 0.569530 | Bias: 0.112382\n",
            "Iteration: 183596 | Cost/Loss: 0.074223 | Weight: 0.569530 | Bias: 0.112382\n",
            "Iteration: 183597 | Cost/Loss: 0.074223 | Weight: 0.569531 | Bias: 0.112383\n",
            "Iteration: 183598 | Cost/Loss: 0.074223 | Weight: 0.569531 | Bias: 0.112383\n",
            "Iteration: 183599 | Cost/Loss: 0.074223 | Weight: 0.569531 | Bias: 0.112383\n",
            "Iteration: 183600 | Cost/Loss: 0.074223 | Weight: 0.569531 | Bias: 0.112383\n",
            "Iteration: 183601 | Cost/Loss: 0.074223 | Weight: 0.569532 | Bias: 0.112384\n",
            "Iteration: 183602 | Cost/Loss: 0.074223 | Weight: 0.569532 | Bias: 0.112384\n",
            "Iteration: 183603 | Cost/Loss: 0.074223 | Weight: 0.569532 | Bias: 0.112384\n",
            "Iteration: 183604 | Cost/Loss: 0.074223 | Weight: 0.569533 | Bias: 0.112385\n",
            "Iteration: 183605 | Cost/Loss: 0.074223 | Weight: 0.569533 | Bias: 0.112385\n",
            "Iteration: 183606 | Cost/Loss: 0.074223 | Weight: 0.569533 | Bias: 0.112385\n",
            "Iteration: 183607 | Cost/Loss: 0.074223 | Weight: 0.569534 | Bias: 0.112386\n",
            "Iteration: 183608 | Cost/Loss: 0.074223 | Weight: 0.569534 | Bias: 0.112386\n",
            "Iteration: 183609 | Cost/Loss: 0.074223 | Weight: 0.569534 | Bias: 0.112386\n",
            "Iteration: 183610 | Cost/Loss: 0.074223 | Weight: 0.569534 | Bias: 0.112387\n",
            "Iteration: 183611 | Cost/Loss: 0.074223 | Weight: 0.569535 | Bias: 0.112387\n",
            "Iteration: 183612 | Cost/Loss: 0.074223 | Weight: 0.569535 | Bias: 0.112387\n",
            "Iteration: 183613 | Cost/Loss: 0.074223 | Weight: 0.569535 | Bias: 0.112387\n",
            "Iteration: 183614 | Cost/Loss: 0.074223 | Weight: 0.569536 | Bias: 0.112388\n",
            "Iteration: 183615 | Cost/Loss: 0.074223 | Weight: 0.569536 | Bias: 0.112388\n",
            "Iteration: 183616 | Cost/Loss: 0.074223 | Weight: 0.569536 | Bias: 0.112388\n",
            "Iteration: 183617 | Cost/Loss: 0.074223 | Weight: 0.569537 | Bias: 0.112389\n",
            "Iteration: 183618 | Cost/Loss: 0.074223 | Weight: 0.569537 | Bias: 0.112389\n",
            "Iteration: 183619 | Cost/Loss: 0.074223 | Weight: 0.569537 | Bias: 0.112389\n",
            "Iteration: 183620 | Cost/Loss: 0.074223 | Weight: 0.569537 | Bias: 0.112390\n",
            "Iteration: 183621 | Cost/Loss: 0.074223 | Weight: 0.569538 | Bias: 0.112390\n",
            "Iteration: 183622 | Cost/Loss: 0.074222 | Weight: 0.569538 | Bias: 0.112390\n",
            "Iteration: 183623 | Cost/Loss: 0.074222 | Weight: 0.569538 | Bias: 0.112390\n",
            "Iteration: 183624 | Cost/Loss: 0.074222 | Weight: 0.569539 | Bias: 0.112391\n",
            "Iteration: 183625 | Cost/Loss: 0.074222 | Weight: 0.569539 | Bias: 0.112391\n",
            "Iteration: 183626 | Cost/Loss: 0.074222 | Weight: 0.569539 | Bias: 0.112391\n",
            "Iteration: 183627 | Cost/Loss: 0.074222 | Weight: 0.569539 | Bias: 0.112392\n",
            "Iteration: 183628 | Cost/Loss: 0.074222 | Weight: 0.569540 | Bias: 0.112392\n",
            "Iteration: 183629 | Cost/Loss: 0.074222 | Weight: 0.569540 | Bias: 0.112392\n",
            "Iteration: 183630 | Cost/Loss: 0.074222 | Weight: 0.569540 | Bias: 0.112393\n",
            "Iteration: 183631 | Cost/Loss: 0.074222 | Weight: 0.569541 | Bias: 0.112393\n",
            "Iteration: 183632 | Cost/Loss: 0.074222 | Weight: 0.569541 | Bias: 0.112393\n",
            "Iteration: 183633 | Cost/Loss: 0.074222 | Weight: 0.569541 | Bias: 0.112394\n",
            "Iteration: 183634 | Cost/Loss: 0.074222 | Weight: 0.569542 | Bias: 0.112394\n",
            "Iteration: 183635 | Cost/Loss: 0.074222 | Weight: 0.569542 | Bias: 0.112394\n",
            "Iteration: 183636 | Cost/Loss: 0.074222 | Weight: 0.569542 | Bias: 0.112394\n",
            "Iteration: 183637 | Cost/Loss: 0.074222 | Weight: 0.569542 | Bias: 0.112395\n",
            "Iteration: 183638 | Cost/Loss: 0.074222 | Weight: 0.569543 | Bias: 0.112395\n",
            "Iteration: 183639 | Cost/Loss: 0.074222 | Weight: 0.569543 | Bias: 0.112395\n",
            "Iteration: 183640 | Cost/Loss: 0.074222 | Weight: 0.569543 | Bias: 0.112396\n",
            "Iteration: 183641 | Cost/Loss: 0.074222 | Weight: 0.569544 | Bias: 0.112396\n",
            "Iteration: 183642 | Cost/Loss: 0.074222 | Weight: 0.569544 | Bias: 0.112396\n",
            "Iteration: 183643 | Cost/Loss: 0.074222 | Weight: 0.569544 | Bias: 0.112397\n",
            "Iteration: 183644 | Cost/Loss: 0.074222 | Weight: 0.569545 | Bias: 0.112397\n",
            "Iteration: 183645 | Cost/Loss: 0.074222 | Weight: 0.569545 | Bias: 0.112397\n",
            "Iteration: 183646 | Cost/Loss: 0.074222 | Weight: 0.569545 | Bias: 0.112398\n",
            "Iteration: 183647 | Cost/Loss: 0.074222 | Weight: 0.569545 | Bias: 0.112398\n",
            "Iteration: 183648 | Cost/Loss: 0.074222 | Weight: 0.569546 | Bias: 0.112398\n",
            "Iteration: 183649 | Cost/Loss: 0.074222 | Weight: 0.569546 | Bias: 0.112398\n",
            "Iteration: 183650 | Cost/Loss: 0.074222 | Weight: 0.569546 | Bias: 0.112399\n",
            "Iteration: 183651 | Cost/Loss: 0.074222 | Weight: 0.569547 | Bias: 0.112399\n",
            "Iteration: 183652 | Cost/Loss: 0.074222 | Weight: 0.569547 | Bias: 0.112399\n",
            "Iteration: 183653 | Cost/Loss: 0.074222 | Weight: 0.569547 | Bias: 0.112400\n",
            "Iteration: 183654 | Cost/Loss: 0.074222 | Weight: 0.569548 | Bias: 0.112400\n",
            "Iteration: 183655 | Cost/Loss: 0.074222 | Weight: 0.569548 | Bias: 0.112400\n",
            "Iteration: 183656 | Cost/Loss: 0.074222 | Weight: 0.569548 | Bias: 0.112401\n",
            "Iteration: 183657 | Cost/Loss: 0.074222 | Weight: 0.569548 | Bias: 0.112401\n",
            "Iteration: 183658 | Cost/Loss: 0.074222 | Weight: 0.569549 | Bias: 0.112401\n",
            "Iteration: 183659 | Cost/Loss: 0.074222 | Weight: 0.569549 | Bias: 0.112401\n",
            "Iteration: 183660 | Cost/Loss: 0.074222 | Weight: 0.569549 | Bias: 0.112402\n",
            "Iteration: 183661 | Cost/Loss: 0.074222 | Weight: 0.569550 | Bias: 0.112402\n",
            "Iteration: 183662 | Cost/Loss: 0.074222 | Weight: 0.569550 | Bias: 0.112402\n",
            "Iteration: 183663 | Cost/Loss: 0.074221 | Weight: 0.569550 | Bias: 0.112403\n",
            "Iteration: 183664 | Cost/Loss: 0.074221 | Weight: 0.569551 | Bias: 0.112403\n",
            "Iteration: 183665 | Cost/Loss: 0.074221 | Weight: 0.569551 | Bias: 0.112403\n",
            "Iteration: 183666 | Cost/Loss: 0.074221 | Weight: 0.569551 | Bias: 0.112404\n",
            "Iteration: 183667 | Cost/Loss: 0.074221 | Weight: 0.569551 | Bias: 0.112404\n",
            "Iteration: 183668 | Cost/Loss: 0.074221 | Weight: 0.569552 | Bias: 0.112404\n",
            "Iteration: 183669 | Cost/Loss: 0.074221 | Weight: 0.569552 | Bias: 0.112405\n",
            "Iteration: 183670 | Cost/Loss: 0.074221 | Weight: 0.569552 | Bias: 0.112405\n",
            "Iteration: 183671 | Cost/Loss: 0.074221 | Weight: 0.569553 | Bias: 0.112405\n",
            "Iteration: 183672 | Cost/Loss: 0.074221 | Weight: 0.569553 | Bias: 0.112405\n",
            "Iteration: 183673 | Cost/Loss: 0.074221 | Weight: 0.569553 | Bias: 0.112406\n",
            "Iteration: 183674 | Cost/Loss: 0.074221 | Weight: 0.569553 | Bias: 0.112406\n",
            "Iteration: 183675 | Cost/Loss: 0.074221 | Weight: 0.569554 | Bias: 0.112406\n",
            "Iteration: 183676 | Cost/Loss: 0.074221 | Weight: 0.569554 | Bias: 0.112407\n",
            "Iteration: 183677 | Cost/Loss: 0.074221 | Weight: 0.569554 | Bias: 0.112407\n",
            "Iteration: 183678 | Cost/Loss: 0.074221 | Weight: 0.569555 | Bias: 0.112407\n",
            "Iteration: 183679 | Cost/Loss: 0.074221 | Weight: 0.569555 | Bias: 0.112408\n",
            "Iteration: 183680 | Cost/Loss: 0.074221 | Weight: 0.569555 | Bias: 0.112408\n",
            "Iteration: 183681 | Cost/Loss: 0.074221 | Weight: 0.569556 | Bias: 0.112408\n",
            "Iteration: 183682 | Cost/Loss: 0.074221 | Weight: 0.569556 | Bias: 0.112409\n",
            "Iteration: 183683 | Cost/Loss: 0.074221 | Weight: 0.569556 | Bias: 0.112409\n",
            "Iteration: 183684 | Cost/Loss: 0.074221 | Weight: 0.569556 | Bias: 0.112409\n",
            "Iteration: 183685 | Cost/Loss: 0.074221 | Weight: 0.569557 | Bias: 0.112409\n",
            "Iteration: 183686 | Cost/Loss: 0.074221 | Weight: 0.569557 | Bias: 0.112410\n",
            "Iteration: 183687 | Cost/Loss: 0.074221 | Weight: 0.569557 | Bias: 0.112410\n",
            "Iteration: 183688 | Cost/Loss: 0.074221 | Weight: 0.569558 | Bias: 0.112410\n",
            "Iteration: 183689 | Cost/Loss: 0.074221 | Weight: 0.569558 | Bias: 0.112411\n",
            "Iteration: 183690 | Cost/Loss: 0.074221 | Weight: 0.569558 | Bias: 0.112411\n",
            "Iteration: 183691 | Cost/Loss: 0.074221 | Weight: 0.569559 | Bias: 0.112411\n",
            "Iteration: 183692 | Cost/Loss: 0.074221 | Weight: 0.569559 | Bias: 0.112412\n",
            "Iteration: 183693 | Cost/Loss: 0.074221 | Weight: 0.569559 | Bias: 0.112412\n",
            "Iteration: 183694 | Cost/Loss: 0.074221 | Weight: 0.569559 | Bias: 0.112412\n",
            "Iteration: 183695 | Cost/Loss: 0.074221 | Weight: 0.569560 | Bias: 0.112412\n",
            "Iteration: 183696 | Cost/Loss: 0.074221 | Weight: 0.569560 | Bias: 0.112413\n",
            "Iteration: 183697 | Cost/Loss: 0.074221 | Weight: 0.569560 | Bias: 0.112413\n",
            "Iteration: 183698 | Cost/Loss: 0.074221 | Weight: 0.569561 | Bias: 0.112413\n",
            "Iteration: 183699 | Cost/Loss: 0.074221 | Weight: 0.569561 | Bias: 0.112414\n",
            "Iteration: 183700 | Cost/Loss: 0.074221 | Weight: 0.569561 | Bias: 0.112414\n",
            "Iteration: 183701 | Cost/Loss: 0.074221 | Weight: 0.569562 | Bias: 0.112414\n",
            "Iteration: 183702 | Cost/Loss: 0.074221 | Weight: 0.569562 | Bias: 0.112415\n",
            "Iteration: 183703 | Cost/Loss: 0.074221 | Weight: 0.569562 | Bias: 0.112415\n",
            "Iteration: 183704 | Cost/Loss: 0.074220 | Weight: 0.569562 | Bias: 0.112415\n",
            "Iteration: 183705 | Cost/Loss: 0.074220 | Weight: 0.569563 | Bias: 0.112416\n",
            "Iteration: 183706 | Cost/Loss: 0.074220 | Weight: 0.569563 | Bias: 0.112416\n",
            "Iteration: 183707 | Cost/Loss: 0.074220 | Weight: 0.569563 | Bias: 0.112416\n",
            "Iteration: 183708 | Cost/Loss: 0.074220 | Weight: 0.569564 | Bias: 0.112416\n",
            "Iteration: 183709 | Cost/Loss: 0.074220 | Weight: 0.569564 | Bias: 0.112417\n",
            "Iteration: 183710 | Cost/Loss: 0.074220 | Weight: 0.569564 | Bias: 0.112417\n",
            "Iteration: 183711 | Cost/Loss: 0.074220 | Weight: 0.569565 | Bias: 0.112417\n",
            "Iteration: 183712 | Cost/Loss: 0.074220 | Weight: 0.569565 | Bias: 0.112418\n",
            "Iteration: 183713 | Cost/Loss: 0.074220 | Weight: 0.569565 | Bias: 0.112418\n",
            "Iteration: 183714 | Cost/Loss: 0.074220 | Weight: 0.569565 | Bias: 0.112418\n",
            "Iteration: 183715 | Cost/Loss: 0.074220 | Weight: 0.569566 | Bias: 0.112419\n",
            "Iteration: 183716 | Cost/Loss: 0.074220 | Weight: 0.569566 | Bias: 0.112419\n",
            "Iteration: 183717 | Cost/Loss: 0.074220 | Weight: 0.569566 | Bias: 0.112419\n",
            "Iteration: 183718 | Cost/Loss: 0.074220 | Weight: 0.569567 | Bias: 0.112420\n",
            "Iteration: 183719 | Cost/Loss: 0.074220 | Weight: 0.569567 | Bias: 0.112420\n",
            "Iteration: 183720 | Cost/Loss: 0.074220 | Weight: 0.569567 | Bias: 0.112420\n",
            "Iteration: 183721 | Cost/Loss: 0.074220 | Weight: 0.569568 | Bias: 0.112420\n",
            "Iteration: 183722 | Cost/Loss: 0.074220 | Weight: 0.569568 | Bias: 0.112421\n",
            "Iteration: 183723 | Cost/Loss: 0.074220 | Weight: 0.569568 | Bias: 0.112421\n",
            "Iteration: 183724 | Cost/Loss: 0.074220 | Weight: 0.569568 | Bias: 0.112421\n",
            "Iteration: 183725 | Cost/Loss: 0.074220 | Weight: 0.569569 | Bias: 0.112422\n",
            "Iteration: 183726 | Cost/Loss: 0.074220 | Weight: 0.569569 | Bias: 0.112422\n",
            "Iteration: 183727 | Cost/Loss: 0.074220 | Weight: 0.569569 | Bias: 0.112422\n",
            "Iteration: 183728 | Cost/Loss: 0.074220 | Weight: 0.569570 | Bias: 0.112423\n",
            "Iteration: 183729 | Cost/Loss: 0.074220 | Weight: 0.569570 | Bias: 0.112423\n",
            "Iteration: 183730 | Cost/Loss: 0.074220 | Weight: 0.569570 | Bias: 0.112423\n",
            "Iteration: 183731 | Cost/Loss: 0.074220 | Weight: 0.569570 | Bias: 0.112423\n",
            "Iteration: 183732 | Cost/Loss: 0.074220 | Weight: 0.569571 | Bias: 0.112424\n",
            "Iteration: 183733 | Cost/Loss: 0.074220 | Weight: 0.569571 | Bias: 0.112424\n",
            "Iteration: 183734 | Cost/Loss: 0.074220 | Weight: 0.569571 | Bias: 0.112424\n",
            "Iteration: 183735 | Cost/Loss: 0.074220 | Weight: 0.569572 | Bias: 0.112425\n",
            "Iteration: 183736 | Cost/Loss: 0.074220 | Weight: 0.569572 | Bias: 0.112425\n",
            "Iteration: 183737 | Cost/Loss: 0.074220 | Weight: 0.569572 | Bias: 0.112425\n",
            "Iteration: 183738 | Cost/Loss: 0.074220 | Weight: 0.569573 | Bias: 0.112426\n",
            "Iteration: 183739 | Cost/Loss: 0.074220 | Weight: 0.569573 | Bias: 0.112426\n",
            "Iteration: 183740 | Cost/Loss: 0.074220 | Weight: 0.569573 | Bias: 0.112426\n",
            "Iteration: 183741 | Cost/Loss: 0.074220 | Weight: 0.569573 | Bias: 0.112427\n",
            "Iteration: 183742 | Cost/Loss: 0.074220 | Weight: 0.569574 | Bias: 0.112427\n",
            "Iteration: 183743 | Cost/Loss: 0.074220 | Weight: 0.569574 | Bias: 0.112427\n",
            "Iteration: 183744 | Cost/Loss: 0.074219 | Weight: 0.569574 | Bias: 0.112427\n",
            "Iteration: 183745 | Cost/Loss: 0.074219 | Weight: 0.569575 | Bias: 0.112428\n",
            "Iteration: 183746 | Cost/Loss: 0.074219 | Weight: 0.569575 | Bias: 0.112428\n",
            "Iteration: 183747 | Cost/Loss: 0.074219 | Weight: 0.569575 | Bias: 0.112428\n",
            "Iteration: 183748 | Cost/Loss: 0.074219 | Weight: 0.569576 | Bias: 0.112429\n",
            "Iteration: 183749 | Cost/Loss: 0.074219 | Weight: 0.569576 | Bias: 0.112429\n",
            "Iteration: 183750 | Cost/Loss: 0.074219 | Weight: 0.569576 | Bias: 0.112429\n",
            "Iteration: 183751 | Cost/Loss: 0.074219 | Weight: 0.569576 | Bias: 0.112430\n",
            "Iteration: 183752 | Cost/Loss: 0.074219 | Weight: 0.569577 | Bias: 0.112430\n",
            "Iteration: 183753 | Cost/Loss: 0.074219 | Weight: 0.569577 | Bias: 0.112430\n",
            "Iteration: 183754 | Cost/Loss: 0.074219 | Weight: 0.569577 | Bias: 0.112430\n",
            "Iteration: 183755 | Cost/Loss: 0.074219 | Weight: 0.569578 | Bias: 0.112431\n",
            "Iteration: 183756 | Cost/Loss: 0.074219 | Weight: 0.569578 | Bias: 0.112431\n",
            "Iteration: 183757 | Cost/Loss: 0.074219 | Weight: 0.569578 | Bias: 0.112431\n",
            "Iteration: 183758 | Cost/Loss: 0.074219 | Weight: 0.569579 | Bias: 0.112432\n",
            "Iteration: 183759 | Cost/Loss: 0.074219 | Weight: 0.569579 | Bias: 0.112432\n",
            "Iteration: 183760 | Cost/Loss: 0.074219 | Weight: 0.569579 | Bias: 0.112432\n",
            "Iteration: 183761 | Cost/Loss: 0.074219 | Weight: 0.569579 | Bias: 0.112433\n",
            "Iteration: 183762 | Cost/Loss: 0.074219 | Weight: 0.569580 | Bias: 0.112433\n",
            "Iteration: 183763 | Cost/Loss: 0.074219 | Weight: 0.569580 | Bias: 0.112433\n",
            "Iteration: 183764 | Cost/Loss: 0.074219 | Weight: 0.569580 | Bias: 0.112434\n",
            "Iteration: 183765 | Cost/Loss: 0.074219 | Weight: 0.569581 | Bias: 0.112434\n",
            "Iteration: 183766 | Cost/Loss: 0.074219 | Weight: 0.569581 | Bias: 0.112434\n",
            "Iteration: 183767 | Cost/Loss: 0.074219 | Weight: 0.569581 | Bias: 0.112434\n",
            "Iteration: 183768 | Cost/Loss: 0.074219 | Weight: 0.569582 | Bias: 0.112435\n",
            "Iteration: 183769 | Cost/Loss: 0.074219 | Weight: 0.569582 | Bias: 0.112435\n",
            "Iteration: 183770 | Cost/Loss: 0.074219 | Weight: 0.569582 | Bias: 0.112435\n",
            "Iteration: 183771 | Cost/Loss: 0.074219 | Weight: 0.569582 | Bias: 0.112436\n",
            "Iteration: 183772 | Cost/Loss: 0.074219 | Weight: 0.569583 | Bias: 0.112436\n",
            "Iteration: 183773 | Cost/Loss: 0.074219 | Weight: 0.569583 | Bias: 0.112436\n",
            "Iteration: 183774 | Cost/Loss: 0.074219 | Weight: 0.569583 | Bias: 0.112437\n",
            "Iteration: 183775 | Cost/Loss: 0.074219 | Weight: 0.569584 | Bias: 0.112437\n",
            "Iteration: 183776 | Cost/Loss: 0.074219 | Weight: 0.569584 | Bias: 0.112437\n",
            "Iteration: 183777 | Cost/Loss: 0.074219 | Weight: 0.569584 | Bias: 0.112438\n",
            "Iteration: 183778 | Cost/Loss: 0.074219 | Weight: 0.569584 | Bias: 0.112438\n",
            "Iteration: 183779 | Cost/Loss: 0.074219 | Weight: 0.569585 | Bias: 0.112438\n",
            "Iteration: 183780 | Cost/Loss: 0.074219 | Weight: 0.569585 | Bias: 0.112438\n",
            "Iteration: 183781 | Cost/Loss: 0.074219 | Weight: 0.569585 | Bias: 0.112439\n",
            "Iteration: 183782 | Cost/Loss: 0.074219 | Weight: 0.569586 | Bias: 0.112439\n",
            "Iteration: 183783 | Cost/Loss: 0.074219 | Weight: 0.569586 | Bias: 0.112439\n",
            "Iteration: 183784 | Cost/Loss: 0.074219 | Weight: 0.569586 | Bias: 0.112440\n",
            "Iteration: 183785 | Cost/Loss: 0.074218 | Weight: 0.569587 | Bias: 0.112440\n",
            "Iteration: 183786 | Cost/Loss: 0.074218 | Weight: 0.569587 | Bias: 0.112440\n",
            "Iteration: 183787 | Cost/Loss: 0.074218 | Weight: 0.569587 | Bias: 0.112441\n",
            "Iteration: 183788 | Cost/Loss: 0.074218 | Weight: 0.569587 | Bias: 0.112441\n",
            "Iteration: 183789 | Cost/Loss: 0.074218 | Weight: 0.569588 | Bias: 0.112441\n",
            "Iteration: 183790 | Cost/Loss: 0.074218 | Weight: 0.569588 | Bias: 0.112441\n",
            "Iteration: 183791 | Cost/Loss: 0.074218 | Weight: 0.569588 | Bias: 0.112442\n",
            "Iteration: 183792 | Cost/Loss: 0.074218 | Weight: 0.569589 | Bias: 0.112442\n",
            "Iteration: 183793 | Cost/Loss: 0.074218 | Weight: 0.569589 | Bias: 0.112442\n",
            "Iteration: 183794 | Cost/Loss: 0.074218 | Weight: 0.569589 | Bias: 0.112443\n",
            "Iteration: 183795 | Cost/Loss: 0.074218 | Weight: 0.569590 | Bias: 0.112443\n",
            "Iteration: 183796 | Cost/Loss: 0.074218 | Weight: 0.569590 | Bias: 0.112443\n",
            "Iteration: 183797 | Cost/Loss: 0.074218 | Weight: 0.569590 | Bias: 0.112444\n",
            "Iteration: 183798 | Cost/Loss: 0.074218 | Weight: 0.569590 | Bias: 0.112444\n",
            "Iteration: 183799 | Cost/Loss: 0.074218 | Weight: 0.569591 | Bias: 0.112444\n",
            "Iteration: 183800 | Cost/Loss: 0.074218 | Weight: 0.569591 | Bias: 0.112445\n",
            "Iteration: 183801 | Cost/Loss: 0.074218 | Weight: 0.569591 | Bias: 0.112445\n",
            "Iteration: 183802 | Cost/Loss: 0.074218 | Weight: 0.569592 | Bias: 0.112445\n",
            "Iteration: 183803 | Cost/Loss: 0.074218 | Weight: 0.569592 | Bias: 0.112445\n",
            "Iteration: 183804 | Cost/Loss: 0.074218 | Weight: 0.569592 | Bias: 0.112446\n",
            "Iteration: 183805 | Cost/Loss: 0.074218 | Weight: 0.569593 | Bias: 0.112446\n",
            "Iteration: 183806 | Cost/Loss: 0.074218 | Weight: 0.569593 | Bias: 0.112446\n",
            "Iteration: 183807 | Cost/Loss: 0.074218 | Weight: 0.569593 | Bias: 0.112447\n",
            "Iteration: 183808 | Cost/Loss: 0.074218 | Weight: 0.569593 | Bias: 0.112447\n",
            "Iteration: 183809 | Cost/Loss: 0.074218 | Weight: 0.569594 | Bias: 0.112447\n",
            "Iteration: 183810 | Cost/Loss: 0.074218 | Weight: 0.569594 | Bias: 0.112448\n",
            "Iteration: 183811 | Cost/Loss: 0.074218 | Weight: 0.569594 | Bias: 0.112448\n",
            "Iteration: 183812 | Cost/Loss: 0.074218 | Weight: 0.569595 | Bias: 0.112448\n",
            "Iteration: 183813 | Cost/Loss: 0.074218 | Weight: 0.569595 | Bias: 0.112449\n",
            "Iteration: 183814 | Cost/Loss: 0.074218 | Weight: 0.569595 | Bias: 0.112449\n",
            "Iteration: 183815 | Cost/Loss: 0.074218 | Weight: 0.569596 | Bias: 0.112449\n",
            "Iteration: 183816 | Cost/Loss: 0.074218 | Weight: 0.569596 | Bias: 0.112449\n",
            "Iteration: 183817 | Cost/Loss: 0.074218 | Weight: 0.569596 | Bias: 0.112450\n",
            "Iteration: 183818 | Cost/Loss: 0.074218 | Weight: 0.569596 | Bias: 0.112450\n",
            "Iteration: 183819 | Cost/Loss: 0.074218 | Weight: 0.569597 | Bias: 0.112450\n",
            "Iteration: 183820 | Cost/Loss: 0.074218 | Weight: 0.569597 | Bias: 0.112451\n",
            "Iteration: 183821 | Cost/Loss: 0.074218 | Weight: 0.569597 | Bias: 0.112451\n",
            "Iteration: 183822 | Cost/Loss: 0.074218 | Weight: 0.569598 | Bias: 0.112451\n",
            "Iteration: 183823 | Cost/Loss: 0.074218 | Weight: 0.569598 | Bias: 0.112452\n",
            "Iteration: 183824 | Cost/Loss: 0.074218 | Weight: 0.569598 | Bias: 0.112452\n",
            "Iteration: 183825 | Cost/Loss: 0.074217 | Weight: 0.569598 | Bias: 0.112452\n",
            "Iteration: 183826 | Cost/Loss: 0.074217 | Weight: 0.569599 | Bias: 0.112452\n",
            "Iteration: 183827 | Cost/Loss: 0.074217 | Weight: 0.569599 | Bias: 0.112453\n",
            "Iteration: 183828 | Cost/Loss: 0.074217 | Weight: 0.569599 | Bias: 0.112453\n",
            "Iteration: 183829 | Cost/Loss: 0.074217 | Weight: 0.569600 | Bias: 0.112453\n",
            "Iteration: 183830 | Cost/Loss: 0.074217 | Weight: 0.569600 | Bias: 0.112454\n",
            "Iteration: 183831 | Cost/Loss: 0.074217 | Weight: 0.569600 | Bias: 0.112454\n",
            "Iteration: 183832 | Cost/Loss: 0.074217 | Weight: 0.569601 | Bias: 0.112454\n",
            "Iteration: 183833 | Cost/Loss: 0.074217 | Weight: 0.569601 | Bias: 0.112455\n",
            "Iteration: 183834 | Cost/Loss: 0.074217 | Weight: 0.569601 | Bias: 0.112455\n",
            "Iteration: 183835 | Cost/Loss: 0.074217 | Weight: 0.569601 | Bias: 0.112455\n",
            "Iteration: 183836 | Cost/Loss: 0.074217 | Weight: 0.569602 | Bias: 0.112456\n",
            "Iteration: 183837 | Cost/Loss: 0.074217 | Weight: 0.569602 | Bias: 0.112456\n",
            "Iteration: 183838 | Cost/Loss: 0.074217 | Weight: 0.569602 | Bias: 0.112456\n",
            "Iteration: 183839 | Cost/Loss: 0.074217 | Weight: 0.569603 | Bias: 0.112456\n",
            "Iteration: 183840 | Cost/Loss: 0.074217 | Weight: 0.569603 | Bias: 0.112457\n",
            "Iteration: 183841 | Cost/Loss: 0.074217 | Weight: 0.569603 | Bias: 0.112457\n",
            "Iteration: 183842 | Cost/Loss: 0.074217 | Weight: 0.569604 | Bias: 0.112457\n",
            "Iteration: 183843 | Cost/Loss: 0.074217 | Weight: 0.569604 | Bias: 0.112458\n",
            "Iteration: 183844 | Cost/Loss: 0.074217 | Weight: 0.569604 | Bias: 0.112458\n",
            "Iteration: 183845 | Cost/Loss: 0.074217 | Weight: 0.569604 | Bias: 0.112458\n",
            "Iteration: 183846 | Cost/Loss: 0.074217 | Weight: 0.569605 | Bias: 0.112459\n",
            "Iteration: 183847 | Cost/Loss: 0.074217 | Weight: 0.569605 | Bias: 0.112459\n",
            "Iteration: 183848 | Cost/Loss: 0.074217 | Weight: 0.569605 | Bias: 0.112459\n",
            "Iteration: 183849 | Cost/Loss: 0.074217 | Weight: 0.569606 | Bias: 0.112460\n",
            "Iteration: 183850 | Cost/Loss: 0.074217 | Weight: 0.569606 | Bias: 0.112460\n",
            "Iteration: 183851 | Cost/Loss: 0.074217 | Weight: 0.569606 | Bias: 0.112460\n",
            "Iteration: 183852 | Cost/Loss: 0.074217 | Weight: 0.569607 | Bias: 0.112460\n",
            "Iteration: 183853 | Cost/Loss: 0.074217 | Weight: 0.569607 | Bias: 0.112461\n",
            "Iteration: 183854 | Cost/Loss: 0.074217 | Weight: 0.569607 | Bias: 0.112461\n",
            "Iteration: 183855 | Cost/Loss: 0.074217 | Weight: 0.569607 | Bias: 0.112461\n",
            "Iteration: 183856 | Cost/Loss: 0.074217 | Weight: 0.569608 | Bias: 0.112462\n",
            "Iteration: 183857 | Cost/Loss: 0.074217 | Weight: 0.569608 | Bias: 0.112462\n",
            "Iteration: 183858 | Cost/Loss: 0.074217 | Weight: 0.569608 | Bias: 0.112462\n",
            "Iteration: 183859 | Cost/Loss: 0.074217 | Weight: 0.569609 | Bias: 0.112463\n",
            "Iteration: 183860 | Cost/Loss: 0.074217 | Weight: 0.569609 | Bias: 0.112463\n",
            "Iteration: 183861 | Cost/Loss: 0.074217 | Weight: 0.569609 | Bias: 0.112463\n",
            "Iteration: 183862 | Cost/Loss: 0.074217 | Weight: 0.569610 | Bias: 0.112463\n",
            "Iteration: 183863 | Cost/Loss: 0.074217 | Weight: 0.569610 | Bias: 0.112464\n",
            "Iteration: 183864 | Cost/Loss: 0.074217 | Weight: 0.569610 | Bias: 0.112464\n",
            "Iteration: 183865 | Cost/Loss: 0.074217 | Weight: 0.569610 | Bias: 0.112464\n",
            "Iteration: 183866 | Cost/Loss: 0.074216 | Weight: 0.569611 | Bias: 0.112465\n",
            "Iteration: 183867 | Cost/Loss: 0.074216 | Weight: 0.569611 | Bias: 0.112465\n",
            "Iteration: 183868 | Cost/Loss: 0.074216 | Weight: 0.569611 | Bias: 0.112465\n",
            "Iteration: 183869 | Cost/Loss: 0.074216 | Weight: 0.569612 | Bias: 0.112466\n",
            "Iteration: 183870 | Cost/Loss: 0.074216 | Weight: 0.569612 | Bias: 0.112466\n",
            "Iteration: 183871 | Cost/Loss: 0.074216 | Weight: 0.569612 | Bias: 0.112466\n",
            "Iteration: 183872 | Cost/Loss: 0.074216 | Weight: 0.569613 | Bias: 0.112467\n",
            "Iteration: 183873 | Cost/Loss: 0.074216 | Weight: 0.569613 | Bias: 0.112467\n",
            "Iteration: 183874 | Cost/Loss: 0.074216 | Weight: 0.569613 | Bias: 0.112467\n",
            "Iteration: 183875 | Cost/Loss: 0.074216 | Weight: 0.569613 | Bias: 0.112467\n",
            "Iteration: 183876 | Cost/Loss: 0.074216 | Weight: 0.569614 | Bias: 0.112468\n",
            "Iteration: 183877 | Cost/Loss: 0.074216 | Weight: 0.569614 | Bias: 0.112468\n",
            "Iteration: 183878 | Cost/Loss: 0.074216 | Weight: 0.569614 | Bias: 0.112468\n",
            "Iteration: 183879 | Cost/Loss: 0.074216 | Weight: 0.569615 | Bias: 0.112469\n",
            "Iteration: 183880 | Cost/Loss: 0.074216 | Weight: 0.569615 | Bias: 0.112469\n",
            "Iteration: 183881 | Cost/Loss: 0.074216 | Weight: 0.569615 | Bias: 0.112469\n",
            "Iteration: 183882 | Cost/Loss: 0.074216 | Weight: 0.569615 | Bias: 0.112470\n",
            "Iteration: 183883 | Cost/Loss: 0.074216 | Weight: 0.569616 | Bias: 0.112470\n",
            "Iteration: 183884 | Cost/Loss: 0.074216 | Weight: 0.569616 | Bias: 0.112470\n",
            "Iteration: 183885 | Cost/Loss: 0.074216 | Weight: 0.569616 | Bias: 0.112471\n",
            "Iteration: 183886 | Cost/Loss: 0.074216 | Weight: 0.569617 | Bias: 0.112471\n",
            "Iteration: 183887 | Cost/Loss: 0.074216 | Weight: 0.569617 | Bias: 0.112471\n",
            "Iteration: 183888 | Cost/Loss: 0.074216 | Weight: 0.569617 | Bias: 0.112471\n",
            "Iteration: 183889 | Cost/Loss: 0.074216 | Weight: 0.569618 | Bias: 0.112472\n",
            "Iteration: 183890 | Cost/Loss: 0.074216 | Weight: 0.569618 | Bias: 0.112472\n",
            "Iteration: 183891 | Cost/Loss: 0.074216 | Weight: 0.569618 | Bias: 0.112472\n",
            "Iteration: 183892 | Cost/Loss: 0.074216 | Weight: 0.569618 | Bias: 0.112473\n",
            "Iteration: 183893 | Cost/Loss: 0.074216 | Weight: 0.569619 | Bias: 0.112473\n",
            "Iteration: 183894 | Cost/Loss: 0.074216 | Weight: 0.569619 | Bias: 0.112473\n",
            "Iteration: 183895 | Cost/Loss: 0.074216 | Weight: 0.569619 | Bias: 0.112474\n",
            "Iteration: 183896 | Cost/Loss: 0.074216 | Weight: 0.569620 | Bias: 0.112474\n",
            "Iteration: 183897 | Cost/Loss: 0.074216 | Weight: 0.569620 | Bias: 0.112474\n",
            "Iteration: 183898 | Cost/Loss: 0.074216 | Weight: 0.569620 | Bias: 0.112474\n",
            "Iteration: 183899 | Cost/Loss: 0.074216 | Weight: 0.569621 | Bias: 0.112475\n",
            "Iteration: 183900 | Cost/Loss: 0.074216 | Weight: 0.569621 | Bias: 0.112475\n",
            "Iteration: 183901 | Cost/Loss: 0.074216 | Weight: 0.569621 | Bias: 0.112475\n",
            "Iteration: 183902 | Cost/Loss: 0.074216 | Weight: 0.569621 | Bias: 0.112476\n",
            "Iteration: 183903 | Cost/Loss: 0.074216 | Weight: 0.569622 | Bias: 0.112476\n",
            "Iteration: 183904 | Cost/Loss: 0.074216 | Weight: 0.569622 | Bias: 0.112476\n",
            "Iteration: 183905 | Cost/Loss: 0.074216 | Weight: 0.569622 | Bias: 0.112477\n",
            "Iteration: 183906 | Cost/Loss: 0.074215 | Weight: 0.569623 | Bias: 0.112477\n",
            "Iteration: 183907 | Cost/Loss: 0.074215 | Weight: 0.569623 | Bias: 0.112477\n",
            "Iteration: 183908 | Cost/Loss: 0.074215 | Weight: 0.569623 | Bias: 0.112478\n",
            "Iteration: 183909 | Cost/Loss: 0.074215 | Weight: 0.569624 | Bias: 0.112478\n",
            "Iteration: 183910 | Cost/Loss: 0.074215 | Weight: 0.569624 | Bias: 0.112478\n",
            "Iteration: 183911 | Cost/Loss: 0.074215 | Weight: 0.569624 | Bias: 0.112478\n",
            "Iteration: 183912 | Cost/Loss: 0.074215 | Weight: 0.569624 | Bias: 0.112479\n",
            "Iteration: 183913 | Cost/Loss: 0.074215 | Weight: 0.569625 | Bias: 0.112479\n",
            "Iteration: 183914 | Cost/Loss: 0.074215 | Weight: 0.569625 | Bias: 0.112479\n",
            "Iteration: 183915 | Cost/Loss: 0.074215 | Weight: 0.569625 | Bias: 0.112480\n",
            "Iteration: 183916 | Cost/Loss: 0.074215 | Weight: 0.569626 | Bias: 0.112480\n",
            "Iteration: 183917 | Cost/Loss: 0.074215 | Weight: 0.569626 | Bias: 0.112480\n",
            "Iteration: 183918 | Cost/Loss: 0.074215 | Weight: 0.569626 | Bias: 0.112481\n",
            "Iteration: 183919 | Cost/Loss: 0.074215 | Weight: 0.569627 | Bias: 0.112481\n",
            "Iteration: 183920 | Cost/Loss: 0.074215 | Weight: 0.569627 | Bias: 0.112481\n",
            "Iteration: 183921 | Cost/Loss: 0.074215 | Weight: 0.569627 | Bias: 0.112482\n",
            "Iteration: 183922 | Cost/Loss: 0.074215 | Weight: 0.569627 | Bias: 0.112482\n",
            "Iteration: 183923 | Cost/Loss: 0.074215 | Weight: 0.569628 | Bias: 0.112482\n",
            "Iteration: 183924 | Cost/Loss: 0.074215 | Weight: 0.569628 | Bias: 0.112482\n",
            "Iteration: 183925 | Cost/Loss: 0.074215 | Weight: 0.569628 | Bias: 0.112483\n",
            "Iteration: 183926 | Cost/Loss: 0.074215 | Weight: 0.569629 | Bias: 0.112483\n",
            "Iteration: 183927 | Cost/Loss: 0.074215 | Weight: 0.569629 | Bias: 0.112483\n",
            "Iteration: 183928 | Cost/Loss: 0.074215 | Weight: 0.569629 | Bias: 0.112484\n",
            "Iteration: 183929 | Cost/Loss: 0.074215 | Weight: 0.569629 | Bias: 0.112484\n",
            "Iteration: 183930 | Cost/Loss: 0.074215 | Weight: 0.569630 | Bias: 0.112484\n",
            "Iteration: 183931 | Cost/Loss: 0.074215 | Weight: 0.569630 | Bias: 0.112485\n",
            "Iteration: 183932 | Cost/Loss: 0.074215 | Weight: 0.569630 | Bias: 0.112485\n",
            "Iteration: 183933 | Cost/Loss: 0.074215 | Weight: 0.569631 | Bias: 0.112485\n",
            "Iteration: 183934 | Cost/Loss: 0.074215 | Weight: 0.569631 | Bias: 0.112485\n",
            "Iteration: 183935 | Cost/Loss: 0.074215 | Weight: 0.569631 | Bias: 0.112486\n",
            "Iteration: 183936 | Cost/Loss: 0.074215 | Weight: 0.569632 | Bias: 0.112486\n",
            "Iteration: 183937 | Cost/Loss: 0.074215 | Weight: 0.569632 | Bias: 0.112486\n",
            "Iteration: 183938 | Cost/Loss: 0.074215 | Weight: 0.569632 | Bias: 0.112487\n",
            "Iteration: 183939 | Cost/Loss: 0.074215 | Weight: 0.569632 | Bias: 0.112487\n",
            "Iteration: 183940 | Cost/Loss: 0.074215 | Weight: 0.569633 | Bias: 0.112487\n",
            "Iteration: 183941 | Cost/Loss: 0.074215 | Weight: 0.569633 | Bias: 0.112488\n",
            "Iteration: 183942 | Cost/Loss: 0.074215 | Weight: 0.569633 | Bias: 0.112488\n",
            "Iteration: 183943 | Cost/Loss: 0.074215 | Weight: 0.569634 | Bias: 0.112488\n",
            "Iteration: 183944 | Cost/Loss: 0.074215 | Weight: 0.569634 | Bias: 0.112489\n",
            "Iteration: 183945 | Cost/Loss: 0.074215 | Weight: 0.569634 | Bias: 0.112489\n",
            "Iteration: 183946 | Cost/Loss: 0.074215 | Weight: 0.569635 | Bias: 0.112489\n",
            "Iteration: 183947 | Cost/Loss: 0.074214 | Weight: 0.569635 | Bias: 0.112489\n",
            "Iteration: 183948 | Cost/Loss: 0.074214 | Weight: 0.569635 | Bias: 0.112490\n",
            "Iteration: 183949 | Cost/Loss: 0.074214 | Weight: 0.569635 | Bias: 0.112490\n",
            "Iteration: 183950 | Cost/Loss: 0.074214 | Weight: 0.569636 | Bias: 0.112490\n",
            "Iteration: 183951 | Cost/Loss: 0.074214 | Weight: 0.569636 | Bias: 0.112491\n",
            "Iteration: 183952 | Cost/Loss: 0.074214 | Weight: 0.569636 | Bias: 0.112491\n",
            "Iteration: 183953 | Cost/Loss: 0.074214 | Weight: 0.569637 | Bias: 0.112491\n",
            "Iteration: 183954 | Cost/Loss: 0.074214 | Weight: 0.569637 | Bias: 0.112492\n",
            "Iteration: 183955 | Cost/Loss: 0.074214 | Weight: 0.569637 | Bias: 0.112492\n",
            "Iteration: 183956 | Cost/Loss: 0.074214 | Weight: 0.569638 | Bias: 0.112492\n",
            "Iteration: 183957 | Cost/Loss: 0.074214 | Weight: 0.569638 | Bias: 0.112493\n",
            "Iteration: 183958 | Cost/Loss: 0.074214 | Weight: 0.569638 | Bias: 0.112493\n",
            "Iteration: 183959 | Cost/Loss: 0.074214 | Weight: 0.569638 | Bias: 0.112493\n",
            "Iteration: 183960 | Cost/Loss: 0.074214 | Weight: 0.569639 | Bias: 0.112493\n",
            "Iteration: 183961 | Cost/Loss: 0.074214 | Weight: 0.569639 | Bias: 0.112494\n",
            "Iteration: 183962 | Cost/Loss: 0.074214 | Weight: 0.569639 | Bias: 0.112494\n",
            "Iteration: 183963 | Cost/Loss: 0.074214 | Weight: 0.569640 | Bias: 0.112494\n",
            "Iteration: 183964 | Cost/Loss: 0.074214 | Weight: 0.569640 | Bias: 0.112495\n",
            "Iteration: 183965 | Cost/Loss: 0.074214 | Weight: 0.569640 | Bias: 0.112495\n",
            "Iteration: 183966 | Cost/Loss: 0.074214 | Weight: 0.569641 | Bias: 0.112495\n",
            "Iteration: 183967 | Cost/Loss: 0.074214 | Weight: 0.569641 | Bias: 0.112496\n",
            "Iteration: 183968 | Cost/Loss: 0.074214 | Weight: 0.569641 | Bias: 0.112496\n",
            "Iteration: 183969 | Cost/Loss: 0.074214 | Weight: 0.569641 | Bias: 0.112496\n",
            "Iteration: 183970 | Cost/Loss: 0.074214 | Weight: 0.569642 | Bias: 0.112496\n",
            "Iteration: 183971 | Cost/Loss: 0.074214 | Weight: 0.569642 | Bias: 0.112497\n",
            "Iteration: 183972 | Cost/Loss: 0.074214 | Weight: 0.569642 | Bias: 0.112497\n",
            "Iteration: 183973 | Cost/Loss: 0.074214 | Weight: 0.569643 | Bias: 0.112497\n",
            "Iteration: 183974 | Cost/Loss: 0.074214 | Weight: 0.569643 | Bias: 0.112498\n",
            "Iteration: 183975 | Cost/Loss: 0.074214 | Weight: 0.569643 | Bias: 0.112498\n",
            "Iteration: 183976 | Cost/Loss: 0.074214 | Weight: 0.569643 | Bias: 0.112498\n",
            "Iteration: 183977 | Cost/Loss: 0.074214 | Weight: 0.569644 | Bias: 0.112499\n",
            "Iteration: 183978 | Cost/Loss: 0.074214 | Weight: 0.569644 | Bias: 0.112499\n",
            "Iteration: 183979 | Cost/Loss: 0.074214 | Weight: 0.569644 | Bias: 0.112499\n",
            "Iteration: 183980 | Cost/Loss: 0.074214 | Weight: 0.569645 | Bias: 0.112500\n",
            "Iteration: 183981 | Cost/Loss: 0.074214 | Weight: 0.569645 | Bias: 0.112500\n",
            "Iteration: 183982 | Cost/Loss: 0.074214 | Weight: 0.569645 | Bias: 0.112500\n",
            "Iteration: 183983 | Cost/Loss: 0.074214 | Weight: 0.569646 | Bias: 0.112500\n",
            "Iteration: 183984 | Cost/Loss: 0.074214 | Weight: 0.569646 | Bias: 0.112501\n",
            "Iteration: 183985 | Cost/Loss: 0.074214 | Weight: 0.569646 | Bias: 0.112501\n",
            "Iteration: 183986 | Cost/Loss: 0.074214 | Weight: 0.569646 | Bias: 0.112501\n",
            "Iteration: 183987 | Cost/Loss: 0.074214 | Weight: 0.569647 | Bias: 0.112502\n",
            "Iteration: 183988 | Cost/Loss: 0.074213 | Weight: 0.569647 | Bias: 0.112502\n",
            "Iteration: 183989 | Cost/Loss: 0.074213 | Weight: 0.569647 | Bias: 0.112502\n",
            "Iteration: 183990 | Cost/Loss: 0.074213 | Weight: 0.569648 | Bias: 0.112503\n",
            "Iteration: 183991 | Cost/Loss: 0.074213 | Weight: 0.569648 | Bias: 0.112503\n",
            "Iteration: 183992 | Cost/Loss: 0.074213 | Weight: 0.569648 | Bias: 0.112503\n",
            "Iteration: 183993 | Cost/Loss: 0.074213 | Weight: 0.569649 | Bias: 0.112504\n",
            "Iteration: 183994 | Cost/Loss: 0.074213 | Weight: 0.569649 | Bias: 0.112504\n",
            "Iteration: 183995 | Cost/Loss: 0.074213 | Weight: 0.569649 | Bias: 0.112504\n",
            "Iteration: 183996 | Cost/Loss: 0.074213 | Weight: 0.569649 | Bias: 0.112504\n",
            "Iteration: 183997 | Cost/Loss: 0.074213 | Weight: 0.569650 | Bias: 0.112505\n",
            "Iteration: 183998 | Cost/Loss: 0.074213 | Weight: 0.569650 | Bias: 0.112505\n",
            "Iteration: 183999 | Cost/Loss: 0.074213 | Weight: 0.569650 | Bias: 0.112505\n",
            "Iteration: 184000 | Cost/Loss: 0.074213 | Weight: 0.569651 | Bias: 0.112506\n",
            "Iteration: 184001 | Cost/Loss: 0.074213 | Weight: 0.569651 | Bias: 0.112506\n",
            "Iteration: 184002 | Cost/Loss: 0.074213 | Weight: 0.569651 | Bias: 0.112506\n",
            "Iteration: 184003 | Cost/Loss: 0.074213 | Weight: 0.569652 | Bias: 0.112507\n",
            "Iteration: 184004 | Cost/Loss: 0.074213 | Weight: 0.569652 | Bias: 0.112507\n",
            "Iteration: 184005 | Cost/Loss: 0.074213 | Weight: 0.569652 | Bias: 0.112507\n",
            "Iteration: 184006 | Cost/Loss: 0.074213 | Weight: 0.569652 | Bias: 0.112507\n",
            "Iteration: 184007 | Cost/Loss: 0.074213 | Weight: 0.569653 | Bias: 0.112508\n",
            "Iteration: 184008 | Cost/Loss: 0.074213 | Weight: 0.569653 | Bias: 0.112508\n",
            "Iteration: 184009 | Cost/Loss: 0.074213 | Weight: 0.569653 | Bias: 0.112508\n",
            "Iteration: 184010 | Cost/Loss: 0.074213 | Weight: 0.569654 | Bias: 0.112509\n",
            "Iteration: 184011 | Cost/Loss: 0.074213 | Weight: 0.569654 | Bias: 0.112509\n",
            "Iteration: 184012 | Cost/Loss: 0.074213 | Weight: 0.569654 | Bias: 0.112509\n",
            "Iteration: 184013 | Cost/Loss: 0.074213 | Weight: 0.569655 | Bias: 0.112510\n",
            "Iteration: 184014 | Cost/Loss: 0.074213 | Weight: 0.569655 | Bias: 0.112510\n",
            "Iteration: 184015 | Cost/Loss: 0.074213 | Weight: 0.569655 | Bias: 0.112510\n",
            "Iteration: 184016 | Cost/Loss: 0.074213 | Weight: 0.569655 | Bias: 0.112511\n",
            "Iteration: 184017 | Cost/Loss: 0.074213 | Weight: 0.569656 | Bias: 0.112511\n",
            "Iteration: 184018 | Cost/Loss: 0.074213 | Weight: 0.569656 | Bias: 0.112511\n",
            "Iteration: 184019 | Cost/Loss: 0.074213 | Weight: 0.569656 | Bias: 0.112511\n",
            "Iteration: 184020 | Cost/Loss: 0.074213 | Weight: 0.569657 | Bias: 0.112512\n",
            "Iteration: 184021 | Cost/Loss: 0.074213 | Weight: 0.569657 | Bias: 0.112512\n",
            "Iteration: 184022 | Cost/Loss: 0.074213 | Weight: 0.569657 | Bias: 0.112512\n",
            "Iteration: 184023 | Cost/Loss: 0.074213 | Weight: 0.569658 | Bias: 0.112513\n",
            "Iteration: 184024 | Cost/Loss: 0.074213 | Weight: 0.569658 | Bias: 0.112513\n",
            "Iteration: 184025 | Cost/Loss: 0.074213 | Weight: 0.569658 | Bias: 0.112513\n",
            "Iteration: 184026 | Cost/Loss: 0.074213 | Weight: 0.569658 | Bias: 0.112514\n",
            "Iteration: 184027 | Cost/Loss: 0.074213 | Weight: 0.569659 | Bias: 0.112514\n",
            "Iteration: 184028 | Cost/Loss: 0.074212 | Weight: 0.569659 | Bias: 0.112514\n",
            "Iteration: 184029 | Cost/Loss: 0.074212 | Weight: 0.569659 | Bias: 0.112515\n",
            "Iteration: 184030 | Cost/Loss: 0.074212 | Weight: 0.569660 | Bias: 0.112515\n",
            "Iteration: 184031 | Cost/Loss: 0.074212 | Weight: 0.569660 | Bias: 0.112515\n",
            "Iteration: 184032 | Cost/Loss: 0.074212 | Weight: 0.569660 | Bias: 0.112515\n",
            "Iteration: 184033 | Cost/Loss: 0.074212 | Weight: 0.569660 | Bias: 0.112516\n",
            "Iteration: 184034 | Cost/Loss: 0.074212 | Weight: 0.569661 | Bias: 0.112516\n",
            "Iteration: 184035 | Cost/Loss: 0.074212 | Weight: 0.569661 | Bias: 0.112516\n",
            "Iteration: 184036 | Cost/Loss: 0.074212 | Weight: 0.569661 | Bias: 0.112517\n",
            "Iteration: 184037 | Cost/Loss: 0.074212 | Weight: 0.569662 | Bias: 0.112517\n",
            "Iteration: 184038 | Cost/Loss: 0.074212 | Weight: 0.569662 | Bias: 0.112517\n",
            "Iteration: 184039 | Cost/Loss: 0.074212 | Weight: 0.569662 | Bias: 0.112518\n",
            "Iteration: 184040 | Cost/Loss: 0.074212 | Weight: 0.569663 | Bias: 0.112518\n",
            "Iteration: 184041 | Cost/Loss: 0.074212 | Weight: 0.569663 | Bias: 0.112518\n",
            "Iteration: 184042 | Cost/Loss: 0.074212 | Weight: 0.569663 | Bias: 0.112518\n",
            "Iteration: 184043 | Cost/Loss: 0.074212 | Weight: 0.569663 | Bias: 0.112519\n",
            "Iteration: 184044 | Cost/Loss: 0.074212 | Weight: 0.569664 | Bias: 0.112519\n",
            "Iteration: 184045 | Cost/Loss: 0.074212 | Weight: 0.569664 | Bias: 0.112519\n",
            "Iteration: 184046 | Cost/Loss: 0.074212 | Weight: 0.569664 | Bias: 0.112520\n",
            "Iteration: 184047 | Cost/Loss: 0.074212 | Weight: 0.569665 | Bias: 0.112520\n",
            "Iteration: 184048 | Cost/Loss: 0.074212 | Weight: 0.569665 | Bias: 0.112520\n",
            "Iteration: 184049 | Cost/Loss: 0.074212 | Weight: 0.569665 | Bias: 0.112521\n",
            "Iteration: 184050 | Cost/Loss: 0.074212 | Weight: 0.569666 | Bias: 0.112521\n",
            "Iteration: 184051 | Cost/Loss: 0.074212 | Weight: 0.569666 | Bias: 0.112521\n",
            "Iteration: 184052 | Cost/Loss: 0.074212 | Weight: 0.569666 | Bias: 0.112522\n",
            "Iteration: 184053 | Cost/Loss: 0.074212 | Weight: 0.569666 | Bias: 0.112522\n",
            "Iteration: 184054 | Cost/Loss: 0.074212 | Weight: 0.569667 | Bias: 0.112522\n",
            "Iteration: 184055 | Cost/Loss: 0.074212 | Weight: 0.569667 | Bias: 0.112522\n",
            "Iteration: 184056 | Cost/Loss: 0.074212 | Weight: 0.569667 | Bias: 0.112523\n",
            "Iteration: 184057 | Cost/Loss: 0.074212 | Weight: 0.569668 | Bias: 0.112523\n",
            "Iteration: 184058 | Cost/Loss: 0.074212 | Weight: 0.569668 | Bias: 0.112523\n",
            "Iteration: 184059 | Cost/Loss: 0.074212 | Weight: 0.569668 | Bias: 0.112524\n",
            "Iteration: 184060 | Cost/Loss: 0.074212 | Weight: 0.569669 | Bias: 0.112524\n",
            "Iteration: 184061 | Cost/Loss: 0.074212 | Weight: 0.569669 | Bias: 0.112524\n",
            "Iteration: 184062 | Cost/Loss: 0.074212 | Weight: 0.569669 | Bias: 0.112525\n",
            "Iteration: 184063 | Cost/Loss: 0.074212 | Weight: 0.569669 | Bias: 0.112525\n",
            "Iteration: 184064 | Cost/Loss: 0.074212 | Weight: 0.569670 | Bias: 0.112525\n",
            "Iteration: 184065 | Cost/Loss: 0.074212 | Weight: 0.569670 | Bias: 0.112526\n",
            "Iteration: 184066 | Cost/Loss: 0.074212 | Weight: 0.569670 | Bias: 0.112526\n",
            "Iteration: 184067 | Cost/Loss: 0.074212 | Weight: 0.569671 | Bias: 0.112526\n",
            "Iteration: 184068 | Cost/Loss: 0.074212 | Weight: 0.569671 | Bias: 0.112526\n",
            "Iteration: 184069 | Cost/Loss: 0.074211 | Weight: 0.569671 | Bias: 0.112527\n",
            "Iteration: 184070 | Cost/Loss: 0.074211 | Weight: 0.569672 | Bias: 0.112527\n",
            "Iteration: 184071 | Cost/Loss: 0.074211 | Weight: 0.569672 | Bias: 0.112527\n",
            "Iteration: 184072 | Cost/Loss: 0.074211 | Weight: 0.569672 | Bias: 0.112528\n",
            "Iteration: 184073 | Cost/Loss: 0.074211 | Weight: 0.569672 | Bias: 0.112528\n",
            "Iteration: 184074 | Cost/Loss: 0.074211 | Weight: 0.569673 | Bias: 0.112528\n",
            "Iteration: 184075 | Cost/Loss: 0.074211 | Weight: 0.569673 | Bias: 0.112529\n",
            "Iteration: 184076 | Cost/Loss: 0.074211 | Weight: 0.569673 | Bias: 0.112529\n",
            "Iteration: 184077 | Cost/Loss: 0.074211 | Weight: 0.569674 | Bias: 0.112529\n",
            "Iteration: 184078 | Cost/Loss: 0.074211 | Weight: 0.569674 | Bias: 0.112529\n",
            "Iteration: 184079 | Cost/Loss: 0.074211 | Weight: 0.569674 | Bias: 0.112530\n",
            "Iteration: 184080 | Cost/Loss: 0.074211 | Weight: 0.569674 | Bias: 0.112530\n",
            "Iteration: 184081 | Cost/Loss: 0.074211 | Weight: 0.569675 | Bias: 0.112530\n",
            "Iteration: 184082 | Cost/Loss: 0.074211 | Weight: 0.569675 | Bias: 0.112531\n",
            "Iteration: 184083 | Cost/Loss: 0.074211 | Weight: 0.569675 | Bias: 0.112531\n",
            "Iteration: 184084 | Cost/Loss: 0.074211 | Weight: 0.569676 | Bias: 0.112531\n",
            "Iteration: 184085 | Cost/Loss: 0.074211 | Weight: 0.569676 | Bias: 0.112532\n",
            "Iteration: 184086 | Cost/Loss: 0.074211 | Weight: 0.569676 | Bias: 0.112532\n",
            "Iteration: 184087 | Cost/Loss: 0.074211 | Weight: 0.569677 | Bias: 0.112532\n",
            "Iteration: 184088 | Cost/Loss: 0.074211 | Weight: 0.569677 | Bias: 0.112533\n",
            "Iteration: 184089 | Cost/Loss: 0.074211 | Weight: 0.569677 | Bias: 0.112533\n",
            "Iteration: 184090 | Cost/Loss: 0.074211 | Weight: 0.569677 | Bias: 0.112533\n",
            "Iteration: 184091 | Cost/Loss: 0.074211 | Weight: 0.569678 | Bias: 0.112533\n",
            "Iteration: 184092 | Cost/Loss: 0.074211 | Weight: 0.569678 | Bias: 0.112534\n",
            "Iteration: 184093 | Cost/Loss: 0.074211 | Weight: 0.569678 | Bias: 0.112534\n",
            "Iteration: 184094 | Cost/Loss: 0.074211 | Weight: 0.569679 | Bias: 0.112534\n",
            "Iteration: 184095 | Cost/Loss: 0.074211 | Weight: 0.569679 | Bias: 0.112535\n",
            "Iteration: 184096 | Cost/Loss: 0.074211 | Weight: 0.569679 | Bias: 0.112535\n",
            "Iteration: 184097 | Cost/Loss: 0.074211 | Weight: 0.569680 | Bias: 0.112535\n",
            "Iteration: 184098 | Cost/Loss: 0.074211 | Weight: 0.569680 | Bias: 0.112536\n",
            "Iteration: 184099 | Cost/Loss: 0.074211 | Weight: 0.569680 | Bias: 0.112536\n",
            "Iteration: 184100 | Cost/Loss: 0.074211 | Weight: 0.569680 | Bias: 0.112536\n",
            "Iteration: 184101 | Cost/Loss: 0.074211 | Weight: 0.569681 | Bias: 0.112536\n",
            "Iteration: 184102 | Cost/Loss: 0.074211 | Weight: 0.569681 | Bias: 0.112537\n",
            "Iteration: 184103 | Cost/Loss: 0.074211 | Weight: 0.569681 | Bias: 0.112537\n",
            "Iteration: 184104 | Cost/Loss: 0.074211 | Weight: 0.569682 | Bias: 0.112537\n",
            "Iteration: 184105 | Cost/Loss: 0.074211 | Weight: 0.569682 | Bias: 0.112538\n",
            "Iteration: 184106 | Cost/Loss: 0.074211 | Weight: 0.569682 | Bias: 0.112538\n",
            "Iteration: 184107 | Cost/Loss: 0.074211 | Weight: 0.569683 | Bias: 0.112538\n",
            "Iteration: 184108 | Cost/Loss: 0.074211 | Weight: 0.569683 | Bias: 0.112539\n",
            "Iteration: 184109 | Cost/Loss: 0.074211 | Weight: 0.569683 | Bias: 0.112539\n",
            "Iteration: 184110 | Cost/Loss: 0.074210 | Weight: 0.569683 | Bias: 0.112539\n",
            "Iteration: 184111 | Cost/Loss: 0.074210 | Weight: 0.569684 | Bias: 0.112540\n",
            "Iteration: 184112 | Cost/Loss: 0.074210 | Weight: 0.569684 | Bias: 0.112540\n",
            "Iteration: 184113 | Cost/Loss: 0.074210 | Weight: 0.569684 | Bias: 0.112540\n",
            "Iteration: 184114 | Cost/Loss: 0.074210 | Weight: 0.569685 | Bias: 0.112540\n",
            "Iteration: 184115 | Cost/Loss: 0.074210 | Weight: 0.569685 | Bias: 0.112541\n",
            "Iteration: 184116 | Cost/Loss: 0.074210 | Weight: 0.569685 | Bias: 0.112541\n",
            "Iteration: 184117 | Cost/Loss: 0.074210 | Weight: 0.569686 | Bias: 0.112541\n",
            "Iteration: 184118 | Cost/Loss: 0.074210 | Weight: 0.569686 | Bias: 0.112542\n",
            "Iteration: 184119 | Cost/Loss: 0.074210 | Weight: 0.569686 | Bias: 0.112542\n",
            "Iteration: 184120 | Cost/Loss: 0.074210 | Weight: 0.569686 | Bias: 0.112542\n",
            "Iteration: 184121 | Cost/Loss: 0.074210 | Weight: 0.569687 | Bias: 0.112543\n",
            "Iteration: 184122 | Cost/Loss: 0.074210 | Weight: 0.569687 | Bias: 0.112543\n",
            "Iteration: 184123 | Cost/Loss: 0.074210 | Weight: 0.569687 | Bias: 0.112543\n",
            "Iteration: 184124 | Cost/Loss: 0.074210 | Weight: 0.569688 | Bias: 0.112544\n",
            "Iteration: 184125 | Cost/Loss: 0.074210 | Weight: 0.569688 | Bias: 0.112544\n",
            "Iteration: 184126 | Cost/Loss: 0.074210 | Weight: 0.569688 | Bias: 0.112544\n",
            "Iteration: 184127 | Cost/Loss: 0.074210 | Weight: 0.569688 | Bias: 0.112544\n",
            "Iteration: 184128 | Cost/Loss: 0.074210 | Weight: 0.569689 | Bias: 0.112545\n",
            "Iteration: 184129 | Cost/Loss: 0.074210 | Weight: 0.569689 | Bias: 0.112545\n",
            "Iteration: 184130 | Cost/Loss: 0.074210 | Weight: 0.569689 | Bias: 0.112545\n",
            "Iteration: 184131 | Cost/Loss: 0.074210 | Weight: 0.569690 | Bias: 0.112546\n",
            "Iteration: 184132 | Cost/Loss: 0.074210 | Weight: 0.569690 | Bias: 0.112546\n",
            "Iteration: 184133 | Cost/Loss: 0.074210 | Weight: 0.569690 | Bias: 0.112546\n",
            "Iteration: 184134 | Cost/Loss: 0.074210 | Weight: 0.569691 | Bias: 0.112547\n",
            "Iteration: 184135 | Cost/Loss: 0.074210 | Weight: 0.569691 | Bias: 0.112547\n",
            "Iteration: 184136 | Cost/Loss: 0.074210 | Weight: 0.569691 | Bias: 0.112547\n",
            "Iteration: 184137 | Cost/Loss: 0.074210 | Weight: 0.569691 | Bias: 0.112547\n",
            "Iteration: 184138 | Cost/Loss: 0.074210 | Weight: 0.569692 | Bias: 0.112548\n",
            "Iteration: 184139 | Cost/Loss: 0.074210 | Weight: 0.569692 | Bias: 0.112548\n",
            "Iteration: 184140 | Cost/Loss: 0.074210 | Weight: 0.569692 | Bias: 0.112548\n",
            "Iteration: 184141 | Cost/Loss: 0.074210 | Weight: 0.569693 | Bias: 0.112549\n",
            "Iteration: 184142 | Cost/Loss: 0.074210 | Weight: 0.569693 | Bias: 0.112549\n",
            "Iteration: 184143 | Cost/Loss: 0.074210 | Weight: 0.569693 | Bias: 0.112549\n",
            "Iteration: 184144 | Cost/Loss: 0.074210 | Weight: 0.569694 | Bias: 0.112550\n",
            "Iteration: 184145 | Cost/Loss: 0.074210 | Weight: 0.569694 | Bias: 0.112550\n",
            "Iteration: 184146 | Cost/Loss: 0.074210 | Weight: 0.569694 | Bias: 0.112550\n",
            "Iteration: 184147 | Cost/Loss: 0.074210 | Weight: 0.569694 | Bias: 0.112551\n",
            "Iteration: 184148 | Cost/Loss: 0.074210 | Weight: 0.569695 | Bias: 0.112551\n",
            "Iteration: 184149 | Cost/Loss: 0.074210 | Weight: 0.569695 | Bias: 0.112551\n",
            "Iteration: 184150 | Cost/Loss: 0.074209 | Weight: 0.569695 | Bias: 0.112551\n",
            "Iteration: 184151 | Cost/Loss: 0.074209 | Weight: 0.569696 | Bias: 0.112552\n",
            "Iteration: 184152 | Cost/Loss: 0.074209 | Weight: 0.569696 | Bias: 0.112552\n",
            "Iteration: 184153 | Cost/Loss: 0.074209 | Weight: 0.569696 | Bias: 0.112552\n",
            "Iteration: 184154 | Cost/Loss: 0.074209 | Weight: 0.569697 | Bias: 0.112553\n",
            "Iteration: 184155 | Cost/Loss: 0.074209 | Weight: 0.569697 | Bias: 0.112553\n",
            "Iteration: 184156 | Cost/Loss: 0.074209 | Weight: 0.569697 | Bias: 0.112553\n",
            "Iteration: 184157 | Cost/Loss: 0.074209 | Weight: 0.569697 | Bias: 0.112554\n",
            "Iteration: 184158 | Cost/Loss: 0.074209 | Weight: 0.569698 | Bias: 0.112554\n",
            "Iteration: 184159 | Cost/Loss: 0.074209 | Weight: 0.569698 | Bias: 0.112554\n",
            "Iteration: 184160 | Cost/Loss: 0.074209 | Weight: 0.569698 | Bias: 0.112555\n",
            "Iteration: 184161 | Cost/Loss: 0.074209 | Weight: 0.569699 | Bias: 0.112555\n",
            "Iteration: 184162 | Cost/Loss: 0.074209 | Weight: 0.569699 | Bias: 0.112555\n",
            "Iteration: 184163 | Cost/Loss: 0.074209 | Weight: 0.569699 | Bias: 0.112555\n",
            "Iteration: 184164 | Cost/Loss: 0.074209 | Weight: 0.569700 | Bias: 0.112556\n",
            "Iteration: 184165 | Cost/Loss: 0.074209 | Weight: 0.569700 | Bias: 0.112556\n",
            "Iteration: 184166 | Cost/Loss: 0.074209 | Weight: 0.569700 | Bias: 0.112556\n",
            "Iteration: 184167 | Cost/Loss: 0.074209 | Weight: 0.569700 | Bias: 0.112557\n",
            "Iteration: 184168 | Cost/Loss: 0.074209 | Weight: 0.569701 | Bias: 0.112557\n",
            "Iteration: 184169 | Cost/Loss: 0.074209 | Weight: 0.569701 | Bias: 0.112557\n",
            "Iteration: 184170 | Cost/Loss: 0.074209 | Weight: 0.569701 | Bias: 0.112558\n",
            "Iteration: 184171 | Cost/Loss: 0.074209 | Weight: 0.569702 | Bias: 0.112558\n",
            "Iteration: 184172 | Cost/Loss: 0.074209 | Weight: 0.569702 | Bias: 0.112558\n",
            "Iteration: 184173 | Cost/Loss: 0.074209 | Weight: 0.569702 | Bias: 0.112558\n",
            "Iteration: 184174 | Cost/Loss: 0.074209 | Weight: 0.569703 | Bias: 0.112559\n",
            "Iteration: 184175 | Cost/Loss: 0.074209 | Weight: 0.569703 | Bias: 0.112559\n",
            "Iteration: 184176 | Cost/Loss: 0.074209 | Weight: 0.569703 | Bias: 0.112559\n",
            "Iteration: 184177 | Cost/Loss: 0.074209 | Weight: 0.569703 | Bias: 0.112560\n",
            "Iteration: 184178 | Cost/Loss: 0.074209 | Weight: 0.569704 | Bias: 0.112560\n",
            "Iteration: 184179 | Cost/Loss: 0.074209 | Weight: 0.569704 | Bias: 0.112560\n",
            "Iteration: 184180 | Cost/Loss: 0.074209 | Weight: 0.569704 | Bias: 0.112561\n",
            "Iteration: 184181 | Cost/Loss: 0.074209 | Weight: 0.569705 | Bias: 0.112561\n",
            "Iteration: 184182 | Cost/Loss: 0.074209 | Weight: 0.569705 | Bias: 0.112561\n",
            "Iteration: 184183 | Cost/Loss: 0.074209 | Weight: 0.569705 | Bias: 0.112562\n",
            "Iteration: 184184 | Cost/Loss: 0.074209 | Weight: 0.569705 | Bias: 0.112562\n",
            "Iteration: 184185 | Cost/Loss: 0.074209 | Weight: 0.569706 | Bias: 0.112562\n",
            "Iteration: 184186 | Cost/Loss: 0.074209 | Weight: 0.569706 | Bias: 0.112562\n",
            "Iteration: 184187 | Cost/Loss: 0.074209 | Weight: 0.569706 | Bias: 0.112563\n",
            "Iteration: 184188 | Cost/Loss: 0.074209 | Weight: 0.569707 | Bias: 0.112563\n",
            "Iteration: 184189 | Cost/Loss: 0.074209 | Weight: 0.569707 | Bias: 0.112563\n",
            "Iteration: 184190 | Cost/Loss: 0.074209 | Weight: 0.569707 | Bias: 0.112564\n",
            "Iteration: 184191 | Cost/Loss: 0.074208 | Weight: 0.569708 | Bias: 0.112564\n",
            "Iteration: 184192 | Cost/Loss: 0.074208 | Weight: 0.569708 | Bias: 0.112564\n",
            "Iteration: 184193 | Cost/Loss: 0.074208 | Weight: 0.569708 | Bias: 0.112565\n",
            "Iteration: 184194 | Cost/Loss: 0.074208 | Weight: 0.569708 | Bias: 0.112565\n",
            "Iteration: 184195 | Cost/Loss: 0.074208 | Weight: 0.569709 | Bias: 0.112565\n",
            "Iteration: 184196 | Cost/Loss: 0.074208 | Weight: 0.569709 | Bias: 0.112566\n",
            "Iteration: 184197 | Cost/Loss: 0.074208 | Weight: 0.569709 | Bias: 0.112566\n",
            "Iteration: 184198 | Cost/Loss: 0.074208 | Weight: 0.569710 | Bias: 0.112566\n",
            "Iteration: 184199 | Cost/Loss: 0.074208 | Weight: 0.569710 | Bias: 0.112566\n",
            "Iteration: 184200 | Cost/Loss: 0.074208 | Weight: 0.569710 | Bias: 0.112567\n",
            "Iteration: 184201 | Cost/Loss: 0.074208 | Weight: 0.569711 | Bias: 0.112567\n",
            "Iteration: 184202 | Cost/Loss: 0.074208 | Weight: 0.569711 | Bias: 0.112567\n",
            "Iteration: 184203 | Cost/Loss: 0.074208 | Weight: 0.569711 | Bias: 0.112568\n",
            "Iteration: 184204 | Cost/Loss: 0.074208 | Weight: 0.569711 | Bias: 0.112568\n",
            "Iteration: 184205 | Cost/Loss: 0.074208 | Weight: 0.569712 | Bias: 0.112568\n",
            "Iteration: 184206 | Cost/Loss: 0.074208 | Weight: 0.569712 | Bias: 0.112569\n",
            "Iteration: 184207 | Cost/Loss: 0.074208 | Weight: 0.569712 | Bias: 0.112569\n",
            "Iteration: 184208 | Cost/Loss: 0.074208 | Weight: 0.569713 | Bias: 0.112569\n",
            "Iteration: 184209 | Cost/Loss: 0.074208 | Weight: 0.569713 | Bias: 0.112569\n",
            "Iteration: 184210 | Cost/Loss: 0.074208 | Weight: 0.569713 | Bias: 0.112570\n",
            "Iteration: 184211 | Cost/Loss: 0.074208 | Weight: 0.569714 | Bias: 0.112570\n",
            "Iteration: 184212 | Cost/Loss: 0.074208 | Weight: 0.569714 | Bias: 0.112570\n",
            "Iteration: 184213 | Cost/Loss: 0.074208 | Weight: 0.569714 | Bias: 0.112571\n",
            "Iteration: 184214 | Cost/Loss: 0.074208 | Weight: 0.569714 | Bias: 0.112571\n",
            "Iteration: 184215 | Cost/Loss: 0.074208 | Weight: 0.569715 | Bias: 0.112571\n",
            "Iteration: 184216 | Cost/Loss: 0.074208 | Weight: 0.569715 | Bias: 0.112572\n",
            "Iteration: 184217 | Cost/Loss: 0.074208 | Weight: 0.569715 | Bias: 0.112572\n",
            "Iteration: 184218 | Cost/Loss: 0.074208 | Weight: 0.569716 | Bias: 0.112572\n",
            "Iteration: 184219 | Cost/Loss: 0.074208 | Weight: 0.569716 | Bias: 0.112573\n",
            "Iteration: 184220 | Cost/Loss: 0.074208 | Weight: 0.569716 | Bias: 0.112573\n",
            "Iteration: 184221 | Cost/Loss: 0.074208 | Weight: 0.569717 | Bias: 0.112573\n",
            "Iteration: 184222 | Cost/Loss: 0.074208 | Weight: 0.569717 | Bias: 0.112573\n",
            "Iteration: 184223 | Cost/Loss: 0.074208 | Weight: 0.569717 | Bias: 0.112574\n",
            "Iteration: 184224 | Cost/Loss: 0.074208 | Weight: 0.569717 | Bias: 0.112574\n",
            "Iteration: 184225 | Cost/Loss: 0.074208 | Weight: 0.569718 | Bias: 0.112574\n",
            "Iteration: 184226 | Cost/Loss: 0.074208 | Weight: 0.569718 | Bias: 0.112575\n",
            "Iteration: 184227 | Cost/Loss: 0.074208 | Weight: 0.569718 | Bias: 0.112575\n",
            "Iteration: 184228 | Cost/Loss: 0.074208 | Weight: 0.569719 | Bias: 0.112575\n",
            "Iteration: 184229 | Cost/Loss: 0.074208 | Weight: 0.569719 | Bias: 0.112576\n",
            "Iteration: 184230 | Cost/Loss: 0.074208 | Weight: 0.569719 | Bias: 0.112576\n",
            "Iteration: 184231 | Cost/Loss: 0.074207 | Weight: 0.569719 | Bias: 0.112576\n",
            "Iteration: 184232 | Cost/Loss: 0.074207 | Weight: 0.569720 | Bias: 0.112577\n",
            "Iteration: 184233 | Cost/Loss: 0.074207 | Weight: 0.569720 | Bias: 0.112577\n",
            "Iteration: 184234 | Cost/Loss: 0.074207 | Weight: 0.569720 | Bias: 0.112577\n",
            "Iteration: 184235 | Cost/Loss: 0.074207 | Weight: 0.569721 | Bias: 0.112577\n",
            "Iteration: 184236 | Cost/Loss: 0.074207 | Weight: 0.569721 | Bias: 0.112578\n",
            "Iteration: 184237 | Cost/Loss: 0.074207 | Weight: 0.569721 | Bias: 0.112578\n",
            "Iteration: 184238 | Cost/Loss: 0.074207 | Weight: 0.569722 | Bias: 0.112578\n",
            "Iteration: 184239 | Cost/Loss: 0.074207 | Weight: 0.569722 | Bias: 0.112579\n",
            "Iteration: 184240 | Cost/Loss: 0.074207 | Weight: 0.569722 | Bias: 0.112579\n",
            "Iteration: 184241 | Cost/Loss: 0.074207 | Weight: 0.569722 | Bias: 0.112579\n",
            "Iteration: 184242 | Cost/Loss: 0.074207 | Weight: 0.569723 | Bias: 0.112580\n",
            "Iteration: 184243 | Cost/Loss: 0.074207 | Weight: 0.569723 | Bias: 0.112580\n",
            "Iteration: 184244 | Cost/Loss: 0.074207 | Weight: 0.569723 | Bias: 0.112580\n",
            "Iteration: 184245 | Cost/Loss: 0.074207 | Weight: 0.569724 | Bias: 0.112580\n",
            "Iteration: 184246 | Cost/Loss: 0.074207 | Weight: 0.569724 | Bias: 0.112581\n",
            "Iteration: 184247 | Cost/Loss: 0.074207 | Weight: 0.569724 | Bias: 0.112581\n",
            "Iteration: 184248 | Cost/Loss: 0.074207 | Weight: 0.569725 | Bias: 0.112581\n",
            "Iteration: 184249 | Cost/Loss: 0.074207 | Weight: 0.569725 | Bias: 0.112582\n",
            "Iteration: 184250 | Cost/Loss: 0.074207 | Weight: 0.569725 | Bias: 0.112582\n",
            "Iteration: 184251 | Cost/Loss: 0.074207 | Weight: 0.569725 | Bias: 0.112582\n",
            "Iteration: 184252 | Cost/Loss: 0.074207 | Weight: 0.569726 | Bias: 0.112583\n",
            "Iteration: 184253 | Cost/Loss: 0.074207 | Weight: 0.569726 | Bias: 0.112583\n",
            "Iteration: 184254 | Cost/Loss: 0.074207 | Weight: 0.569726 | Bias: 0.112583\n",
            "Iteration: 184255 | Cost/Loss: 0.074207 | Weight: 0.569727 | Bias: 0.112584\n",
            "Iteration: 184256 | Cost/Loss: 0.074207 | Weight: 0.569727 | Bias: 0.112584\n",
            "Iteration: 184257 | Cost/Loss: 0.074207 | Weight: 0.569727 | Bias: 0.112584\n",
            "Iteration: 184258 | Cost/Loss: 0.074207 | Weight: 0.569728 | Bias: 0.112584\n",
            "Iteration: 184259 | Cost/Loss: 0.074207 | Weight: 0.569728 | Bias: 0.112585\n",
            "Iteration: 184260 | Cost/Loss: 0.074207 | Weight: 0.569728 | Bias: 0.112585\n",
            "Iteration: 184261 | Cost/Loss: 0.074207 | Weight: 0.569728 | Bias: 0.112585\n",
            "Iteration: 184262 | Cost/Loss: 0.074207 | Weight: 0.569729 | Bias: 0.112586\n",
            "Iteration: 184263 | Cost/Loss: 0.074207 | Weight: 0.569729 | Bias: 0.112586\n",
            "Iteration: 184264 | Cost/Loss: 0.074207 | Weight: 0.569729 | Bias: 0.112586\n",
            "Iteration: 184265 | Cost/Loss: 0.074207 | Weight: 0.569730 | Bias: 0.112587\n",
            "Iteration: 184266 | Cost/Loss: 0.074207 | Weight: 0.569730 | Bias: 0.112587\n",
            "Iteration: 184267 | Cost/Loss: 0.074207 | Weight: 0.569730 | Bias: 0.112587\n",
            "Iteration: 184268 | Cost/Loss: 0.074207 | Weight: 0.569731 | Bias: 0.112588\n",
            "Iteration: 184269 | Cost/Loss: 0.074207 | Weight: 0.569731 | Bias: 0.112588\n",
            "Iteration: 184270 | Cost/Loss: 0.074207 | Weight: 0.569731 | Bias: 0.112588\n",
            "Iteration: 184271 | Cost/Loss: 0.074207 | Weight: 0.569731 | Bias: 0.112588\n",
            "Iteration: 184272 | Cost/Loss: 0.074206 | Weight: 0.569732 | Bias: 0.112589\n",
            "Iteration: 184273 | Cost/Loss: 0.074206 | Weight: 0.569732 | Bias: 0.112589\n",
            "Iteration: 184274 | Cost/Loss: 0.074206 | Weight: 0.569732 | Bias: 0.112589\n",
            "Iteration: 184275 | Cost/Loss: 0.074206 | Weight: 0.569733 | Bias: 0.112590\n",
            "Iteration: 184276 | Cost/Loss: 0.074206 | Weight: 0.569733 | Bias: 0.112590\n",
            "Iteration: 184277 | Cost/Loss: 0.074206 | Weight: 0.569733 | Bias: 0.112590\n",
            "Iteration: 184278 | Cost/Loss: 0.074206 | Weight: 0.569734 | Bias: 0.112591\n",
            "Iteration: 184279 | Cost/Loss: 0.074206 | Weight: 0.569734 | Bias: 0.112591\n",
            "Iteration: 184280 | Cost/Loss: 0.074206 | Weight: 0.569734 | Bias: 0.112591\n",
            "Iteration: 184281 | Cost/Loss: 0.074206 | Weight: 0.569734 | Bias: 0.112591\n",
            "Iteration: 184282 | Cost/Loss: 0.074206 | Weight: 0.569735 | Bias: 0.112592\n",
            "Iteration: 184283 | Cost/Loss: 0.074206 | Weight: 0.569735 | Bias: 0.112592\n",
            "Iteration: 184284 | Cost/Loss: 0.074206 | Weight: 0.569735 | Bias: 0.112592\n",
            "Iteration: 184285 | Cost/Loss: 0.074206 | Weight: 0.569736 | Bias: 0.112593\n",
            "Iteration: 184286 | Cost/Loss: 0.074206 | Weight: 0.569736 | Bias: 0.112593\n",
            "Iteration: 184287 | Cost/Loss: 0.074206 | Weight: 0.569736 | Bias: 0.112593\n",
            "Iteration: 184288 | Cost/Loss: 0.074206 | Weight: 0.569736 | Bias: 0.112594\n",
            "Iteration: 184289 | Cost/Loss: 0.074206 | Weight: 0.569737 | Bias: 0.112594\n",
            "Iteration: 184290 | Cost/Loss: 0.074206 | Weight: 0.569737 | Bias: 0.112594\n",
            "Iteration: 184291 | Cost/Loss: 0.074206 | Weight: 0.569737 | Bias: 0.112595\n",
            "Iteration: 184292 | Cost/Loss: 0.074206 | Weight: 0.569738 | Bias: 0.112595\n",
            "Iteration: 184293 | Cost/Loss: 0.074206 | Weight: 0.569738 | Bias: 0.112595\n",
            "Iteration: 184294 | Cost/Loss: 0.074206 | Weight: 0.569738 | Bias: 0.112595\n",
            "Iteration: 184295 | Cost/Loss: 0.074206 | Weight: 0.569739 | Bias: 0.112596\n",
            "Iteration: 184296 | Cost/Loss: 0.074206 | Weight: 0.569739 | Bias: 0.112596\n",
            "Iteration: 184297 | Cost/Loss: 0.074206 | Weight: 0.569739 | Bias: 0.112596\n",
            "Iteration: 184298 | Cost/Loss: 0.074206 | Weight: 0.569739 | Bias: 0.112597\n",
            "Iteration: 184299 | Cost/Loss: 0.074206 | Weight: 0.569740 | Bias: 0.112597\n",
            "Iteration: 184300 | Cost/Loss: 0.074206 | Weight: 0.569740 | Bias: 0.112597\n",
            "Iteration: 184301 | Cost/Loss: 0.074206 | Weight: 0.569740 | Bias: 0.112598\n",
            "Iteration: 184302 | Cost/Loss: 0.074206 | Weight: 0.569741 | Bias: 0.112598\n",
            "Iteration: 184303 | Cost/Loss: 0.074206 | Weight: 0.569741 | Bias: 0.112598\n",
            "Iteration: 184304 | Cost/Loss: 0.074206 | Weight: 0.569741 | Bias: 0.112599\n",
            "Iteration: 184305 | Cost/Loss: 0.074206 | Weight: 0.569742 | Bias: 0.112599\n",
            "Iteration: 184306 | Cost/Loss: 0.074206 | Weight: 0.569742 | Bias: 0.112599\n",
            "Iteration: 184307 | Cost/Loss: 0.074206 | Weight: 0.569742 | Bias: 0.112599\n",
            "Iteration: 184308 | Cost/Loss: 0.074206 | Weight: 0.569742 | Bias: 0.112600\n",
            "Iteration: 184309 | Cost/Loss: 0.074206 | Weight: 0.569743 | Bias: 0.112600\n",
            "Iteration: 184310 | Cost/Loss: 0.074206 | Weight: 0.569743 | Bias: 0.112600\n",
            "Iteration: 184311 | Cost/Loss: 0.074206 | Weight: 0.569743 | Bias: 0.112601\n",
            "Iteration: 184312 | Cost/Loss: 0.074205 | Weight: 0.569744 | Bias: 0.112601\n",
            "Iteration: 184313 | Cost/Loss: 0.074205 | Weight: 0.569744 | Bias: 0.112601\n",
            "Iteration: 184314 | Cost/Loss: 0.074205 | Weight: 0.569744 | Bias: 0.112602\n",
            "Iteration: 184315 | Cost/Loss: 0.074205 | Weight: 0.569745 | Bias: 0.112602\n",
            "Iteration: 184316 | Cost/Loss: 0.074205 | Weight: 0.569745 | Bias: 0.112602\n",
            "Iteration: 184317 | Cost/Loss: 0.074205 | Weight: 0.569745 | Bias: 0.112602\n",
            "Iteration: 184318 | Cost/Loss: 0.074205 | Weight: 0.569745 | Bias: 0.112603\n",
            "Iteration: 184319 | Cost/Loss: 0.074205 | Weight: 0.569746 | Bias: 0.112603\n",
            "Iteration: 184320 | Cost/Loss: 0.074205 | Weight: 0.569746 | Bias: 0.112603\n",
            "Iteration: 184321 | Cost/Loss: 0.074205 | Weight: 0.569746 | Bias: 0.112604\n",
            "Iteration: 184322 | Cost/Loss: 0.074205 | Weight: 0.569747 | Bias: 0.112604\n",
            "Iteration: 184323 | Cost/Loss: 0.074205 | Weight: 0.569747 | Bias: 0.112604\n",
            "Iteration: 184324 | Cost/Loss: 0.074205 | Weight: 0.569747 | Bias: 0.112605\n",
            "Iteration: 184325 | Cost/Loss: 0.074205 | Weight: 0.569748 | Bias: 0.112605\n",
            "Iteration: 184326 | Cost/Loss: 0.074205 | Weight: 0.569748 | Bias: 0.112605\n",
            "Iteration: 184327 | Cost/Loss: 0.074205 | Weight: 0.569748 | Bias: 0.112606\n",
            "Iteration: 184328 | Cost/Loss: 0.074205 | Weight: 0.569748 | Bias: 0.112606\n",
            "Iteration: 184329 | Cost/Loss: 0.074205 | Weight: 0.569749 | Bias: 0.112606\n",
            "Iteration: 184330 | Cost/Loss: 0.074205 | Weight: 0.569749 | Bias: 0.112606\n",
            "Iteration: 184331 | Cost/Loss: 0.074205 | Weight: 0.569749 | Bias: 0.112607\n",
            "Iteration: 184332 | Cost/Loss: 0.074205 | Weight: 0.569750 | Bias: 0.112607\n",
            "Iteration: 184333 | Cost/Loss: 0.074205 | Weight: 0.569750 | Bias: 0.112607\n",
            "Iteration: 184334 | Cost/Loss: 0.074205 | Weight: 0.569750 | Bias: 0.112608\n",
            "Iteration: 184335 | Cost/Loss: 0.074205 | Weight: 0.569750 | Bias: 0.112608\n",
            "Iteration: 184336 | Cost/Loss: 0.074205 | Weight: 0.569751 | Bias: 0.112608\n",
            "Iteration: 184337 | Cost/Loss: 0.074205 | Weight: 0.569751 | Bias: 0.112609\n",
            "Iteration: 184338 | Cost/Loss: 0.074205 | Weight: 0.569751 | Bias: 0.112609\n",
            "Iteration: 184339 | Cost/Loss: 0.074205 | Weight: 0.569752 | Bias: 0.112609\n",
            "Iteration: 184340 | Cost/Loss: 0.074205 | Weight: 0.569752 | Bias: 0.112610\n",
            "Iteration: 184341 | Cost/Loss: 0.074205 | Weight: 0.569752 | Bias: 0.112610\n",
            "Iteration: 184342 | Cost/Loss: 0.074205 | Weight: 0.569753 | Bias: 0.112610\n",
            "Iteration: 184343 | Cost/Loss: 0.074205 | Weight: 0.569753 | Bias: 0.112610\n",
            "Iteration: 184344 | Cost/Loss: 0.074205 | Weight: 0.569753 | Bias: 0.112611\n",
            "Iteration: 184345 | Cost/Loss: 0.074205 | Weight: 0.569753 | Bias: 0.112611\n",
            "Iteration: 184346 | Cost/Loss: 0.074205 | Weight: 0.569754 | Bias: 0.112611\n",
            "Iteration: 184347 | Cost/Loss: 0.074205 | Weight: 0.569754 | Bias: 0.112612\n",
            "Iteration: 184348 | Cost/Loss: 0.074205 | Weight: 0.569754 | Bias: 0.112612\n",
            "Iteration: 184349 | Cost/Loss: 0.074205 | Weight: 0.569755 | Bias: 0.112612\n",
            "Iteration: 184350 | Cost/Loss: 0.074205 | Weight: 0.569755 | Bias: 0.112613\n",
            "Iteration: 184351 | Cost/Loss: 0.074205 | Weight: 0.569755 | Bias: 0.112613\n",
            "Iteration: 184352 | Cost/Loss: 0.074205 | Weight: 0.569756 | Bias: 0.112613\n",
            "Iteration: 184353 | Cost/Loss: 0.074204 | Weight: 0.569756 | Bias: 0.112613\n",
            "Iteration: 184354 | Cost/Loss: 0.074204 | Weight: 0.569756 | Bias: 0.112614\n",
            "Iteration: 184355 | Cost/Loss: 0.074204 | Weight: 0.569756 | Bias: 0.112614\n",
            "Iteration: 184356 | Cost/Loss: 0.074204 | Weight: 0.569757 | Bias: 0.112614\n",
            "Iteration: 184357 | Cost/Loss: 0.074204 | Weight: 0.569757 | Bias: 0.112615\n",
            "Iteration: 184358 | Cost/Loss: 0.074204 | Weight: 0.569757 | Bias: 0.112615\n",
            "Iteration: 184359 | Cost/Loss: 0.074204 | Weight: 0.569758 | Bias: 0.112615\n",
            "Iteration: 184360 | Cost/Loss: 0.074204 | Weight: 0.569758 | Bias: 0.112616\n",
            "Iteration: 184361 | Cost/Loss: 0.074204 | Weight: 0.569758 | Bias: 0.112616\n",
            "Iteration: 184362 | Cost/Loss: 0.074204 | Weight: 0.569759 | Bias: 0.112616\n",
            "Iteration: 184363 | Cost/Loss: 0.074204 | Weight: 0.569759 | Bias: 0.112617\n",
            "Iteration: 184364 | Cost/Loss: 0.074204 | Weight: 0.569759 | Bias: 0.112617\n",
            "Iteration: 184365 | Cost/Loss: 0.074204 | Weight: 0.569759 | Bias: 0.112617\n",
            "Iteration: 184366 | Cost/Loss: 0.074204 | Weight: 0.569760 | Bias: 0.112617\n",
            "Iteration: 184367 | Cost/Loss: 0.074204 | Weight: 0.569760 | Bias: 0.112618\n",
            "Iteration: 184368 | Cost/Loss: 0.074204 | Weight: 0.569760 | Bias: 0.112618\n",
            "Iteration: 184369 | Cost/Loss: 0.074204 | Weight: 0.569761 | Bias: 0.112618\n",
            "Iteration: 184370 | Cost/Loss: 0.074204 | Weight: 0.569761 | Bias: 0.112619\n",
            "Iteration: 184371 | Cost/Loss: 0.074204 | Weight: 0.569761 | Bias: 0.112619\n",
            "Iteration: 184372 | Cost/Loss: 0.074204 | Weight: 0.569762 | Bias: 0.112619\n",
            "Iteration: 184373 | Cost/Loss: 0.074204 | Weight: 0.569762 | Bias: 0.112620\n",
            "Iteration: 184374 | Cost/Loss: 0.074204 | Weight: 0.569762 | Bias: 0.112620\n",
            "Iteration: 184375 | Cost/Loss: 0.074204 | Weight: 0.569762 | Bias: 0.112620\n",
            "Iteration: 184376 | Cost/Loss: 0.074204 | Weight: 0.569763 | Bias: 0.112621\n",
            "Iteration: 184377 | Cost/Loss: 0.074204 | Weight: 0.569763 | Bias: 0.112621\n",
            "Iteration: 184378 | Cost/Loss: 0.074204 | Weight: 0.569763 | Bias: 0.112621\n",
            "Iteration: 184379 | Cost/Loss: 0.074204 | Weight: 0.569764 | Bias: 0.112621\n",
            "Iteration: 184380 | Cost/Loss: 0.074204 | Weight: 0.569764 | Bias: 0.112622\n",
            "Iteration: 184381 | Cost/Loss: 0.074204 | Weight: 0.569764 | Bias: 0.112622\n",
            "Iteration: 184382 | Cost/Loss: 0.074204 | Weight: 0.569764 | Bias: 0.112622\n",
            "Iteration: 184383 | Cost/Loss: 0.074204 | Weight: 0.569765 | Bias: 0.112623\n",
            "Iteration: 184384 | Cost/Loss: 0.074204 | Weight: 0.569765 | Bias: 0.112623\n",
            "Iteration: 184385 | Cost/Loss: 0.074204 | Weight: 0.569765 | Bias: 0.112623\n",
            "Iteration: 184386 | Cost/Loss: 0.074204 | Weight: 0.569766 | Bias: 0.112624\n",
            "Iteration: 184387 | Cost/Loss: 0.074204 | Weight: 0.569766 | Bias: 0.112624\n",
            "Iteration: 184388 | Cost/Loss: 0.074204 | Weight: 0.569766 | Bias: 0.112624\n",
            "Iteration: 184389 | Cost/Loss: 0.074204 | Weight: 0.569767 | Bias: 0.112624\n",
            "Iteration: 184390 | Cost/Loss: 0.074204 | Weight: 0.569767 | Bias: 0.112625\n",
            "Iteration: 184391 | Cost/Loss: 0.074204 | Weight: 0.569767 | Bias: 0.112625\n",
            "Iteration: 184392 | Cost/Loss: 0.074204 | Weight: 0.569767 | Bias: 0.112625\n",
            "Iteration: 184393 | Cost/Loss: 0.074203 | Weight: 0.569768 | Bias: 0.112626\n",
            "Iteration: 184394 | Cost/Loss: 0.074203 | Weight: 0.569768 | Bias: 0.112626\n",
            "Iteration: 184395 | Cost/Loss: 0.074203 | Weight: 0.569768 | Bias: 0.112626\n",
            "Iteration: 184396 | Cost/Loss: 0.074203 | Weight: 0.569769 | Bias: 0.112627\n",
            "Iteration: 184397 | Cost/Loss: 0.074203 | Weight: 0.569769 | Bias: 0.112627\n",
            "Iteration: 184398 | Cost/Loss: 0.074203 | Weight: 0.569769 | Bias: 0.112627\n",
            "Iteration: 184399 | Cost/Loss: 0.074203 | Weight: 0.569770 | Bias: 0.112628\n",
            "Iteration: 184400 | Cost/Loss: 0.074203 | Weight: 0.569770 | Bias: 0.112628\n",
            "Iteration: 184401 | Cost/Loss: 0.074203 | Weight: 0.569770 | Bias: 0.112628\n",
            "Iteration: 184402 | Cost/Loss: 0.074203 | Weight: 0.569770 | Bias: 0.112628\n",
            "Iteration: 184403 | Cost/Loss: 0.074203 | Weight: 0.569771 | Bias: 0.112629\n",
            "Iteration: 184404 | Cost/Loss: 0.074203 | Weight: 0.569771 | Bias: 0.112629\n",
            "Iteration: 184405 | Cost/Loss: 0.074203 | Weight: 0.569771 | Bias: 0.112629\n",
            "Iteration: 184406 | Cost/Loss: 0.074203 | Weight: 0.569772 | Bias: 0.112630\n",
            "Iteration: 184407 | Cost/Loss: 0.074203 | Weight: 0.569772 | Bias: 0.112630\n",
            "Iteration: 184408 | Cost/Loss: 0.074203 | Weight: 0.569772 | Bias: 0.112630\n",
            "Iteration: 184409 | Cost/Loss: 0.074203 | Weight: 0.569773 | Bias: 0.112631\n",
            "Iteration: 184410 | Cost/Loss: 0.074203 | Weight: 0.569773 | Bias: 0.112631\n",
            "Iteration: 184411 | Cost/Loss: 0.074203 | Weight: 0.569773 | Bias: 0.112631\n",
            "Iteration: 184412 | Cost/Loss: 0.074203 | Weight: 0.569773 | Bias: 0.112631\n",
            "Iteration: 184413 | Cost/Loss: 0.074203 | Weight: 0.569774 | Bias: 0.112632\n",
            "Iteration: 184414 | Cost/Loss: 0.074203 | Weight: 0.569774 | Bias: 0.112632\n",
            "Iteration: 184415 | Cost/Loss: 0.074203 | Weight: 0.569774 | Bias: 0.112632\n",
            "Iteration: 184416 | Cost/Loss: 0.074203 | Weight: 0.569775 | Bias: 0.112633\n",
            "Iteration: 184417 | Cost/Loss: 0.074203 | Weight: 0.569775 | Bias: 0.112633\n",
            "Iteration: 184418 | Cost/Loss: 0.074203 | Weight: 0.569775 | Bias: 0.112633\n",
            "Iteration: 184419 | Cost/Loss: 0.074203 | Weight: 0.569776 | Bias: 0.112634\n",
            "Iteration: 184420 | Cost/Loss: 0.074203 | Weight: 0.569776 | Bias: 0.112634\n",
            "Iteration: 184421 | Cost/Loss: 0.074203 | Weight: 0.569776 | Bias: 0.112634\n",
            "Iteration: 184422 | Cost/Loss: 0.074203 | Weight: 0.569776 | Bias: 0.112635\n",
            "Iteration: 184423 | Cost/Loss: 0.074203 | Weight: 0.569777 | Bias: 0.112635\n",
            "Iteration: 184424 | Cost/Loss: 0.074203 | Weight: 0.569777 | Bias: 0.112635\n",
            "Iteration: 184425 | Cost/Loss: 0.074203 | Weight: 0.569777 | Bias: 0.112635\n",
            "Iteration: 184426 | Cost/Loss: 0.074203 | Weight: 0.569778 | Bias: 0.112636\n",
            "Iteration: 184427 | Cost/Loss: 0.074203 | Weight: 0.569778 | Bias: 0.112636\n",
            "Iteration: 184428 | Cost/Loss: 0.074203 | Weight: 0.569778 | Bias: 0.112636\n",
            "Iteration: 184429 | Cost/Loss: 0.074203 | Weight: 0.569779 | Bias: 0.112637\n",
            "Iteration: 184430 | Cost/Loss: 0.074203 | Weight: 0.569779 | Bias: 0.112637\n",
            "Iteration: 184431 | Cost/Loss: 0.074203 | Weight: 0.569779 | Bias: 0.112637\n",
            "Iteration: 184432 | Cost/Loss: 0.074203 | Weight: 0.569779 | Bias: 0.112638\n",
            "Iteration: 184433 | Cost/Loss: 0.074203 | Weight: 0.569780 | Bias: 0.112638\n",
            "Iteration: 184434 | Cost/Loss: 0.074202 | Weight: 0.569780 | Bias: 0.112638\n",
            "Iteration: 184435 | Cost/Loss: 0.074202 | Weight: 0.569780 | Bias: 0.112639\n",
            "Iteration: 184436 | Cost/Loss: 0.074202 | Weight: 0.569781 | Bias: 0.112639\n",
            "Iteration: 184437 | Cost/Loss: 0.074202 | Weight: 0.569781 | Bias: 0.112639\n",
            "Iteration: 184438 | Cost/Loss: 0.074202 | Weight: 0.569781 | Bias: 0.112639\n",
            "Iteration: 184439 | Cost/Loss: 0.074202 | Weight: 0.569781 | Bias: 0.112640\n",
            "Iteration: 184440 | Cost/Loss: 0.074202 | Weight: 0.569782 | Bias: 0.112640\n",
            "Iteration: 184441 | Cost/Loss: 0.074202 | Weight: 0.569782 | Bias: 0.112640\n",
            "Iteration: 184442 | Cost/Loss: 0.074202 | Weight: 0.569782 | Bias: 0.112641\n",
            "Iteration: 184443 | Cost/Loss: 0.074202 | Weight: 0.569783 | Bias: 0.112641\n",
            "Iteration: 184444 | Cost/Loss: 0.074202 | Weight: 0.569783 | Bias: 0.112641\n",
            "Iteration: 184445 | Cost/Loss: 0.074202 | Weight: 0.569783 | Bias: 0.112642\n",
            "Iteration: 184446 | Cost/Loss: 0.074202 | Weight: 0.569784 | Bias: 0.112642\n",
            "Iteration: 184447 | Cost/Loss: 0.074202 | Weight: 0.569784 | Bias: 0.112642\n",
            "Iteration: 184448 | Cost/Loss: 0.074202 | Weight: 0.569784 | Bias: 0.112642\n",
            "Iteration: 184449 | Cost/Loss: 0.074202 | Weight: 0.569784 | Bias: 0.112643\n",
            "Iteration: 184450 | Cost/Loss: 0.074202 | Weight: 0.569785 | Bias: 0.112643\n",
            "Iteration: 184451 | Cost/Loss: 0.074202 | Weight: 0.569785 | Bias: 0.112643\n",
            "Iteration: 184452 | Cost/Loss: 0.074202 | Weight: 0.569785 | Bias: 0.112644\n",
            "Iteration: 184453 | Cost/Loss: 0.074202 | Weight: 0.569786 | Bias: 0.112644\n",
            "Iteration: 184454 | Cost/Loss: 0.074202 | Weight: 0.569786 | Bias: 0.112644\n",
            "Iteration: 184455 | Cost/Loss: 0.074202 | Weight: 0.569786 | Bias: 0.112645\n",
            "Iteration: 184456 | Cost/Loss: 0.074202 | Weight: 0.569787 | Bias: 0.112645\n",
            "Iteration: 184457 | Cost/Loss: 0.074202 | Weight: 0.569787 | Bias: 0.112645\n",
            "Iteration: 184458 | Cost/Loss: 0.074202 | Weight: 0.569787 | Bias: 0.112646\n",
            "Iteration: 184459 | Cost/Loss: 0.074202 | Weight: 0.569787 | Bias: 0.112646\n",
            "Iteration: 184460 | Cost/Loss: 0.074202 | Weight: 0.569788 | Bias: 0.112646\n",
            "Iteration: 184461 | Cost/Loss: 0.074202 | Weight: 0.569788 | Bias: 0.112646\n",
            "Iteration: 184462 | Cost/Loss: 0.074202 | Weight: 0.569788 | Bias: 0.112647\n",
            "Iteration: 184463 | Cost/Loss: 0.074202 | Weight: 0.569789 | Bias: 0.112647\n",
            "Iteration: 184464 | Cost/Loss: 0.074202 | Weight: 0.569789 | Bias: 0.112647\n",
            "Iteration: 184465 | Cost/Loss: 0.074202 | Weight: 0.569789 | Bias: 0.112648\n",
            "Iteration: 184466 | Cost/Loss: 0.074202 | Weight: 0.569790 | Bias: 0.112648\n",
            "Iteration: 184467 | Cost/Loss: 0.074202 | Weight: 0.569790 | Bias: 0.112648\n",
            "Iteration: 184468 | Cost/Loss: 0.074202 | Weight: 0.569790 | Bias: 0.112649\n",
            "Iteration: 184469 | Cost/Loss: 0.074202 | Weight: 0.569790 | Bias: 0.112649\n",
            "Iteration: 184470 | Cost/Loss: 0.074202 | Weight: 0.569791 | Bias: 0.112649\n",
            "Iteration: 184471 | Cost/Loss: 0.074202 | Weight: 0.569791 | Bias: 0.112650\n",
            "Iteration: 184472 | Cost/Loss: 0.074202 | Weight: 0.569791 | Bias: 0.112650\n",
            "Iteration: 184473 | Cost/Loss: 0.074202 | Weight: 0.569792 | Bias: 0.112650\n",
            "Iteration: 184474 | Cost/Loss: 0.074202 | Weight: 0.569792 | Bias: 0.112650\n",
            "Iteration: 184475 | Cost/Loss: 0.074201 | Weight: 0.569792 | Bias: 0.112651\n",
            "Iteration: 184476 | Cost/Loss: 0.074201 | Weight: 0.569793 | Bias: 0.112651\n",
            "Iteration: 184477 | Cost/Loss: 0.074201 | Weight: 0.569793 | Bias: 0.112651\n",
            "Iteration: 184478 | Cost/Loss: 0.074201 | Weight: 0.569793 | Bias: 0.112652\n",
            "Iteration: 184479 | Cost/Loss: 0.074201 | Weight: 0.569793 | Bias: 0.112652\n",
            "Iteration: 184480 | Cost/Loss: 0.074201 | Weight: 0.569794 | Bias: 0.112652\n",
            "Iteration: 184481 | Cost/Loss: 0.074201 | Weight: 0.569794 | Bias: 0.112653\n",
            "Iteration: 184482 | Cost/Loss: 0.074201 | Weight: 0.569794 | Bias: 0.112653\n",
            "Iteration: 184483 | Cost/Loss: 0.074201 | Weight: 0.569795 | Bias: 0.112653\n",
            "Iteration: 184484 | Cost/Loss: 0.074201 | Weight: 0.569795 | Bias: 0.112653\n",
            "Iteration: 184485 | Cost/Loss: 0.074201 | Weight: 0.569795 | Bias: 0.112654\n",
            "Iteration: 184486 | Cost/Loss: 0.074201 | Weight: 0.569795 | Bias: 0.112654\n",
            "Iteration: 184487 | Cost/Loss: 0.074201 | Weight: 0.569796 | Bias: 0.112654\n",
            "Iteration: 184488 | Cost/Loss: 0.074201 | Weight: 0.569796 | Bias: 0.112655\n",
            "Iteration: 184489 | Cost/Loss: 0.074201 | Weight: 0.569796 | Bias: 0.112655\n",
            "Iteration: 184490 | Cost/Loss: 0.074201 | Weight: 0.569797 | Bias: 0.112655\n",
            "Iteration: 184491 | Cost/Loss: 0.074201 | Weight: 0.569797 | Bias: 0.112656\n",
            "Iteration: 184492 | Cost/Loss: 0.074201 | Weight: 0.569797 | Bias: 0.112656\n",
            "Iteration: 184493 | Cost/Loss: 0.074201 | Weight: 0.569798 | Bias: 0.112656\n",
            "Iteration: 184494 | Cost/Loss: 0.074201 | Weight: 0.569798 | Bias: 0.112657\n",
            "Iteration: 184495 | Cost/Loss: 0.074201 | Weight: 0.569798 | Bias: 0.112657\n",
            "Iteration: 184496 | Cost/Loss: 0.074201 | Weight: 0.569798 | Bias: 0.112657\n",
            "Iteration: 184497 | Cost/Loss: 0.074201 | Weight: 0.569799 | Bias: 0.112657\n",
            "Iteration: 184498 | Cost/Loss: 0.074201 | Weight: 0.569799 | Bias: 0.112658\n",
            "Iteration: 184499 | Cost/Loss: 0.074201 | Weight: 0.569799 | Bias: 0.112658\n",
            "Iteration: 184500 | Cost/Loss: 0.074201 | Weight: 0.569800 | Bias: 0.112658\n",
            "Iteration: 184501 | Cost/Loss: 0.074201 | Weight: 0.569800 | Bias: 0.112659\n",
            "Iteration: 184502 | Cost/Loss: 0.074201 | Weight: 0.569800 | Bias: 0.112659\n",
            "Iteration: 184503 | Cost/Loss: 0.074201 | Weight: 0.569801 | Bias: 0.112659\n",
            "Iteration: 184504 | Cost/Loss: 0.074201 | Weight: 0.569801 | Bias: 0.112660\n",
            "Iteration: 184505 | Cost/Loss: 0.074201 | Weight: 0.569801 | Bias: 0.112660\n",
            "Iteration: 184506 | Cost/Loss: 0.074201 | Weight: 0.569801 | Bias: 0.112660\n",
            "Iteration: 184507 | Cost/Loss: 0.074201 | Weight: 0.569802 | Bias: 0.112661\n",
            "Iteration: 184508 | Cost/Loss: 0.074201 | Weight: 0.569802 | Bias: 0.112661\n",
            "Iteration: 184509 | Cost/Loss: 0.074201 | Weight: 0.569802 | Bias: 0.112661\n",
            "Iteration: 184510 | Cost/Loss: 0.074201 | Weight: 0.569803 | Bias: 0.112661\n",
            "Iteration: 184511 | Cost/Loss: 0.074201 | Weight: 0.569803 | Bias: 0.112662\n",
            "Iteration: 184512 | Cost/Loss: 0.074201 | Weight: 0.569803 | Bias: 0.112662\n",
            "Iteration: 184513 | Cost/Loss: 0.074201 | Weight: 0.569804 | Bias: 0.112662\n",
            "Iteration: 184514 | Cost/Loss: 0.074201 | Weight: 0.569804 | Bias: 0.112663\n",
            "Iteration: 184515 | Cost/Loss: 0.074200 | Weight: 0.569804 | Bias: 0.112663\n",
            "Iteration: 184516 | Cost/Loss: 0.074200 | Weight: 0.569804 | Bias: 0.112663\n",
            "Iteration: 184517 | Cost/Loss: 0.074200 | Weight: 0.569805 | Bias: 0.112664\n",
            "Iteration: 184518 | Cost/Loss: 0.074200 | Weight: 0.569805 | Bias: 0.112664\n",
            "Iteration: 184519 | Cost/Loss: 0.074200 | Weight: 0.569805 | Bias: 0.112664\n",
            "Iteration: 184520 | Cost/Loss: 0.074200 | Weight: 0.569806 | Bias: 0.112664\n",
            "Iteration: 184521 | Cost/Loss: 0.074200 | Weight: 0.569806 | Bias: 0.112665\n",
            "Iteration: 184522 | Cost/Loss: 0.074200 | Weight: 0.569806 | Bias: 0.112665\n",
            "Iteration: 184523 | Cost/Loss: 0.074200 | Weight: 0.569807 | Bias: 0.112665\n",
            "Iteration: 184524 | Cost/Loss: 0.074200 | Weight: 0.569807 | Bias: 0.112666\n",
            "Iteration: 184525 | Cost/Loss: 0.074200 | Weight: 0.569807 | Bias: 0.112666\n",
            "Iteration: 184526 | Cost/Loss: 0.074200 | Weight: 0.569807 | Bias: 0.112666\n",
            "Iteration: 184527 | Cost/Loss: 0.074200 | Weight: 0.569808 | Bias: 0.112667\n",
            "Iteration: 184528 | Cost/Loss: 0.074200 | Weight: 0.569808 | Bias: 0.112667\n",
            "Iteration: 184529 | Cost/Loss: 0.074200 | Weight: 0.569808 | Bias: 0.112667\n",
            "Iteration: 184530 | Cost/Loss: 0.074200 | Weight: 0.569809 | Bias: 0.112668\n",
            "Iteration: 184531 | Cost/Loss: 0.074200 | Weight: 0.569809 | Bias: 0.112668\n",
            "Iteration: 184532 | Cost/Loss: 0.074200 | Weight: 0.569809 | Bias: 0.112668\n",
            "Iteration: 184533 | Cost/Loss: 0.074200 | Weight: 0.569809 | Bias: 0.112668\n",
            "Iteration: 184534 | Cost/Loss: 0.074200 | Weight: 0.569810 | Bias: 0.112669\n",
            "Iteration: 184535 | Cost/Loss: 0.074200 | Weight: 0.569810 | Bias: 0.112669\n",
            "Iteration: 184536 | Cost/Loss: 0.074200 | Weight: 0.569810 | Bias: 0.112669\n",
            "Iteration: 184537 | Cost/Loss: 0.074200 | Weight: 0.569811 | Bias: 0.112670\n",
            "Iteration: 184538 | Cost/Loss: 0.074200 | Weight: 0.569811 | Bias: 0.112670\n",
            "Iteration: 184539 | Cost/Loss: 0.074200 | Weight: 0.569811 | Bias: 0.112670\n",
            "Iteration: 184540 | Cost/Loss: 0.074200 | Weight: 0.569812 | Bias: 0.112671\n",
            "Iteration: 184541 | Cost/Loss: 0.074200 | Weight: 0.569812 | Bias: 0.112671\n",
            "Iteration: 184542 | Cost/Loss: 0.074200 | Weight: 0.569812 | Bias: 0.112671\n",
            "Iteration: 184543 | Cost/Loss: 0.074200 | Weight: 0.569812 | Bias: 0.112672\n",
            "Iteration: 184544 | Cost/Loss: 0.074200 | Weight: 0.569813 | Bias: 0.112672\n",
            "Iteration: 184545 | Cost/Loss: 0.074200 | Weight: 0.569813 | Bias: 0.112672\n",
            "Iteration: 184546 | Cost/Loss: 0.074200 | Weight: 0.569813 | Bias: 0.112672\n",
            "Iteration: 184547 | Cost/Loss: 0.074200 | Weight: 0.569814 | Bias: 0.112673\n",
            "Iteration: 184548 | Cost/Loss: 0.074200 | Weight: 0.569814 | Bias: 0.112673\n",
            "Iteration: 184549 | Cost/Loss: 0.074200 | Weight: 0.569814 | Bias: 0.112673\n",
            "Iteration: 184550 | Cost/Loss: 0.074200 | Weight: 0.569815 | Bias: 0.112674\n",
            "Iteration: 184551 | Cost/Loss: 0.074200 | Weight: 0.569815 | Bias: 0.112674\n",
            "Iteration: 184552 | Cost/Loss: 0.074200 | Weight: 0.569815 | Bias: 0.112674\n",
            "Iteration: 184553 | Cost/Loss: 0.074200 | Weight: 0.569815 | Bias: 0.112675\n",
            "Iteration: 184554 | Cost/Loss: 0.074200 | Weight: 0.569816 | Bias: 0.112675\n",
            "Iteration: 184555 | Cost/Loss: 0.074200 | Weight: 0.569816 | Bias: 0.112675\n",
            "Iteration: 184556 | Cost/Loss: 0.074199 | Weight: 0.569816 | Bias: 0.112675\n",
            "Iteration: 184557 | Cost/Loss: 0.074199 | Weight: 0.569817 | Bias: 0.112676\n",
            "Iteration: 184558 | Cost/Loss: 0.074199 | Weight: 0.569817 | Bias: 0.112676\n",
            "Iteration: 184559 | Cost/Loss: 0.074199 | Weight: 0.569817 | Bias: 0.112676\n",
            "Iteration: 184560 | Cost/Loss: 0.074199 | Weight: 0.569818 | Bias: 0.112677\n",
            "Iteration: 184561 | Cost/Loss: 0.074199 | Weight: 0.569818 | Bias: 0.112677\n",
            "Iteration: 184562 | Cost/Loss: 0.074199 | Weight: 0.569818 | Bias: 0.112677\n",
            "Iteration: 184563 | Cost/Loss: 0.074199 | Weight: 0.569818 | Bias: 0.112678\n",
            "Iteration: 184564 | Cost/Loss: 0.074199 | Weight: 0.569819 | Bias: 0.112678\n",
            "Iteration: 184565 | Cost/Loss: 0.074199 | Weight: 0.569819 | Bias: 0.112678\n",
            "Iteration: 184566 | Cost/Loss: 0.074199 | Weight: 0.569819 | Bias: 0.112679\n",
            "Iteration: 184567 | Cost/Loss: 0.074199 | Weight: 0.569820 | Bias: 0.112679\n",
            "Iteration: 184568 | Cost/Loss: 0.074199 | Weight: 0.569820 | Bias: 0.112679\n",
            "Iteration: 184569 | Cost/Loss: 0.074199 | Weight: 0.569820 | Bias: 0.112679\n",
            "Iteration: 184570 | Cost/Loss: 0.074199 | Weight: 0.569821 | Bias: 0.112680\n",
            "Iteration: 184571 | Cost/Loss: 0.074199 | Weight: 0.569821 | Bias: 0.112680\n",
            "Iteration: 184572 | Cost/Loss: 0.074199 | Weight: 0.569821 | Bias: 0.112680\n",
            "Iteration: 184573 | Cost/Loss: 0.074199 | Weight: 0.569821 | Bias: 0.112681\n",
            "Iteration: 184574 | Cost/Loss: 0.074199 | Weight: 0.569822 | Bias: 0.112681\n",
            "Iteration: 184575 | Cost/Loss: 0.074199 | Weight: 0.569822 | Bias: 0.112681\n",
            "Iteration: 184576 | Cost/Loss: 0.074199 | Weight: 0.569822 | Bias: 0.112682\n",
            "Iteration: 184577 | Cost/Loss: 0.074199 | Weight: 0.569823 | Bias: 0.112682\n",
            "Iteration: 184578 | Cost/Loss: 0.074199 | Weight: 0.569823 | Bias: 0.112682\n",
            "Iteration: 184579 | Cost/Loss: 0.074199 | Weight: 0.569823 | Bias: 0.112683\n",
            "Iteration: 184580 | Cost/Loss: 0.074199 | Weight: 0.569824 | Bias: 0.112683\n",
            "Iteration: 184581 | Cost/Loss: 0.074199 | Weight: 0.569824 | Bias: 0.112683\n",
            "Iteration: 184582 | Cost/Loss: 0.074199 | Weight: 0.569824 | Bias: 0.112683\n",
            "Iteration: 184583 | Cost/Loss: 0.074199 | Weight: 0.569824 | Bias: 0.112684\n",
            "Iteration: 184584 | Cost/Loss: 0.074199 | Weight: 0.569825 | Bias: 0.112684\n",
            "Iteration: 184585 | Cost/Loss: 0.074199 | Weight: 0.569825 | Bias: 0.112684\n",
            "Iteration: 184586 | Cost/Loss: 0.074199 | Weight: 0.569825 | Bias: 0.112685\n",
            "Iteration: 184587 | Cost/Loss: 0.074199 | Weight: 0.569826 | Bias: 0.112685\n",
            "Iteration: 184588 | Cost/Loss: 0.074199 | Weight: 0.569826 | Bias: 0.112685\n",
            "Iteration: 184589 | Cost/Loss: 0.074199 | Weight: 0.569826 | Bias: 0.112686\n",
            "Iteration: 184590 | Cost/Loss: 0.074199 | Weight: 0.569826 | Bias: 0.112686\n",
            "Iteration: 184591 | Cost/Loss: 0.074199 | Weight: 0.569827 | Bias: 0.112686\n",
            "Iteration: 184592 | Cost/Loss: 0.074199 | Weight: 0.569827 | Bias: 0.112686\n",
            "Iteration: 184593 | Cost/Loss: 0.074199 | Weight: 0.569827 | Bias: 0.112687\n",
            "Iteration: 184594 | Cost/Loss: 0.074199 | Weight: 0.569828 | Bias: 0.112687\n",
            "Iteration: 184595 | Cost/Loss: 0.074199 | Weight: 0.569828 | Bias: 0.112687\n",
            "Iteration: 184596 | Cost/Loss: 0.074198 | Weight: 0.569828 | Bias: 0.112688\n",
            "Iteration: 184597 | Cost/Loss: 0.074198 | Weight: 0.569829 | Bias: 0.112688\n",
            "Iteration: 184598 | Cost/Loss: 0.074198 | Weight: 0.569829 | Bias: 0.112688\n",
            "Iteration: 184599 | Cost/Loss: 0.074198 | Weight: 0.569829 | Bias: 0.112689\n",
            "Iteration: 184600 | Cost/Loss: 0.074198 | Weight: 0.569829 | Bias: 0.112689\n",
            "Iteration: 184601 | Cost/Loss: 0.074198 | Weight: 0.569830 | Bias: 0.112689\n",
            "Iteration: 184602 | Cost/Loss: 0.074198 | Weight: 0.569830 | Bias: 0.112690\n",
            "Iteration: 184603 | Cost/Loss: 0.074198 | Weight: 0.569830 | Bias: 0.112690\n",
            "Iteration: 184604 | Cost/Loss: 0.074198 | Weight: 0.569831 | Bias: 0.112690\n",
            "Iteration: 184605 | Cost/Loss: 0.074198 | Weight: 0.569831 | Bias: 0.112690\n",
            "Iteration: 184606 | Cost/Loss: 0.074198 | Weight: 0.569831 | Bias: 0.112691\n",
            "Iteration: 184607 | Cost/Loss: 0.074198 | Weight: 0.569832 | Bias: 0.112691\n",
            "Iteration: 184608 | Cost/Loss: 0.074198 | Weight: 0.569832 | Bias: 0.112691\n",
            "Iteration: 184609 | Cost/Loss: 0.074198 | Weight: 0.569832 | Bias: 0.112692\n",
            "Iteration: 184610 | Cost/Loss: 0.074198 | Weight: 0.569832 | Bias: 0.112692\n",
            "Iteration: 184611 | Cost/Loss: 0.074198 | Weight: 0.569833 | Bias: 0.112692\n",
            "Iteration: 184612 | Cost/Loss: 0.074198 | Weight: 0.569833 | Bias: 0.112693\n",
            "Iteration: 184613 | Cost/Loss: 0.074198 | Weight: 0.569833 | Bias: 0.112693\n",
            "Iteration: 184614 | Cost/Loss: 0.074198 | Weight: 0.569834 | Bias: 0.112693\n",
            "Iteration: 184615 | Cost/Loss: 0.074198 | Weight: 0.569834 | Bias: 0.112694\n",
            "Iteration: 184616 | Cost/Loss: 0.074198 | Weight: 0.569834 | Bias: 0.112694\n",
            "Iteration: 184617 | Cost/Loss: 0.074198 | Weight: 0.569835 | Bias: 0.112694\n",
            "Iteration: 184618 | Cost/Loss: 0.074198 | Weight: 0.569835 | Bias: 0.112694\n",
            "Iteration: 184619 | Cost/Loss: 0.074198 | Weight: 0.569835 | Bias: 0.112695\n",
            "Iteration: 184620 | Cost/Loss: 0.074198 | Weight: 0.569835 | Bias: 0.112695\n",
            "Iteration: 184621 | Cost/Loss: 0.074198 | Weight: 0.569836 | Bias: 0.112695\n",
            "Iteration: 184622 | Cost/Loss: 0.074198 | Weight: 0.569836 | Bias: 0.112696\n",
            "Iteration: 184623 | Cost/Loss: 0.074198 | Weight: 0.569836 | Bias: 0.112696\n",
            "Iteration: 184624 | Cost/Loss: 0.074198 | Weight: 0.569837 | Bias: 0.112696\n",
            "Iteration: 184625 | Cost/Loss: 0.074198 | Weight: 0.569837 | Bias: 0.112697\n",
            "Iteration: 184626 | Cost/Loss: 0.074198 | Weight: 0.569837 | Bias: 0.112697\n",
            "Iteration: 184627 | Cost/Loss: 0.074198 | Weight: 0.569838 | Bias: 0.112697\n",
            "Iteration: 184628 | Cost/Loss: 0.074198 | Weight: 0.569838 | Bias: 0.112697\n",
            "Iteration: 184629 | Cost/Loss: 0.074198 | Weight: 0.569838 | Bias: 0.112698\n",
            "Iteration: 184630 | Cost/Loss: 0.074198 | Weight: 0.569838 | Bias: 0.112698\n",
            "Iteration: 184631 | Cost/Loss: 0.074198 | Weight: 0.569839 | Bias: 0.112698\n",
            "Iteration: 184632 | Cost/Loss: 0.074198 | Weight: 0.569839 | Bias: 0.112699\n",
            "Iteration: 184633 | Cost/Loss: 0.074198 | Weight: 0.569839 | Bias: 0.112699\n",
            "Iteration: 184634 | Cost/Loss: 0.074198 | Weight: 0.569840 | Bias: 0.112699\n",
            "Iteration: 184635 | Cost/Loss: 0.074198 | Weight: 0.569840 | Bias: 0.112700\n",
            "Iteration: 184636 | Cost/Loss: 0.074198 | Weight: 0.569840 | Bias: 0.112700\n",
            "Iteration: 184637 | Cost/Loss: 0.074197 | Weight: 0.569840 | Bias: 0.112700\n",
            "Iteration: 184638 | Cost/Loss: 0.074197 | Weight: 0.569841 | Bias: 0.112701\n",
            "Iteration: 184639 | Cost/Loss: 0.074197 | Weight: 0.569841 | Bias: 0.112701\n",
            "Iteration: 184640 | Cost/Loss: 0.074197 | Weight: 0.569841 | Bias: 0.112701\n",
            "Iteration: 184641 | Cost/Loss: 0.074197 | Weight: 0.569842 | Bias: 0.112701\n",
            "Iteration: 184642 | Cost/Loss: 0.074197 | Weight: 0.569842 | Bias: 0.112702\n",
            "Iteration: 184643 | Cost/Loss: 0.074197 | Weight: 0.569842 | Bias: 0.112702\n",
            "Iteration: 184644 | Cost/Loss: 0.074197 | Weight: 0.569843 | Bias: 0.112702\n",
            "Iteration: 184645 | Cost/Loss: 0.074197 | Weight: 0.569843 | Bias: 0.112703\n",
            "Iteration: 184646 | Cost/Loss: 0.074197 | Weight: 0.569843 | Bias: 0.112703\n",
            "Iteration: 184647 | Cost/Loss: 0.074197 | Weight: 0.569843 | Bias: 0.112703\n",
            "Iteration: 184648 | Cost/Loss: 0.074197 | Weight: 0.569844 | Bias: 0.112704\n",
            "Iteration: 184649 | Cost/Loss: 0.074197 | Weight: 0.569844 | Bias: 0.112704\n",
            "Iteration: 184650 | Cost/Loss: 0.074197 | Weight: 0.569844 | Bias: 0.112704\n",
            "Iteration: 184651 | Cost/Loss: 0.074197 | Weight: 0.569845 | Bias: 0.112705\n",
            "Iteration: 184652 | Cost/Loss: 0.074197 | Weight: 0.569845 | Bias: 0.112705\n",
            "Iteration: 184653 | Cost/Loss: 0.074197 | Weight: 0.569845 | Bias: 0.112705\n",
            "Iteration: 184654 | Cost/Loss: 0.074197 | Weight: 0.569846 | Bias: 0.112705\n",
            "Iteration: 184655 | Cost/Loss: 0.074197 | Weight: 0.569846 | Bias: 0.112706\n",
            "Iteration: 184656 | Cost/Loss: 0.074197 | Weight: 0.569846 | Bias: 0.112706\n",
            "Iteration: 184657 | Cost/Loss: 0.074197 | Weight: 0.569846 | Bias: 0.112706\n",
            "Iteration: 184658 | Cost/Loss: 0.074197 | Weight: 0.569847 | Bias: 0.112707\n",
            "Iteration: 184659 | Cost/Loss: 0.074197 | Weight: 0.569847 | Bias: 0.112707\n",
            "Iteration: 184660 | Cost/Loss: 0.074197 | Weight: 0.569847 | Bias: 0.112707\n",
            "Iteration: 184661 | Cost/Loss: 0.074197 | Weight: 0.569848 | Bias: 0.112708\n",
            "Iteration: 184662 | Cost/Loss: 0.074197 | Weight: 0.569848 | Bias: 0.112708\n",
            "Iteration: 184663 | Cost/Loss: 0.074197 | Weight: 0.569848 | Bias: 0.112708\n",
            "Iteration: 184664 | Cost/Loss: 0.074197 | Weight: 0.569849 | Bias: 0.112708\n",
            "Iteration: 184665 | Cost/Loss: 0.074197 | Weight: 0.569849 | Bias: 0.112709\n",
            "Iteration: 184666 | Cost/Loss: 0.074197 | Weight: 0.569849 | Bias: 0.112709\n",
            "Iteration: 184667 | Cost/Loss: 0.074197 | Weight: 0.569849 | Bias: 0.112709\n",
            "Iteration: 184668 | Cost/Loss: 0.074197 | Weight: 0.569850 | Bias: 0.112710\n",
            "Iteration: 184669 | Cost/Loss: 0.074197 | Weight: 0.569850 | Bias: 0.112710\n",
            "Iteration: 184670 | Cost/Loss: 0.074197 | Weight: 0.569850 | Bias: 0.112710\n",
            "Iteration: 184671 | Cost/Loss: 0.074197 | Weight: 0.569851 | Bias: 0.112711\n",
            "Iteration: 184672 | Cost/Loss: 0.074197 | Weight: 0.569851 | Bias: 0.112711\n",
            "Iteration: 184673 | Cost/Loss: 0.074197 | Weight: 0.569851 | Bias: 0.112711\n",
            "Iteration: 184674 | Cost/Loss: 0.074197 | Weight: 0.569852 | Bias: 0.112712\n",
            "Iteration: 184675 | Cost/Loss: 0.074197 | Weight: 0.569852 | Bias: 0.112712\n",
            "Iteration: 184676 | Cost/Loss: 0.074197 | Weight: 0.569852 | Bias: 0.112712\n",
            "Iteration: 184677 | Cost/Loss: 0.074197 | Weight: 0.569852 | Bias: 0.112712\n",
            "Iteration: 184678 | Cost/Loss: 0.074196 | Weight: 0.569853 | Bias: 0.112713\n",
            "Iteration: 184679 | Cost/Loss: 0.074196 | Weight: 0.569853 | Bias: 0.112713\n",
            "Iteration: 184680 | Cost/Loss: 0.074196 | Weight: 0.569853 | Bias: 0.112713\n",
            "Iteration: 184681 | Cost/Loss: 0.074196 | Weight: 0.569854 | Bias: 0.112714\n",
            "Iteration: 184682 | Cost/Loss: 0.074196 | Weight: 0.569854 | Bias: 0.112714\n",
            "Iteration: 184683 | Cost/Loss: 0.074196 | Weight: 0.569854 | Bias: 0.112714\n",
            "Iteration: 184684 | Cost/Loss: 0.074196 | Weight: 0.569854 | Bias: 0.112715\n",
            "Iteration: 184685 | Cost/Loss: 0.074196 | Weight: 0.569855 | Bias: 0.112715\n",
            "Iteration: 184686 | Cost/Loss: 0.074196 | Weight: 0.569855 | Bias: 0.112715\n",
            "Iteration: 184687 | Cost/Loss: 0.074196 | Weight: 0.569855 | Bias: 0.112716\n",
            "Iteration: 184688 | Cost/Loss: 0.074196 | Weight: 0.569856 | Bias: 0.112716\n",
            "Iteration: 184689 | Cost/Loss: 0.074196 | Weight: 0.569856 | Bias: 0.112716\n",
            "Iteration: 184690 | Cost/Loss: 0.074196 | Weight: 0.569856 | Bias: 0.112716\n",
            "Iteration: 184691 | Cost/Loss: 0.074196 | Weight: 0.569857 | Bias: 0.112717\n",
            "Iteration: 184692 | Cost/Loss: 0.074196 | Weight: 0.569857 | Bias: 0.112717\n",
            "Iteration: 184693 | Cost/Loss: 0.074196 | Weight: 0.569857 | Bias: 0.112717\n",
            "Iteration: 184694 | Cost/Loss: 0.074196 | Weight: 0.569857 | Bias: 0.112718\n",
            "Iteration: 184695 | Cost/Loss: 0.074196 | Weight: 0.569858 | Bias: 0.112718\n",
            "Iteration: 184696 | Cost/Loss: 0.074196 | Weight: 0.569858 | Bias: 0.112718\n",
            "Iteration: 184697 | Cost/Loss: 0.074196 | Weight: 0.569858 | Bias: 0.112719\n",
            "Iteration: 184698 | Cost/Loss: 0.074196 | Weight: 0.569859 | Bias: 0.112719\n",
            "Iteration: 184699 | Cost/Loss: 0.074196 | Weight: 0.569859 | Bias: 0.112719\n",
            "Iteration: 184700 | Cost/Loss: 0.074196 | Weight: 0.569859 | Bias: 0.112719\n",
            "Iteration: 184701 | Cost/Loss: 0.074196 | Weight: 0.569860 | Bias: 0.112720\n",
            "Iteration: 184702 | Cost/Loss: 0.074196 | Weight: 0.569860 | Bias: 0.112720\n",
            "Iteration: 184703 | Cost/Loss: 0.074196 | Weight: 0.569860 | Bias: 0.112720\n",
            "Iteration: 184704 | Cost/Loss: 0.074196 | Weight: 0.569860 | Bias: 0.112721\n",
            "Iteration: 184705 | Cost/Loss: 0.074196 | Weight: 0.569861 | Bias: 0.112721\n",
            "Iteration: 184706 | Cost/Loss: 0.074196 | Weight: 0.569861 | Bias: 0.112721\n",
            "Iteration: 184707 | Cost/Loss: 0.074196 | Weight: 0.569861 | Bias: 0.112722\n",
            "Iteration: 184708 | Cost/Loss: 0.074196 | Weight: 0.569862 | Bias: 0.112722\n",
            "Iteration: 184709 | Cost/Loss: 0.074196 | Weight: 0.569862 | Bias: 0.112722\n",
            "Iteration: 184710 | Cost/Loss: 0.074196 | Weight: 0.569862 | Bias: 0.112723\n",
            "Iteration: 184711 | Cost/Loss: 0.074196 | Weight: 0.569863 | Bias: 0.112723\n",
            "Iteration: 184712 | Cost/Loss: 0.074196 | Weight: 0.569863 | Bias: 0.112723\n",
            "Iteration: 184713 | Cost/Loss: 0.074196 | Weight: 0.569863 | Bias: 0.112723\n",
            "Iteration: 184714 | Cost/Loss: 0.074196 | Weight: 0.569863 | Bias: 0.112724\n",
            "Iteration: 184715 | Cost/Loss: 0.074196 | Weight: 0.569864 | Bias: 0.112724\n",
            "Iteration: 184716 | Cost/Loss: 0.074196 | Weight: 0.569864 | Bias: 0.112724\n",
            "Iteration: 184717 | Cost/Loss: 0.074196 | Weight: 0.569864 | Bias: 0.112725\n",
            "Iteration: 184718 | Cost/Loss: 0.074195 | Weight: 0.569865 | Bias: 0.112725\n",
            "Iteration: 184719 | Cost/Loss: 0.074195 | Weight: 0.569865 | Bias: 0.112725\n",
            "Iteration: 184720 | Cost/Loss: 0.074195 | Weight: 0.569865 | Bias: 0.112726\n",
            "Iteration: 184721 | Cost/Loss: 0.074195 | Weight: 0.569866 | Bias: 0.112726\n",
            "Iteration: 184722 | Cost/Loss: 0.074195 | Weight: 0.569866 | Bias: 0.112726\n",
            "Iteration: 184723 | Cost/Loss: 0.074195 | Weight: 0.569866 | Bias: 0.112727\n",
            "Iteration: 184724 | Cost/Loss: 0.074195 | Weight: 0.569866 | Bias: 0.112727\n",
            "Iteration: 184725 | Cost/Loss: 0.074195 | Weight: 0.569867 | Bias: 0.112727\n",
            "Iteration: 184726 | Cost/Loss: 0.074195 | Weight: 0.569867 | Bias: 0.112727\n",
            "Iteration: 184727 | Cost/Loss: 0.074195 | Weight: 0.569867 | Bias: 0.112728\n",
            "Iteration: 184728 | Cost/Loss: 0.074195 | Weight: 0.569868 | Bias: 0.112728\n",
            "Iteration: 184729 | Cost/Loss: 0.074195 | Weight: 0.569868 | Bias: 0.112728\n",
            "Iteration: 184730 | Cost/Loss: 0.074195 | Weight: 0.569868 | Bias: 0.112729\n",
            "Iteration: 184731 | Cost/Loss: 0.074195 | Weight: 0.569869 | Bias: 0.112729\n",
            "Iteration: 184732 | Cost/Loss: 0.074195 | Weight: 0.569869 | Bias: 0.112729\n",
            "Iteration: 184733 | Cost/Loss: 0.074195 | Weight: 0.569869 | Bias: 0.112730\n",
            "Iteration: 184734 | Cost/Loss: 0.074195 | Weight: 0.569869 | Bias: 0.112730\n",
            "Iteration: 184735 | Cost/Loss: 0.074195 | Weight: 0.569870 | Bias: 0.112730\n",
            "Iteration: 184736 | Cost/Loss: 0.074195 | Weight: 0.569870 | Bias: 0.112730\n",
            "Iteration: 184737 | Cost/Loss: 0.074195 | Weight: 0.569870 | Bias: 0.112731\n",
            "Iteration: 184738 | Cost/Loss: 0.074195 | Weight: 0.569871 | Bias: 0.112731\n",
            "Iteration: 184739 | Cost/Loss: 0.074195 | Weight: 0.569871 | Bias: 0.112731\n",
            "Iteration: 184740 | Cost/Loss: 0.074195 | Weight: 0.569871 | Bias: 0.112732\n",
            "Iteration: 184741 | Cost/Loss: 0.074195 | Weight: 0.569871 | Bias: 0.112732\n",
            "Iteration: 184742 | Cost/Loss: 0.074195 | Weight: 0.569872 | Bias: 0.112732\n",
            "Iteration: 184743 | Cost/Loss: 0.074195 | Weight: 0.569872 | Bias: 0.112733\n",
            "Iteration: 184744 | Cost/Loss: 0.074195 | Weight: 0.569872 | Bias: 0.112733\n",
            "Iteration: 184745 | Cost/Loss: 0.074195 | Weight: 0.569873 | Bias: 0.112733\n",
            "Iteration: 184746 | Cost/Loss: 0.074195 | Weight: 0.569873 | Bias: 0.112734\n",
            "Iteration: 184747 | Cost/Loss: 0.074195 | Weight: 0.569873 | Bias: 0.112734\n",
            "Iteration: 184748 | Cost/Loss: 0.074195 | Weight: 0.569874 | Bias: 0.112734\n",
            "Iteration: 184749 | Cost/Loss: 0.074195 | Weight: 0.569874 | Bias: 0.112734\n",
            "Iteration: 184750 | Cost/Loss: 0.074195 | Weight: 0.569874 | Bias: 0.112735\n",
            "Iteration: 184751 | Cost/Loss: 0.074195 | Weight: 0.569874 | Bias: 0.112735\n",
            "Iteration: 184752 | Cost/Loss: 0.074195 | Weight: 0.569875 | Bias: 0.112735\n",
            "Iteration: 184753 | Cost/Loss: 0.074195 | Weight: 0.569875 | Bias: 0.112736\n",
            "Iteration: 184754 | Cost/Loss: 0.074195 | Weight: 0.569875 | Bias: 0.112736\n",
            "Iteration: 184755 | Cost/Loss: 0.074195 | Weight: 0.569876 | Bias: 0.112736\n",
            "Iteration: 184756 | Cost/Loss: 0.074195 | Weight: 0.569876 | Bias: 0.112737\n",
            "Iteration: 184757 | Cost/Loss: 0.074195 | Weight: 0.569876 | Bias: 0.112737\n",
            "Iteration: 184758 | Cost/Loss: 0.074195 | Weight: 0.569877 | Bias: 0.112737\n",
            "Iteration: 184759 | Cost/Loss: 0.074194 | Weight: 0.569877 | Bias: 0.112737\n",
            "Iteration: 184760 | Cost/Loss: 0.074194 | Weight: 0.569877 | Bias: 0.112738\n",
            "Iteration: 184761 | Cost/Loss: 0.074194 | Weight: 0.569877 | Bias: 0.112738\n",
            "Iteration: 184762 | Cost/Loss: 0.074194 | Weight: 0.569878 | Bias: 0.112738\n",
            "Iteration: 184763 | Cost/Loss: 0.074194 | Weight: 0.569878 | Bias: 0.112739\n",
            "Iteration: 184764 | Cost/Loss: 0.074194 | Weight: 0.569878 | Bias: 0.112739\n",
            "Iteration: 184765 | Cost/Loss: 0.074194 | Weight: 0.569879 | Bias: 0.112739\n",
            "Iteration: 184766 | Cost/Loss: 0.074194 | Weight: 0.569879 | Bias: 0.112740\n",
            "Iteration: 184767 | Cost/Loss: 0.074194 | Weight: 0.569879 | Bias: 0.112740\n",
            "Iteration: 184768 | Cost/Loss: 0.074194 | Weight: 0.569880 | Bias: 0.112740\n",
            "Iteration: 184769 | Cost/Loss: 0.074194 | Weight: 0.569880 | Bias: 0.112741\n",
            "Iteration: 184770 | Cost/Loss: 0.074194 | Weight: 0.569880 | Bias: 0.112741\n",
            "Iteration: 184771 | Cost/Loss: 0.074194 | Weight: 0.569880 | Bias: 0.112741\n",
            "Iteration: 184772 | Cost/Loss: 0.074194 | Weight: 0.569881 | Bias: 0.112741\n",
            "Iteration: 184773 | Cost/Loss: 0.074194 | Weight: 0.569881 | Bias: 0.112742\n",
            "Iteration: 184774 | Cost/Loss: 0.074194 | Weight: 0.569881 | Bias: 0.112742\n",
            "Iteration: 184775 | Cost/Loss: 0.074194 | Weight: 0.569882 | Bias: 0.112742\n",
            "Iteration: 184776 | Cost/Loss: 0.074194 | Weight: 0.569882 | Bias: 0.112743\n",
            "Iteration: 184777 | Cost/Loss: 0.074194 | Weight: 0.569882 | Bias: 0.112743\n",
            "Iteration: 184778 | Cost/Loss: 0.074194 | Weight: 0.569883 | Bias: 0.112743\n",
            "Iteration: 184779 | Cost/Loss: 0.074194 | Weight: 0.569883 | Bias: 0.112744\n",
            "Iteration: 184780 | Cost/Loss: 0.074194 | Weight: 0.569883 | Bias: 0.112744\n",
            "Iteration: 184781 | Cost/Loss: 0.074194 | Weight: 0.569883 | Bias: 0.112744\n",
            "Iteration: 184782 | Cost/Loss: 0.074194 | Weight: 0.569884 | Bias: 0.112745\n",
            "Iteration: 184783 | Cost/Loss: 0.074194 | Weight: 0.569884 | Bias: 0.112745\n",
            "Iteration: 184784 | Cost/Loss: 0.074194 | Weight: 0.569884 | Bias: 0.112745\n",
            "Iteration: 184785 | Cost/Loss: 0.074194 | Weight: 0.569885 | Bias: 0.112745\n",
            "Iteration: 184786 | Cost/Loss: 0.074194 | Weight: 0.569885 | Bias: 0.112746\n",
            "Iteration: 184787 | Cost/Loss: 0.074194 | Weight: 0.569885 | Bias: 0.112746\n",
            "Iteration: 184788 | Cost/Loss: 0.074194 | Weight: 0.569885 | Bias: 0.112746\n",
            "Iteration: 184789 | Cost/Loss: 0.074194 | Weight: 0.569886 | Bias: 0.112747\n",
            "Iteration: 184790 | Cost/Loss: 0.074194 | Weight: 0.569886 | Bias: 0.112747\n",
            "Iteration: 184791 | Cost/Loss: 0.074194 | Weight: 0.569886 | Bias: 0.112747\n",
            "Iteration: 184792 | Cost/Loss: 0.074194 | Weight: 0.569887 | Bias: 0.112748\n",
            "Iteration: 184793 | Cost/Loss: 0.074194 | Weight: 0.569887 | Bias: 0.112748\n",
            "Iteration: 184794 | Cost/Loss: 0.074194 | Weight: 0.569887 | Bias: 0.112748\n",
            "Iteration: 184795 | Cost/Loss: 0.074194 | Weight: 0.569888 | Bias: 0.112748\n",
            "Iteration: 184796 | Cost/Loss: 0.074194 | Weight: 0.569888 | Bias: 0.112749\n",
            "Iteration: 184797 | Cost/Loss: 0.074194 | Weight: 0.569888 | Bias: 0.112749\n",
            "Iteration: 184798 | Cost/Loss: 0.074194 | Weight: 0.569888 | Bias: 0.112749\n",
            "Iteration: 184799 | Cost/Loss: 0.074193 | Weight: 0.569889 | Bias: 0.112750\n",
            "Iteration: 184800 | Cost/Loss: 0.074193 | Weight: 0.569889 | Bias: 0.112750\n",
            "Iteration: 184801 | Cost/Loss: 0.074193 | Weight: 0.569889 | Bias: 0.112750\n",
            "Iteration: 184802 | Cost/Loss: 0.074193 | Weight: 0.569890 | Bias: 0.112751\n",
            "Iteration: 184803 | Cost/Loss: 0.074193 | Weight: 0.569890 | Bias: 0.112751\n",
            "Iteration: 184804 | Cost/Loss: 0.074193 | Weight: 0.569890 | Bias: 0.112751\n",
            "Iteration: 184805 | Cost/Loss: 0.074193 | Weight: 0.569891 | Bias: 0.112752\n",
            "Iteration: 184806 | Cost/Loss: 0.074193 | Weight: 0.569891 | Bias: 0.112752\n",
            "Iteration: 184807 | Cost/Loss: 0.074193 | Weight: 0.569891 | Bias: 0.112752\n",
            "Iteration: 184808 | Cost/Loss: 0.074193 | Weight: 0.569891 | Bias: 0.112752\n",
            "Iteration: 184809 | Cost/Loss: 0.074193 | Weight: 0.569892 | Bias: 0.112753\n",
            "Iteration: 184810 | Cost/Loss: 0.074193 | Weight: 0.569892 | Bias: 0.112753\n",
            "Iteration: 184811 | Cost/Loss: 0.074193 | Weight: 0.569892 | Bias: 0.112753\n",
            "Iteration: 184812 | Cost/Loss: 0.074193 | Weight: 0.569893 | Bias: 0.112754\n",
            "Iteration: 184813 | Cost/Loss: 0.074193 | Weight: 0.569893 | Bias: 0.112754\n",
            "Iteration: 184814 | Cost/Loss: 0.074193 | Weight: 0.569893 | Bias: 0.112754\n",
            "Iteration: 184815 | Cost/Loss: 0.074193 | Weight: 0.569894 | Bias: 0.112755\n",
            "Iteration: 184816 | Cost/Loss: 0.074193 | Weight: 0.569894 | Bias: 0.112755\n",
            "Iteration: 184817 | Cost/Loss: 0.074193 | Weight: 0.569894 | Bias: 0.112755\n",
            "Iteration: 184818 | Cost/Loss: 0.074193 | Weight: 0.569894 | Bias: 0.112756\n",
            "Iteration: 184819 | Cost/Loss: 0.074193 | Weight: 0.569895 | Bias: 0.112756\n",
            "Iteration: 184820 | Cost/Loss: 0.074193 | Weight: 0.569895 | Bias: 0.112756\n",
            "Iteration: 184821 | Cost/Loss: 0.074193 | Weight: 0.569895 | Bias: 0.112756\n",
            "Iteration: 184822 | Cost/Loss: 0.074193 | Weight: 0.569896 | Bias: 0.112757\n",
            "Iteration: 184823 | Cost/Loss: 0.074193 | Weight: 0.569896 | Bias: 0.112757\n",
            "Iteration: 184824 | Cost/Loss: 0.074193 | Weight: 0.569896 | Bias: 0.112757\n",
            "Iteration: 184825 | Cost/Loss: 0.074193 | Weight: 0.569897 | Bias: 0.112758\n",
            "Iteration: 184826 | Cost/Loss: 0.074193 | Weight: 0.569897 | Bias: 0.112758\n",
            "Iteration: 184827 | Cost/Loss: 0.074193 | Weight: 0.569897 | Bias: 0.112758\n",
            "Iteration: 184828 | Cost/Loss: 0.074193 | Weight: 0.569897 | Bias: 0.112759\n",
            "Iteration: 184829 | Cost/Loss: 0.074193 | Weight: 0.569898 | Bias: 0.112759\n",
            "Iteration: 184830 | Cost/Loss: 0.074193 | Weight: 0.569898 | Bias: 0.112759\n",
            "Iteration: 184831 | Cost/Loss: 0.074193 | Weight: 0.569898 | Bias: 0.112759\n",
            "Iteration: 184832 | Cost/Loss: 0.074193 | Weight: 0.569899 | Bias: 0.112760\n",
            "Iteration: 184833 | Cost/Loss: 0.074193 | Weight: 0.569899 | Bias: 0.112760\n",
            "Iteration: 184834 | Cost/Loss: 0.074193 | Weight: 0.569899 | Bias: 0.112760\n",
            "Iteration: 184835 | Cost/Loss: 0.074193 | Weight: 0.569899 | Bias: 0.112761\n",
            "Iteration: 184836 | Cost/Loss: 0.074193 | Weight: 0.569900 | Bias: 0.112761\n",
            "Iteration: 184837 | Cost/Loss: 0.074193 | Weight: 0.569900 | Bias: 0.112761\n",
            "Iteration: 184838 | Cost/Loss: 0.074193 | Weight: 0.569900 | Bias: 0.112762\n",
            "Iteration: 184839 | Cost/Loss: 0.074193 | Weight: 0.569901 | Bias: 0.112762\n",
            "Iteration: 184840 | Cost/Loss: 0.074192 | Weight: 0.569901 | Bias: 0.112762\n",
            "Iteration: 184841 | Cost/Loss: 0.074192 | Weight: 0.569901 | Bias: 0.112763\n",
            "Iteration: 184842 | Cost/Loss: 0.074192 | Weight: 0.569902 | Bias: 0.112763\n",
            "Iteration: 184843 | Cost/Loss: 0.074192 | Weight: 0.569902 | Bias: 0.112763\n",
            "Iteration: 184844 | Cost/Loss: 0.074192 | Weight: 0.569902 | Bias: 0.112763\n",
            "Iteration: 184845 | Cost/Loss: 0.074192 | Weight: 0.569902 | Bias: 0.112764\n",
            "Iteration: 184846 | Cost/Loss: 0.074192 | Weight: 0.569903 | Bias: 0.112764\n",
            "Iteration: 184847 | Cost/Loss: 0.074192 | Weight: 0.569903 | Bias: 0.112764\n",
            "Iteration: 184848 | Cost/Loss: 0.074192 | Weight: 0.569903 | Bias: 0.112765\n",
            "Iteration: 184849 | Cost/Loss: 0.074192 | Weight: 0.569904 | Bias: 0.112765\n",
            "Iteration: 184850 | Cost/Loss: 0.074192 | Weight: 0.569904 | Bias: 0.112765\n",
            "Iteration: 184851 | Cost/Loss: 0.074192 | Weight: 0.569904 | Bias: 0.112766\n",
            "Iteration: 184852 | Cost/Loss: 0.074192 | Weight: 0.569905 | Bias: 0.112766\n",
            "Iteration: 184853 | Cost/Loss: 0.074192 | Weight: 0.569905 | Bias: 0.112766\n",
            "Iteration: 184854 | Cost/Loss: 0.074192 | Weight: 0.569905 | Bias: 0.112767\n",
            "Iteration: 184855 | Cost/Loss: 0.074192 | Weight: 0.569905 | Bias: 0.112767\n",
            "Iteration: 184856 | Cost/Loss: 0.074192 | Weight: 0.569906 | Bias: 0.112767\n",
            "Iteration: 184857 | Cost/Loss: 0.074192 | Weight: 0.569906 | Bias: 0.112767\n",
            "Iteration: 184858 | Cost/Loss: 0.074192 | Weight: 0.569906 | Bias: 0.112768\n",
            "Iteration: 184859 | Cost/Loss: 0.074192 | Weight: 0.569907 | Bias: 0.112768\n",
            "Iteration: 184860 | Cost/Loss: 0.074192 | Weight: 0.569907 | Bias: 0.112768\n",
            "Iteration: 184861 | Cost/Loss: 0.074192 | Weight: 0.569907 | Bias: 0.112769\n",
            "Iteration: 184862 | Cost/Loss: 0.074192 | Weight: 0.569908 | Bias: 0.112769\n",
            "Iteration: 184863 | Cost/Loss: 0.074192 | Weight: 0.569908 | Bias: 0.112769\n",
            "Iteration: 184864 | Cost/Loss: 0.074192 | Weight: 0.569908 | Bias: 0.112770\n",
            "Iteration: 184865 | Cost/Loss: 0.074192 | Weight: 0.569908 | Bias: 0.112770\n",
            "Iteration: 184866 | Cost/Loss: 0.074192 | Weight: 0.569909 | Bias: 0.112770\n",
            "Iteration: 184867 | Cost/Loss: 0.074192 | Weight: 0.569909 | Bias: 0.112770\n",
            "Iteration: 184868 | Cost/Loss: 0.074192 | Weight: 0.569909 | Bias: 0.112771\n",
            "Iteration: 184869 | Cost/Loss: 0.074192 | Weight: 0.569910 | Bias: 0.112771\n",
            "Iteration: 184870 | Cost/Loss: 0.074192 | Weight: 0.569910 | Bias: 0.112771\n",
            "Iteration: 184871 | Cost/Loss: 0.074192 | Weight: 0.569910 | Bias: 0.112772\n",
            "Iteration: 184872 | Cost/Loss: 0.074192 | Weight: 0.569911 | Bias: 0.112772\n",
            "Iteration: 184873 | Cost/Loss: 0.074192 | Weight: 0.569911 | Bias: 0.112772\n",
            "Iteration: 184874 | Cost/Loss: 0.074192 | Weight: 0.569911 | Bias: 0.112773\n",
            "Iteration: 184875 | Cost/Loss: 0.074192 | Weight: 0.569911 | Bias: 0.112773\n",
            "Iteration: 184876 | Cost/Loss: 0.074192 | Weight: 0.569912 | Bias: 0.112773\n",
            "Iteration: 184877 | Cost/Loss: 0.074192 | Weight: 0.569912 | Bias: 0.112774\n",
            "Iteration: 184878 | Cost/Loss: 0.074192 | Weight: 0.569912 | Bias: 0.112774\n",
            "Iteration: 184879 | Cost/Loss: 0.074192 | Weight: 0.569913 | Bias: 0.112774\n",
            "Iteration: 184880 | Cost/Loss: 0.074192 | Weight: 0.569913 | Bias: 0.112774\n",
            "Iteration: 184881 | Cost/Loss: 0.074191 | Weight: 0.569913 | Bias: 0.112775\n",
            "Iteration: 184882 | Cost/Loss: 0.074191 | Weight: 0.569914 | Bias: 0.112775\n",
            "Iteration: 184883 | Cost/Loss: 0.074191 | Weight: 0.569914 | Bias: 0.112775\n",
            "Iteration: 184884 | Cost/Loss: 0.074191 | Weight: 0.569914 | Bias: 0.112776\n",
            "Iteration: 184885 | Cost/Loss: 0.074191 | Weight: 0.569914 | Bias: 0.112776\n",
            "Iteration: 184886 | Cost/Loss: 0.074191 | Weight: 0.569915 | Bias: 0.112776\n",
            "Iteration: 184887 | Cost/Loss: 0.074191 | Weight: 0.569915 | Bias: 0.112777\n",
            "Iteration: 184888 | Cost/Loss: 0.074191 | Weight: 0.569915 | Bias: 0.112777\n",
            "Iteration: 184889 | Cost/Loss: 0.074191 | Weight: 0.569916 | Bias: 0.112777\n",
            "Iteration: 184890 | Cost/Loss: 0.074191 | Weight: 0.569916 | Bias: 0.112778\n",
            "Iteration: 184891 | Cost/Loss: 0.074191 | Weight: 0.569916 | Bias: 0.112778\n",
            "Iteration: 184892 | Cost/Loss: 0.074191 | Weight: 0.569916 | Bias: 0.112778\n",
            "Iteration: 184893 | Cost/Loss: 0.074191 | Weight: 0.569917 | Bias: 0.112778\n",
            "Iteration: 184894 | Cost/Loss: 0.074191 | Weight: 0.569917 | Bias: 0.112779\n",
            "Iteration: 184895 | Cost/Loss: 0.074191 | Weight: 0.569917 | Bias: 0.112779\n",
            "Iteration: 184896 | Cost/Loss: 0.074191 | Weight: 0.569918 | Bias: 0.112779\n",
            "Iteration: 184897 | Cost/Loss: 0.074191 | Weight: 0.569918 | Bias: 0.112780\n",
            "Iteration: 184898 | Cost/Loss: 0.074191 | Weight: 0.569918 | Bias: 0.112780\n",
            "Iteration: 184899 | Cost/Loss: 0.074191 | Weight: 0.569919 | Bias: 0.112780\n",
            "Iteration: 184900 | Cost/Loss: 0.074191 | Weight: 0.569919 | Bias: 0.112781\n",
            "Iteration: 184901 | Cost/Loss: 0.074191 | Weight: 0.569919 | Bias: 0.112781\n",
            "Iteration: 184902 | Cost/Loss: 0.074191 | Weight: 0.569919 | Bias: 0.112781\n",
            "Iteration: 184903 | Cost/Loss: 0.074191 | Weight: 0.569920 | Bias: 0.112781\n",
            "Iteration: 184904 | Cost/Loss: 0.074191 | Weight: 0.569920 | Bias: 0.112782\n",
            "Iteration: 184905 | Cost/Loss: 0.074191 | Weight: 0.569920 | Bias: 0.112782\n",
            "Iteration: 184906 | Cost/Loss: 0.074191 | Weight: 0.569921 | Bias: 0.112782\n",
            "Iteration: 184907 | Cost/Loss: 0.074191 | Weight: 0.569921 | Bias: 0.112783\n",
            "Iteration: 184908 | Cost/Loss: 0.074191 | Weight: 0.569921 | Bias: 0.112783\n",
            "Iteration: 184909 | Cost/Loss: 0.074191 | Weight: 0.569922 | Bias: 0.112783\n",
            "Iteration: 184910 | Cost/Loss: 0.074191 | Weight: 0.569922 | Bias: 0.112784\n",
            "Iteration: 184911 | Cost/Loss: 0.074191 | Weight: 0.569922 | Bias: 0.112784\n",
            "Iteration: 184912 | Cost/Loss: 0.074191 | Weight: 0.569922 | Bias: 0.112784\n",
            "Iteration: 184913 | Cost/Loss: 0.074191 | Weight: 0.569923 | Bias: 0.112785\n",
            "Iteration: 184914 | Cost/Loss: 0.074191 | Weight: 0.569923 | Bias: 0.112785\n",
            "Iteration: 184915 | Cost/Loss: 0.074191 | Weight: 0.569923 | Bias: 0.112785\n",
            "Iteration: 184916 | Cost/Loss: 0.074191 | Weight: 0.569924 | Bias: 0.112785\n",
            "Iteration: 184917 | Cost/Loss: 0.074191 | Weight: 0.569924 | Bias: 0.112786\n",
            "Iteration: 184918 | Cost/Loss: 0.074191 | Weight: 0.569924 | Bias: 0.112786\n",
            "Iteration: 184919 | Cost/Loss: 0.074191 | Weight: 0.569925 | Bias: 0.112786\n",
            "Iteration: 184920 | Cost/Loss: 0.074191 | Weight: 0.569925 | Bias: 0.112787\n",
            "Iteration: 184921 | Cost/Loss: 0.074190 | Weight: 0.569925 | Bias: 0.112787\n",
            "Iteration: 184922 | Cost/Loss: 0.074190 | Weight: 0.569925 | Bias: 0.112787\n",
            "Iteration: 184923 | Cost/Loss: 0.074190 | Weight: 0.569926 | Bias: 0.112788\n",
            "Iteration: 184924 | Cost/Loss: 0.074190 | Weight: 0.569926 | Bias: 0.112788\n",
            "Iteration: 184925 | Cost/Loss: 0.074190 | Weight: 0.569926 | Bias: 0.112788\n",
            "Iteration: 184926 | Cost/Loss: 0.074190 | Weight: 0.569927 | Bias: 0.112789\n",
            "Iteration: 184927 | Cost/Loss: 0.074190 | Weight: 0.569927 | Bias: 0.112789\n",
            "Iteration: 184928 | Cost/Loss: 0.074190 | Weight: 0.569927 | Bias: 0.112789\n",
            "Iteration: 184929 | Cost/Loss: 0.074190 | Weight: 0.569928 | Bias: 0.112789\n",
            "Iteration: 184930 | Cost/Loss: 0.074190 | Weight: 0.569928 | Bias: 0.112790\n",
            "Iteration: 184931 | Cost/Loss: 0.074190 | Weight: 0.569928 | Bias: 0.112790\n",
            "Iteration: 184932 | Cost/Loss: 0.074190 | Weight: 0.569928 | Bias: 0.112790\n",
            "Iteration: 184933 | Cost/Loss: 0.074190 | Weight: 0.569929 | Bias: 0.112791\n",
            "Iteration: 184934 | Cost/Loss: 0.074190 | Weight: 0.569929 | Bias: 0.112791\n",
            "Iteration: 184935 | Cost/Loss: 0.074190 | Weight: 0.569929 | Bias: 0.112791\n",
            "Iteration: 184936 | Cost/Loss: 0.074190 | Weight: 0.569930 | Bias: 0.112792\n",
            "Iteration: 184937 | Cost/Loss: 0.074190 | Weight: 0.569930 | Bias: 0.112792\n",
            "Iteration: 184938 | Cost/Loss: 0.074190 | Weight: 0.569930 | Bias: 0.112792\n",
            "Iteration: 184939 | Cost/Loss: 0.074190 | Weight: 0.569930 | Bias: 0.112792\n",
            "Iteration: 184940 | Cost/Loss: 0.074190 | Weight: 0.569931 | Bias: 0.112793\n",
            "Iteration: 184941 | Cost/Loss: 0.074190 | Weight: 0.569931 | Bias: 0.112793\n",
            "Iteration: 184942 | Cost/Loss: 0.074190 | Weight: 0.569931 | Bias: 0.112793\n",
            "Iteration: 184943 | Cost/Loss: 0.074190 | Weight: 0.569932 | Bias: 0.112794\n",
            "Iteration: 184944 | Cost/Loss: 0.074190 | Weight: 0.569932 | Bias: 0.112794\n",
            "Iteration: 184945 | Cost/Loss: 0.074190 | Weight: 0.569932 | Bias: 0.112794\n",
            "Iteration: 184946 | Cost/Loss: 0.074190 | Weight: 0.569933 | Bias: 0.112795\n",
            "Iteration: 184947 | Cost/Loss: 0.074190 | Weight: 0.569933 | Bias: 0.112795\n",
            "Iteration: 184948 | Cost/Loss: 0.074190 | Weight: 0.569933 | Bias: 0.112795\n",
            "Iteration: 184949 | Cost/Loss: 0.074190 | Weight: 0.569933 | Bias: 0.112796\n",
            "Iteration: 184950 | Cost/Loss: 0.074190 | Weight: 0.569934 | Bias: 0.112796\n",
            "Iteration: 184951 | Cost/Loss: 0.074190 | Weight: 0.569934 | Bias: 0.112796\n",
            "Iteration: 184952 | Cost/Loss: 0.074190 | Weight: 0.569934 | Bias: 0.112796\n",
            "Iteration: 184953 | Cost/Loss: 0.074190 | Weight: 0.569935 | Bias: 0.112797\n",
            "Iteration: 184954 | Cost/Loss: 0.074190 | Weight: 0.569935 | Bias: 0.112797\n",
            "Iteration: 184955 | Cost/Loss: 0.074190 | Weight: 0.569935 | Bias: 0.112797\n",
            "Iteration: 184956 | Cost/Loss: 0.074190 | Weight: 0.569936 | Bias: 0.112798\n",
            "Iteration: 184957 | Cost/Loss: 0.074190 | Weight: 0.569936 | Bias: 0.112798\n",
            "Iteration: 184958 | Cost/Loss: 0.074190 | Weight: 0.569936 | Bias: 0.112798\n",
            "Iteration: 184959 | Cost/Loss: 0.074190 | Weight: 0.569936 | Bias: 0.112799\n",
            "Iteration: 184960 | Cost/Loss: 0.074190 | Weight: 0.569937 | Bias: 0.112799\n",
            "Iteration: 184961 | Cost/Loss: 0.074190 | Weight: 0.569937 | Bias: 0.112799\n",
            "Iteration: 184962 | Cost/Loss: 0.074189 | Weight: 0.569937 | Bias: 0.112800\n",
            "Iteration: 184963 | Cost/Loss: 0.074189 | Weight: 0.569938 | Bias: 0.112800\n",
            "Iteration: 184964 | Cost/Loss: 0.074189 | Weight: 0.569938 | Bias: 0.112800\n",
            "Iteration: 184965 | Cost/Loss: 0.074189 | Weight: 0.569938 | Bias: 0.112800\n",
            "Iteration: 184966 | Cost/Loss: 0.074189 | Weight: 0.569939 | Bias: 0.112801\n",
            "Iteration: 184967 | Cost/Loss: 0.074189 | Weight: 0.569939 | Bias: 0.112801\n",
            "Iteration: 184968 | Cost/Loss: 0.074189 | Weight: 0.569939 | Bias: 0.112801\n",
            "Iteration: 184969 | Cost/Loss: 0.074189 | Weight: 0.569939 | Bias: 0.112802\n",
            "Iteration: 184970 | Cost/Loss: 0.074189 | Weight: 0.569940 | Bias: 0.112802\n",
            "Iteration: 184971 | Cost/Loss: 0.074189 | Weight: 0.569940 | Bias: 0.112802\n",
            "Iteration: 184972 | Cost/Loss: 0.074189 | Weight: 0.569940 | Bias: 0.112803\n",
            "Iteration: 184973 | Cost/Loss: 0.074189 | Weight: 0.569941 | Bias: 0.112803\n",
            "Iteration: 184974 | Cost/Loss: 0.074189 | Weight: 0.569941 | Bias: 0.112803\n",
            "Iteration: 184975 | Cost/Loss: 0.074189 | Weight: 0.569941 | Bias: 0.112803\n",
            "Iteration: 184976 | Cost/Loss: 0.074189 | Weight: 0.569942 | Bias: 0.112804\n",
            "Iteration: 184977 | Cost/Loss: 0.074189 | Weight: 0.569942 | Bias: 0.112804\n",
            "Iteration: 184978 | Cost/Loss: 0.074189 | Weight: 0.569942 | Bias: 0.112804\n",
            "Iteration: 184979 | Cost/Loss: 0.074189 | Weight: 0.569942 | Bias: 0.112805\n",
            "Iteration: 184980 | Cost/Loss: 0.074189 | Weight: 0.569943 | Bias: 0.112805\n",
            "Iteration: 184981 | Cost/Loss: 0.074189 | Weight: 0.569943 | Bias: 0.112805\n",
            "Iteration: 184982 | Cost/Loss: 0.074189 | Weight: 0.569943 | Bias: 0.112806\n",
            "Iteration: 184983 | Cost/Loss: 0.074189 | Weight: 0.569944 | Bias: 0.112806\n",
            "Iteration: 184984 | Cost/Loss: 0.074189 | Weight: 0.569944 | Bias: 0.112806\n",
            "Iteration: 184985 | Cost/Loss: 0.074189 | Weight: 0.569944 | Bias: 0.112807\n",
            "Iteration: 184986 | Cost/Loss: 0.074189 | Weight: 0.569945 | Bias: 0.112807\n",
            "Iteration: 184987 | Cost/Loss: 0.074189 | Weight: 0.569945 | Bias: 0.112807\n",
            "Iteration: 184988 | Cost/Loss: 0.074189 | Weight: 0.569945 | Bias: 0.112807\n",
            "Iteration: 184989 | Cost/Loss: 0.074189 | Weight: 0.569945 | Bias: 0.112808\n",
            "Iteration: 184990 | Cost/Loss: 0.074189 | Weight: 0.569946 | Bias: 0.112808\n",
            "Iteration: 184991 | Cost/Loss: 0.074189 | Weight: 0.569946 | Bias: 0.112808\n",
            "Iteration: 184992 | Cost/Loss: 0.074189 | Weight: 0.569946 | Bias: 0.112809\n",
            "Iteration: 184993 | Cost/Loss: 0.074189 | Weight: 0.569947 | Bias: 0.112809\n",
            "Iteration: 184994 | Cost/Loss: 0.074189 | Weight: 0.569947 | Bias: 0.112809\n",
            "Iteration: 184995 | Cost/Loss: 0.074189 | Weight: 0.569947 | Bias: 0.112810\n",
            "Iteration: 184996 | Cost/Loss: 0.074189 | Weight: 0.569947 | Bias: 0.112810\n",
            "Iteration: 184997 | Cost/Loss: 0.074189 | Weight: 0.569948 | Bias: 0.112810\n",
            "Iteration: 184998 | Cost/Loss: 0.074189 | Weight: 0.569948 | Bias: 0.112811\n",
            "Iteration: 184999 | Cost/Loss: 0.074189 | Weight: 0.569948 | Bias: 0.112811\n",
            "Iteration: 185000 | Cost/Loss: 0.074189 | Weight: 0.569949 | Bias: 0.112811\n",
            "Iteration: 185001 | Cost/Loss: 0.074189 | Weight: 0.569949 | Bias: 0.112811\n",
            "Iteration: 185002 | Cost/Loss: 0.074188 | Weight: 0.569949 | Bias: 0.112812\n",
            "Iteration: 185003 | Cost/Loss: 0.074188 | Weight: 0.569950 | Bias: 0.112812\n",
            "Iteration: 185004 | Cost/Loss: 0.074188 | Weight: 0.569950 | Bias: 0.112812\n",
            "Iteration: 185005 | Cost/Loss: 0.074188 | Weight: 0.569950 | Bias: 0.112813\n",
            "Iteration: 185006 | Cost/Loss: 0.074188 | Weight: 0.569950 | Bias: 0.112813\n",
            "Iteration: 185007 | Cost/Loss: 0.074188 | Weight: 0.569951 | Bias: 0.112813\n",
            "Iteration: 185008 | Cost/Loss: 0.074188 | Weight: 0.569951 | Bias: 0.112814\n",
            "Iteration: 185009 | Cost/Loss: 0.074188 | Weight: 0.569951 | Bias: 0.112814\n",
            "Iteration: 185010 | Cost/Loss: 0.074188 | Weight: 0.569952 | Bias: 0.112814\n",
            "Iteration: 185011 | Cost/Loss: 0.074188 | Weight: 0.569952 | Bias: 0.112814\n",
            "Iteration: 185012 | Cost/Loss: 0.074188 | Weight: 0.569952 | Bias: 0.112815\n",
            "Iteration: 185013 | Cost/Loss: 0.074188 | Weight: 0.569953 | Bias: 0.112815\n",
            "Iteration: 185014 | Cost/Loss: 0.074188 | Weight: 0.569953 | Bias: 0.112815\n",
            "Iteration: 185015 | Cost/Loss: 0.074188 | Weight: 0.569953 | Bias: 0.112816\n",
            "Iteration: 185016 | Cost/Loss: 0.074188 | Weight: 0.569953 | Bias: 0.112816\n",
            "Iteration: 185017 | Cost/Loss: 0.074188 | Weight: 0.569954 | Bias: 0.112816\n",
            "Iteration: 185018 | Cost/Loss: 0.074188 | Weight: 0.569954 | Bias: 0.112817\n",
            "Iteration: 185019 | Cost/Loss: 0.074188 | Weight: 0.569954 | Bias: 0.112817\n",
            "Iteration: 185020 | Cost/Loss: 0.074188 | Weight: 0.569955 | Bias: 0.112817\n",
            "Iteration: 185021 | Cost/Loss: 0.074188 | Weight: 0.569955 | Bias: 0.112818\n",
            "Iteration: 185022 | Cost/Loss: 0.074188 | Weight: 0.569955 | Bias: 0.112818\n",
            "Iteration: 185023 | Cost/Loss: 0.074188 | Weight: 0.569956 | Bias: 0.112818\n",
            "Iteration: 185024 | Cost/Loss: 0.074188 | Weight: 0.569956 | Bias: 0.112818\n",
            "Iteration: 185025 | Cost/Loss: 0.074188 | Weight: 0.569956 | Bias: 0.112819\n",
            "Iteration: 185026 | Cost/Loss: 0.074188 | Weight: 0.569956 | Bias: 0.112819\n",
            "Iteration: 185027 | Cost/Loss: 0.074188 | Weight: 0.569957 | Bias: 0.112819\n",
            "Iteration: 185028 | Cost/Loss: 0.074188 | Weight: 0.569957 | Bias: 0.112820\n",
            "Iteration: 185029 | Cost/Loss: 0.074188 | Weight: 0.569957 | Bias: 0.112820\n",
            "Iteration: 185030 | Cost/Loss: 0.074188 | Weight: 0.569958 | Bias: 0.112820\n",
            "Iteration: 185031 | Cost/Loss: 0.074188 | Weight: 0.569958 | Bias: 0.112821\n",
            "Iteration: 185032 | Cost/Loss: 0.074188 | Weight: 0.569958 | Bias: 0.112821\n",
            "Iteration: 185033 | Cost/Loss: 0.074188 | Weight: 0.569959 | Bias: 0.112821\n",
            "Iteration: 185034 | Cost/Loss: 0.074188 | Weight: 0.569959 | Bias: 0.112822\n",
            "Iteration: 185035 | Cost/Loss: 0.074188 | Weight: 0.569959 | Bias: 0.112822\n",
            "Iteration: 185036 | Cost/Loss: 0.074188 | Weight: 0.569959 | Bias: 0.112822\n",
            "Iteration: 185037 | Cost/Loss: 0.074188 | Weight: 0.569960 | Bias: 0.112822\n",
            "Iteration: 185038 | Cost/Loss: 0.074188 | Weight: 0.569960 | Bias: 0.112823\n",
            "Iteration: 185039 | Cost/Loss: 0.074188 | Weight: 0.569960 | Bias: 0.112823\n",
            "Iteration: 185040 | Cost/Loss: 0.074188 | Weight: 0.569961 | Bias: 0.112823\n",
            "Iteration: 185041 | Cost/Loss: 0.074188 | Weight: 0.569961 | Bias: 0.112824\n",
            "Iteration: 185042 | Cost/Loss: 0.074188 | Weight: 0.569961 | Bias: 0.112824\n",
            "Iteration: 185043 | Cost/Loss: 0.074187 | Weight: 0.569961 | Bias: 0.112824\n",
            "Iteration: 185044 | Cost/Loss: 0.074187 | Weight: 0.569962 | Bias: 0.112825\n",
            "Iteration: 185045 | Cost/Loss: 0.074187 | Weight: 0.569962 | Bias: 0.112825\n",
            "Iteration: 185046 | Cost/Loss: 0.074187 | Weight: 0.569962 | Bias: 0.112825\n",
            "Iteration: 185047 | Cost/Loss: 0.074187 | Weight: 0.569963 | Bias: 0.112825\n",
            "Iteration: 185048 | Cost/Loss: 0.074187 | Weight: 0.569963 | Bias: 0.112826\n",
            "Iteration: 185049 | Cost/Loss: 0.074187 | Weight: 0.569963 | Bias: 0.112826\n",
            "Iteration: 185050 | Cost/Loss: 0.074187 | Weight: 0.569964 | Bias: 0.112826\n",
            "Iteration: 185051 | Cost/Loss: 0.074187 | Weight: 0.569964 | Bias: 0.112827\n",
            "Iteration: 185052 | Cost/Loss: 0.074187 | Weight: 0.569964 | Bias: 0.112827\n",
            "Iteration: 185053 | Cost/Loss: 0.074187 | Weight: 0.569964 | Bias: 0.112827\n",
            "Iteration: 185054 | Cost/Loss: 0.074187 | Weight: 0.569965 | Bias: 0.112828\n",
            "Iteration: 185055 | Cost/Loss: 0.074187 | Weight: 0.569965 | Bias: 0.112828\n",
            "Iteration: 185056 | Cost/Loss: 0.074187 | Weight: 0.569965 | Bias: 0.112828\n",
            "Iteration: 185057 | Cost/Loss: 0.074187 | Weight: 0.569966 | Bias: 0.112829\n",
            "Iteration: 185058 | Cost/Loss: 0.074187 | Weight: 0.569966 | Bias: 0.112829\n",
            "Iteration: 185059 | Cost/Loss: 0.074187 | Weight: 0.569966 | Bias: 0.112829\n",
            "Iteration: 185060 | Cost/Loss: 0.074187 | Weight: 0.569967 | Bias: 0.112829\n",
            "Iteration: 185061 | Cost/Loss: 0.074187 | Weight: 0.569967 | Bias: 0.112830\n",
            "Iteration: 185062 | Cost/Loss: 0.074187 | Weight: 0.569967 | Bias: 0.112830\n",
            "Iteration: 185063 | Cost/Loss: 0.074187 | Weight: 0.569967 | Bias: 0.112830\n",
            "Iteration: 185064 | Cost/Loss: 0.074187 | Weight: 0.569968 | Bias: 0.112831\n",
            "Iteration: 185065 | Cost/Loss: 0.074187 | Weight: 0.569968 | Bias: 0.112831\n",
            "Iteration: 185066 | Cost/Loss: 0.074187 | Weight: 0.569968 | Bias: 0.112831\n",
            "Iteration: 185067 | Cost/Loss: 0.074187 | Weight: 0.569969 | Bias: 0.112832\n",
            "Iteration: 185068 | Cost/Loss: 0.074187 | Weight: 0.569969 | Bias: 0.112832\n",
            "Iteration: 185069 | Cost/Loss: 0.074187 | Weight: 0.569969 | Bias: 0.112832\n",
            "Iteration: 185070 | Cost/Loss: 0.074187 | Weight: 0.569970 | Bias: 0.112833\n",
            "Iteration: 185071 | Cost/Loss: 0.074187 | Weight: 0.569970 | Bias: 0.112833\n",
            "Iteration: 185072 | Cost/Loss: 0.074187 | Weight: 0.569970 | Bias: 0.112833\n",
            "Iteration: 185073 | Cost/Loss: 0.074187 | Weight: 0.569970 | Bias: 0.112833\n",
            "Iteration: 185074 | Cost/Loss: 0.074187 | Weight: 0.569971 | Bias: 0.112834\n",
            "Iteration: 185075 | Cost/Loss: 0.074187 | Weight: 0.569971 | Bias: 0.112834\n",
            "Iteration: 185076 | Cost/Loss: 0.074187 | Weight: 0.569971 | Bias: 0.112834\n",
            "Iteration: 185077 | Cost/Loss: 0.074187 | Weight: 0.569972 | Bias: 0.112835\n",
            "Iteration: 185078 | Cost/Loss: 0.074187 | Weight: 0.569972 | Bias: 0.112835\n",
            "Iteration: 185079 | Cost/Loss: 0.074187 | Weight: 0.569972 | Bias: 0.112835\n",
            "Iteration: 185080 | Cost/Loss: 0.074187 | Weight: 0.569973 | Bias: 0.112836\n",
            "Iteration: 185081 | Cost/Loss: 0.074187 | Weight: 0.569973 | Bias: 0.112836\n",
            "Iteration: 185082 | Cost/Loss: 0.074187 | Weight: 0.569973 | Bias: 0.112836\n",
            "Iteration: 185083 | Cost/Loss: 0.074186 | Weight: 0.569973 | Bias: 0.112836\n",
            "Iteration: 185084 | Cost/Loss: 0.074186 | Weight: 0.569974 | Bias: 0.112837\n",
            "Iteration: 185085 | Cost/Loss: 0.074186 | Weight: 0.569974 | Bias: 0.112837\n",
            "Iteration: 185086 | Cost/Loss: 0.074186 | Weight: 0.569974 | Bias: 0.112837\n",
            "Iteration: 185087 | Cost/Loss: 0.074186 | Weight: 0.569975 | Bias: 0.112838\n",
            "Iteration: 185088 | Cost/Loss: 0.074186 | Weight: 0.569975 | Bias: 0.112838\n",
            "Iteration: 185089 | Cost/Loss: 0.074186 | Weight: 0.569975 | Bias: 0.112838\n",
            "Iteration: 185090 | Cost/Loss: 0.074186 | Weight: 0.569975 | Bias: 0.112839\n",
            "Iteration: 185091 | Cost/Loss: 0.074186 | Weight: 0.569976 | Bias: 0.112839\n",
            "Iteration: 185092 | Cost/Loss: 0.074186 | Weight: 0.569976 | Bias: 0.112839\n",
            "Iteration: 185093 | Cost/Loss: 0.074186 | Weight: 0.569976 | Bias: 0.112840\n",
            "Iteration: 185094 | Cost/Loss: 0.074186 | Weight: 0.569977 | Bias: 0.112840\n",
            "Iteration: 185095 | Cost/Loss: 0.074186 | Weight: 0.569977 | Bias: 0.112840\n",
            "Iteration: 185096 | Cost/Loss: 0.074186 | Weight: 0.569977 | Bias: 0.112840\n",
            "Iteration: 185097 | Cost/Loss: 0.074186 | Weight: 0.569978 | Bias: 0.112841\n",
            "Iteration: 185098 | Cost/Loss: 0.074186 | Weight: 0.569978 | Bias: 0.112841\n",
            "Iteration: 185099 | Cost/Loss: 0.074186 | Weight: 0.569978 | Bias: 0.112841\n",
            "Iteration: 185100 | Cost/Loss: 0.074186 | Weight: 0.569978 | Bias: 0.112842\n",
            "Iteration: 185101 | Cost/Loss: 0.074186 | Weight: 0.569979 | Bias: 0.112842\n",
            "Iteration: 185102 | Cost/Loss: 0.074186 | Weight: 0.569979 | Bias: 0.112842\n",
            "Iteration: 185103 | Cost/Loss: 0.074186 | Weight: 0.569979 | Bias: 0.112843\n",
            "Iteration: 185104 | Cost/Loss: 0.074186 | Weight: 0.569980 | Bias: 0.112843\n",
            "Iteration: 185105 | Cost/Loss: 0.074186 | Weight: 0.569980 | Bias: 0.112843\n",
            "Iteration: 185106 | Cost/Loss: 0.074186 | Weight: 0.569980 | Bias: 0.112843\n",
            "Iteration: 185107 | Cost/Loss: 0.074186 | Weight: 0.569981 | Bias: 0.112844\n",
            "Iteration: 185108 | Cost/Loss: 0.074186 | Weight: 0.569981 | Bias: 0.112844\n",
            "Iteration: 185109 | Cost/Loss: 0.074186 | Weight: 0.569981 | Bias: 0.112844\n",
            "Iteration: 185110 | Cost/Loss: 0.074186 | Weight: 0.569981 | Bias: 0.112845\n",
            "Iteration: 185111 | Cost/Loss: 0.074186 | Weight: 0.569982 | Bias: 0.112845\n",
            "Iteration: 185112 | Cost/Loss: 0.074186 | Weight: 0.569982 | Bias: 0.112845\n",
            "Iteration: 185113 | Cost/Loss: 0.074186 | Weight: 0.569982 | Bias: 0.112846\n",
            "Iteration: 185114 | Cost/Loss: 0.074186 | Weight: 0.569983 | Bias: 0.112846\n",
            "Iteration: 185115 | Cost/Loss: 0.074186 | Weight: 0.569983 | Bias: 0.112846\n",
            "Iteration: 185116 | Cost/Loss: 0.074186 | Weight: 0.569983 | Bias: 0.112847\n",
            "Iteration: 185117 | Cost/Loss: 0.074186 | Weight: 0.569984 | Bias: 0.112847\n",
            "Iteration: 185118 | Cost/Loss: 0.074186 | Weight: 0.569984 | Bias: 0.112847\n",
            "Iteration: 185119 | Cost/Loss: 0.074186 | Weight: 0.569984 | Bias: 0.112847\n",
            "Iteration: 185120 | Cost/Loss: 0.074186 | Weight: 0.569984 | Bias: 0.112848\n",
            "Iteration: 185121 | Cost/Loss: 0.074186 | Weight: 0.569985 | Bias: 0.112848\n",
            "Iteration: 185122 | Cost/Loss: 0.074186 | Weight: 0.569985 | Bias: 0.112848\n",
            "Iteration: 185123 | Cost/Loss: 0.074186 | Weight: 0.569985 | Bias: 0.112849\n",
            "Iteration: 185124 | Cost/Loss: 0.074185 | Weight: 0.569986 | Bias: 0.112849\n",
            "Iteration: 185125 | Cost/Loss: 0.074185 | Weight: 0.569986 | Bias: 0.112849\n",
            "Iteration: 185126 | Cost/Loss: 0.074185 | Weight: 0.569986 | Bias: 0.112850\n",
            "Iteration: 185127 | Cost/Loss: 0.074185 | Weight: 0.569987 | Bias: 0.112850\n",
            "Iteration: 185128 | Cost/Loss: 0.074185 | Weight: 0.569987 | Bias: 0.112850\n",
            "Iteration: 185129 | Cost/Loss: 0.074185 | Weight: 0.569987 | Bias: 0.112851\n",
            "Iteration: 185130 | Cost/Loss: 0.074185 | Weight: 0.569987 | Bias: 0.112851\n",
            "Iteration: 185131 | Cost/Loss: 0.074185 | Weight: 0.569988 | Bias: 0.112851\n",
            "Iteration: 185132 | Cost/Loss: 0.074185 | Weight: 0.569988 | Bias: 0.112851\n",
            "Iteration: 185133 | Cost/Loss: 0.074185 | Weight: 0.569988 | Bias: 0.112852\n",
            "Iteration: 185134 | Cost/Loss: 0.074185 | Weight: 0.569989 | Bias: 0.112852\n",
            "Iteration: 185135 | Cost/Loss: 0.074185 | Weight: 0.569989 | Bias: 0.112852\n",
            "Iteration: 185136 | Cost/Loss: 0.074185 | Weight: 0.569989 | Bias: 0.112853\n",
            "Iteration: 185137 | Cost/Loss: 0.074185 | Weight: 0.569990 | Bias: 0.112853\n",
            "Iteration: 185138 | Cost/Loss: 0.074185 | Weight: 0.569990 | Bias: 0.112853\n",
            "Iteration: 185139 | Cost/Loss: 0.074185 | Weight: 0.569990 | Bias: 0.112854\n",
            "Iteration: 185140 | Cost/Loss: 0.074185 | Weight: 0.569990 | Bias: 0.112854\n",
            "Iteration: 185141 | Cost/Loss: 0.074185 | Weight: 0.569991 | Bias: 0.112854\n",
            "Iteration: 185142 | Cost/Loss: 0.074185 | Weight: 0.569991 | Bias: 0.112854\n",
            "Iteration: 185143 | Cost/Loss: 0.074185 | Weight: 0.569991 | Bias: 0.112855\n",
            "Iteration: 185144 | Cost/Loss: 0.074185 | Weight: 0.569992 | Bias: 0.112855\n",
            "Iteration: 185145 | Cost/Loss: 0.074185 | Weight: 0.569992 | Bias: 0.112855\n",
            "Iteration: 185146 | Cost/Loss: 0.074185 | Weight: 0.569992 | Bias: 0.112856\n",
            "Iteration: 185147 | Cost/Loss: 0.074185 | Weight: 0.569992 | Bias: 0.112856\n",
            "Iteration: 185148 | Cost/Loss: 0.074185 | Weight: 0.569993 | Bias: 0.112856\n",
            "Iteration: 185149 | Cost/Loss: 0.074185 | Weight: 0.569993 | Bias: 0.112857\n",
            "Iteration: 185150 | Cost/Loss: 0.074185 | Weight: 0.569993 | Bias: 0.112857\n",
            "Iteration: 185151 | Cost/Loss: 0.074185 | Weight: 0.569994 | Bias: 0.112857\n",
            "Iteration: 185152 | Cost/Loss: 0.074185 | Weight: 0.569994 | Bias: 0.112858\n",
            "Iteration: 185153 | Cost/Loss: 0.074185 | Weight: 0.569994 | Bias: 0.112858\n",
            "Iteration: 185154 | Cost/Loss: 0.074185 | Weight: 0.569995 | Bias: 0.112858\n",
            "Iteration: 185155 | Cost/Loss: 0.074185 | Weight: 0.569995 | Bias: 0.112858\n",
            "Iteration: 185156 | Cost/Loss: 0.074185 | Weight: 0.569995 | Bias: 0.112859\n",
            "Iteration: 185157 | Cost/Loss: 0.074185 | Weight: 0.569995 | Bias: 0.112859\n",
            "Iteration: 185158 | Cost/Loss: 0.074185 | Weight: 0.569996 | Bias: 0.112859\n",
            "Iteration: 185159 | Cost/Loss: 0.074185 | Weight: 0.569996 | Bias: 0.112860\n",
            "Iteration: 185160 | Cost/Loss: 0.074185 | Weight: 0.569996 | Bias: 0.112860\n",
            "Iteration: 185161 | Cost/Loss: 0.074185 | Weight: 0.569997 | Bias: 0.112860\n",
            "Iteration: 185162 | Cost/Loss: 0.074185 | Weight: 0.569997 | Bias: 0.112861\n",
            "Iteration: 185163 | Cost/Loss: 0.074185 | Weight: 0.569997 | Bias: 0.112861\n",
            "Iteration: 185164 | Cost/Loss: 0.074185 | Weight: 0.569998 | Bias: 0.112861\n",
            "Iteration: 185165 | Cost/Loss: 0.074184 | Weight: 0.569998 | Bias: 0.112862\n",
            "Iteration: 185166 | Cost/Loss: 0.074184 | Weight: 0.569998 | Bias: 0.112862\n",
            "Iteration: 185167 | Cost/Loss: 0.074184 | Weight: 0.569998 | Bias: 0.112862\n",
            "Iteration: 185168 | Cost/Loss: 0.074184 | Weight: 0.569999 | Bias: 0.112862\n",
            "Iteration: 185169 | Cost/Loss: 0.074184 | Weight: 0.569999 | Bias: 0.112863\n",
            "Iteration: 185170 | Cost/Loss: 0.074184 | Weight: 0.569999 | Bias: 0.112863\n",
            "Iteration: 185171 | Cost/Loss: 0.074184 | Weight: 0.570000 | Bias: 0.112863\n",
            "Iteration: 185172 | Cost/Loss: 0.074184 | Weight: 0.570000 | Bias: 0.112864\n",
            "Iteration: 185173 | Cost/Loss: 0.074184 | Weight: 0.570000 | Bias: 0.112864\n",
            "Iteration: 185174 | Cost/Loss: 0.074184 | Weight: 0.570001 | Bias: 0.112864\n",
            "Iteration: 185175 | Cost/Loss: 0.074184 | Weight: 0.570001 | Bias: 0.112865\n",
            "Iteration: 185176 | Cost/Loss: 0.074184 | Weight: 0.570001 | Bias: 0.112865\n",
            "Iteration: 185177 | Cost/Loss: 0.074184 | Weight: 0.570001 | Bias: 0.112865\n",
            "Iteration: 185178 | Cost/Loss: 0.074184 | Weight: 0.570002 | Bias: 0.112865\n",
            "Iteration: 185179 | Cost/Loss: 0.074184 | Weight: 0.570002 | Bias: 0.112866\n",
            "Iteration: 185180 | Cost/Loss: 0.074184 | Weight: 0.570002 | Bias: 0.112866\n",
            "Iteration: 185181 | Cost/Loss: 0.074184 | Weight: 0.570003 | Bias: 0.112866\n",
            "Iteration: 185182 | Cost/Loss: 0.074184 | Weight: 0.570003 | Bias: 0.112867\n",
            "Iteration: 185183 | Cost/Loss: 0.074184 | Weight: 0.570003 | Bias: 0.112867\n",
            "Iteration: 185184 | Cost/Loss: 0.074184 | Weight: 0.570004 | Bias: 0.112867\n",
            "Iteration: 185185 | Cost/Loss: 0.074184 | Weight: 0.570004 | Bias: 0.112868\n",
            "Iteration: 185186 | Cost/Loss: 0.074184 | Weight: 0.570004 | Bias: 0.112868\n",
            "Iteration: 185187 | Cost/Loss: 0.074184 | Weight: 0.570004 | Bias: 0.112868\n",
            "Iteration: 185188 | Cost/Loss: 0.074184 | Weight: 0.570005 | Bias: 0.112869\n",
            "Iteration: 185189 | Cost/Loss: 0.074184 | Weight: 0.570005 | Bias: 0.112869\n",
            "Iteration: 185190 | Cost/Loss: 0.074184 | Weight: 0.570005 | Bias: 0.112869\n",
            "Iteration: 185191 | Cost/Loss: 0.074184 | Weight: 0.570006 | Bias: 0.112869\n",
            "Iteration: 185192 | Cost/Loss: 0.074184 | Weight: 0.570006 | Bias: 0.112870\n",
            "Iteration: 185193 | Cost/Loss: 0.074184 | Weight: 0.570006 | Bias: 0.112870\n",
            "Iteration: 185194 | Cost/Loss: 0.074184 | Weight: 0.570006 | Bias: 0.112870\n",
            "Iteration: 185195 | Cost/Loss: 0.074184 | Weight: 0.570007 | Bias: 0.112871\n",
            "Iteration: 185196 | Cost/Loss: 0.074184 | Weight: 0.570007 | Bias: 0.112871\n",
            "Iteration: 185197 | Cost/Loss: 0.074184 | Weight: 0.570007 | Bias: 0.112871\n",
            "Iteration: 185198 | Cost/Loss: 0.074184 | Weight: 0.570008 | Bias: 0.112872\n",
            "Iteration: 185199 | Cost/Loss: 0.074184 | Weight: 0.570008 | Bias: 0.112872\n",
            "Iteration: 185200 | Cost/Loss: 0.074184 | Weight: 0.570008 | Bias: 0.112872\n",
            "Iteration: 185201 | Cost/Loss: 0.074184 | Weight: 0.570009 | Bias: 0.112873\n",
            "Iteration: 185202 | Cost/Loss: 0.074184 | Weight: 0.570009 | Bias: 0.112873\n",
            "Iteration: 185203 | Cost/Loss: 0.074184 | Weight: 0.570009 | Bias: 0.112873\n",
            "Iteration: 185204 | Cost/Loss: 0.074184 | Weight: 0.570009 | Bias: 0.112873\n",
            "Iteration: 185205 | Cost/Loss: 0.074183 | Weight: 0.570010 | Bias: 0.112874\n",
            "Iteration: 185206 | Cost/Loss: 0.074183 | Weight: 0.570010 | Bias: 0.112874\n",
            "Iteration: 185207 | Cost/Loss: 0.074183 | Weight: 0.570010 | Bias: 0.112874\n",
            "Iteration: 185208 | Cost/Loss: 0.074183 | Weight: 0.570011 | Bias: 0.112875\n",
            "Iteration: 185209 | Cost/Loss: 0.074183 | Weight: 0.570011 | Bias: 0.112875\n",
            "Iteration: 185210 | Cost/Loss: 0.074183 | Weight: 0.570011 | Bias: 0.112875\n",
            "Iteration: 185211 | Cost/Loss: 0.074183 | Weight: 0.570012 | Bias: 0.112876\n",
            "Iteration: 185212 | Cost/Loss: 0.074183 | Weight: 0.570012 | Bias: 0.112876\n",
            "Iteration: 185213 | Cost/Loss: 0.074183 | Weight: 0.570012 | Bias: 0.112876\n",
            "Iteration: 185214 | Cost/Loss: 0.074183 | Weight: 0.570012 | Bias: 0.112876\n",
            "Iteration: 185215 | Cost/Loss: 0.074183 | Weight: 0.570013 | Bias: 0.112877\n",
            "Iteration: 185216 | Cost/Loss: 0.074183 | Weight: 0.570013 | Bias: 0.112877\n",
            "Iteration: 185217 | Cost/Loss: 0.074183 | Weight: 0.570013 | Bias: 0.112877\n",
            "Iteration: 185218 | Cost/Loss: 0.074183 | Weight: 0.570014 | Bias: 0.112878\n",
            "Iteration: 185219 | Cost/Loss: 0.074183 | Weight: 0.570014 | Bias: 0.112878\n",
            "Iteration: 185220 | Cost/Loss: 0.074183 | Weight: 0.570014 | Bias: 0.112878\n",
            "Iteration: 185221 | Cost/Loss: 0.074183 | Weight: 0.570015 | Bias: 0.112879\n",
            "Iteration: 185222 | Cost/Loss: 0.074183 | Weight: 0.570015 | Bias: 0.112879\n",
            "Iteration: 185223 | Cost/Loss: 0.074183 | Weight: 0.570015 | Bias: 0.112879\n",
            "Iteration: 185224 | Cost/Loss: 0.074183 | Weight: 0.570015 | Bias: 0.112880\n",
            "Iteration: 185225 | Cost/Loss: 0.074183 | Weight: 0.570016 | Bias: 0.112880\n",
            "Iteration: 185226 | Cost/Loss: 0.074183 | Weight: 0.570016 | Bias: 0.112880\n",
            "Iteration: 185227 | Cost/Loss: 0.074183 | Weight: 0.570016 | Bias: 0.112880\n",
            "Iteration: 185228 | Cost/Loss: 0.074183 | Weight: 0.570017 | Bias: 0.112881\n",
            "Iteration: 185229 | Cost/Loss: 0.074183 | Weight: 0.570017 | Bias: 0.112881\n",
            "Iteration: 185230 | Cost/Loss: 0.074183 | Weight: 0.570017 | Bias: 0.112881\n",
            "Iteration: 185231 | Cost/Loss: 0.074183 | Weight: 0.570018 | Bias: 0.112882\n",
            "Iteration: 185232 | Cost/Loss: 0.074183 | Weight: 0.570018 | Bias: 0.112882\n",
            "Iteration: 185233 | Cost/Loss: 0.074183 | Weight: 0.570018 | Bias: 0.112882\n",
            "Iteration: 185234 | Cost/Loss: 0.074183 | Weight: 0.570018 | Bias: 0.112883\n",
            "Iteration: 185235 | Cost/Loss: 0.074183 | Weight: 0.570019 | Bias: 0.112883\n",
            "Iteration: 185236 | Cost/Loss: 0.074183 | Weight: 0.570019 | Bias: 0.112883\n",
            "Iteration: 185237 | Cost/Loss: 0.074183 | Weight: 0.570019 | Bias: 0.112884\n",
            "Iteration: 185238 | Cost/Loss: 0.074183 | Weight: 0.570020 | Bias: 0.112884\n",
            "Iteration: 185239 | Cost/Loss: 0.074183 | Weight: 0.570020 | Bias: 0.112884\n",
            "Iteration: 185240 | Cost/Loss: 0.074183 | Weight: 0.570020 | Bias: 0.112884\n",
            "Iteration: 185241 | Cost/Loss: 0.074183 | Weight: 0.570020 | Bias: 0.112885\n",
            "Iteration: 185242 | Cost/Loss: 0.074183 | Weight: 0.570021 | Bias: 0.112885\n",
            "Iteration: 185243 | Cost/Loss: 0.074183 | Weight: 0.570021 | Bias: 0.112885\n",
            "Iteration: 185244 | Cost/Loss: 0.074183 | Weight: 0.570021 | Bias: 0.112886\n",
            "Iteration: 185245 | Cost/Loss: 0.074183 | Weight: 0.570022 | Bias: 0.112886\n",
            "Iteration: 185246 | Cost/Loss: 0.074182 | Weight: 0.570022 | Bias: 0.112886\n",
            "Iteration: 185247 | Cost/Loss: 0.074182 | Weight: 0.570022 | Bias: 0.112887\n",
            "Iteration: 185248 | Cost/Loss: 0.074182 | Weight: 0.570023 | Bias: 0.112887\n",
            "Iteration: 185249 | Cost/Loss: 0.074182 | Weight: 0.570023 | Bias: 0.112887\n",
            "Iteration: 185250 | Cost/Loss: 0.074182 | Weight: 0.570023 | Bias: 0.112887\n",
            "Iteration: 185251 | Cost/Loss: 0.074182 | Weight: 0.570023 | Bias: 0.112888\n",
            "Iteration: 185252 | Cost/Loss: 0.074182 | Weight: 0.570024 | Bias: 0.112888\n",
            "Iteration: 185253 | Cost/Loss: 0.074182 | Weight: 0.570024 | Bias: 0.112888\n",
            "Iteration: 185254 | Cost/Loss: 0.074182 | Weight: 0.570024 | Bias: 0.112889\n",
            "Iteration: 185255 | Cost/Loss: 0.074182 | Weight: 0.570025 | Bias: 0.112889\n",
            "Iteration: 185256 | Cost/Loss: 0.074182 | Weight: 0.570025 | Bias: 0.112889\n",
            "Iteration: 185257 | Cost/Loss: 0.074182 | Weight: 0.570025 | Bias: 0.112890\n",
            "Iteration: 185258 | Cost/Loss: 0.074182 | Weight: 0.570026 | Bias: 0.112890\n",
            "Iteration: 185259 | Cost/Loss: 0.074182 | Weight: 0.570026 | Bias: 0.112890\n",
            "Iteration: 185260 | Cost/Loss: 0.074182 | Weight: 0.570026 | Bias: 0.112891\n",
            "Iteration: 185261 | Cost/Loss: 0.074182 | Weight: 0.570026 | Bias: 0.112891\n",
            "Iteration: 185262 | Cost/Loss: 0.074182 | Weight: 0.570027 | Bias: 0.112891\n",
            "Iteration: 185263 | Cost/Loss: 0.074182 | Weight: 0.570027 | Bias: 0.112891\n",
            "Iteration: 185264 | Cost/Loss: 0.074182 | Weight: 0.570027 | Bias: 0.112892\n",
            "Iteration: 185265 | Cost/Loss: 0.074182 | Weight: 0.570028 | Bias: 0.112892\n",
            "Iteration: 185266 | Cost/Loss: 0.074182 | Weight: 0.570028 | Bias: 0.112892\n",
            "Iteration: 185267 | Cost/Loss: 0.074182 | Weight: 0.570028 | Bias: 0.112893\n",
            "Iteration: 185268 | Cost/Loss: 0.074182 | Weight: 0.570029 | Bias: 0.112893\n",
            "Iteration: 185269 | Cost/Loss: 0.074182 | Weight: 0.570029 | Bias: 0.112893\n",
            "Iteration: 185270 | Cost/Loss: 0.074182 | Weight: 0.570029 | Bias: 0.112894\n",
            "Iteration: 185271 | Cost/Loss: 0.074182 | Weight: 0.570029 | Bias: 0.112894\n",
            "Iteration: 185272 | Cost/Loss: 0.074182 | Weight: 0.570030 | Bias: 0.112894\n",
            "Iteration: 185273 | Cost/Loss: 0.074182 | Weight: 0.570030 | Bias: 0.112895\n",
            "Iteration: 185274 | Cost/Loss: 0.074182 | Weight: 0.570030 | Bias: 0.112895\n",
            "Iteration: 185275 | Cost/Loss: 0.074182 | Weight: 0.570031 | Bias: 0.112895\n",
            "Iteration: 185276 | Cost/Loss: 0.074182 | Weight: 0.570031 | Bias: 0.112895\n",
            "Iteration: 185277 | Cost/Loss: 0.074182 | Weight: 0.570031 | Bias: 0.112896\n",
            "Iteration: 185278 | Cost/Loss: 0.074182 | Weight: 0.570032 | Bias: 0.112896\n",
            "Iteration: 185279 | Cost/Loss: 0.074182 | Weight: 0.570032 | Bias: 0.112896\n",
            "Iteration: 185280 | Cost/Loss: 0.074182 | Weight: 0.570032 | Bias: 0.112897\n",
            "Iteration: 185281 | Cost/Loss: 0.074182 | Weight: 0.570032 | Bias: 0.112897\n",
            "Iteration: 185282 | Cost/Loss: 0.074182 | Weight: 0.570033 | Bias: 0.112897\n",
            "Iteration: 185283 | Cost/Loss: 0.074182 | Weight: 0.570033 | Bias: 0.112898\n",
            "Iteration: 185284 | Cost/Loss: 0.074182 | Weight: 0.570033 | Bias: 0.112898\n",
            "Iteration: 185285 | Cost/Loss: 0.074182 | Weight: 0.570034 | Bias: 0.112898\n",
            "Iteration: 185286 | Cost/Loss: 0.074181 | Weight: 0.570034 | Bias: 0.112898\n",
            "Iteration: 185287 | Cost/Loss: 0.074181 | Weight: 0.570034 | Bias: 0.112899\n",
            "Iteration: 185288 | Cost/Loss: 0.074181 | Weight: 0.570035 | Bias: 0.112899\n",
            "Iteration: 185289 | Cost/Loss: 0.074181 | Weight: 0.570035 | Bias: 0.112899\n",
            "Iteration: 185290 | Cost/Loss: 0.074181 | Weight: 0.570035 | Bias: 0.112900\n",
            "Iteration: 185291 | Cost/Loss: 0.074181 | Weight: 0.570035 | Bias: 0.112900\n",
            "Iteration: 185292 | Cost/Loss: 0.074181 | Weight: 0.570036 | Bias: 0.112900\n",
            "Iteration: 185293 | Cost/Loss: 0.074181 | Weight: 0.570036 | Bias: 0.112901\n",
            "Iteration: 185294 | Cost/Loss: 0.074181 | Weight: 0.570036 | Bias: 0.112901\n",
            "Iteration: 185295 | Cost/Loss: 0.074181 | Weight: 0.570037 | Bias: 0.112901\n",
            "Iteration: 185296 | Cost/Loss: 0.074181 | Weight: 0.570037 | Bias: 0.112902\n",
            "Iteration: 185297 | Cost/Loss: 0.074181 | Weight: 0.570037 | Bias: 0.112902\n",
            "Iteration: 185298 | Cost/Loss: 0.074181 | Weight: 0.570037 | Bias: 0.112902\n",
            "Iteration: 185299 | Cost/Loss: 0.074181 | Weight: 0.570038 | Bias: 0.112902\n",
            "Iteration: 185300 | Cost/Loss: 0.074181 | Weight: 0.570038 | Bias: 0.112903\n",
            "Iteration: 185301 | Cost/Loss: 0.074181 | Weight: 0.570038 | Bias: 0.112903\n",
            "Iteration: 185302 | Cost/Loss: 0.074181 | Weight: 0.570039 | Bias: 0.112903\n",
            "Iteration: 185303 | Cost/Loss: 0.074181 | Weight: 0.570039 | Bias: 0.112904\n",
            "Iteration: 185304 | Cost/Loss: 0.074181 | Weight: 0.570039 | Bias: 0.112904\n",
            "Iteration: 185305 | Cost/Loss: 0.074181 | Weight: 0.570040 | Bias: 0.112904\n",
            "Iteration: 185306 | Cost/Loss: 0.074181 | Weight: 0.570040 | Bias: 0.112905\n",
            "Iteration: 185307 | Cost/Loss: 0.074181 | Weight: 0.570040 | Bias: 0.112905\n",
            "Iteration: 185308 | Cost/Loss: 0.074181 | Weight: 0.570040 | Bias: 0.112905\n",
            "Iteration: 185309 | Cost/Loss: 0.074181 | Weight: 0.570041 | Bias: 0.112906\n",
            "Iteration: 185310 | Cost/Loss: 0.074181 | Weight: 0.570041 | Bias: 0.112906\n",
            "Iteration: 185311 | Cost/Loss: 0.074181 | Weight: 0.570041 | Bias: 0.112906\n",
            "Iteration: 185312 | Cost/Loss: 0.074181 | Weight: 0.570042 | Bias: 0.112906\n",
            "Iteration: 185313 | Cost/Loss: 0.074181 | Weight: 0.570042 | Bias: 0.112907\n",
            "Iteration: 185314 | Cost/Loss: 0.074181 | Weight: 0.570042 | Bias: 0.112907\n",
            "Iteration: 185315 | Cost/Loss: 0.074181 | Weight: 0.570043 | Bias: 0.112907\n",
            "Iteration: 185316 | Cost/Loss: 0.074181 | Weight: 0.570043 | Bias: 0.112908\n",
            "Iteration: 185317 | Cost/Loss: 0.074181 | Weight: 0.570043 | Bias: 0.112908\n",
            "Iteration: 185318 | Cost/Loss: 0.074181 | Weight: 0.570043 | Bias: 0.112908\n",
            "Iteration: 185319 | Cost/Loss: 0.074181 | Weight: 0.570044 | Bias: 0.112909\n",
            "Iteration: 185320 | Cost/Loss: 0.074181 | Weight: 0.570044 | Bias: 0.112909\n",
            "Iteration: 185321 | Cost/Loss: 0.074181 | Weight: 0.570044 | Bias: 0.112909\n",
            "Iteration: 185322 | Cost/Loss: 0.074181 | Weight: 0.570045 | Bias: 0.112909\n",
            "Iteration: 185323 | Cost/Loss: 0.074181 | Weight: 0.570045 | Bias: 0.112910"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "\n",
        "__global__ void linear_regression(float *inputs, float *targets, int size, float *weights, float *bias, float learning_rate, int epochs) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float cost;\n",
        "    for (int epoch = 0; epoch < epochs; ++epoch) {\n",
        "        float predicted = inputs[idx] * weights[0] + bias[0];\n",
        "        float loss = predicted - targets[idx];\n",
        "        float d_weights = inputs[idx] * loss / (2 * size);\n",
        "        float d_bias = loss / (2 * size);\n",
        "        weights[0] -= learning_rate * d_weights;\n",
        "        bias[0] -= learning_rate * d_bias;\n",
        "        cost = sqrtf(powf(loss, 2) / (2 * size));\n",
        "        if (idx == 0) {\n",
        "            printf(\"Iteration: %d | Cost/Loss: %f | Weight: %f | Bias: %f\\n\", epoch + 1, cost, weights[0], bias[0]);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    int m = 300; // Number of training data points\n",
        "    int n = 50; // Number of testing data points\n",
        "    float learning_rate = 0.0001;\n",
        "    int epochs = 200000;\n",
        "    float a = 0.5; // y = ax + b\n",
        "    float b = 2.0;\n",
        "    int size = m;\n",
        "    int dataSize = size * sizeof(float);\n",
        "    float *h_inputs, *h_targets, *h_weights, *h_bias;\n",
        "    float *d_inputs, *d_targets, *d_weights, *d_bias;\n",
        "\n",
        "    // Allocate host memory\n",
        "    h_inputs = (float*)malloc(dataSize);\n",
        "    h_targets = (float*)malloc(dataSize);\n",
        "    h_weights = (float*)malloc(sizeof(float));\n",
        "    h_bias = (float*)malloc(sizeof(float));\n",
        "\n",
        "    // Generate data\n",
        "    for (int i = 0; i < m; ++i) {\n",
        "        h_inputs[i] = i + 1;\n",
        "        h_targets[i] = (i + 1) * a + b;\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaMalloc((void**)&d_inputs, dataSize);\n",
        "    cudaMalloc((void**)&d_targets, dataSize);\n",
        "    cudaMalloc((void**)&d_weights, sizeof(float));\n",
        "    cudaMalloc((void**)&d_bias, sizeof(float));\n",
        "\n",
        "    // Copy data to device memory\n",
        "    cudaMemcpy(d_inputs, h_inputs, dataSize, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_targets, h_targets, dataSize, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Initialize weights and bias\n",
        "    h_weights[0] = 0;\n",
        "    h_bias[0] = 0;\n",
        "\n",
        "    // Copy initial weights and bias to device memory\n",
        "    cudaMemcpy(d_weights, h_weights, sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_bias, h_bias, sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch kernel\n",
        "    linear_regression<<<1, m>>>(d_inputs, d_targets, size, d_weights, d_bias, learning_rate, epochs);\n",
        "\n",
        "    // Copy back weights and bias\n",
        "    cudaMemcpy(h_weights, d_weights, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(h_bias, d_bias, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Final Weights: %f\\n\", h_weights[0]);\n",
        "    printf(\"Final Bias: %f\\n\", h_bias[0]);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_inputs);\n",
        "    cudaFree(d_targets);\n",
        "    cudaFree(d_weights);\n",
        "    cudaFree(d_bias);\n",
        "\n",
        "    // Free host memory\n",
        "    free(h_inputs);\n",
        "    free(h_targets);\n",
        "    free(h_weights);\n",
        "    free(h_bias);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "pHPP4_oK8Sqn",
        "outputId": "3ab96912-3b93-4e23-c70b-4ea7c617740d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-5-a504d8acd278>, line 5)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-a504d8acd278>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    __global__ void linear_regression(float *inputs, float *targets, int size, float *weights, float *bias, float learning_rate, int epochs) {\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4"
      ],
      "metadata": {
        "id": "4TUi2GvA35r7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <chrono>\n",
        "\n",
        "#define N 512\n",
        "#define Niter 1000\n",
        "\n",
        "void addCPU(int *a, int *b, int *c) {\n",
        "    for (int i = 0; i < N*N ; i++) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void addKernel1D (int *a, int *b, int *c) {\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    while (tid < N*N) {\n",
        "        c[tid] = a[tid] + b[tid];\n",
        "        tid += blockDim.x * gridDim.x;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void addKernel2D (int *a, int *b, int *c) {\n",
        "    int tidx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int tidy = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int id = tidx + tidy * N;\n",
        "    while (tidx < N && tidy < N) {\n",
        "        c[id] = a[id] + b[id];\n",
        "        tidx += blockDim.x * gridDim.x;\n",
        "        tidy += blockDim.y * gridDim.y;\n",
        "        id = tidx + tidy * N;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    int A[N*N], B[N*N], C[N*N], D[N*N];\n",
        "    int *d_A, *d_B, *d_C;\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaMalloc(&d_A, N*N*sizeof(int));\n",
        "    cudaMalloc(&d_B, N*N*sizeof(int));\n",
        "    cudaMalloc(&d_C, N*N*sizeof(int));\n",
        "\n",
        "    for (int i = 0 ; i < N*N ; i++) {\n",
        "            A[i] = i;\n",
        "            B[i] = i+1;\n",
        "    }\n",
        "    cudaMemcpy(d_A, A, N*N*sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, N*N*sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    auto t_start = std::chrono::high_resolution_clock::now();\n",
        "    for (int i = 0; i <  Niter ; i++) // We do Niter to have an averaged execution time\n",
        "      addCPU(A, B, C);\n",
        "    auto t_end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    cudaDeviceProp properties;\n",
        "    cudaGetDeviceProperties(&properties, 0);\n",
        "    int nThreads = properties.maxThreadsPerBlock; // Get maximum number of threads per block\n",
        "    int nBlocks = (N*N + nThreads - 1) / nThreads; // Get right number of blocks to cover our problem\n",
        "\n",
        "    dim3 gridDim(8,nBlocks/8+1);\n",
        "    dim3 blockDim(2,nThreads/2);\n",
        "\n",
        "    addKernel1D<<<nBlocks,nThreads>>>(d_A, d_B, d_C); // WARM-UP\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    for (int i = 0; i <  Niter ; i++) // We do Niter to have an averaged execution time\n",
        "      addKernel1D<<<nBlocks,nThreads>>>(d_A, d_B, d_C);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    float ms;\n",
        "    cudaEventElapsedTime(&ms, start, stop);\n",
        "\n",
        "    cudaMemcpy(D, d_C, N*N*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(B, d_B, N*N*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    int diff = 0;\n",
        "    for (int i = 0 ; i < N ; i++) {\n",
        "        if(D[i] != C[i]) diff = D[i] - C[i];\n",
        "    }\n",
        "    if(diff != 0) {\n",
        "        printf(\"Wrong computation : diff = %d\", diff);\n",
        "        return 0;\n",
        "    }\n",
        "    printf(\"CPU execution time = %f ms\\n\", std::chrono::duration<double, std::milli>(t_end-t_start).count()/Niter);\n",
        "    printf(\"GPU execution time 1D = %f ms\\n\", ms/Niter);\n",
        "    addKernel2D<<<gridDim,blockDim>>>(d_A, d_B, d_C); // WARM-UP\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    for (int i = 0; i <  Niter ; i++) // We do Niter to have an averaged execution time\n",
        "      addKernel2D<<<gridDim,blockDim>>>(d_A, d_B, d_C);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&ms, start, stop);\n",
        "\n",
        "    cudaMemcpy(D, d_C, N*N*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(B, d_B, N*N*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    diff = 0;\n",
        "    for (int i = 0 ; i < N ; i++) {\n",
        "        if(D[i] != C[i]) diff = D[i] - C[i];\n",
        "    }\n",
        "    if(diff != 0) {\n",
        "        printf(\"Wrong computation : diff = %d\", diff);\n",
        "        return 0;\n",
        "    }\n",
        "    printf(\"GPU execution time 2D = %f ms\\n\", ms/Niter);\n",
        "\n",
        "  cudaFree(d_A);\n",
        "  cudaFree(d_B);\n",
        "  cudaFree(d_C);\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "QYT9qRDa37rS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e0d48e-8755-498e-bb15-3066b3b4fd3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU execution time = 0.754999 ms\n",
            "GPU execution time 1D = 0.011890 ms\n",
            "GPU execution time 2D = 0.007938 ms\n",
            "\n"
          ]
        }
      ]
    }
  ]
}